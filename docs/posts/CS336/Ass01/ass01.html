<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Assignment 01 è¦æ±‚æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ¶µç›–æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å®šä¹‰ã€è®­ç»ƒå’Œè¯„ä¼°ç­‰æ­¥éª¤ã€‚é€šè¿‡è¿™ä¸ªä½œä¸šï¼Œæˆ‘ä»¬å°†å·©å›ºå¯¹è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€æ¦‚å¿µçš„ç†è§£ï¼Œå¹¶æŒæ¡ä½¿ç”¨PyTorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å‘çš„åŸºæœ¬æŠ€èƒ½">

<title>Assignment 01: Tokenization &amp; Language Modeling â€“ Learning Note</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../posts/CS336/Ass02/ass02.html" rel="next">
<link href="../../../posts/CS336/Lecture16&amp;17/lec16.html" rel="prev">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-d955a6f9d49e1ec5ed65a13bb8102cd7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-54ea7a8788961299870a163422834ed2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-d955a6f9d49e1ec5ed65a13bb8102cd7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
<script>
    MathJax = {
        loader: {
        load: ['[tex]/boldsymbol']
        },
        tex: {
        tags: "all",
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true,
        packages: {
            '[+]': ['boldsymbol']
        }
        }
    };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script>
document.addEventListener("DOMContentLoaded", function () {
  document.querySelectorAll(".foldable-header").forEach(header => {
    header.addEventListener("click", () => {
      const block = header.closest(".foldable");
      if (block) {
        block.classList.toggle("is-open");
      }
    });

    // å¯è®¿é—®æ€§ï¼ˆé”®ç›˜ï¼‰
    header.setAttribute("tabindex", "0");
    header.addEventListener("keydown", e => {
      if (e.key === "Enter" || e.key === " ") {
        e.preventDefault();
        header.click();
      }
    });
  });
});
</script>
    <style type="text/css">
    .ps-root .ps-algorithm {
      border-top: 2px solid;
      border-bottom: 2px solid;
    }
    .pseudocode-container {
      text-align: left;
    }
    </style>
  
      <style type="text/css">
      .ps-algorithm > .ps-line {
        text-align: left;
      }
      </style>
    

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../posts/CS336/index.html">ğŸ“ Stanford CS336: LLM from Scratch</a></li><li class="breadcrumb-item"><a href="../../../posts/CS336/Ass01/ass01.html">Assignment 01: BPE Tokenizer &amp; Transformer LM</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../.././style/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/YYZhang2025" title="GitHub organization" class="quarto-navigation-tool px-1" aria-label="GitHub organization"><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/zhang-yuyang/" title="LinkedIn" class="quarto-navigation-tool px-1" aria-label="LinkedIn"><i class="bi bi-linkedin"></i></a>
    <a href="https://yyzhang2025.github.io/posts/Blogs/blogs_index.html" title="Personal Blogs" class="quarto-navigation-tool px-1" aria-label="Personal Blogs"><i class="bi bi-globe"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">ğŸ“ 100 AI Papers with Code</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/100_Papers_index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this series</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/01-transformer/Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision Transformer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">ğŸ“ Stanford CS336: LLM from Scratch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this course</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture01/lec01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 01: Introduction &amp; BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture02/lec02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 02: PyTorch Basics &amp; Resource Accounts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture03/lec03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 03: Transformer LM Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture04/lec04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 04: MoE Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture05&amp;06/lec05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 05&amp;06: GPU Optimization, Triton &amp; FlashAttention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture07&amp;08/lec07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 07&amp;08: Parallelism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture9&amp;11/lec9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 09&amp;11: Scaling Laws</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture10/lec10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 10: Inference &amp; Deployment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture12/lec12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 12: Evaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture13&amp;14/lec13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 13&amp;14: Data Collection &amp; Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture15/lec15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture16&amp;17/lec16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass01/ass01.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Assignment 01: BPE Tokenizer &amp; Transformer LM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass02/ass02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 02: Flash Attention &amp; Parallelism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass05/ass05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 05: SFT &amp; GRPO</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">ğŸ“– Deep Learning Foundation &amp; Concepts</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/DLFaC/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this book</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preliminaries" id="toc-preliminaries" class="nav-link active" data-scroll-target="#preliminaries"><span class="header-section-number">1</span> Preliminaries</a>
  <ul>
  <li><a href="#download-start-code-and-dataset" id="toc-download-start-code-and-dataset" class="nav-link" data-scroll-target="#download-start-code-and-dataset"><span class="header-section-number">1.1</span> Download Start Code and Dataset</a></li>
  </ul></li>
  <li><a href="#part-01-byte-pair-encoding-bpe-implementation" id="toc-part-01-byte-pair-encoding-bpe-implementation" class="nav-link" data-scroll-target="#part-01-byte-pair-encoding-bpe-implementation"><span class="header-section-number">2</span> Part 01: Byte Pair Encoding (BPE) Implementation</a>
  <ul>
  <li><a href="#sec-bpe-recap" id="toc-sec-bpe-recap" class="nav-link" data-scroll-target="#sec-bpe-recap"><span class="header-section-number">2.1</span> BPE Algorithm Recap</a></li>
  <li><a href="#sec-bpe-v0" id="toc-sec-bpe-v0" class="nav-link" data-scroll-target="#sec-bpe-v0"><span class="header-section-number">2.2</span> BPE Version 0</a></li>
  <li><a href="#pre-processing" id="toc-pre-processing" class="nav-link" data-scroll-target="#pre-processing"><span class="header-section-number">2.3</span> Pre-Processing</a>
  <ul>
  <li><a href="#special-tokens-based-splitting" id="toc-special-tokens-based-splitting" class="nav-link" data-scroll-target="#special-tokens-based-splitting"><span class="header-section-number">2.3.1</span> Special Tokens Based Splitting</a></li>
  <li><a href="#regex-based-splitting-pre-tokenization" id="toc-regex-based-splitting-pre-tokenization" class="nav-link" data-scroll-target="#regex-based-splitting-pre-tokenization"><span class="header-section-number">2.3.2</span> Regex-based Splitting (Pre-Tokenization)</a></li>
  <li><a href="#multi-processing" id="toc-multi-processing" class="nav-link" data-scroll-target="#multi-processing"><span class="header-section-number">2.3.3</span> Multi-Processing</a></li>
  <li><a href="#others" id="toc-others" class="nav-link" data-scroll-target="#others"><span class="header-section-number">2.3.4</span> Others</a></li>
  </ul></li>
  <li><a href="#bpe-version-1-using-heap" id="toc-bpe-version-1-using-heap" class="nav-link" data-scroll-target="#bpe-version-1-using-heap"><span class="header-section-number">2.4</span> BPE Version 1: Using Heap</a></li>
  <li><a href="#bpe-version-2-using-heap-indexing" id="toc-bpe-version-2-using-heap-indexing" class="nav-link" data-scroll-target="#bpe-version-2-using-heap-indexing"><span class="header-section-number">2.5</span> BPE Version 2: Using Heap + Indexing</a></li>
  <li><a href="#train-bpe" id="toc-train-bpe" class="nav-link" data-scroll-target="#train-bpe"><span class="header-section-number">2.6</span> Train BPE</a></li>
  <li><a href="#bpe-on-tinystory" id="toc-bpe-on-tinystory" class="nav-link" data-scroll-target="#bpe-on-tinystory"><span class="header-section-number">2.7</span> BPE on TinyStory</a></li>
  <li><a href="#bpe-tokenizer" id="toc-bpe-tokenizer" class="nav-link" data-scroll-target="#bpe-tokenizer"><span class="header-section-number">2.8</span> BPE Tokenizer</a>
  <ul>
  <li><a href="#encode-in-bpetokenizer" id="toc-encode-in-bpetokenizer" class="nav-link" data-scroll-target="#encode-in-bpetokenizer"><span class="header-section-number">2.8.1</span> Encode in BPETokenizer</a></li>
  </ul></li>
  <li><a href="#tokenize-and-save-file" id="toc-tokenize-and-save-file" class="nav-link" data-scroll-target="#tokenize-and-save-file"><span class="header-section-number">2.9</span> Tokenize and Save File</a></li>
  <li><a href="#part-01-summary" id="toc-part-01-summary" class="nav-link" data-scroll-target="#part-01-summary"><span class="header-section-number">2.10</span> Part 01 Summary</a></li>
  </ul></li>
  <li><a href="#part-02-language-model-implementation" id="toc-part-02-language-model-implementation" class="nav-link" data-scroll-target="#part-02-language-model-implementation"><span class="header-section-number">3</span> Part 02: Language Model Implementation</a>
  <ul>
  <li><a href="#linear-module" id="toc-linear-module" class="nav-link" data-scroll-target="#linear-module"><span class="header-section-number">3.1</span> Linear Module</a></li>
  <li><a href="#embedding-model" id="toc-embedding-model" class="nav-link" data-scroll-target="#embedding-model"><span class="header-section-number">3.2</span> Embedding Model</a></li>
  <li><a href="#rms-norm" id="toc-rms-norm" class="nav-link" data-scroll-target="#rms-norm"><span class="header-section-number">3.3</span> RMS-Norm</a></li>
  <li><a href="#pointwise-feed-forward-network" id="toc-pointwise-feed-forward-network" class="nav-link" data-scroll-target="#pointwise-feed-forward-network"><span class="header-section-number">3.4</span> PointWise Feed Forward Network</a></li>
  <li><a href="#rope" id="toc-rope" class="nav-link" data-scroll-target="#rope"><span class="header-section-number">3.5</span> RoPE</a>
  <ul>
  <li><a href="#rope-çš„å®ç°ç»†èŠ‚" id="toc-rope-çš„å®ç°ç»†èŠ‚" class="nav-link" data-scroll-target="#rope-çš„å®ç°ç»†èŠ‚"><span class="header-section-number">3.5.1</span> RoPE çš„å®ç°ç»†èŠ‚</a></li>
  </ul></li>
  <li><a href="#multi-headed-attention" id="toc-multi-headed-attention" class="nav-link" data-scroll-target="#multi-headed-attention"><span class="header-section-number">3.6</span> Multi-Headed Attention</a>
  <ul>
  <li><a href="#scaled-dot-product-attention" id="toc-scaled-dot-product-attention" class="nav-link" data-scroll-target="#scaled-dot-product-attention"><span class="header-section-number">3.6.1</span> Scaled Dot-Product Attention</a>
  <ul class="collapse">
  <li><a href="#softmax-function" id="toc-softmax-function" class="nav-link" data-scroll-target="#softmax-function"><span class="header-section-number">3.6.1.1</span> Softmax Function</a></li>
  <li><a href="#scaled-dot-product-attention-1" id="toc-scaled-dot-product-attention-1" class="nav-link" data-scroll-target="#scaled-dot-product-attention-1"><span class="header-section-number">3.6.1.2</span> Scaled Dot Product Attention</a></li>
  <li><a href="#causal-masking" id="toc-causal-masking" class="nav-link" data-scroll-target="#causal-masking"><span class="header-section-number">3.6.1.3</span> Causal Masking</a></li>
  </ul></li>
  <li><a href="#multi-headed-attention-1" id="toc-multi-headed-attention-1" class="nav-link" data-scroll-target="#multi-headed-attention-1"><span class="header-section-number">3.6.2</span> Multi Headed Attention</a></li>
  <li><a href="#shape-transformations-in-attention" id="toc-shape-transformations-in-attention" class="nav-link" data-scroll-target="#shape-transformations-in-attention"><span class="header-section-number">3.6.3</span> Shape Transformations in Attention</a></li>
  <li><a href="#rope-in-attention" id="toc-rope-in-attention" class="nav-link" data-scroll-target="#rope-in-attention"><span class="header-section-number">3.6.4</span> RoPE in Attention</a></li>
  </ul></li>
  <li><a href="#transformer-block" id="toc-transformer-block" class="nav-link" data-scroll-target="#transformer-block"><span class="header-section-number">3.7</span> Transformer Block</a>
  <ul>
  <li><a href="#sec-pre-norm" id="toc-sec-pre-norm" class="nav-link" data-scroll-target="#sec-pre-norm"><span class="header-section-number">3.7.0.1</span> Pre-Norm</a></li>
  </ul></li>
  <li><a href="#output-layer" id="toc-output-layer" class="nav-link" data-scroll-target="#output-layer"><span class="header-section-number">3.8</span> Output Layer</a>
  <ul>
  <li><a href="#weight-tying" id="toc-weight-tying" class="nav-link" data-scroll-target="#weight-tying"><span class="header-section-number">3.8.1</span> Weight Tying</a></li>
  </ul></li>
  <li><a href="#full-transformer-model" id="toc-full-transformer-model" class="nav-link" data-scroll-target="#full-transformer-model"><span class="header-section-number">3.9</span> Full Transformer Model</a></li>
  <li><a href="#part-02-summary" id="toc-part-02-summary" class="nav-link" data-scroll-target="#part-02-summary"><span class="header-section-number">3.10</span> Part 02 Summary</a></li>
  </ul></li>
  <li><a href="#part-03-optimizer-training-code" id="toc-part-03-optimizer-training-code" class="nav-link" data-scroll-target="#part-03-optimizer-training-code"><span class="header-section-number">4</span> Part 03: Optimizer &amp; Training Code</a>
  <ul>
  <li><a href="#loss-perplexity" id="toc-loss-perplexity" class="nav-link" data-scroll-target="#loss-perplexity"><span class="header-section-number">4.1</span> Loss &amp; Perplexity</a>
  <ul>
  <li><a href="#cross-entropy-loss" id="toc-cross-entropy-loss" class="nav-link" data-scroll-target="#cross-entropy-loss"><span class="header-section-number">4.1.1</span> Cross Entropy Loss</a></li>
  <li><a href="#perplexity" id="toc-perplexity" class="nav-link" data-scroll-target="#perplexity"><span class="header-section-number">4.1.2</span> Perplexity</a></li>
  </ul></li>
  <li><a href="#optimizer-learning-rate-scheduler" id="toc-optimizer-learning-rate-scheduler" class="nav-link" data-scroll-target="#optimizer-learning-rate-scheduler"><span class="header-section-number">4.2</span> Optimizer &amp; Learning Rate Scheduler</a>
  <ul>
  <li><a href="#adamw" id="toc-adamw" class="nav-link" data-scroll-target="#adamw"><span class="header-section-number">4.2.1</span> AdamW</a></li>
  <li><a href="#cosine-annealing-learning-rate-scheduler" id="toc-cosine-annealing-learning-rate-scheduler" class="nav-link" data-scroll-target="#cosine-annealing-learning-rate-scheduler"><span class="header-section-number">4.2.2</span> Cosine Annealing Learning Rate Scheduler</a></li>
  <li><a href="#gradient-clipping" id="toc-gradient-clipping" class="nav-link" data-scroll-target="#gradient-clipping"><span class="header-section-number">4.2.3</span> Gradient Clipping</a></li>
  <li><a href="#put-together" id="toc-put-together" class="nav-link" data-scroll-target="#put-together"><span class="header-section-number">4.2.4</span> Put Together</a></li>
  </ul></li>
  <li><a href="#dataloader" id="toc-dataloader" class="nav-link" data-scroll-target="#dataloader"><span class="header-section-number">4.3</span> Dataloader</a></li>
  <li><a href="#checkpoint" id="toc-checkpoint" class="nav-link" data-scroll-target="#checkpoint"><span class="header-section-number">4.4</span> Checkpoint</a></li>
  <li><a href="#training-looping" id="toc-training-looping" class="nav-link" data-scroll-target="#training-looping"><span class="header-section-number">4.5</span> Training Looping</a></li>
  </ul></li>
  <li><a href="#part-04-generation" id="toc-part-04-generation" class="nav-link" data-scroll-target="#part-04-generation"><span class="header-section-number">5</span> Part 04: Generation</a>
  <ul>
  <li><a href="#greedy-sampling" id="toc-greedy-sampling" class="nav-link" data-scroll-target="#greedy-sampling"><span class="header-section-number">5.1</span> Greedy Sampling</a></li>
  <li><a href="#top-k-sampling" id="toc-top-k-sampling" class="nav-link" data-scroll-target="#top-k-sampling"><span class="header-section-number">5.2</span> Top-K Sampling</a></li>
  <li><a href="#top-p-sampling" id="toc-top-p-sampling" class="nav-link" data-scroll-target="#top-p-sampling"><span class="header-section-number">5.3</span> Top-P Sampling</a></li>
  <li><a href="#temperature" id="toc-temperature" class="nav-link" data-scroll-target="#temperature"><span class="header-section-number">5.4</span> Temperature</a></li>
  <li><a href="#part-04-summary" id="toc-part-04-summary" class="nav-link" data-scroll-target="#part-04-summary"><span class="header-section-number">5.5</span> Part 04 Summary</a></li>
  </ul></li>
  <li><a href="#part-05-experiments" id="toc-part-05-experiments" class="nav-link" data-scroll-target="#part-05-experiments"><span class="header-section-number">6</span> Part 05: Experiments</a>
  <ul>
  <li><a href="#plots" id="toc-plots" class="nav-link" data-scroll-target="#plots"><span class="header-section-number">6.1</span> Plots</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">7</span> Summary</a></li>
  <li><a href="#in-the-end" id="toc-in-the-end" class="nav-link" data-scroll-target="#in-the-end"><span class="header-section-number">8</span> In the End</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../posts/CS336/index.html">ğŸ“ Stanford CS336: LLM from Scratch</a></li><li class="breadcrumb-item"><a href="../../../posts/CS336/Ass01/ass01.html">Assignment 01: BPE Tokenizer &amp; Transformer LM</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Assignment 01: Tokenization &amp; Language Modeling</h1>
</div>

<div>
  <div class="description">
    Assignment 01 è¦æ±‚æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ¶µç›–æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å®šä¹‰ã€è®­ç»ƒå’Œè¯„ä¼°ç­‰æ­¥éª¤ã€‚é€šè¿‡è¿™ä¸ªä½œä¸šï¼Œæˆ‘ä»¬å°†å·©å›ºå¯¹è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€æ¦‚å¿µçš„ç†è§£ï¼Œå¹¶æŒæ¡ä½¿ç”¨PyTorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å‘çš„åŸºæœ¬æŠ€èƒ½
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Assignment 01 è¦æ±‚æˆ‘ä»¬ä»0å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ¶µç›–ï¼š</p>
<ul>
<li>Tokenization ç®—æ³•çš„å®ç°</li>
<li>æ¨¡å‹çš„å®šä¹‰</li>
<li>ä¼˜åŒ–å™¨çš„å®šä¹‰</li>
<li>è®­ç»ƒä»£ç </li>
</ul>
<p>é€šè¿‡è¿™ä¸€ä¸ªAssignmentï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£åˆ°åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„LMæ¨¡å‹çš„å…¨éƒ¨æµç¨‹ï¼Œåç»­çš„è¯¾ç¨‹ä»¥åŠAssignmentéƒ½ä¼šåŸºäºè¿™ä¸ªæµç¨‹è¿›è¡Œæ‰©å±•å’Œä¼˜åŒ–ã€‚</p>
<ul>
<li>Original Start Code: <a href="https://github.com/stanford-cs336/assignment1-basics">GitHub</a></li>
<li>My Solution Link: <a href="https://github.com/YYZhang2025/Stanford-CS336">GitHub</a></li>
</ul>
<p>åœ¨å®Œæˆè¿™ä¸ªAssignmentä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å­¦ä¹ Lecture 01,02,03 çš„å†…å®¹ï¼Œä¸»è¦åŒ…æ‹¬ï¼š</p>
<ul>
<li>Byte Pair Encoding (BPE)ç®—æ³•</li>
<li>Transformeræ¨¡å‹</li>
<li>è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•</li>
<li>ä¼˜åŒ–å™¨çš„ä½¿ç”¨</li>
<li>PyTorchçš„åŸºæœ¬ä½¿ç”¨</li>
</ul>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¯¹Transformeræœ‰ä¸€å®šçš„äº†è§£ï¼Œå¦‚æœä½ ä¸äº†è§£Transformerï¼Œæˆ‘ä¸ªäººæ¨èé˜…è¯»è¿™ç¯‡ 100-PaperwithCodeç³»åˆ—çš„ç¬¬ä¸€ç¯‡ï¼š<a href="https://yyzhang2025.github.io/posts/PapersWithCode/01-transformer/Transformer.html">01 Attention is all you Need</a>.</p>
<p>å¯¹äºä¸ç†Ÿæ‚‰LMçš„åŒå­¦ä»¬æ¥è¯´ï¼Œè¿™ä¸ªAssignmentå¯èƒ½æœ‰ä¸€å®šçš„éš¾åº¦ï¼Œæ¯•ç«Ÿå…‰ä»»åŠ¡çš„æè¿°å°±50å¤šé¡µã€‚ä¸è¿‡ï¼Œåªè¦æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œè¿˜æ˜¯å¯ä»¥å®Œæˆè¿™ä¸ªAssignmentçš„ã€‚åŠ æ²¹ï¼Œåˆ«æ”¾å¼ƒğŸ˜ƒğŸ˜ƒï¼ï¼</p>
<p>é¢„è®¡éœ€è¦çš„æ—¶é—´<tag style="color:red">10hours</tag>.</p>
<section id="preliminaries" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Preliminaries</h1>
<section id="download-start-code-and-dataset" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="download-start-code-and-dataset"><span class="header-section-number">1.1</span> Download Start Code and Dataset</h2>
<p>é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½Start Codeï¼š</p>
<div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">git</span> clone https://github.com/stanford-cs336/assignment1-basics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>ä¸‹è½½å®Œä»£ç ä¹‹åï¼Œæˆ‘ä»¬å†ä¸‹è½½æ•°æ®é›†ï¼š</p>
<div class="sourceCode" id="cb2" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> data</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="bu">cd</span> data</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="fu">wget</span> https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="fu">wget</span> https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="fu">wget</span> https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz</span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="fu">gunzip</span> owt_train.txt.gz</span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="fu">wget</span> https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="fu">gunzip</span> owt_valid.txt.gz</span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="bu">cd</span> ..</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>ä¸Šé¢è¿™ä¸ªä»£ç ä¼šä¸‹è½½ä¸¤ä¸ªæ•°æ®é›†ï¼š</p>
<ul>
<li><a href="https://huggingface.co/datasets/roneneldan/TinyStories">TinyStories</a>ï¼šä¸€ä¸ªéå¸¸å°çš„æ•…äº‹æ•°æ®é›†(1GB) ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•ä»£ç ã€‚</li>
<li><a href="https://huggingface.co/datasets/stanford-cs336/owt-sample">OpenWebText (OWT) Sample</a>ï¼šä¸€ä¸ªè¾ƒå¤§çš„æ–‡æœ¬æ•°æ®é›†(4.7GB)ï¼Œé€‚åˆè¿›è¡Œæ›´æ·±å…¥çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
</ul>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®‰è£… <code>uv</code>:</p>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p><code>uv</code>æ˜¯ä»€ä¹ˆï¼Ÿ</p>
</div>
<div class="note-container foldable-content">
<p><code>uv</code>æ˜¯ä¸€ä¸ªè½»é‡çº§çš„Pythoné¡¹ç›®ç®¡ç†å’Œè¿è¡Œå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´æ–¹ä¾¿åœ°è¿è¡Œå’Œæµ‹è¯•ä»£ç ã€‚åœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<code>uv</code>æ¥è¿è¡Œæµ‹è¯•å’Œç®¡ç†é¡¹ç›®ä¾èµ–ã€‚</p>
</div>
</div>
<div class="sourceCode" id="cb3" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="ex">pip</span> install uv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>å®‰è£…å®Œ<code>uv</code>ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ä¸€ä¸‹çš„ä»£ç æ¥è¿è¡Œæµ‹è¯•ä»£ç ï¼š</p>
<div class="sourceCode" id="cb4" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">uv</span> run pytest </span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="ex">uv</span> run python train.py </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="part-01-byte-pair-encoding-bpe-implementation" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Part 01: Byte Pair Encoding (BPE) Implementation</h1>
<p>åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°Byte Pair Encoding (BPE) <span class="citation" data-cites="NeuralMachineTranslation2016sennrich">(<a href="#ref-NeuralMachineTranslation2016sennrich" role="doc-biblioref">Sennrich, Haddow, and Birch 2016</a>)</span>ç®—æ³•ï¼Œç”¨äºæ–‡æœ¬çš„tokenizationã€‚åœ¨<a href="https://yyzhang2025.github.io/posts/LearningNotes/CS336/Lectures/Lecture01/lec01.html">Lecture 01</a>ä¸­ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†BPEçš„åŸºæœ¬åŸç†å’Œå®ç°æ–¹æ³•ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä»£ç æ¥è¿›ä¸€æ­¥çš„å®ç°å¹¶ä¸”ä¼˜åŒ–BPEç®—æ³•ã€‚</p>
<section id="sec-bpe-recap" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-bpe-recap"><span class="header-section-number">2.1</span> BPE Algorithm Recap</h2>
<p>å›é¡¾ä¸€ä¸‹BPEç®—æ³•çš„åŸºæœ¬æ­¥éª¤ï¼š</p>
<ol type="1">
<li><strong>Initialization</strong>: å°†è¾“å…¥æ–‡æœ¬è§†ä¸ºå­—èŠ‚åºåˆ—ï¼Œæ¯ä¸ªå­—èŠ‚ä½œä¸ºä¸€ä¸ªtokenã€‚åˆå§‹åŒ–è¯æ±‡è¡¨åŒ…å«æ‰€æœ‰å¯èƒ½çš„å­—èŠ‚ï¼ˆ0-255ï¼‰ã€‚ä»¥åŠSpecial Tokensï¼Œæ¯”å¦‚ <code>&lt;|endoftext|&gt;</code></li>
<li><strong>Count Pairs</strong>: ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚</li>
<li><strong>Merge Pairs</strong>: å°†é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹å…¶åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„tokenï¼Œæ›´æ–°æ–‡æœ¬å’Œè¯æ±‡è¡¨:
<ol type="1">
<li><strong>Get the most frequent pair</strong>: æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹ã€‚</li>
<li><strong>Add the new pair</strong>: å°†è¿™ä¸ªæ–°çš„å­—èŠ‚å¯¹åŠ å…¥è¯æ±‡è¡¨ã€‚</li>
<li><strong>Update the word counter</strong>: æ›´æ–°æ–‡æœ¬ä¸­æ‰€æœ‰å‡ºç°è¯¥å­—èŠ‚å¯¹çš„åœ°æ–¹ã€‚</li>
<li><strong>Update Pairs Counts</strong>: é‡æ–°ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚</li>
</ol></li>
<li><strong>Repeat</strong>: é‡å¤æ­¥éª¤2,3ï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„åˆå¹¶æ¬¡æ•°</li>
</ol>
<p>BPE çš„ä¼ªä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div id="algo-bpe" class="pseudocode-container quarto-float" data-caption-prefix="Algorithm" data-no-end="false" data-line-number-punc=":" data-indent-size="1.2em" data-pseudocode-number="1" data-line-number="true" data-comment-delimiter="#">
<div class="pseudocode">
\begin{algorithm} \caption{BPE Training} \begin{algorithmic} \Require Corpus text $\mathcal{D}$ \Require Number of merges $M$ \Require Special tokens $\mathcal{S}$ (e.g., \texttt{&lt;|endoftext|&gt;}) \Ensure Vocabulary $V$, merge rules list $\Pi$ \State Convert each document $x \in \mathcal{D}$ into bytes $b(x)$ \State Initialize tokenized corpus as sequences of single-byte tokens \State $V \gets \{0,1,\dots,255\} \cup \mathcal{S}$ \State $\Pi \gets [\,]$ \For{$t = 1$ \textbf{to} $M$} \State $C \gets$ empty map from pair $\to$ count \For{\textbf{each} token sequence $s$ in the corpus} \Comment{Count adjacent byte-token pairs} \For{\textbf{each} index $i$ from $1$ to $|s|-1$} \State $C[(s_i, s_{i+1})] \gets C[(s_i, s_{i+1})] + 1$ \EndFor \EndFor \State Choose $(a,b)$ with the largest count in $C$ \Comment{Select the most frequent pair} \State Define a new token $new$ as the merge of $(a,b)$ \State $V \gets V \cup \{new\}$ \Comment{Create a new merged token and record the merge rule} \State Append $(a,b)\rightarrow new$ to $\Pi$ \For{\textbf{each} token sequence $s$ in the corpus} \Comment{Replace all occurrences of $(a,b)$ in the corpus} \State Replace adjacent $(a,b)$ with $new$ left-to-right (non-overlapping) \EndFor \EndFor \State \Return $V, \Pi$ \end{algorithmic} \end{algorithm}
</div>
</div>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬æ¥å®ç°ä¸€ä¸‹æœ€ç®€å•çš„BPEç®—æ³•:</p>
</section>
<section id="sec-bpe-v0" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-bpe-v0"><span class="header-section-number">2.2</span> BPE Version 0</h2>
<p>å‡å¦‚æˆ‘ä»¬è¦Tokenizedä»¥ä¸‹çš„æ–‡æœ¬ï¼š</p>
<div class="sourceCode" id="cb5" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>string <span class="op">=</span> <span class="st">""" </span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="st">low low low low low &lt;|endoftext|&gt;</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="st">lower lower widest widest widest &lt;|endoftext|&gt;</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="st">newest newest newest newest newest newest </span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><tag style="color:orange">Step1</tag> è¦åšçš„å°±æ˜¯åˆå§‹åŒ–æˆ‘ä»¬çš„è¯æ±‡è¡¨ï¼š</p>
<div class="sourceCode" id="cb6" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">def</span> init_vocab(special_tokens: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>]:</span>
<span id="cb6-2"><a href="#cb6-2"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>] <span class="op">=</span> {x: <span class="bu">bytes</span>([x]) <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>)}  <span class="co"># idx -&gt; byte representation</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>    current_index <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span class="cf">if</span> special_tokens:</span>
<span id="cb6-6"><a href="#cb6-6"></a>        <span class="cf">for</span> token <span class="kw">in</span> special_tokens:</span>
<span id="cb6-7"><a href="#cb6-7"></a>            token_bytes <span class="op">=</span> token.encode(<span class="st">"utf-8"</span>)</span>
<span id="cb6-8"><a href="#cb6-8"></a>            vocab[current_index] <span class="op">=</span> token_bytes</span>
<span id="cb6-9"><a href="#cb6-9"></a>            current_index <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-10"><a href="#cb6-10"></a></span>
<span id="cb6-11"><a href="#cb6-11"></a>    <span class="cf">return</span> vocab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>åˆå§‹åŒ–æ—¶ï¼Œæˆ‘ä»¬ä¼šå…ˆä¸ºæ‰€æœ‰ byte å€¼ 0â€“255 å»ºç«‹åŸºç¡€è¯è¡¨ï¼ˆæ–‡æœ¬å…ˆç”¨ <code>UTF-8</code> ç¼–ç æˆå­—èŠ‚åºåˆ—æ¥å¤„ç†ï¼‰ï¼Œå¹¶é¢å¤–åŠ å…¥ <strong>special tokens</strong>ï¼›åœ¨ç¼–ç è¿‡ç¨‹ä¸­è¿™äº› <strong>special tokens</strong> ä¼šè¢« <span class="hilite-teal">ä¼˜å…ˆåŒ¹é…å¹¶ä½œä¸ºæ•´ä½“ä¿ç•™ï¼Œä¸å‚ä¸æ™®é€šçš„åˆ‡åˆ†ä¸ BPE åˆå¹¶</span>ã€‚</p>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬æ¥å®ç°<tag style="color:orange">Step2</tag>: ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚</p>
<div class="sourceCode" id="cb7" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">def</span> pair_counts(word_counter: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...], <span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>]:</span>
<span id="cb7-2"><a href="#cb7-2"></a>    pairs: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> {}</span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a>    <span class="cf">for</span> word, count <span class="kw">in</span> word_counter.items():</span>
<span id="cb7-5"><a href="#cb7-5"></a>        <span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(word, word[<span class="dv">1</span>:]):</span>
<span id="cb7-6"><a href="#cb7-6"></a>            pairs[(a, b)] <span class="op">=</span> pairs.get((a, b), <span class="dv">0</span>) <span class="op">+</span> count</span>
<span id="cb7-7"><a href="#cb7-7"></a></span>
<span id="cb7-8"><a href="#cb7-8"></a>    <span class="cf">return</span> pairs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æˆ‘ä»¬å…ˆç»Ÿè®¡æ¯ä¸ªè¯ï¼ˆtoken åºåˆ—ï¼‰å‡ºç°çš„æ¬¡æ•° countï¼Œå†åœ¨éå†è¯¥è¯çš„ç›¸é‚» token å¯¹æ—¶ï¼ŒæŠŠæ¯ä¸ª pair çš„å‡ºç°æ¬¡æ•°ç´¯åŠ  countï¼Œä»è€Œå¾—åˆ°å…¨è¯­æ–™çš„ pair é¢‘æ¬¡ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç° <tag style="color:orange">Step3.1</tag>: æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éµå¾ªçš„è§„åˆ™æ˜¯ï¼š</p>
<ol type="1">
<li>é¢‘ç‡æœ€é«˜çš„pair</li>
<li>è‹¥å¤šä¸ª pair é¢‘ç‡ç›¸åŒï¼Œæˆ‘ä»¬æŒ‰ pair çš„å­—å…¸åºï¼ˆå…ˆæ¯”å·¦ tokenï¼Œå†æ¯”å³ tokenï¼‰é€‰æ‹©æ›´å¤§çš„é‚£ä¸ªã€‚</li>
</ol>
<div class="sourceCode" id="cb8" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">def</span> get_most_frequent_pair(</span>
<span id="cb8-2"><a href="#cb8-2"></a>    pair_counter: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>],</span>
<span id="cb8-3"><a href="#cb8-3"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]:</span>
<span id="cb8-4"><a href="#cb8-4"></a>    max_freq <span class="op">=</span> <span class="bu">max</span>(pair_counter.values())</span>
<span id="cb8-5"><a href="#cb8-5"></a>    candidates <span class="op">=</span> [pair <span class="cf">for</span> pair, freq <span class="kw">in</span> pair_counter.items() <span class="cf">if</span> freq <span class="op">==</span> max_freq]</span>
<span id="cb8-6"><a href="#cb8-6"></a>    res <span class="op">=</span> <span class="bu">max</span>(candidates)</span>
<span id="cb8-7"><a href="#cb8-7"></a></span>
<span id="cb8-8"><a href="#cb8-8"></a>    <span class="cf">return</span> res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>å®ƒ(<code>res</code>)æ˜¯æœ¬è½®è¦ merge çš„ pairï¼ˆå°†å®ƒæ›¿æ¢ä¸ºä¸€ä¸ªæ–° tokenï¼‰</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç°<tag style="color:orange">Step3.2</tag>: å°†è¿™ä¸ªæ–°çš„å­—èŠ‚å¯¹åŠ å…¥è¯æ±‡è¡¨ï¼š</p>
<div class="sourceCode" id="cb9" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">def</span> add_pair_to_vocab(</span>
<span id="cb9-2"><a href="#cb9-2"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>],</span>
<span id="cb9-3"><a href="#cb9-3"></a>    pair: <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>],</span>
<span id="cb9-4"><a href="#cb9-4"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb9-5"><a href="#cb9-5"></a>    index1, index2 <span class="op">=</span> pair</span>
<span id="cb9-6"><a href="#cb9-6"></a>    vocab[<span class="bu">len</span>(vocab)] <span class="op">=</span> vocab[index1] <span class="op">+</span> vocab[index2]</span>
<span id="cb9-7"><a href="#cb9-7"></a>    <span class="cf">return</span> <span class="bu">len</span>(vocab) <span class="op">-</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>å°†è¿™ä¸ªæ–°çš„pairåŠ å…¥è¯æ±‡è¡¨åï¼Œæˆ‘ä»¬éœ€è¦å®ç° <tag style="color:orange">Step3.3</tag> å’Œ <tag style="color:orange">Step3.4</tag>: <u>æ›´æ–°æ–‡æœ¬ä¸­æ‰€æœ‰å‡ºç°è¯¥å­—èŠ‚å¯¹çš„åœ°æ–¹ï¼Œä»¥åŠé‡æ–°ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡</u>ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦éå†æ‰€æœ‰çš„wordï¼Œæ¥çœ‹æ˜¯ä¸æ˜¯æœ‰è¿™ä¸ªpairå‡ºç°ï¼Œè‹¥å‡ºç°äº†ï¼Œå°±å°†å…¶åˆå¹¶æˆä¸€ä¸ªæ–°çš„tokenã€‚ åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é‡æ–°ç»Ÿè®¡æ‰€æœ‰çš„pairçš„é¢‘ç‡ã€‚</p>
<div class="sourceCode" id="cb10" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> merge_pair_ids(</span>
<span id="cb10-2"><a href="#cb10-2"></a>    word_counter: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">bytes</span>] <span class="op">|</span> <span class="bu">tuple</span>[<span class="bu">int</span>], <span class="bu">int</span>],</span>
<span id="cb10-3"><a href="#cb10-3"></a>    pair: <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>],</span>
<span id="cb10-4"><a href="#cb10-4"></a>    new_id: <span class="bu">int</span>,</span>
<span id="cb10-5"><a href="#cb10-5"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>], <span class="bu">int</span>], <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>]]:</span>
<span id="cb10-6"><a href="#cb10-6"></a>    new_word_counter: defaultdict[<span class="bu">tuple</span>[<span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb10-7"><a href="#cb10-7"></a>    updated_pair_counts: defaultdict[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a>    <span class="cf">for</span> token, freq <span class="kw">in</span> word_counter.items():</span>
<span id="cb10-10"><a href="#cb10-10"></a>        new_token <span class="op">=</span> []</span>
<span id="cb10-11"><a href="#cb10-11"></a>        i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-12"><a href="#cb10-12"></a>        L <span class="op">=</span> <span class="bu">len</span>(token)</span>
<span id="cb10-13"><a href="#cb10-13"></a></span>
<span id="cb10-14"><a href="#cb10-14"></a>        <span class="cf">while</span> i <span class="op">&lt;</span> L:</span>
<span id="cb10-15"><a href="#cb10-15"></a>            <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> L <span class="kw">and</span> (token[i], token[i <span class="op">+</span> <span class="dv">1</span>]) <span class="op">==</span> pair:</span>
<span id="cb10-16"><a href="#cb10-16"></a>                new_token.append(new_id)</span>
<span id="cb10-17"><a href="#cb10-17"></a>                i <span class="op">+=</span> <span class="dv">2</span></span>
<span id="cb10-18"><a href="#cb10-18"></a>            <span class="cf">else</span>:</span>
<span id="cb10-19"><a href="#cb10-19"></a>                new_token.append(token[i])</span>
<span id="cb10-20"><a href="#cb10-20"></a>                i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb10-21"><a href="#cb10-21"></a></span>
<span id="cb10-22"><a href="#cb10-22"></a>        new_word_counter[<span class="bu">tuple</span>(new_token)] <span class="op">+=</span> freq</span>
<span id="cb10-23"><a href="#cb10-23"></a></span>
<span id="cb10-24"><a href="#cb10-24"></a>        <span class="cf">for</span> index1, index2 <span class="kw">in</span> <span class="bu">zip</span>(new_token[:<span class="op">-</span><span class="dv">1</span>], new_token[<span class="dv">1</span>:]):</span>
<span id="cb10-25"><a href="#cb10-25"></a>            updated_pair_counts[(index1, index2)] <span class="op">+=</span> freq</span>
<span id="cb10-26"><a href="#cb10-26"></a></span>
<span id="cb10-27"><a href="#cb10-27"></a>    <span class="cf">return</span> <span class="bu">dict</span>(new_word_counter), <span class="bu">dict</span>(updated_pair_counts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†ä¸€è½®ï¼Œé‡å¤ä»¥ä¸Šçš„æ­¥éª¤ï¼Œç›´åˆ°æˆ‘ä»¬è¾¾åˆ°ç›®æ ‡çš„è½®æ•°ï¼Œæ”¾åœ¨ä¸€èµ·ä»£ç å°±æ˜¯ï¼š</p>
<div class="sourceCode" id="cb11" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">def</span> train_bpe(</span>
<span id="cb11-2"><a href="#cb11-2"></a>    string: <span class="bu">str</span> <span class="op">=</span> string,</span>
<span id="cb11-3"><a href="#cb11-3"></a>    vocab_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">263</span>,</span>
<span id="cb11-4"><a href="#cb11-4"></a>    special_tokens: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">=</span> special_tokens,</span>
<span id="cb11-5"><a href="#cb11-5"></a>    save_path: <span class="bu">str</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb11-6"><a href="#cb11-6"></a>):</span>
<span id="cb11-7"><a href="#cb11-7"></a>    vocab <span class="op">=</span> init_vocab(special_tokens)</span>
<span id="cb11-8"><a href="#cb11-8"></a>    num_merges <span class="op">=</span> vocab_size <span class="op">-</span> <span class="bu">len</span>(vocab)</span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a>    merges: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> {}</span>
<span id="cb11-11"><a href="#cb11-11"></a></span>
<span id="cb11-12"><a href="#cb11-12"></a>    word_counter <span class="op">=</span> pre_tokenize(string, special_tokens, including_special<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-13"><a href="#cb11-13"></a></span>
<span id="cb11-14"><a href="#cb11-14"></a>    pairs_freqs <span class="op">=</span> pair_counts(word_counter)</span>
<span id="cb11-15"><a href="#cb11-15"></a></span>
<span id="cb11-16"><a href="#cb11-16"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_merges):</span>
<span id="cb11-17"><a href="#cb11-17"></a>        most_common_pair <span class="op">=</span> get_most_frequent_pair(pairs_freqs)</span>
<span id="cb11-18"><a href="#cb11-18"></a>        new_index <span class="op">=</span> add_pair_to_vocab(vocab, most_common_pair)</span>
<span id="cb11-19"><a href="#cb11-19"></a>        merges[most_common_pair] <span class="op">=</span> new_index</span>
<span id="cb11-20"><a href="#cb11-20"></a>        word_counter, pairs_freqs <span class="op">=</span> merge_pair_ids(word_counter, most_common_pair, new_index)</span>
<span id="cb11-21"><a href="#cb11-21"></a>    </span>
<span id="cb11-22"><a href="#cb11-22"></a>    <span class="cf">return</span> vocab, merges</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è¿™ä¹Ÿå°±æ˜¯æˆ‘ä»¬æœ€ç®€å•çš„BPEçš„ç®—æ³•ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºBPE Version0, å½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªä»£ç ï¼Œå¹¶ä¸”æŠŠ<code>vocab_size</code>è®¾ç½®ä¸º263æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹mergesçš„é¡ºåºã€‚</p>
<div class="sourceCode" id="cb12" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>train_bpe(</span>
<span id="cb12-2"><a href="#cb12-2"></a>    string<span class="op">=</span>string,</span>
<span id="cb12-3"><a href="#cb12-3"></a>    vocab_size<span class="op">=</span><span class="dv">256</span> <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="dv">6</span>, <span class="co"># 256 bytes + 1 special token + 6 merges</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>    special_tokens<span class="op">=</span>special_tokens,</span>
<span id="cb12-5"><a href="#cb12-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb13" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb13-1"><a href="#cb13-1"></a>Most common pair: (b's', b't') -&gt; 9</span>
<span id="cb13-2"><a href="#cb13-2"></a>Most common pair: (b'e', b'st') -&gt; 9</span>
<span id="cb13-3"><a href="#cb13-3"></a>Most common pair: (b'o', b'w') -&gt; 7</span>
<span id="cb13-4"><a href="#cb13-4"></a>Most common pair: (b'l', b'ow') -&gt; 7</span>
<span id="cb13-5"><a href="#cb13-5"></a>Most common pair: (b'w', b'est') -&gt; 6</span>
<span id="cb13-6"><a href="#cb13-6"></a>Most common pair: (b'n', b'e') -&gt; 6</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡è¿™ä¸ªç‰ˆæœ¬çš„BPEç®—æ³•æ˜¯æ­£ç¡®çš„ï¼Œä½†æ˜¯å®ƒçš„æ•ˆç‡éå¸¸ä½ï¼Œå› ä¸ºæ¯æ¬¡æˆ‘ä»¬éƒ½éœ€è¦éå†æ‰€æœ‰çš„pairï¼Œæ¥æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„pairï¼Œè¿™æ ·çš„æ—¶é—´å¤æ‚åº¦æ˜¯ <span class="math inline">\(\mathcal{O}(N \cdot P)\)</span>ï¼Œå…¶ä¸­Næ˜¯åˆå¹¶çš„æ¬¡æ•°ï¼ŒPæ˜¯pairçš„æ•°é‡ã€‚å¦‚æœåªæ˜¯ç”¨è¿™ç§ç®€å•çš„ç®—æ³•ï¼Œæˆ‘ä»¬æ˜¯é€šä¸è¿‡æµ‹è¯•çš„ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦ä¼˜åŒ–è¿™ä¸ªç®—æ³•ï¼Œä¸è¿‡åœ¨ä¼˜åŒ–ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€ä¸‹Pre-Processingçš„æ­¥éª¤ã€‚</p>
</section>
<section id="pre-processing" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="pre-processing"><span class="header-section-number">2.3</span> Pre-Processing</h2>
<p>åœ¨å®ç°BPEç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼ˆPre-Processingï¼‰ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ï¼š</p>
<ol type="1">
<li>æ ¹æ®<strong>Special Tokens</strong>æ¥åˆ†æ–‡æœ¬</li>
<li>æ ¹æ®æ­£åˆ™è¡¨è¾¾æ¥åˆ†æ–‡æœ¬</li>
</ol>
<p>æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹æ ¹æ®<strong>Special Tokens</strong>æ¥åˆ†æ–‡æœ¬çš„æƒ…å†µ</p>
<section id="special-tokens-based-splitting" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="special-tokens-based-splitting"><span class="header-section-number">2.3.1</span> Special Tokens Based Splitting</h3>
<p>åœ¨è¿™ä¸€èŠ‚(<a href="#sec-bpe-recap" class="quarto-xref">Section&nbsp;2.1</a>) ï¼Œæˆ‘ä»¬å·²ç»äº†è§£è¿‡äº†ï¼Œåœ¨åˆå§‹åŒ–<code>vocab</code> æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦åˆå§‹åŒ–special tokensï¼Œå…¶ä¸­ä¸€ä¸ªå¸¸è§çš„special tokenså°±æ˜¯ <code>&lt;|endoftext|&gt;</code>. è¿™ä¸ªtokenæ„å‘³ç€ä¸€æ®µæ–‡æœ¬çš„ç»“æŸã€‚ç»™å‡ºä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æƒ…å°±æ˜¯æŠŠè¿™ä¸ªæ–‡æœ¬åˆ†æˆè®¸å¤šæ®µï¼Œä»£ç çš„å®ç°å¦‚ä¸‹ï¼š</p>
<div class="sourceCode" id="cb14" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">def</span> split_by_special_tokens(text: <span class="bu">str</span>, special_tokens: <span class="bu">list</span>[<span class="bu">str</span>], include_special: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">str</span>]:</span>
<span id="cb14-2"><a href="#cb14-2"></a>    <span class="cf">if</span> <span class="kw">not</span> special_tokens:</span>
<span id="cb14-3"><a href="#cb14-3"></a>        <span class="cf">return</span> [text]</span>
<span id="cb14-4"><a href="#cb14-4"></a></span>
<span id="cb14-5"><a href="#cb14-5"></a>    special_tokens_sorted <span class="op">=</span> <span class="bu">sorted</span>(special_tokens, key<span class="op">=</span><span class="bu">len</span>, reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a>    pattern <span class="op">=</span> <span class="st">"|"</span>.join(re.escape(t) <span class="cf">for</span> t <span class="kw">in</span> special_tokens_sorted)</span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a>    <span class="cf">if</span> include_special:</span>
<span id="cb14-9"><a href="#cb14-9"></a>        special_chunks <span class="op">=</span> re.split(<span class="ss">f"(</span><span class="sc">{</span>pattern<span class="sc">}</span><span class="ss">)"</span>, text)</span>
<span id="cb14-10"><a href="#cb14-10"></a>    <span class="cf">else</span>:</span>
<span id="cb14-11"><a href="#cb14-11"></a>        <span class="co"># Split without capturing the special tokens</span></span>
<span id="cb14-12"><a href="#cb14-12"></a>        special_chunks <span class="op">=</span> re.split(pattern, text)</span>
<span id="cb14-13"><a href="#cb14-13"></a></span>
<span id="cb14-14"><a href="#cb14-14"></a>    <span class="cf">return</span> special_chunks</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº† Special Token-aware çš„åˆ‡åˆ†ï¼š</p>
<ol type="1">
<li>é€šè¿‡æŠŠæ‰€æœ‰ special tokens å…ˆæŒ‰é•¿åº¦é™åºæ’åºï¼Œå¹¶ç”¨æ­£åˆ™æ„é€ åŒ¹é… patternï¼Œæˆ‘ä»¬å¯ä»¥æŠŠåŸå§‹é•¿æ–‡æœ¬æ‹†æˆä¸€ç³»åˆ— æ™®é€šæ–‡æœ¬ç‰‡æ®µï¼ˆä»¥åŠå¯é€‰çš„ special token ç‰‡æ®µï¼‰ã€‚</li>
<li>å½“ <code>include_special=True</code> æ—¶ï¼Œ<code>re.split(f"({pattern})", text)</code> ä¼šæŠŠåŒ¹é…åˆ°çš„ special token ä¹Ÿä¿ç•™ä¸‹æ¥ï¼Œä»è€Œåœ¨åç»­ç¼–ç æ—¶æˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬å½“ä½œâ€œåŸå­ tokenâ€ç›´æ¥æ˜ å°„åˆ°å¯¹åº”çš„ idï¼›</li>
<li>å½“ <code>include_special=False</code> æ—¶ï¼Œspecial token ä¼šä½œä¸ºåˆ†éš”ç¬¦è¢«ä¸¢å¼ƒï¼Œä»…è¿”å›æ™®é€šæ–‡æœ¬ç‰‡æ®µï¼Œé€‚åˆè®­ç»ƒé˜¶æ®µä¸æƒ³è®© special tokens å‚ä¸ pair ç»Ÿè®¡ / merges çš„åœºæ™¯ã€‚</li>
</ol>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯¹æ¯ä¸ªæ™®é€šç‰‡æ®µæ‰§è¡ŒRegular-basedçš„åˆ‡åˆ†äº†ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šæŠŠæ–‡æœ¬åˆ‡æˆæ›´å°çš„ç‰‡æ®µï¼Œæ¯”å¦‚è¯ã€å­è¯ç‰‡æ®µã€æ ‡ç‚¹åˆ†éš”ç‰‡æ®µç­‰ã€‚</p>
</section>
<section id="regex-based-splitting-pre-tokenization" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="regex-based-splitting-pre-tokenization"><span class="header-section-number">2.3.2</span> Regex-based Splitting (Pre-Tokenization)</h3>
<p><strong>Pre-Tokenizationï¼ˆé¢„åˆ†è¯ï¼‰</strong> å°±æ˜¯åœ¨çœŸæ­£è®­ç»ƒ BPE åˆå¹¶è§„åˆ™ä¹‹å‰ï¼Œå…ˆå¯¹æ•´ä»½è¯­æ–™åšä¸€æ¬¡ç²—ç²’åº¦çš„åˆ‡åˆ†ï¼ŒæŠŠæ–‡æœ¬åˆ‡æˆä¸€æ®µæ®µâ€œæ›´å¤§çš„ç‰‡æ®µâ€ï¼ˆpre-tokenï¼‰ï¼Œç„¶å<strong>åœ¨è¿™äº›ç‰‡æ®µå†…éƒ¨</strong>å»ç»Ÿè®¡ç›¸é‚»å­—èŠ‚ï¼ˆbyte pairï¼‰çš„å‡ºç°é¢‘ç‡ã€‚ã€ é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆéœ€è¦Pre-Tokenizationå‘¢ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š</p>
<hr>
<p><tag style="color:blue">åŸå› ä¸€</tag>ï¼šé¿å…â€œæ¯åˆå¹¶ä¸€æ¬¡å°±å…¨è¯­æ–™æ‰«ä¸€éâ€ <br> æˆ‘ä»¬çŸ¥é“ï¼Œmergeä¸€æ¬¡ï¼Œæˆ‘ä»¬å°±è¦é‡æ–°æ‰«æä¸€æ¬¡ï¼Œä»¥è·å¾—æ›´æ–°åçš„æ–°è¯­æ–™ï¼Œå¦‚æœè¿™ä¸ªè¯­æ–™ç‰¹åˆ«å¤§ï¼Œæˆ–è€…æˆ‘ä»¬mergeçš„æ¬¡æ•°ç‰¹åˆ«å¤šï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´æˆ‘ä»¬ç®—æ³•ç‰¹åˆ«çš„æ…¢ã€‚ <br> è¿™ä¸ªæ—¶å€™æˆ‘ä»¬å°±éœ€è¦Pre-Tokenizationï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š</p>
<ul>
<li>å…ˆæŠŠè¯­æ–™åˆ‡æˆå¾ˆå¤šâ€œpre-tokenâ€ï¼ˆæ¯”å¦‚è¯ã€å­è¯ç‰‡æ®µã€æ ‡ç‚¹åˆ†éš”ç‰‡æ®µç­‰ï¼‰<br>
</li>
<li>ç»Ÿè®¡æ—¶ä¸å†å¯¹æ•´ä¸ªè¯­æ–™é€å­—ç¬¦/é€å­—èŠ‚æ‰«æï¼Œè€Œæ˜¯åˆ©ç”¨é‡å¤å‡ºç°çš„ pre-token çš„æ¬¡æ•°æ¥åŠ é€Ÿã€‚</li>
</ul>
<p>ä¸¾ä¸ªä¾‹å­ï¼š</p>
<ul>
<li>â€˜textâ€™ è¿™ä¸ª pre-token å‡ºç°äº† 10 æ¬¡</li>
<li>å½“æˆ‘ä»¬è¦ç»Ÿè®¡ â€˜tâ€™ å’Œ â€˜eâ€™ ç›¸é‚»å‡ºç°æ¬¡æ•°</li>
<li>åªè¦åœ¨ â€˜textâ€™ é‡Œçœ‹åˆ°ä¸€æ¬¡ â€œtâ€+â€œeâ€ ç›¸é‚»ï¼Œå°±å¯ä»¥ä¸€æ¬¡æ€§æŠŠè®¡æ•°åŠ  10 è€Œä¸æ˜¯æŠŠè¯­æ–™é‡Œæ¯ä¸ª â€˜textâ€™ éƒ½é€å­—èŠ‚å†çœ‹ä¸€éã€‚</li>
</ul>
<hr>
<p><tag style="color:blue">åŸå› äºŒ</tag>ï¼šé¿å…å­¦å‡ºâ€œåªæœ‰æ ‡ç‚¹ä¸åŒâ€çš„é‡å¤ token <br> æ¯”å¦‚æœ‰ä¸¤ä¸ªè¯ <code>dog!</code> å’Œ <code>dog.</code> å¦‚æœæˆ‘ä»¬é‚£ä¸Pre-tokenizationï¼Œé‚£ä¹ˆè¿™ä¸ªå¾ˆå®¹æ˜“è¢«å½“æˆä¸åŒçš„åºåˆ—ï¼Œä»è€Œå¯¹äºè¿™ä¸ªç±»ä¼¼çš„è¯ï¼Œæœ‰ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„IDsã€‚è€Œ Pre-tokenization é€šå¸¸ä¼šç”¨ä¸€äº›è§„åˆ™ï¼ˆæ¯”å¦‚æŒ‰ç©ºç™½ã€æ ‡ç‚¹è¾¹ç•Œç­‰ï¼‰å…ˆåˆ‡å¼€ï¼Œè®© BPE æ›´å¤šåœ¨â€œè¯å†…éƒ¨â€å­¦ä¹ åˆå¹¶è§„å¾‹ï¼Œè€Œä¸æ˜¯æŠŠè¯å’Œå„ç§æ ‡ç‚¹ç²˜åœ¨ä¸€èµ·ä¹±åˆå¹¶ã€‚</p>
<p>åœ¨è¿™ä¸ª Assignment é‡Œï¼Œæˆ‘ä»¬é‡‡ç”¨ regex-based pre-tokenizerï¼ˆGPT-2 ä½¿ç”¨çš„é‚£æ¡æ­£åˆ™ï¼‰ï¼Œå…ˆæŠŠåŸå§‹æ–‡æœ¬åˆ‡æˆä¸€ä¸²â€œé¢„åˆ†è¯ç‰‡æ®µâ€ï¼ˆpre-tokensï¼‰ï¼Œå†å¯¹æ¯ä¸ªç‰‡æ®µåš byte-level BPEã€‚</p>
<div class="sourceCode" id="cb15" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>PAT <span class="op">=</span> <span class="vs">r"""'</span>(?:<span class="pp">[sdmt]</span><span class="cf">|</span><span class="vs">ll</span><span class="cf">|</span><span class="vs">ve</span><span class="cf">|</span><span class="vs">re</span>)<span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="ch">\p{L}</span><span class="op">+</span><span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="ch">\p{N}</span><span class="op">+</span><span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="pp">[^</span><span class="dv">\s</span><span class="ch">\p{L}\p{N}</span><span class="pp">]</span><span class="op">+</span><span class="cf">|</span><span class="dv">\s</span><span class="op">+</span><span class="ex">(</span><span class="fu">?!</span><span class="dv">\S</span><span class="ex">)</span><span class="cf">|</span><span class="dv">\s</span><span class="op">+</span><span class="vs">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p>Regex è¯¦è§£</p>
</div>
<div class="note-container foldable-content">
<p>æˆ‘ä»¬æ¥è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼š å®ƒçš„åˆ†å—è§„åˆ™ï¼ˆä»å·¦åˆ°å³åŒ¹é…ï¼‰ï¼š</p>
<ul>
<li>è‹±è¯­ç¼©å†™/è¯å°¾ï¼šâ€™s, â€™t, â€™re, â€™ve, â€™ll, â€™m, â€™d ç­‰ï¼ˆç¬¬ä¸€æ®µï¼‰</li>
<li>å­—æ¯ä¸²ï¼š ?+ â€”â€” ä¸€æ®µå­—æ¯ï¼ˆå…è®¸å‰é¢å¸¦ä¸€ä¸ªå¯é€‰ç©ºæ ¼ï¼ŒæŠŠç©ºæ ¼â€œç²˜â€åˆ°åé¢çš„ token ä¸Šï¼‰</li>
<li>æ•°å­—ä¸²ï¼š ?+ â€”â€” ä¸€æ®µæ•°å­—ï¼ˆåŒæ ·å…è®¸å‰ç½®ç©ºæ ¼ï¼‰</li>
<li>æ ‡ç‚¹/å…¶å®ƒç¬¦å·ä¸²ï¼š ?[^\s\p{L}\p{N}]+ â€”â€” éç©ºç™½ã€éå­—æ¯ã€éæ•°å­—çš„ä¸€ä¸²ç¬¦å·ï¼ˆä¹Ÿå…è®¸å‰ç½®ç©ºæ ¼ï¼‰</li>
<li>ç©ºç™½ï¼š+(?!)ï¼ˆæœ«å°¾ç©ºç™½ï¼‰æˆ– +ï¼ˆä¸€èˆ¬ç©ºç™½ï¼‰
<ul>
<li>+ï¼šåŒ¹é…ä¸€æ®µç©ºç™½ï¼ˆç©ºæ ¼ã€æ¢è¡Œã€tab ç­‰ï¼‰ã€‚</li>
<li>(?!)ï¼šè´Ÿå‘å‰ç»ï¼Œç¡®ä¿è¿™æ®µç©ºç™½åé¢æ²¡æœ‰éç©ºç™½å­—ç¬¦ï¼ˆå³è¿™æ˜¯è¡Œå°¾æˆ–æ–‡æœ¬æœ«å°¾çš„ç©ºç™½ï¼‰ã€‚</li>
</ul></li>
</ul>
<p>è¿™ç§è®¾è®¡çš„å…³é”®ç‚¹æ˜¯ï¼šå¾ˆå¤š token ä¼šæŠŠå‰å¯¼ç©ºæ ¼åŒ…å«è¿›å»ï¼ˆä¾‹å¦‚ â€ helloâ€ ä¼šè¢«å½“æˆä¸€ä¸ªæ•´ä½“çš„ pre-tokenï¼‰ï¼Œè¿™èƒ½æ›´å¥½åœ°åŒ¹é…è‹±è¯­é‡Œâ€œè¯è¾¹ç•Œ=ç©ºæ ¼â€çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œä¹Ÿæ›´æ¥è¿‘ GPT-2 çš„å®é™… tokenizer è¡Œä¸ºã€‚å¦‚æœä¸ç†è§£ï¼Œä¹Ÿæ²¡æœ‰å…³ç³»ï¼Œç›´æ¥ç”¨è¿™ä¸ªæ­£åˆ™å°±è¡Œã€‚</p>
</div>
</div>
<p>æœ‰äº†è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç° Pre-Tokenization äº†ï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<div class="sourceCode" id="cb16" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">def</span> pre_tokenize(string: <span class="bu">str</span>, special_tokens: <span class="bu">list</span>[<span class="bu">str</span>], including_special: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> Counter:</span>
<span id="cb16-2"><a href="#cb16-2"></a>    word_counter <span class="op">=</span> Counter()</span>
<span id="cb16-3"><a href="#cb16-3"></a></span>
<span id="cb16-4"><a href="#cb16-4"></a>    chunks <span class="op">=</span> split_by_special_tokens(string, special_tokens, include_special<span class="op">=</span>including_special)</span>
<span id="cb16-5"><a href="#cb16-5"></a></span>
<span id="cb16-6"><a href="#cb16-6"></a>    <span class="cf">for</span> chunk <span class="kw">in</span> chunks:</span>
<span id="cb16-7"><a href="#cb16-7"></a>        <span class="cf">if</span> including_special <span class="kw">and</span> chunk <span class="kw">in</span> special_tokens:</span>
<span id="cb16-8"><a href="#cb16-8"></a>            word_counter[<span class="bu">tuple</span>(string_to_bytes(chunk))] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-9"><a href="#cb16-9"></a>        <span class="cf">else</span>:</span>
<span id="cb16-10"><a href="#cb16-10"></a>            <span class="cf">for</span> match <span class="kw">in</span> re.finditer(PAT, chunk):</span>
<span id="cb16-11"><a href="#cb16-11"></a>                word <span class="op">=</span> match.group(<span class="dv">0</span>)</span>
<span id="cb16-12"><a href="#cb16-12"></a>                word_encoded <span class="op">=</span> <span class="bu">tuple</span>(string_to_bytes(word, return_int<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb16-13"><a href="#cb16-13"></a>                word_counter[word_encoded] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-14"><a href="#cb16-14"></a></span>
<span id="cb16-15"><a href="#cb16-15"></a>    <span class="cf">return</span> word_counter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>é€šè¿‡ pre-tokenizationï¼Œæˆ‘ä»¬æŠŠåŸå§‹æ–‡æœ¬è½¬æ¢æˆè®¸å¤šâ€œé¢„åˆ†è¯ç‰‡æ®µâ€çš„ byte/id åºåˆ—ï¼Œå¹¶ç”¨ Counter ç»Ÿè®¡æ¯ç§ç‰‡æ®µå‡ºç°çš„æ¬¡æ•°ã€‚åç»­åœ¨ç»Ÿè®¡ pair é¢‘ç‡æ—¶ï¼Œæ¯ä¸ªç‰‡æ®µçš„ç›¸é‚» token å¯¹å‡ºç°æ¬¡æ•°éƒ½ä¼šæŒ‰å…¶ count åŠ æƒç´¯åŠ ï¼Œä»è€Œå¾—åˆ°å…¨è¯­æ–™çš„ pair é¢‘æ¬¡ã€‚</p>
</section>
<section id="multi-processing" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="multi-processing"><span class="header-section-number">2.3.3</span> Multi-Processing</h3>
<p>ä»¥ä¸Šè¿™ä¸¤æ­¥ï¼ˆSpecial Token-aware Splitting å’Œ Regex-based Pre-Tokenizationï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ª Multi-Processing</p>
<div class="tip foldable is-open">
<div class="tip-header foldable-header">
<p>Multi-Processing Review</p>
</div>
<div class="tip-container foldable-content">
<p>Python çš„<a href="https://docs.python.org/3/library/multiprocessing.html">MultiProcessing</a> æ˜¯ä¸€ä¸ª- <strong>å¤šè¿›ç¨‹</strong> æ›´é€‚åˆ CPU å¯†é›†å‹ä»»åŠ¡ï¼ˆæ¯”å¦‚é¢„åˆ†è¯ã€ç»Ÿè®¡ï¼‰ã€‚ï¼Œæˆ‘ä»¬åªéœ€è¦äº†è§£ä»¥ä¸‹çš„å†…å®¹ï¼š</p>
<div class="sourceCode" id="cb17" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="im">from</span> multiprocessing <span class="im">import</span> Process, Queue  </span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="im">import</span> queue  </span>
<span id="cb17-3"><a href="#cb17-3"></a><span class="im">from</span> collections <span class="im">import</span> Counter </span>
<span id="cb17-4"><a href="#cb17-4"></a></span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="kw">def</span> task(<span class="op">*</span>args):  <span class="co"># å®šä¹‰å®é™…è¦å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡å‡½æ•°</span></span>
<span id="cb17-6"><a href="#cb17-6"></a>    <span class="co"># ... do something ...  # è¿™é‡Œå†™ä½ çš„çœŸå®ä»»åŠ¡é€»è¾‘</span></span>
<span id="cb17-7"><a href="#cb17-7"></a>    <span class="cf">return</span> Counter()  <span class="co"># è¿”å›ä¸€ä¸ª Counterï¼ˆç¤ºä¾‹ï¼‰ï¼Œä¾¿äºä¸»è¿›ç¨‹èšåˆ</span></span>
<span id="cb17-8"><a href="#cb17-8"></a></span>
<span id="cb17-9"><a href="#cb17-9"></a><span class="kw">def</span> task_worker(out_queue: Queue, <span class="op">*</span>args):  <span class="co"># workerï¼šæ¥æ”¶è¾“å‡ºé˜Ÿåˆ—å’Œä»»åŠ¡å‚æ•°</span></span>
<span id="cb17-10"><a href="#cb17-10"></a></span>
<span id="cb17-11"><a href="#cb17-11"></a>    output <span class="op">=</span> task(<span class="op">*</span>args)  <span class="co"># æ‰§è¡Œä»»åŠ¡ï¼Œå¾—åˆ°éƒ¨åˆ†ç»“æœ</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>    </span>
<span id="cb17-13"><a href="#cb17-13"></a>    out_queue.put(output)  <span class="co"># æŠŠç»“æœæ”¾è¿›é˜Ÿåˆ—ï¼Œäº¤ç»™ä¸»è¿›ç¨‹æ±‡æ€»</span></span>
<span id="cb17-14"><a href="#cb17-14"></a></span>
<span id="cb17-15"><a href="#cb17-15"></a>num_process <span class="op">=</span> <span class="dv">4</span>  <span class="co"># è¿›ç¨‹æ•°ç¤ºä¾‹ï¼ˆä½ éœ€è¦è‡ªå·±è®¾ç½®ï¼‰</span></span>
<span id="cb17-16"><a href="#cb17-16"></a>task_args_list <span class="op">=</span> [(<span class="st">"a"</span>,), (<span class="st">"b"</span>,), (<span class="st">"c"</span>,), (<span class="st">"d"</span>,)]  <span class="co"># æ¯ä¸ªè¿›ç¨‹çš„å‚æ•°ç¤ºä¾‹ï¼ˆä½ éœ€è¦æ›¿æ¢æˆçœŸå®å‚æ•°ï¼‰</span></span>
<span id="cb17-17"><a href="#cb17-17"></a></span>
<span id="cb17-18"><a href="#cb17-18"></a>out_queue: Queue <span class="op">=</span> manager.Queue() <span class="co"># åˆ›å»ºè¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—</span></span>
<span id="cb17-19"><a href="#cb17-19"></a>processes: <span class="bu">list</span>[Process] <span class="op">=</span> []  <span class="co"># ä¿å­˜æ‰€æœ‰è¿›ç¨‹å¯¹è±¡ï¼Œæ–¹ä¾¿åé¢ join</span></span>
<span id="cb17-20"><a href="#cb17-20"></a></span>
<span id="cb17-21"><a href="#cb17-21"></a><span class="cf">for</span> args <span class="kw">in</span> task_args_list:  <span class="co"># éå†æ¯ä¸ªä»»åŠ¡çš„å‚æ•°</span></span>
<span id="cb17-22"><a href="#cb17-22"></a>    p <span class="op">=</span> Process(target<span class="op">=</span>task_worker, args<span class="op">=</span>(out_queue, <span class="op">*</span>args))  <span class="co"># åˆ›å»ºè¿›ç¨‹ï¼Œå¹¶æŠŠé˜Ÿåˆ—+å‚æ•°ä¼ ç»™ worker</span></span>
<span id="cb17-23"><a href="#cb17-23"></a>    processes.append(p)  <span class="co"># è®°å½•è¿›ç¨‹å¯¹è±¡</span></span>
<span id="cb17-24"><a href="#cb17-24"></a>    p.start()  <span class="co"># å¯åŠ¨è¿›ç¨‹å¼€å§‹æ‰§è¡Œ</span></span>
<span id="cb17-25"><a href="#cb17-25"></a></span>
<span id="cb17-26"><a href="#cb17-26"></a>all_out <span class="op">=</span> Counter()  <span class="co"># ä¸»è¿›ç¨‹çš„æ€» Counterï¼Œç”¨äºç´¯åŠ æ‰€æœ‰éƒ¨åˆ†ç»“æœ</span></span>
<span id="cb17-27"><a href="#cb17-27"></a></span>
<span id="cb17-28"><a href="#cb17-28"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(processes)):  <span class="co"># é¢„æœŸæ¯ä¸ªè¿›ç¨‹éƒ½ä¼š put ä¸€æ¬¡ç»“æœï¼Œæ‰€ä»¥æ”¶ len(processes) æ¬¡</span></span>
<span id="cb17-29"><a href="#cb17-29"></a>    <span class="cf">try</span>:</span>
<span id="cb17-30"><a href="#cb17-30"></a>        partial_out <span class="op">=</span> out_queue.get(timeout<span class="op">=</span><span class="dv">10</span>)  <span class="co"># ä»é˜Ÿåˆ—å–ä¸€ä¸ªç»“æœï¼Œæœ€å¤šç­‰å¾… 10 ç§’</span></span>
<span id="cb17-31"><a href="#cb17-31"></a>        all_out.update(partial_out)  <span class="co"># æŠŠè¿™ä¸ªè¿›ç¨‹çš„ Counter åˆå¹¶åˆ°æ€» Counter</span></span>
<span id="cb17-32"><a href="#cb17-32"></a>    <span class="cf">except</span> queue.Empty:  <span class="co"># å¦‚æœè¶…æ—¶æ²¡å–åˆ°ï¼Œå°±è·³è¿‡</span></span>
<span id="cb17-33"><a href="#cb17-33"></a>        <span class="cf">continue</span>  <span class="co"># ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª</span></span>
<span id="cb17-34"><a href="#cb17-34"></a></span>
<span id="cb17-35"><a href="#cb17-35"></a><span class="cf">for</span> p <span class="kw">in</span> processes:  <span class="co"># éå†æ‰€æœ‰è¿›ç¨‹</span></span>
<span id="cb17-36"><a href="#cb17-36"></a>    p.join()  <span class="co"># ç­‰å¾…è¿›ç¨‹ç»“æŸ</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>æœ‰äº†è¿™äº›å‰ç½®çŸ¥è¯†ä¹‹åï¼Œå®ç°è¿™ä¸ªPre-Processingçš„æ­¥éª¤å°±å¾ˆå®¹æ˜“äº†ï¼Œä»¥ä¸‹æ˜¯Pre-processçš„ä»£ç </p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/tokenizer.py</strong></pre>
</div>
<div class="sourceCode" id="cb18" data-filename="cs336_basics/tokenizer/tokenizer.py" data-code-line-numbers="32"><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">def</span> pre_tokenize_string_worker(<span class="op">*</span>args):</span>
<span id="cb18-2"><a href="#cb18-2"></a>    input_path, special_tokens, queue, start, end, include_special <span class="op">=</span> args</span>
<span id="cb18-3"><a href="#cb18-3"></a></span>
<span id="cb18-4"><a href="#cb18-4"></a>    <span class="co"># Read the chunk from the file</span></span>
<span id="cb18-5"><a href="#cb18-5"></a>    <span class="cf">with</span> <span class="bu">open</span>(input_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb18-6"><a href="#cb18-6"></a>        f.seek(start)</span>
<span id="cb18-7"><a href="#cb18-7"></a>        chunk <span class="op">=</span> f.read(end <span class="op">-</span> start).decode(<span class="st">"utf-8"</span>, errors<span class="op">=</span><span class="st">"ignore"</span>)</span>
<span id="cb18-8"><a href="#cb18-8"></a></span>
<span id="cb18-9"><a href="#cb18-9"></a>    word_counter <span class="op">=</span> pre_tokenize(chunk, special_tokens, include_special)</span>
<span id="cb18-10"><a href="#cb18-10"></a></span>
<span id="cb18-11"><a href="#cb18-11"></a>    <span class="co"># Put the result in the queue</span></span>
<span id="cb18-12"><a href="#cb18-12"></a>    queue.put(word_counter)</span>
<span id="cb18-13"><a href="#cb18-13"></a></span>
<span id="cb18-14"><a href="#cb18-14"></a><span class="kw">def</span> train_bpe():</span>
<span id="cb18-15"><a href="#cb18-15"></a>    <span class="cf">with</span> <span class="bu">open</span>(input_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb18-16"><a href="#cb18-16"></a>        chunk_boundaries <span class="op">=</span> find_chunk_boundaries(</span>
<span id="cb18-17"><a href="#cb18-17"></a>            f, desired_num_chunks<span class="op">=</span>kwargs.get(<span class="st">"desired_num_chunks"</span>, NUM_PROCESSES), split_special_token<span class="op">=</span><span class="st">b"</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb18-18"><a href="#cb18-18"></a>        )</span>
<span id="cb18-19"><a href="#cb18-19"></a>    </span>
<span id="cb18-20"><a href="#cb18-20"></a>    manager <span class="op">=</span> Manager()</span>
<span id="cb18-21"><a href="#cb18-21"></a>    queue <span class="op">=</span> manager.Queue()</span>
<span id="cb18-22"><a href="#cb18-22"></a>    processes: <span class="bu">list</span>[Process] <span class="op">=</span> []</span>
<span id="cb18-23"><a href="#cb18-23"></a>    </span>
<span id="cb18-24"><a href="#cb18-24"></a>    <span class="cf">for</span> start, end <span class="kw">in</span> <span class="bu">zip</span>(chunk_boundaries[:<span class="op">-</span><span class="dv">1</span>], chunk_boundaries[<span class="dv">1</span>:]):</span>
<span id="cb18-25"><a href="#cb18-25"></a>        p <span class="op">=</span> Process(</span>
<span id="cb18-26"><a href="#cb18-26"></a>            target<span class="op">=</span>pre_tokenize_string_worker,</span>
<span id="cb18-27"><a href="#cb18-27"></a>            args<span class="op">=</span>(input_path, special_tokens, queue, start, end, <span class="va">False</span>),</span>
<span id="cb18-28"><a href="#cb18-28"></a>        )</span>
<span id="cb18-29"><a href="#cb18-29"></a>        processes.append(p)</span>
<span id="cb18-30"><a href="#cb18-30"></a>        p.start()</span>
<span id="cb18-31"><a href="#cb18-31"></a></span>
<span id="cb18-32"><a href="#cb18-32"></a>    word_counter <span class="op">=</span> Counter() </span>
<span id="cb18-33"><a href="#cb18-33"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(processes)):</span>
<span id="cb18-34"><a href="#cb18-34"></a>        <span class="cf">try</span>:</span>
<span id="cb18-35"><a href="#cb18-35"></a>            partial_counter <span class="op">=</span> queue.get(timeout<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-36"><a href="#cb18-36"></a>            word_counter.update(partial_counter)</span>
<span id="cb18-37"><a href="#cb18-37"></a>        <span class="cf">except</span> Empty:</span>
<span id="cb18-38"><a href="#cb18-38"></a>            <span class="cf">continue</span></span>
<span id="cb18-39"><a href="#cb18-39"></a>    <span class="cf">for</span> p <span class="kw">in</span> processes:</span>
<span id="cb18-40"><a href="#cb18-40"></a>        p.join()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>é€šè¿‡è¿™ä¸ªåˆé›†ï¼Œæˆ‘ä»¬çš„å¾—åˆ°äº† <code>word_counter</code> è¿™ä¸ªå˜é‡. å®ƒè®°å½•äº†æ¯ä¸ª pre-tokenï¼ˆbyte/id åºåˆ—ï¼‰åœ¨æ•´ä¸ªè¯­æ–™ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥åŸºäºè¿™ä¸ª <code>word_counter</code> æ¥ç»Ÿè®¡ pair é¢‘æ¬¡ï¼Œå¹¶è¿›è¡Œ BPE åˆå¹¶äº†.</p>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p>Multi-Processing æ³¨æ„äº‹é¡¹</p>
</div>
<div class="note-container foldable-content">
<p>éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œè¿›ç¨‹æ•°ï¼ˆNUM_PROCESSORï¼‰å¹¶ä¸æ˜¯è¶Šå¤šè¶Šå¥½ã€‚åœ¨å®é™…å®ç°ä¸­ï¼Œå½“è¿›ç¨‹æ•°ç»§ç»­å¢å¤§æ—¶ï¼Œæ•´ä½“é€Ÿåº¦åè€Œå¯èƒ½å˜æ…¢ï¼Œä¸»è¦åŸå› æœ‰ä¸‰ç‚¹ï¼š</p>
<ol type="1">
<li>åˆ›å»ºä¸è°ƒåº¦å¼€é”€ï¼šå¯åŠ¨å¤šä¸ªè¿›ç¨‹æœ¬èº«å°±æœ‰æˆæœ¬ï¼ˆfork/spawnã€åˆå§‹åŒ–ã€è°ƒåº¦ï¼‰ï¼Œä»»åŠ¡è¶Šç»†ç¢ï¼Œè¿™éƒ¨åˆ†å¼€é”€å æ¯”è¶Šé«˜ã€‚</li>
<li>è·¨è¿›ç¨‹é€šä¿¡æˆæœ¬ï¼šå¤šè¿›ç¨‹ä¹‹é—´éœ€è¦ä¼ é€’æ•°æ®ï¼ˆä¾‹å¦‚æŠŠ chunk åˆ†å‘ç»™ workerã€å†æŠŠç»Ÿè®¡ç»“æœæ±‡æ€»å›æ¥ï¼‰ï¼Œä¼šå¼•å…¥åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼ˆpickleï¼‰ä»¥åŠ IPC çš„é¢å¤–è€—æ—¶ã€‚</li>
<li>å†…å­˜ä¸ç¼“å­˜å‹åŠ›ï¼šè¿›ç¨‹è¶Šå¤šï¼Œå¾€å¾€ä¼šå¸¦æ¥æ›´é«˜çš„å†…å­˜å ç”¨ä¸ cache/memory bandwidth ç«äº‰ï¼Œåè€Œæ‹–æ…¢ååã€‚</li>
</ol>
<p>å› æ­¤ï¼Œå¤šè¿›ç¨‹çš„æœ€ä½³æ•°é‡é€šå¸¸å–å†³äºï¼šä»»åŠ¡ç²’åº¦ã€æ•°æ®è§„æ¨¡ã€CPU æ ¸æ•°ã€ä»¥åŠ IPC çš„æ¯”ä¾‹ã€‚åœ¨æœ¬æ¬¡ Assignment çš„è¯­æ–™è§„æ¨¡ä¸å®ç°æ–¹å¼ä¸‹ï¼Œä¸€ä¸ªç»éªŒä¸Šæ›´ç¨³çš„é€‰æ‹©æ˜¯ <code>NUM_PROCESSOR=4</code>ï¼šæ—¢èƒ½è·å¾—æ˜æ˜¾çš„å¹¶è¡ŒåŠ é€Ÿï¼Œåˆèƒ½é¿å…è¿‡å¤šè¿›ç¨‹å¸¦æ¥çš„é¢å¤–å¼€é”€ä¸æ‹¥å¡ã€‚</p>
</div>
</div>
</section>
<section id="others" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="others"><span class="header-section-number">2.3.4</span> Others</h3>
<p>é™¤äº† word_counterï¼ˆè®°å½•æ¯ä¸ª word/token åºåˆ—å‡ºç°æ¬¡æ•°ï¼‰ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä¼šé¢å¤–æ„å»ºä¸¤ä¸ªè¾…åŠ©ç»“æ„ï¼Œæ¥æ”¯æŒåç»­ æ›´é«˜æ•ˆçš„ pair ç»Ÿè®¡ä¸æ›´æ–°ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/tokenizer.py</strong></pre>
</div>
<div class="sourceCode" id="cb19" data-filename="cs336_basics/tokenizer/tokenizer.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>pairs_counter <span class="op">=</span> Counter()</span>
<span id="cb19-2"><a href="#cb19-2"></a>pair_to_words: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">set</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...]]] <span class="op">=</span> defaultdict(<span class="bu">set</span>)</span>
<span id="cb19-3"><a href="#cb19-3"></a><span class="cf">for</span> word <span class="kw">in</span> word_counter:</span>
<span id="cb19-4"><a href="#cb19-4"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(word) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb19-5"><a href="#cb19-5"></a>        pair <span class="op">=</span> (word[i], word[i <span class="op">+</span> <span class="dv">1</span>])</span>
<span id="cb19-6"><a href="#cb19-6"></a>        pair_to_words[pair].add(word)</span>
<span id="cb19-7"><a href="#cb19-7"></a>        pairs_counter[pair] <span class="op">+=</span> word_counter[word]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><code>pairs_counter[pair]</code>ï¼šè®°å½•è¯¥ç›¸é‚» pair åœ¨å…¨è¯­æ–™ä¸­çš„æ€»å‡ºç°æ¬¡æ•°ã€‚ å› ä¸ºæ¯ä¸ª word åœ¨è¯­æ–™ä¸­å‡ºç°äº† <code>word_counter[word]</code> æ¬¡ï¼Œæ‰€ä»¥ word å†…éƒ¨æ¯å‡ºç°ä¸€æ¬¡ pairï¼Œå°±ä¸ºå…¨å±€é¢‘æ¬¡è´¡çŒ® <code>word_counter[word]</code>ã€‚</li>
<li><code>pair_to_words[pair]</code>ï¼šè®°å½•è¯¥ pair å‡ºç°åœ¨å“ªäº› wordï¼ˆtoken åºåˆ—ï¼‰é‡Œ, è¿™ä¸ªæ˜ å°„éå¸¸å…³é”®ï¼šå½“æˆ‘ä»¬é€‰æ‹©æŸä¸ª pair è¿›è¡Œ merge æ—¶ï¼Œåªæœ‰åŒ…å«è¯¥ pair çš„ word ä¼šå‘ç”Ÿå˜åŒ–ã€‚å€ŸåŠ© <code>pair_to_words</code>ï¼Œæˆ‘ä»¬å¯ä»¥åªéå†è¿™äº›â€œå—å½±å“çš„ wordsâ€ï¼Œå¹¶å¯¹ <code>pairs_counter</code> åšå±€éƒ¨å¢é‡æ›´æ–°ï¼Œè€Œä¸æ˜¯æ¯è½®éƒ½é‡æ–°æ‰«æå…¨éƒ¨ <code>word_counter</code>ã€‚</li>
</ul>
</section>
</section>
<section id="bpe-version-1-using-heap" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="bpe-version-1-using-heap"><span class="header-section-number">2.4</span> BPE Version 1: Using Heap</h2>
<p>ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„ä¼˜åŒ–ç‚¹æ˜¯ï¼šæ¯ä¸€è½®éƒ½è¦æ‰¾å½“å‰é¢‘ç‡æœ€é«˜çš„ pairã€‚åœ¨ Version 0 (<a href="#sec-bpe-v0" class="quarto-xref">Section&nbsp;2.2</a>) é‡Œï¼Œæˆ‘ä»¬æ¯è½®éƒ½é€šè¿‡éå† pairs_counter æ¥å–æœ€å¤§å€¼ï¼Œè¿™ä¸€æ­¥æ˜¯ <span class="math inline">\(\mathcal{O}(n)\)</span>ï¼ˆ<span class="math inline">\(n\)</span> æ˜¯ pair çš„æ•°é‡ï¼‰ã€‚è€Œè¿™ä¸ªæ“ä½œæ­£å¥½ç¬¦åˆå †ï¼ˆheapï¼‰çš„ä½¿ç”¨åœºæ™¯ï¼šç”¨å †ç»´æŠ¤â€œå½“å‰æœ€å¤§çš„å…ƒç´ â€ï¼Œå°±èƒ½æŠŠâ€œå–æœ€å¤§â€é™åˆ° <span class="math inline">\(\mathcal{O}(\log n)\)</span>ï¼ˆä¸¥æ ¼æ¥è¯´æ˜¯ï¼šå–å †é¡¶æ˜¯ <span class="math inline">\(\mathcal{O}(1)\)</span>ï¼Œä½†å¦‚æœåŒ…å« pop/push æ›´æ–°åˆ™æ˜¯ <span class="math inline">\(\mathcal{O}(\log n)\)</span>ï¼‰ã€‚</p>
<p>å…·ä½“åšæ³•æ˜¯æŠŠæ¯ä¸ª pair ä½œä¸ºå †å…ƒç´ ï¼Œå¹¶æŠŠâ€œæ’åºä¾æ®â€è®¾è®¡æˆï¼š</p>
<ul>
<li>é¢‘æ¬¡è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜</li>
<li>é¢‘æ¬¡ç›¸åŒåˆ™æŒ‰ pair çš„å­—å…¸åºæ›´å¤§è€…ä¼˜å…ˆ</li>
</ul>
<p>åœ¨ Python çš„ <a href="https://docs.python.org/3/library/heapq.html">heapq</a> æ˜¯æœ€å°å †ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç”¨è´Ÿå·æŠŠå®ƒå˜æˆâ€œæœ€å¤§å †â€ï¼Œä¾‹å¦‚å­˜æˆï¼š</p>
<ul>
<li><strong>key = (-freq, -a, -b)</strong></li>
</ul>
<p>è¿™æ ·æ¯ä¸€è½®æˆ‘ä»¬éƒ½èƒ½å¿«é€Ÿæ‹¿åˆ°å€™é€‰çš„â€œæœ€å¸¸è§ pairâ€ã€‚</p>
<p>ä¸è¿‡è¦æ³¨æ„ä¸€ç‚¹ï¼šé¢‘æ¬¡åœ¨ merge ä¹‹åä¼šå‘ç”Ÿå˜åŒ–ï¼Œå› æ­¤å †é‡Œæ—§çš„æ¡ç›®å¯èƒ½å˜â€œè¿‡æœŸâ€ã€‚åœ¨ pop å †é¡¶æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥è¯¥ pair çš„å½“å‰é¢‘æ¬¡æ˜¯å¦å’Œå †é‡Œå­˜çš„é¢‘æ¬¡ä¸€è‡´ï¼›å¦‚æœä¸ä¸€è‡´ï¼Œè¯´æ˜å †é¡¶æ˜¯è¿‡æœŸçš„ï¼Œå°±ç»§ç»­ pop ç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„ pairã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/merge_fn.py</strong></pre>
</div>
<div class="sourceCode" id="cb20" data-filename="cs336_basics/tokenizer/merge_fn.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">class</span> HeapItem:</span>
<span id="cb20-2"><a href="#cb20-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, neg_freq: <span class="bu">int</span>, pair_bytes: <span class="bu">tuple</span>[<span class="bu">bytes</span>, <span class="bu">bytes</span>], pair: <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]):</span>
<span id="cb20-3"><a href="#cb20-3"></a>        <span class="va">self</span>.neg_freq <span class="op">=</span> neg_freq</span>
<span id="cb20-4"><a href="#cb20-4"></a>        <span class="va">self</span>.pair_bytes <span class="op">=</span> pair_bytes</span>
<span id="cb20-5"><a href="#cb20-5"></a>        <span class="va">self</span>.pair <span class="op">=</span> pair</span>
<span id="cb20-6"><a href="#cb20-6"></a></span>
<span id="cb20-7"><a href="#cb20-7"></a>    <span class="kw">def</span> <span class="fu">__lt__</span>(<span class="va">self</span>, other: <span class="st">"HeapItem"</span>) <span class="op">-&gt;</span> <span class="bu">bool</span>:</span>
<span id="cb20-8"><a href="#cb20-8"></a>        <span class="cf">if</span> <span class="va">self</span>.neg_freq <span class="op">!=</span> other.neg_freq:</span>
<span id="cb20-9"><a href="#cb20-9"></a>            <span class="cf">return</span> <span class="va">self</span>.neg_freq <span class="op">&lt;</span> other.neg_freq</span>
<span id="cb20-10"><a href="#cb20-10"></a>        <span class="cf">return</span> <span class="va">self</span>.pair_bytes <span class="op">&gt;</span> other.pair_bytes  <span class="co"># reverse order for max-heap behavior</span></span>
<span id="cb20-11"><a href="#cb20-11"></a></span>
<span id="cb20-12"><a href="#cb20-12"></a></span>
<span id="cb20-13"><a href="#cb20-13"></a><span class="kw">def</span> build_pair_heap(pairs_freqs: Counter, vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>]):</span>
<span id="cb20-14"><a href="#cb20-14"></a>    heap <span class="op">=</span> []</span>
<span id="cb20-15"><a href="#cb20-15"></a>    <span class="cf">for</span> (a, b), f <span class="kw">in</span> pairs_freqs.items():</span>
<span id="cb20-16"><a href="#cb20-16"></a>        <span class="cf">if</span> f <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb20-17"><a href="#cb20-17"></a>            item <span class="op">=</span> HeapItem(<span class="op">-</span>f, (vocab[a], vocab[b]), (a, b))</span>
<span id="cb20-18"><a href="#cb20-18"></a>            heapq.heappush(heap, item)</span>
<span id="cb20-19"><a href="#cb20-19"></a>    <span class="cf">return</span> heap</span>
<span id="cb20-20"><a href="#cb20-20"></a></span>
<span id="cb20-21"><a href="#cb20-21"></a></span>
<span id="cb20-22"><a href="#cb20-22"></a><span class="kw">def</span> pop_most_frequent_pair(heap, pairs_counter: Counter) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]:</span>
<span id="cb20-23"><a href="#cb20-23"></a>    <span class="cf">while</span> heap:</span>
<span id="cb20-24"><a href="#cb20-24"></a>        item <span class="op">=</span> heap[<span class="dv">0</span>]  <span class="co"># Peek at the top item</span></span>
<span id="cb20-25"><a href="#cb20-25"></a>        neg_f <span class="op">=</span> item.neg_freq</span>
<span id="cb20-26"><a href="#cb20-26"></a>        pair <span class="op">=</span> item.pair</span>
<span id="cb20-27"><a href="#cb20-27"></a>        cur_f <span class="op">=</span> pairs_counter.get(pair, <span class="dv">0</span>)</span>
<span id="cb20-28"><a href="#cb20-28"></a>        <span class="cf">if</span> cur_f <span class="op">&lt;=</span> <span class="dv">0</span> <span class="kw">or</span> <span class="op">-</span>neg_f <span class="op">!=</span> cur_f:  <span class="co"># frequency changed, which means the pair we store in heap is stale</span></span>
<span id="cb20-29"><a href="#cb20-29"></a>            heapq.heappop(heap)</span>
<span id="cb20-30"><a href="#cb20-30"></a>            <span class="cf">continue</span></span>
<span id="cb20-31"><a href="#cb20-31"></a>        <span class="cf">return</span> pair</span>
<span id="cb20-32"><a href="#cb20-32"></a></span>
<span id="cb20-33"><a href="#cb20-33"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"No positive-frequency pairs remain"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="bpe-version-2-using-heap-indexing" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="bpe-version-2-using-heap-indexing"><span class="header-section-number">2.5</span> BPE Version 2: Using Heap + Indexing</h2>
<p>é™¤äº†ç”¨ Heap åŠ é€Ÿâ€œé€‰å‡ºé¢‘ç‡æœ€é«˜çš„ pairâ€ï¼Œå¦ä¸€ä¸ªæ›´å…³é”®çš„ç“¶é¢ˆåœ¨äº merge æ›´æ–°é˜¶æ®µï¼šåœ¨ Version 0{<a href="#sec-bpe-v0" class="quarto-xref">Section&nbsp;2.2</a>} é‡Œï¼Œæˆ‘ä»¬æ¯ä¸€è½®éƒ½ä¼šéå† word_counter é‡Œçš„æ‰€æœ‰ wordï¼Œæ£€æŸ¥è¿™ä¸ª word é‡Œæ˜¯å¦å‡ºç°äº†ç›®æ ‡ pairï¼›è¿™ä¸€æ­¥çš„ä»£ä»·é€šå¸¸éå¸¸é«˜ï¼Œå› ä¸ºç»å¤§å¤šæ•° word æ ¹æœ¬ä¸åŒ…å« å½“å‰è¦ merge çš„ pairï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯æŠŠå®ƒä»¬éƒ½æ‰«äº†ä¸€éã€‚</p>
<p>å› æ­¤æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªâ€œå€’æ’ç´¢å¼•â€æ¥åš ç©ºé—´æ¢æ—¶é—´ï¼šæå‰ç»´æŠ¤ä¸€ä¸ªæ˜ å°„ pair -&gt; {wordsâ€¦}ï¼Œè®°å½•æ¯ä¸ª pair å‡ºç°åœ¨å“ªäº› word ä¸­ã€‚è¿™æ ·å½“æˆ‘ä»¬å†³å®š merge æŸä¸ª pair æ—¶ï¼Œå°±åªéœ€è¦éå† pair_to_words[pair] é‡Œçš„é‚£ä¸€å°éƒ¨åˆ† wordï¼Œè€Œä¸å¿…å…¨é‡æ‰«ææ‰€æœ‰ wordã€‚</p>
<p>è¿™ä¹Ÿæ­£æ˜¯æˆ‘ä»¬æ­å»º pair_to_words çš„åŸå› ï¼š</p>
<ul>
<li>æ²¡æœ‰ç´¢å¼•ï¼šæ¯è½® merge éƒ½æ˜¯ å…¨é‡æ‰«ææ‰€æœ‰ wordsï¼ˆæ…¢ï¼Œ<span class="math inline">\(\mathcal{O}(\#words)\)</span> çº§åˆ«ï¼‰ã€‚</li>
<li>æœ‰ç´¢å¼•ï¼šæ¯è½®åªå¤„ç† åŒ…å«è¯¥ pair çš„ words å­é›†ï¼ˆå¿«ï¼Œå¤æ‚åº¦å–å†³äºè¯¥ pair çš„è¦†ç›–èŒƒå›´ï¼Œé€šå¸¸è¿œå°äºå…¨é‡ï¼‰ã€‚</li>
</ul>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨ merge ä¹‹åï¼Œæ›´æ–°è¿™ä¸ªç´¢å¼•ï¼šå½“æŸä¸ª pair è¢« merge æˆä¸€ä¸ªæ–° token åï¼Œæ‰€æœ‰åŒ…å«è¯¥ pair çš„ word éƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æŠŠè¿™äº› word ä»æ—§ pair çš„ç´¢å¼•é‡Œç§»é™¤ï¼Œå¹¶æŠŠå®ƒä»¬æ·»åŠ åˆ°æ–° pair çš„ç´¢å¼•é‡Œã€‚å…·ä½“å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/merge_fn.py</strong></pre>
</div>
<div class="sourceCode" id="cb21" data-filename="cs336_basics/tokenizer/merge_fn.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="kw">def</span> merge_pairs_with_heap_index(</span>
<span id="cb21-2"><a href="#cb21-2"></a>    word_counter: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...], <span class="bu">int</span>],</span>
<span id="cb21-3"><a href="#cb21-3"></a>    pair_counter: Counter,</span>
<span id="cb21-4"><a href="#cb21-4"></a>    target_pair: <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>],</span>
<span id="cb21-5"><a href="#cb21-5"></a>    new_id: <span class="bu">int</span>,</span>
<span id="cb21-6"><a href="#cb21-6"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>],</span>
<span id="cb21-7"><a href="#cb21-7"></a>    pair_heap,</span>
<span id="cb21-8"><a href="#cb21-8"></a>    pair_to_words: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">set</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...]]],</span>
<span id="cb21-9"><a href="#cb21-9"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[</span>
<span id="cb21-10"><a href="#cb21-10"></a>    <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...], <span class="bu">int</span>],</span>
<span id="cb21-11"><a href="#cb21-11"></a>    Counter,</span>
<span id="cb21-12"><a href="#cb21-12"></a>    <span class="bu">list</span>,</span>
<span id="cb21-13"><a href="#cb21-13"></a>    <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">set</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...]]],</span>
<span id="cb21-14"><a href="#cb21-14"></a>]:</span>
<span id="cb21-15"><a href="#cb21-15"></a>    <span class="co"># Start from full counters so unaffected words remain.</span></span>
<span id="cb21-16"><a href="#cb21-16"></a>    new_word_counter: Counter <span class="op">=</span> Counter(word_counter)</span>
<span id="cb21-17"><a href="#cb21-17"></a>    updated_pair_counter: Counter <span class="op">=</span> pair_counter.copy()</span>
<span id="cb21-18"><a href="#cb21-18"></a>    changed_pairs: <span class="bu">set</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]] <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb21-19"><a href="#cb21-19"></a></span>
<span id="cb21-20"><a href="#cb21-20"></a>    <span class="co"># Get all words that contain the target pair.</span></span>
<span id="cb21-21"><a href="#cb21-21"></a>    affected_words <span class="op">=</span> <span class="bu">list</span>(pair_to_words.get(target_pair, <span class="bu">set</span>()))</span>
<span id="cb21-22"><a href="#cb21-22"></a></span>
<span id="cb21-23"><a href="#cb21-23"></a>    <span class="cf">for</span> w <span class="kw">in</span> affected_words:</span>
<span id="cb21-24"><a href="#cb21-24"></a>        freq <span class="op">=</span> word_counter.get(w, <span class="dv">0</span>)</span>
<span id="cb21-25"><a href="#cb21-25"></a>        <span class="cf">if</span> freq <span class="op">&lt;=</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(w) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb21-26"><a href="#cb21-26"></a>            <span class="cf">continue</span></span>
<span id="cb21-27"><a href="#cb21-27"></a></span>
<span id="cb21-28"><a href="#cb21-28"></a>        <span class="co"># 1. Remove the old word from the corpus counts.</span></span>
<span id="cb21-29"><a href="#cb21-29"></a>        new_word_counter[w] <span class="op">-=</span> freq</span>
<span id="cb21-30"><a href="#cb21-30"></a>        <span class="cf">if</span> new_word_counter[w] <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb21-31"><a href="#cb21-31"></a>            <span class="kw">del</span> new_word_counter[w]</span>
<span id="cb21-32"><a href="#cb21-32"></a></span>
<span id="cb21-33"><a href="#cb21-33"></a>        <span class="co"># 2. Subtract ALL old adjacent pairs for this word + remove old word from index.</span></span>
<span id="cb21-34"><a href="#cb21-34"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(w) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb21-35"><a href="#cb21-35"></a>            pair <span class="op">=</span> (w[i], w[i <span class="op">+</span> <span class="dv">1</span>])</span>
<span id="cb21-36"><a href="#cb21-36"></a>            updated_pair_counter[pair] <span class="op">-=</span> freq</span>
<span id="cb21-37"><a href="#cb21-37"></a>            changed_pairs.add(pair)</span>
<span id="cb21-38"><a href="#cb21-38"></a></span>
<span id="cb21-39"><a href="#cb21-39"></a>            s <span class="op">=</span> pair_to_words.get(pair)</span>
<span id="cb21-40"><a href="#cb21-40"></a>            <span class="cf">if</span> s <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-41"><a href="#cb21-41"></a>                s.discard(w)</span>
<span id="cb21-42"><a href="#cb21-42"></a>                <span class="cf">if</span> <span class="kw">not</span> s:</span>
<span id="cb21-43"><a href="#cb21-43"></a>                    <span class="kw">del</span> pair_to_words[pair]</span>
<span id="cb21-44"><a href="#cb21-44"></a></span>
<span id="cb21-45"><a href="#cb21-45"></a>        <span class="co"># 3. Build merged word (greedy left-to-right, same as standard BPE).</span></span>
<span id="cb21-46"><a href="#cb21-46"></a>        new_word <span class="op">=</span> get_new_word(w, target_pair, new_id)</span>
<span id="cb21-47"><a href="#cb21-47"></a>        new_word_counter[new_word] <span class="op">+=</span> freq</span>
<span id="cb21-48"><a href="#cb21-48"></a></span>
<span id="cb21-49"><a href="#cb21-49"></a>        <span class="co"># 4. Add ALL new adjacent pairs for merged word + add merged word into index.</span></span>
<span id="cb21-50"><a href="#cb21-50"></a>        <span class="cf">if</span> <span class="bu">len</span>(new_word) <span class="op">&gt;=</span> <span class="dv">2</span>:</span>
<span id="cb21-51"><a href="#cb21-51"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(new_word) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb21-52"><a href="#cb21-52"></a>                pair <span class="op">=</span> (new_word[i], new_word[i <span class="op">+</span> <span class="dv">1</span>])</span>
<span id="cb21-53"><a href="#cb21-53"></a>                updated_pair_counter[pair] <span class="op">+=</span> freq</span>
<span id="cb21-54"><a href="#cb21-54"></a>                changed_pairs.add(pair)</span>
<span id="cb21-55"><a href="#cb21-55"></a>                pair_to_words.setdefault(pair, <span class="bu">set</span>()).add(new_word)</span>
<span id="cb21-56"><a href="#cb21-56"></a></span>
<span id="cb21-57"><a href="#cb21-57"></a>    <span class="co"># 5. Push updated frequencies for changed pairs into heap (skip non-positive).</span></span>
<span id="cb21-58"><a href="#cb21-58"></a>    <span class="cf">if</span> pair_heap <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-59"><a href="#cb21-59"></a>        <span class="cf">for</span> p <span class="kw">in</span> changed_pairs:</span>
<span id="cb21-60"><a href="#cb21-60"></a>            f <span class="op">=</span> updated_pair_counter.get(p, <span class="dv">0</span>)</span>
<span id="cb21-61"><a href="#cb21-61"></a>            <span class="cf">if</span> f <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb21-62"><a href="#cb21-62"></a>                heapq.heappush(pair_heap, HeapItem(<span class="op">-</span>f, (vocab[p[<span class="dv">0</span>]], vocab[p[<span class="dv">1</span>]]), p))</span>
<span id="cb21-63"><a href="#cb21-63"></a></span>
<span id="cb21-64"><a href="#cb21-64"></a>    <span class="cf">return</span> <span class="bu">dict</span>(new_word_counter), updated_pair_counter, pair_heap, pair_to_words</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>æœ‰äº†è¿™ä¸¤ä¸ªä¼˜åŒ–çš„ç‚¹ï¼ŒBPEçš„è®­ç»ƒé€Ÿåº¦å¯ä»¥å¤§å¤§çš„æå‡ï¼Œ</p>
<div>
<table class="table-hover table">
<caption>Comparison of BPE Versions</caption>
<colgroup>
<col style="width: 27%">
<col style="width: 31%">
<col style="width: 26%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th><strong>ç‰ˆæœ¬</strong></th>
<th><strong>æ‰¾æœ€é¢‘ç¹ pair</strong></th>
<th><strong>æ›´æ–°è®¡æ•°</strong></th>
<th><strong>è®­ç»ƒä¸»å¾ªç¯ç“¶é¢ˆ</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>v0</td>
<td>æ¯è½®æ‰«ä¸€é pairs (<span class="math inline">\(\mathcal{O}(\#pairs)\)</span>)</td>
<td>æ¯è½®é‡ç®—</td>
<td>å¾ˆæ…¢</td>
</tr>
<tr class="even">
<td>heap</td>
<td>pop <span class="math inline">\(\mathcal{O}(\log \#pairs)\)</span></td>
<td>ä»å¯èƒ½æ‰«å¾ˆå¤š</td>
<td>æ›´å¿«</td>
</tr>
<tr class="odd">
<td>heap + pair_to_words</td>
<td>pop <span class="math inline">\(\mathcal{O}(\log \#pairs)\)</span></td>
<td>åªæ›´æ–°å—å½±å“çš„ words/pairs</td>
<td>æ˜æ˜¾æ›´å¿«</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="train-bpe" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="train-bpe"><span class="header-section-number">2.6</span> Train BPE</h2>
<p>å°†ä¸Šé¢çš„å®ç°ï¼Œæ›¿æ¢æˆæˆ‘ä»¬æœ€æ–°çš„å®ç°åï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç°BPEçš„ç®—æ³•ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/tokenizer.py</strong></pre>
</div>
<div class="sourceCode" id="cb22" data-filename="cs336_basics/tokenizer/tokenizer.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="kw">def</span> train_bpe(</span>
<span id="cb22-2"><a href="#cb22-2"></a>    input_path: <span class="bu">str</span> <span class="op">|</span> os.PathLike,</span>
<span id="cb22-3"><a href="#cb22-3"></a>    vocab_size: <span class="bu">int</span>,</span>
<span id="cb22-4"><a href="#cb22-4"></a>    special_tokens: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb22-5"><a href="#cb22-5"></a>    verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb22-6"><a href="#cb22-6"></a>    <span class="op">**</span>kwargs,</span>
<span id="cb22-7"><a href="#cb22-7"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>], <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">bytes</span>, <span class="bu">bytes</span>]]]:</span>
<span id="cb22-8"><a href="#cb22-8"></a>    num_merges <span class="op">=</span> vocab_size <span class="op">-</span> <span class="dv">256</span> <span class="op">-</span> (<span class="bu">len</span>(special_tokens) <span class="cf">if</span> special_tokens <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb22-9"><a href="#cb22-9"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>] <span class="op">=</span> init_vocab(special_tokens)</span>
<span id="cb22-10"><a href="#cb22-10"></a>    merges: <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">bytes</span>, <span class="bu">bytes</span>]] <span class="op">=</span> []</span>
<span id="cb22-11"><a href="#cb22-11"></a></span>
<span id="cb22-12"><a href="#cb22-12"></a>    <span class="co"># 1. Pre-tokenization</span></span>
<span id="cb22-13"><a href="#cb22-13"></a>    <span class="co"># 1.1 Find chunk boundaries</span></span>
<span id="cb22-14"><a href="#cb22-14"></a>    <span class="cf">with</span> <span class="bu">open</span>(input_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb22-15"><a href="#cb22-15"></a>        chunk_boundaries <span class="op">=</span> find_chunk_boundaries(</span>
<span id="cb22-16"><a href="#cb22-16"></a>            f, desired_num_chunks<span class="op">=</span>kwargs.get(<span class="st">"desired_num_chunks"</span>, NUM_PROCESSES), split_special_token<span class="op">=</span><span class="st">b"</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-17"><a href="#cb22-17"></a>        )</span>
<span id="cb22-18"><a href="#cb22-18"></a></span>
<span id="cb22-19"><a href="#cb22-19"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb22-20"><a href="#cb22-20"></a>        print_color(<span class="ss">f"Identified </span><span class="sc">{</span><span class="bu">len</span>(chunk_boundaries) <span class="op">-</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> chunks for pre-tokenization."</span>)</span>
<span id="cb22-21"><a href="#cb22-21"></a></span>
<span id="cb22-22"><a href="#cb22-22"></a>    <span class="co"># 1.2 Count word frequencies across chunks using multiprocessing</span></span>
<span id="cb22-23"><a href="#cb22-23"></a>    manager <span class="op">=</span> Manager()</span>
<span id="cb22-24"><a href="#cb22-24"></a>    queue <span class="op">=</span> manager.Queue()</span>
<span id="cb22-25"><a href="#cb22-25"></a>    processes: <span class="bu">list</span>[Process] <span class="op">=</span> []</span>
<span id="cb22-26"><a href="#cb22-26"></a></span>
<span id="cb22-27"><a href="#cb22-27"></a>    <span class="cf">for</span> start, end <span class="kw">in</span> <span class="bu">zip</span>(chunk_boundaries[:<span class="op">-</span><span class="dv">1</span>], chunk_boundaries[<span class="dv">1</span>:]):</span>
<span id="cb22-28"><a href="#cb22-28"></a>        p <span class="op">=</span> Process(</span>
<span id="cb22-29"><a href="#cb22-29"></a>            target<span class="op">=</span>pre_tokenize_string_worker,</span>
<span id="cb22-30"><a href="#cb22-30"></a>            args<span class="op">=</span>(input_path, special_tokens, queue, start, end, <span class="va">False</span>),</span>
<span id="cb22-31"><a href="#cb22-31"></a>        )</span>
<span id="cb22-32"><a href="#cb22-32"></a>        processes.append(p)</span>
<span id="cb22-33"><a href="#cb22-33"></a>        p.start()</span>
<span id="cb22-34"><a href="#cb22-34"></a></span>
<span id="cb22-35"><a href="#cb22-35"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb22-36"><a href="#cb22-36"></a>        print_color(<span class="st">"Pre-tokenization processes completed. Aggregating results..."</span>)</span>
<span id="cb22-37"><a href="#cb22-37"></a></span>
<span id="cb22-38"><a href="#cb22-38"></a>    word_counter <span class="op">=</span> Counter()</span>
<span id="cb22-39"><a href="#cb22-39"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(processes)):</span>
<span id="cb22-40"><a href="#cb22-40"></a>        <span class="cf">try</span>:</span>
<span id="cb22-41"><a href="#cb22-41"></a>            partial_counter <span class="op">=</span> queue.get(timeout<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-42"><a href="#cb22-42"></a>            word_counter.update(partial_counter)</span>
<span id="cb22-43"><a href="#cb22-43"></a>        <span class="cf">except</span> Empty:</span>
<span id="cb22-44"><a href="#cb22-44"></a>            <span class="cf">continue</span></span>
<span id="cb22-45"><a href="#cb22-45"></a>    <span class="cf">for</span> p <span class="kw">in</span> processes:</span>
<span id="cb22-46"><a href="#cb22-46"></a>        p.join()</span>
<span id="cb22-47"><a href="#cb22-47"></a></span>
<span id="cb22-48"><a href="#cb22-48"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb22-49"><a href="#cb22-49"></a>        print_color(<span class="ss">f"Completed pre-tokenization. Vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(word_counter)<span class="sc">}</span><span class="ss"> unique tokens."</span>)</span>
<span id="cb22-50"><a href="#cb22-50"></a></span>
<span id="cb22-51"><a href="#cb22-51"></a>    pairs_counter <span class="op">=</span> Counter()</span>
<span id="cb22-52"><a href="#cb22-52"></a>    pair_to_words: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">set</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, ...]]] <span class="op">=</span> defaultdict(<span class="bu">set</span>)</span>
<span id="cb22-53"><a href="#cb22-53"></a>    <span class="cf">for</span> word <span class="kw">in</span> word_counter:</span>
<span id="cb22-54"><a href="#cb22-54"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(word) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb22-55"><a href="#cb22-55"></a>            pair <span class="op">=</span> (word[i], word[i <span class="op">+</span> <span class="dv">1</span>])</span>
<span id="cb22-56"><a href="#cb22-56"></a>            pair_to_words[pair].add(word)</span>
<span id="cb22-57"><a href="#cb22-57"></a>            pairs_counter[pair] <span class="op">+=</span> word_counter[word]</span>
<span id="cb22-58"><a href="#cb22-58"></a></span>
<span id="cb22-59"><a href="#cb22-59"></a>    <span class="co"># 2. BPE Core Loop</span></span>
<span id="cb22-60"><a href="#cb22-60"></a>    pair_heap <span class="op">=</span> build_pair_heap(pairs_counter, vocab)</span>
<span id="cb22-61"><a href="#cb22-61"></a></span>
<span id="cb22-62"><a href="#cb22-62"></a>    <span class="cf">for</span> i <span class="kw">in</span> trange(num_merges):</span>
<span id="cb22-63"><a href="#cb22-63"></a>        most_frequent_pair <span class="op">=</span> pop_most_frequent_pair(pair_heap, pairs_counter)</span>
<span id="cb22-64"><a href="#cb22-64"></a>        new_id <span class="op">=</span> update_vocab(vocab, most_frequent_pair)</span>
<span id="cb22-65"><a href="#cb22-65"></a></span>
<span id="cb22-66"><a href="#cb22-66"></a>        word_counter, pairs_counter, pair_heap, pair_to_words <span class="op">=</span> merge_pairs_with_heap_index(</span>
<span id="cb22-67"><a href="#cb22-67"></a>            word_counter, pairs_counter, most_frequent_pair, new_id, vocab, pair_heap, pair_to_words</span>
<span id="cb22-68"><a href="#cb22-68"></a>        )</span>
<span id="cb22-69"><a href="#cb22-69"></a></span>
<span id="cb22-70"><a href="#cb22-70"></a>        merges.append((vocab[most_frequent_pair[<span class="dv">0</span>]], vocab[most_frequent_pair[<span class="dv">1</span>]]))</span>
<span id="cb22-71"><a href="#cb22-71"></a></span>
<span id="cb22-72"><a href="#cb22-72"></a>    <span class="cf">if</span> kwargs.get(<span class="st">"save_path"</span>):</span>
<span id="cb22-73"><a href="#cb22-73"></a>        save_vocab_and_merges(vocab, merges, kwargs[<span class="st">"save_path"</span>])</span>
<span id="cb22-74"><a href="#cb22-74"></a>        <span class="cf">with</span> <span class="bu">open</span>(os.path.join(kwargs[<span class="st">"save_path"</span>], <span class="st">"special_tokens.txt"</span>), <span class="st">"w"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb22-75"><a href="#cb22-75"></a>            <span class="cf">if</span> special_tokens:</span>
<span id="cb22-76"><a href="#cb22-76"></a>                <span class="cf">for</span> token <span class="kw">in</span> special_tokens:</span>
<span id="cb22-77"><a href="#cb22-77"></a>                    f.write(<span class="ss">f"</span><span class="sc">{</span>token<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb22-78"><a href="#cb22-78"></a></span>
<span id="cb22-79"><a href="#cb22-79"></a>    <span class="cf">return</span> vocab, merges</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>è¿è¡Œä¸€ä¸‹æµ‹è¯•ä»£ç </p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>tests/adapters.py</strong></pre>
</div>
<div class="sourceCode" id="cb23" data-filename="tests/adapters.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="im">from</span> cs336_basics.tokenizer.tokenizer <span class="im">import</span> train_bpe</span>
<span id="cb23-2"><a href="#cb23-2"></a></span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="cf">return</span> train_bpe(</span>
<span id="cb23-4"><a href="#cb23-4"></a>    input_path<span class="op">=</span>input_path,</span>
<span id="cb23-5"><a href="#cb23-5"></a>    vocab_size<span class="op">=</span>vocab_size,</span>
<span id="cb23-6"><a href="#cb23-6"></a>    special_tokens<span class="op">=</span>special_tokens,</span>
<span id="cb23-7"><a href="#cb23-7"></a>    <span class="op">**</span>kwargs,</span>
<span id="cb23-8"><a href="#cb23-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb24" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1"></a><span class="ex">uv</span> run pytest tests/test_train_bpe.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æˆ‘ä»¬çœ‹åˆ°ï¼Œæ‰€æœ‰çš„æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ <img src="assets/ass01-train-bpe-test.png" class="img-fluid"></p>
</section>
<section id="bpe-on-tinystory" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="bpe-on-tinystory"><span class="header-section-number">2.7</span> BPE on TinyStory</h2>
<p>åœ¨TinyStoryä¸Šè®­ç»ƒBPEï¼Œ</p>
<div class="sourceCode" id="cb25" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1"></a><span class="ex">uv</span> run python ./train_bpe.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>åªéœ€è¦ä¸åˆ°2minsã€‚</p>
<p><img src="assets/ass01-bpe-tinystories.png" class="img-fluid"></p>
</section>
<section id="bpe-tokenizer" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="bpe-tokenizer"><span class="header-section-number">2.8</span> BPE Tokenizer</h2>
<p>æœ‰äº†<code>vocab</code> <code>merges</code> æˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªBPE Tokenizer</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/tokenizer/tokenizer.py</strong></pre>
</div>
<div class="sourceCode" id="cb26" data-filename="cs336_basics/tokenizer/tokenizer.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="kw">class</span> BPETokenizer:</span>
<span id="cb26-3"><a href="#cb26-3"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb26-4"><a href="#cb26-4"></a>        <span class="va">self</span>,</span>
<span id="cb26-5"><a href="#cb26-5"></a>        vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>],</span>
<span id="cb26-6"><a href="#cb26-6"></a>        merges: <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">bytes</span>, <span class="bu">bytes</span>]],</span>
<span id="cb26-7"><a href="#cb26-7"></a>        special_tokens: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb26-8"><a href="#cb26-8"></a>    ):</span>
<span id="cb26-9"><a href="#cb26-9"></a>        <span class="va">self</span>.vocab <span class="op">=</span> vocab</span>
<span id="cb26-10"><a href="#cb26-10"></a>        <span class="va">self</span>.merges <span class="op">=</span> merges</span>
<span id="cb26-11"><a href="#cb26-11"></a>        <span class="va">self</span>.special_tokens <span class="op">=</span> special_tokens <span class="cf">if</span> special_tokens <span class="cf">else</span> []</span>
<span id="cb26-12"><a href="#cb26-12"></a>        <span class="va">self</span>.special_tokens_bytes <span class="op">=</span> [t.encode(<span class="st">"utf-8"</span>) <span class="cf">for</span> t <span class="kw">in</span> <span class="va">self</span>.special_tokens]</span>
<span id="cb26-13"><a href="#cb26-13"></a>        <span class="va">self</span>.special_set <span class="op">=</span> <span class="bu">set</span>(<span class="va">self</span>.special_tokens_bytes)</span>
<span id="cb26-14"><a href="#cb26-14"></a></span>
<span id="cb26-15"><a href="#cb26-15"></a>        <span class="va">self</span>.vocab_inv <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> <span class="va">self</span>.vocab.items()}</span>
<span id="cb26-16"><a href="#cb26-16"></a></span>
<span id="cb26-17"><a href="#cb26-17"></a>        rank: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> {}</span>
<span id="cb26-18"><a href="#cb26-18"></a>        merge_to_new_id: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> {}</span>
<span id="cb26-19"><a href="#cb26-19"></a></span>
<span id="cb26-20"><a href="#cb26-20"></a>        <span class="cf">for</span> r, (a_bytes, b_bytes) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.merges):</span>
<span id="cb26-21"><a href="#cb26-21"></a>            a_id <span class="op">=</span> <span class="va">self</span>.vocab_inv.get(a_bytes)</span>
<span id="cb26-22"><a href="#cb26-22"></a>            b_id <span class="op">=</span> <span class="va">self</span>.vocab_inv.get(b_bytes)</span>
<span id="cb26-23"><a href="#cb26-23"></a>            <span class="co"># The merged token should be present in vocab; if not, skip this merge rule.</span></span>
<span id="cb26-24"><a href="#cb26-24"></a>            new_id <span class="op">=</span> <span class="va">self</span>.vocab_inv.get(a_bytes <span class="op">+</span> b_bytes)</span>
<span id="cb26-25"><a href="#cb26-25"></a>            <span class="cf">if</span> a_id <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> b_id <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> new_id <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-26"><a href="#cb26-26"></a>                <span class="cf">continue</span></span>
<span id="cb26-27"><a href="#cb26-27"></a>            pair <span class="op">=</span> (a_id, b_id)</span>
<span id="cb26-28"><a href="#cb26-28"></a>            rank[pair] <span class="op">=</span> r</span>
<span id="cb26-29"><a href="#cb26-29"></a>            merge_to_new_id[pair] <span class="op">=</span> new_id</span>
<span id="cb26-30"><a href="#cb26-30"></a></span>
<span id="cb26-31"><a href="#cb26-31"></a>        <span class="va">self</span>.rank <span class="op">=</span> rank</span>
<span id="cb26-32"><a href="#cb26-32"></a>        <span class="va">self</span>.merge_to_new_id <span class="op">=</span> merge_to_new_id</span>
<span id="cb26-33"><a href="#cb26-33"></a></span>
<span id="cb26-34"><a href="#cb26-34"></a>        <span class="va">self</span>.eos_token_id <span class="op">=</span> <span class="va">self</span>.vocab_inv.get(<span class="st">b"&lt;|endoftext|&gt;"</span>, <span class="va">None</span>)</span>
<span id="cb26-35"><a href="#cb26-35"></a>    <span class="kw">def</span> encode(<span class="va">self</span>):</span>
<span id="cb26-36"><a href="#cb26-36"></a>        <span class="cf">pass</span> </span>
<span id="cb26-37"><a href="#cb26-37"></a>    </span>
<span id="cb26-38"><a href="#cb26-38"></a>    <span class="kw">def</span> encode_iterable(<span class="va">self</span>):</span>
<span id="cb26-39"><a href="#cb26-39"></a>        <span class="cf">pass</span></span>
<span id="cb26-40"><a href="#cb26-40"></a>    </span>
<span id="cb26-41"><a href="#cb26-41"></a>    <span class="kw">def</span> decode(<span class="va">self</span>):</span>
<span id="cb26-42"><a href="#cb26-42"></a>        tokens <span class="op">=</span> <span class="st">b""</span>.join(<span class="va">self</span>.vocab.get(i, <span class="st">b"</span><span class="ch">\xef\xbf\xbd</span><span class="st">"</span>) <span class="cf">for</span> i <span class="kw">in</span> ids)</span>
<span id="cb26-43"><a href="#cb26-43"></a>        <span class="cf">return</span> tokens.decode(<span class="st">"utf-8"</span>, errors<span class="op">=</span><span class="st">"replace"</span>)</span>
<span id="cb26-44"><a href="#cb26-44"></a>    <span class="at">@classmethod</span></span>
<span id="cb26-45"><a href="#cb26-45"></a>    <span class="kw">def</span> from_files(</span>
<span id="cb26-46"><a href="#cb26-46"></a>        cls, vocab_filepath: <span class="bu">str</span>, merges_filepath: <span class="bu">str</span>, special_tokens: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">|</span> <span class="bu">str</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-47"><a href="#cb26-47"></a>    ) <span class="op">-&gt;</span> <span class="st">"BPETokenizer"</span>:</span>
<span id="cb26-48"><a href="#cb26-48"></a>        <span class="cf">with</span> <span class="bu">open</span>(vocab_filepath) <span class="im">as</span> vf:</span>
<span id="cb26-49"><a href="#cb26-49"></a>            vocab_data <span class="op">=</span> json.load(vf)</span>
<span id="cb26-50"><a href="#cb26-50"></a>            vocab <span class="op">=</span> {<span class="bu">int</span>(i): <span class="bu">bytes</span>(v, <span class="st">"latin1"</span>) <span class="cf">for</span> v, i <span class="kw">in</span> vocab_data.items()}</span>
<span id="cb26-51"><a href="#cb26-51"></a></span>
<span id="cb26-52"><a href="#cb26-52"></a>        merges <span class="op">=</span> []</span>
<span id="cb26-53"><a href="#cb26-53"></a>        <span class="cf">with</span> <span class="bu">open</span>(merges_filepath) <span class="im">as</span> mf:</span>
<span id="cb26-54"><a href="#cb26-54"></a>            <span class="co"># Skip the first line (header)</span></span>
<span id="cb26-55"><a href="#cb26-55"></a>            <span class="bu">next</span>(mf)</span>
<span id="cb26-56"><a href="#cb26-56"></a>            <span class="cf">for</span> line <span class="kw">in</span> mf:</span>
<span id="cb26-57"><a href="#cb26-57"></a>                <span class="cf">if</span> line.strip() <span class="kw">and</span> <span class="kw">not</span> line.startswith(<span class="st">"#"</span>):</span>
<span id="cb26-58"><a href="#cb26-58"></a>                    parts <span class="op">=</span> line.strip().split()</span>
<span id="cb26-59"><a href="#cb26-59"></a>                    <span class="cf">if</span> <span class="bu">len</span>(parts) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb26-60"><a href="#cb26-60"></a>                        merges.append((<span class="bu">bytes</span>(parts[<span class="dv">0</span>], <span class="st">"latin1"</span>), <span class="bu">bytes</span>(parts[<span class="dv">1</span>], <span class="st">"latin1"</span>)))</span>
<span id="cb26-61"><a href="#cb26-61"></a></span>
<span id="cb26-62"><a href="#cb26-62"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(special_tokens, <span class="bu">str</span>):</span>
<span id="cb26-63"><a href="#cb26-63"></a>            <span class="cf">with</span> <span class="bu">open</span>(special_tokens, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> stf:</span>
<span id="cb26-64"><a href="#cb26-64"></a>                special_tokens_list <span class="op">=</span> [line.strip() <span class="cf">for</span> line <span class="kw">in</span> stf <span class="cf">if</span> line.strip()]</span>
<span id="cb26-65"><a href="#cb26-65"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(special_tokens, <span class="bu">list</span>):</span>
<span id="cb26-66"><a href="#cb26-66"></a>            special_tokens_list <span class="op">=</span> special_tokens</span>
<span id="cb26-67"><a href="#cb26-67"></a>        <span class="cf">else</span>:</span>
<span id="cb26-68"><a href="#cb26-68"></a>            special_tokens_list <span class="op">=</span> []</span>
<span id="cb26-69"><a href="#cb26-69"></a></span>
<span id="cb26-70"><a href="#cb26-70"></a>        <span class="cf">return</span> cls(vocab, merges, special_tokens_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>BPE Tokenizer ä¸»è¦å®ç°ä¸‰ä¸ªåŠŸèƒ½ï¼š</p>
<ol type="1">
<li><code>encode</code>ï¼šæŠŠå­—ç¬¦ä¸²ç¼–ç æˆ token IDs åˆ—è¡¨</li>
<li><code>encode_iterable</code>ï¼šæŠŠå­—ç¬¦ä¸²ç¼–ç æˆ token IDs ç”Ÿæˆå™¨</li>
<li><code>decode</code>ï¼šæŠŠ token IDs åˆ—è¡¨è§£ç æˆå­—ç¬¦ä¸²</li>
</ol>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸»è¦ä»‹ç» encode çš„å®ç°ï¼›ç›¸æ¯”ä¹‹ä¸‹ï¼Œdecode çš„é€»è¾‘æ›´ç›´æ¥ï¼šæŠŠ token ids ä¾æ¬¡æ˜ å°„å›å¯¹åº”çš„ bytesï¼Œæ‹¼æ¥æˆå®Œæ•´çš„å­—èŠ‚åºåˆ—ï¼Œå†ç”¨ UTF-8 è§£ç å¾—åˆ°å­—ç¬¦ä¸²ã€‚éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯ <code>b"\xef\xbf\xbd"</code> çš„å¤„ç†â€”â€”å®ƒæ˜¯ <a href="https://en.wikipedia.org/wiki/Specials_(Unicode_block)">Unicode U+FFFD</a>ï¼ˆreplacement characterï¼Œâ€œï¿½â€ï¼‰åœ¨ UTF-8 ä¸‹çš„å­—èŠ‚è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨ decode æ—¶ä¼šå¯¹æ¯ä¸ª <code>i</code>ï¼ˆtoken idï¼‰æ‰§è¡Œä¸€æ¬¡æŸ¥è¡¨ <code>self.vocab.get(i, ...)</code>ï¼š</p>
<ul>
<li>å¦‚æœ i èƒ½åœ¨è¯è¡¨ä¸­æ‰¾åˆ°ï¼Œå°±å–å‡ºå¯¹åº”çš„ bytesï¼›</li>
<li>å¦‚æœæ‰¾ä¸åˆ°ï¼ˆä¾‹å¦‚é‡åˆ°éæ³•/è¶Šç•Œçš„ idï¼Œæˆ–è¯è¡¨ä¸å®Œæ•´ï¼‰ï¼Œå°±ç”¨ bâ€â€ ä½œä¸ºå…œåº•ã€‚ è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼šå³ä½¿è¾“å…¥ ids ä¸­æ··å…¥äº†æœªçŸ¥ tokenï¼Œdecode ä¹Ÿä¸ä¼šå´©æºƒï¼Œè€Œæ˜¯ç”¨â€œï¿½â€æ˜¾å¼æ ‡è®°æ— æ³•è¿˜åŸçš„éƒ¨åˆ†ï¼Œä¿è¯æ•´ä¸ªè§£ç è¿‡ç¨‹å§‹ç»ˆå¯è¿è¡Œã€è¾“å‡ºå§‹ç»ˆæ˜¯ä¸€ä¸ªåˆæ³•å­—ç¬¦ä¸²ã€‚</li>
</ul>
<section id="encode-in-bpetokenizer" class="level3" data-number="2.8.1">
<h3 data-number="2.8.1" class="anchored" data-anchor-id="encode-in-bpetokenizer"><span class="header-section-number">2.8.1</span> Encode in BPETokenizer</h3>
<div class="sourceCode" id="cb27" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">def</span> encode(<span class="va">self</span>, text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb27-2"><a href="#cb27-2"></a>    <span class="kw">def</span> merge_one_pretoken(ids: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb27-3"><a href="#cb27-3"></a>        <span class="cf">pass</span> </span>
<span id="cb27-4"><a href="#cb27-4"></a>    </span>
<span id="cb27-5"><a href="#cb27-5"></a>    <span class="co"># step 1</span></span>
<span id="cb27-6"><a href="#cb27-6"></a>    byte_tokens <span class="op">=</span> <span class="va">self</span>._pre_tokenize(text)</span>
<span id="cb27-7"><a href="#cb27-7"></a>    </span>
<span id="cb27-8"><a href="#cb27-8"></a>    <span class="co"># step 2</span></span>
<span id="cb27-9"><a href="#cb27-9"></a>    token_ids: <span class="bu">list</span>[<span class="bu">int</span>] <span class="op">=</span> []</span>
<span id="cb27-10"><a href="#cb27-10"></a>    <span class="cf">for</span> btok <span class="kw">in</span> byte_tokens:</span>
<span id="cb27-11"><a href="#cb27-11"></a>        <span class="cf">if</span> btok <span class="kw">in</span> <span class="va">self</span>.special_set:</span>
<span id="cb27-12"><a href="#cb27-12"></a>            token_ids.append(<span class="va">self</span>.vocab_inv[btok])</span>
<span id="cb27-13"><a href="#cb27-13"></a>        <span class="cf">else</span>:</span>
<span id="cb27-14"><a href="#cb27-14"></a>            ids <span class="op">=</span> [<span class="va">self</span>.vocab_inv[<span class="bu">bytes</span>([b])] <span class="cf">for</span> b <span class="kw">in</span> btok]</span>
<span id="cb27-15"><a href="#cb27-15"></a>            token_ids.extend(merge_one_pretoken(ids))</span>
<span id="cb27-16"><a href="#cb27-16"></a></span>
<span id="cb27-17"><a href="#cb27-17"></a>    <span class="cf">return</span> token_ids</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è¿™ä¸ªencodeä¸»è¦åšä¸¤ä¸ªäº‹æƒ…ï¼š</p>
<ol type="1">
<li>Pre-tokenizationï¼šå…ˆç²—ç²’åº¦åˆ‡åˆ†æ–‡æœ¬</li>
<li>å¯¹æ¯ä¸ª pre-token åš BPE merge</li>
</ol>
<p>ç¬¬ä¸€æ­¥å’Œæˆ‘ä»¬ä¹‹å‰å®ç°çš„ä¸€æ ·ï¼Œå¯¹äºç¬¬äºŒæ­¥ï¼Œä¸»è¦çš„å®ç°æ–¹æ³•åœ¨ <code>merge_one_pretoken</code> ä¸­å®ç°ã€‚ åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡Heapå’ŒDouble Linked List æ¥é«˜æ•ˆå®ç°è¿™ä¸ªEncodeã€‚</p>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬ç”¨æ•°ç»„æ¥æ¨¡æ‹ŸåŒå‘é“¾è¡¨ï¼š</p>
<div class="sourceCode" id="cb28" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>prev <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> n</span>
<span id="cb28-2"><a href="#cb28-2"></a>nxt  <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> n</span>
<span id="cb28-3"><a href="#cb28-3"></a>alive <span class="op">=</span> [<span class="va">True</span>] <span class="op">*</span> n</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>åˆå¹¶æ—¶å¹¶ä¸çœŸçš„ del æ‰å…ƒç´ ï¼Œè€Œæ˜¯ï¼š</p>
<ul>
<li>æ ‡è®°è¢«åæ‰çš„èŠ‚ç‚¹ <code>alive[j] = False</code></li>
<li>è°ƒæ•´æŒ‡é’ˆ <code>nxt[i] = nxt[j]ã€prev[nxt[j]] = i</code></li>
</ul>
<p>è¿™æ ·æ¯æ¬¡åˆå¹¶éƒ½æ˜¯ <span class="math inline">\(\mathcal{O}(1)\)</span> çš„æ—¶é—´å¤æ‚åº¦ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªmin heapï¼Œæ¥è·å–æˆ‘ä»¬æœ€å…ˆè¦å®ç°mergeçš„pairï¼Œä¹Ÿå°±æ˜¯åœ¨è®­ç»ƒé˜¶æ®µï¼Œå‡ºç°é¢‘ç‡æœ€é«˜çš„pairã€‚</p>
<p>å †é‡Œå­˜ (rank, i)ï¼Œè¡¨ç¤ºå½“å‰ä½ç½® i ä¸å…¶å³é‚»å±… <code>nxt[i]</code> çš„ pair åœ¨ merge è§„åˆ™ä¸­çš„ä¼˜å…ˆçº§ï¼ˆrank è¶Šå°è¶Šå…ˆåˆå¹¶ï¼‰ã€‚ æ¯æ¬¡å–å‡ºæœ€å° rank çš„å€™é€‰ï¼Œåšä¸€æ¬¡åˆå¹¶ï¼Œç„¶ååªéœ€è¦é‡æ–°æ£€æŸ¥å±€éƒ¨çš„ä¸¤ä¸ª pairï¼š</p>
<ul>
<li>(prev[i], i)</li>
<li>(i, nxt[i])</li>
</ul>
<div class="sourceCode" id="cb29" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>heap: <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]] <span class="op">=</span> []</span>
<span id="cb29-2"><a href="#cb29-2"></a></span>
<span id="cb29-3"><a href="#cb29-3"></a><span class="kw">def</span> push_if_valid(i: <span class="bu">int</span>):</span>
<span id="cb29-4"><a href="#cb29-4"></a>    cur_r <span class="op">=</span> <span class="va">None</span></span>
<span id="cb29-5"><a href="#cb29-5"></a>    j <span class="op">=</span> nxt[i]</span>
<span id="cb29-6"><a href="#cb29-6"></a>    <span class="cf">if</span> j <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">or</span> <span class="kw">not</span> alive[i] <span class="kw">or</span> <span class="kw">not</span> alive[j]:</span>
<span id="cb29-7"><a href="#cb29-7"></a>        cur_r <span class="op">=</span> <span class="va">None</span></span>
<span id="cb29-8"><a href="#cb29-8"></a>    <span class="cf">else</span>:</span>
<span id="cb29-9"><a href="#cb29-9"></a>        cur_r <span class="op">=</span> <span class="va">self</span>.rank.get((ids[i], ids[j]))</span>
<span id="cb29-10"><a href="#cb29-10"></a></span>
<span id="cb29-11"><a href="#cb29-11"></a>    <span class="cf">if</span> cur_r <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb29-12"><a href="#cb29-12"></a>        heapq.heappush(heap, (cur_r, i))</span>
<span id="cb29-13"><a href="#cb29-13"></a></span>
<span id="cb29-14"><a href="#cb29-14"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb29-15"><a href="#cb29-15"></a>    push_if_valid(i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>ä¸ä¹‹å‰çš„heapä¸€æ ·ï¼Œheapé‡Œé¢çš„å†…å®¹ä¼š â€œè¿‡æœŸâ€ï¼š å› ä¸ºåˆå¹¶ä¼šæ”¹å˜é‚»æ¥å…³ç³»ï¼Œå †ä¸­æ—§æ¡ç›®ä¼šè¿‡æœŸï¼Œæ‰€ä»¥æ¯æ¬¡ pop å‡ºæ¥éƒ½è¦éªŒè¯,</p>
<p>æ¥ä¸‹æ¥å°±æ˜¯éå†è¿™ä¸ªheapï¼Œå¦‚æœè¿™ä¸ªheapä¸æ˜¯ç©ºçš„ï¼Œæˆ‘ä»¬å°±å¼¹å‡ºï¼Œå¹¶ä¸”éªŒè¯ï¼š</p>
<p>è¿™æ®µ <code>while heap:</code> æ˜¯æ•´ä¸ª <code>merge_one_pretoken</code> çš„æ ¸å¿ƒï¼šå †é‡Œç»´æŠ¤â€œå½“å‰å¯åˆå¹¶çš„ç›¸é‚» pairâ€ï¼Œæ¯æ¬¡å–å‡º <strong>rank æœ€å°ï¼ˆæœ€ä¼˜å…ˆï¼‰</strong> çš„å€™é€‰è¿›è¡Œåˆå¹¶ï¼Œå¹¶åªæ›´æ–°åˆå¹¶ç‚¹é™„è¿‘çš„å€™é€‰ã€‚</p>
<div class="sourceCode" id="cb30" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="cf">while</span> heap:  <span class="co"># åªè¦è¿˜æœ‰å€™é€‰ pairï¼Œå°±ç»§ç»­å°è¯•åˆå¹¶</span></span>
<span id="cb30-2"><a href="#cb30-2"></a>    r, i <span class="op">=</span> heapq.heappop(heap)  <span class="co"># å–å‡ºå½“å‰ rank æœ€å°çš„å€™é€‰ï¼š(rank, å·¦ç«¯ç‚¹ä½ç½® i)</span></span>
<span id="cb30-3"><a href="#cb30-3"></a>    j <span class="op">=</span> nxt[i]  <span class="co"># å³ç«¯ç‚¹ä½ç½® j æ˜¯ i åœ¨é“¾è¡¨ä¸­çš„åç»§</span></span>
<span id="cb30-4"><a href="#cb30-4"></a>    <span class="cf">if</span> j <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">or</span> <span class="kw">not</span> alive[i] <span class="kw">or</span> <span class="kw">not</span> alive[j]:  <span class="co"># i/j æ— æ•ˆæˆ– i å·²åˆ°å°¾éƒ¨ï¼šè¿™æ˜¯è¿‡æœŸå€™é€‰</span></span>
<span id="cb30-5"><a href="#cb30-5"></a>        <span class="cf">continue</span>  <span class="co"># è·³è¿‡ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå †å…ƒç´ </span></span>
<span id="cb30-6"><a href="#cb30-6"></a></span>
<span id="cb30-7"><a href="#cb30-7"></a>    <span class="co"># stale checkï¼šå †é‡Œçš„è®°å½•å¯èƒ½å·²è¿‡æœŸï¼ˆé‚»å±…å…³ç³»/ids å·²æ”¹å˜ï¼‰ï¼Œéœ€è¦é‡æ–°éªŒè¯</span></span>
<span id="cb30-8"><a href="#cb30-8"></a>    pair <span class="op">=</span> (ids[i], ids[j])  <span class="co"># å½“å‰æ—¶åˆ» i å’Œ j å¯¹åº”çš„ token id ç»„æˆçš„ç›¸é‚» pair</span></span>
<span id="cb30-9"><a href="#cb30-9"></a>    cur_r <span class="op">=</span> <span class="va">self</span>.rank.get(pair)  <span class="co"># æŸ¥è¯¢è¿™ä¸ª pair åœ¨ merge è§„åˆ™ä¸­çš„ rankï¼ˆä¸å¯åˆå¹¶åˆ™ä¸º Noneï¼‰</span></span>
<span id="cb30-10"><a href="#cb30-10"></a>    <span class="cf">if</span> cur_r <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> cur_r <span class="op">!=</span> r:  <span class="co"># ç°åœ¨ä¸å¯åˆå¹¶ï¼Œæˆ– rank å·²ä¸åŒ¹é…ï¼šè¯´æ˜å †å…ƒç´ è¿‡æœŸ</span></span>
<span id="cb30-11"><a href="#cb30-11"></a>        <span class="cf">continue</span>  <span class="co"># è·³è¿‡è¯¥å€™é€‰</span></span>
<span id="cb30-12"><a href="#cb30-12"></a></span>
<span id="cb30-13"><a href="#cb30-13"></a>    <span class="co"># æ‰§è¡Œåˆå¹¶ï¼šæŠŠ (ids[i], ids[j]) åˆæˆä¸€ä¸ªæ–° tokenï¼Œå¹¶å†™å›åˆ°ä½ç½® i</span></span>
<span id="cb30-14"><a href="#cb30-14"></a>    new_id <span class="op">=</span> <span class="va">self</span>.merge_to_new_id.get(pair)  <span class="co"># æŸ¥æ‰¾è¯¥ pair åˆå¹¶åçš„ token id</span></span>
<span id="cb30-15"><a href="#cb30-15"></a>    <span class="cf">if</span> new_id <span class="kw">is</span> <span class="va">None</span>:  <span class="co"># ç†è®ºä¸Šä¸è¯¥å‘ç”Ÿï¼ˆrank æœ‰ä½†æ˜ å°„æ²¡å»ºå¥½ï¼‰ï¼Œå½“ä½œè¿‡æœŸ/å¼‚å¸¸å¤„ç†</span></span>
<span id="cb30-16"><a href="#cb30-16"></a>        <span class="cf">continue</span>  <span class="co"># è·³è¿‡</span></span>
<span id="cb30-17"><a href="#cb30-17"></a>    ids[i] <span class="op">=</span> new_id  <span class="co"># ç”¨æ–° token id è¦†ç›–å·¦ç«¯ç‚¹ iï¼ˆi æˆä¸ºåˆå¹¶åçš„èŠ‚ç‚¹ï¼‰</span></span>
<span id="cb30-18"><a href="#cb30-18"></a></span>
<span id="cb30-19"><a href="#cb30-19"></a>    <span class="co"># ä»é“¾è¡¨ä¸­åˆ é™¤ jï¼šj è¢« i åæ‰äº†</span></span>
<span id="cb30-20"><a href="#cb30-20"></a>    alive[j] <span class="op">=</span> <span class="va">False</span>  <span class="co"># æ ‡è®° j èŠ‚ç‚¹è¢«åˆ é™¤</span></span>
<span id="cb30-21"><a href="#cb30-21"></a>    nj <span class="op">=</span> nxt[j]  <span class="co"># è®°ä½ j çš„åç»§èŠ‚ç‚¹</span></span>
<span id="cb30-22"><a href="#cb30-22"></a>    nxt[i] <span class="op">=</span> nj  <span class="co"># è®© i ç›´æ¥æŒ‡å‘ njï¼ˆè·³è¿‡ jï¼‰</span></span>
<span id="cb30-23"><a href="#cb30-23"></a>    <span class="cf">if</span> nj <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:  <span class="co"># å¦‚æœ nj å­˜åœ¨</span></span>
<span id="cb30-24"><a href="#cb30-24"></a>        prev[nj] <span class="op">=</span> i  <span class="co"># æ›´æ–° nj çš„å‰é©±ä¸º iï¼Œä¿æŒé“¾è¡¨ä¸€è‡´</span></span>
<span id="cb30-25"><a href="#cb30-25"></a></span>
<span id="cb30-26"><a href="#cb30-26"></a>    <span class="co"># å±€éƒ¨æ›´æ–°ï¼šåˆå¹¶åªä¼šå½±å“ i é™„è¿‘çš„ä¸¤ä¸ªç›¸é‚» pair</span></span>
<span id="cb30-27"><a href="#cb30-27"></a>    pi <span class="op">=</span> prev[i]  <span class="co"># i çš„å‰é©±ä½ç½®</span></span>
<span id="cb30-28"><a href="#cb30-28"></a>    <span class="cf">if</span> pi <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:  <span class="co"># å¦‚æœå‰é©±å­˜åœ¨</span></span>
<span id="cb30-29"><a href="#cb30-29"></a>        push_if_valid(pi)  <span class="co"># (pi, i) è¿™ä¸ª pair å¯èƒ½å˜å¾—å¯åˆå¹¶æˆ– rank æ”¹å˜</span></span>
<span id="cb30-30"><a href="#cb30-30"></a>    push_if_valid(i)  <span class="co"># (i, nxt[i]) è¿™ä¸ª pair ä¹Ÿå¯èƒ½å˜å¾—å¯åˆå¹¶æˆ– rank æ”¹å˜</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æœ€åæˆ‘ä»¬åªéœ€è¦æŠŠé“¾è¡¨ç»“æ„è¿˜åŸæˆæœ€ç»ˆçš„tokenåºåˆ—å³å¯ï¼š</p>
<p>åœ¨ BPE åˆå¹¶é˜¶æ®µï¼Œæˆ‘ä»¬ç”¨ <code>prev / nxt / alive</code> ç»´æŠ¤äº†ä¸€ä¸ªâ€œæ•°ç»„æ¨¡æ‹Ÿçš„åŒå‘é“¾è¡¨â€ã€‚åˆå¹¶æ—¶å¹¶ä¸ä¼šçœŸçš„åˆ é™¤ <code>ids</code> é‡Œçš„å…ƒç´ ï¼Œè€Œæ˜¯æŠŠè¢«åæ‰çš„ä½ç½®æ ‡è®°ä¸º <code>alive=False</code>ï¼Œå¹¶é€šè¿‡ <code>nxt</code> è·³è¿‡å®ƒä»¬ã€‚<br>
å› æ­¤åœ¨æ‰€æœ‰åˆå¹¶å®Œæˆåï¼Œéœ€è¦æŠŠâ€œè¿˜æ´»ç€çš„èŠ‚ç‚¹â€æŒ‰é¡ºåºé‡æ–°æ”¶é›†æˆä¸€ä¸ªç´§å‡‘çš„è¾“å‡ºåºåˆ—ï¼š</p>
<div class="sourceCode" id="cb31" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>out: <span class="bu">list</span>[<span class="bu">int</span>] <span class="op">=</span> []          <span class="co"># æœ€ç»ˆåˆå¹¶åçš„ token id åºåˆ—</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>k <span class="op">=</span> <span class="dv">0</span>                        <span class="co"># ä»é“¾è¡¨å¤´ï¼ˆä½ç½® 0ï¼‰å¼€å§‹éå†</span></span>
<span id="cb31-3"><a href="#cb31-3"></a><span class="cf">while</span> k <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:               <span class="co"># -1 è¡¨ç¤ºåˆ°è¾¾é“¾è¡¨æœ«å°¾</span></span>
<span id="cb31-4"><a href="#cb31-4"></a>    <span class="cf">if</span> alive[k]:             <span class="co"># å¦‚æœè¯¥ä½ç½®è¿˜æ²¡æœ‰è¢«åˆå¹¶åˆ é™¤</span></span>
<span id="cb31-5"><a href="#cb31-5"></a>        out.append(ids[k])   <span class="co"># æŠŠå½“å‰ä½ç½®çš„ token id åŠ å…¥è¾“å‡º</span></span>
<span id="cb31-6"><a href="#cb31-6"></a>    k <span class="op">=</span> nxt[k]               <span class="co"># è·³åˆ°ä¸‹ä¸€ä¸ªâ€œä»åœ¨é“¾è¡¨ä¸­çš„â€ä½ç½®</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è‡³æ­¤ï¼Œæˆ‘ä»¬ä»¥åŠå®Œæˆäº†BPEé˜¶æ®µçš„æ‰€æœ‰çš„å†…å®¹ï¼Œæ¥ä¸‹æ¥å°±æ˜¯è¦è®­ç»ƒï¼Œå¹¶å­˜å‚¨æˆ‘ä»¬é¢„å…ˆTokenå¥½çš„å†…å®¹</p>
<div class="sourceCode" id="cb32" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1"></a><span class="ex">uv</span> run pytest tests/test_tokenizer.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="assets/ass01-test-tokenizer.png" class="img-fluid"></p>
</section>
</section>
<section id="tokenize-and-save-file" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="tokenize-and-save-file"><span class="header-section-number">2.9</span> Tokenize and Save File</h2>
<p>æœ‰äº† <code>tokenizer.encode()</code> ä¹‹åï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¸Œæœ›æŠŠä¸€æ•´ä¸ªæ–‡æœ¬æ–‡ä»¶ç¼–ç æˆ <strong>ç´§å‡‘çš„äºŒè¿›åˆ¶ï¼ˆ.binï¼‰</strong>ï¼Œæ–¹ä¾¿åç»­è®­ç»ƒæ—¶ç”¨ <code>np.memmap</code> ä¹‹ç±»çš„æ–¹å¼é«˜æ•ˆåŠ è½½ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½é‡æ–°åˆ†è¯ã€‚</p>
<p>ä¸‹é¢è¿™æ®µå‡½æ•°åšçš„äº‹æƒ…å¾ˆç®€å•ï¼š<strong>æŒ‰è¡Œè¯»å–æ–‡æœ¬ â†’ æŠŠæ¯è¡Œç¼–ç æˆ token ids â†’ ç”¨å›ºå®š dtype å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶</strong>ã€‚</p>
<div class="sourceCode" id="cb33" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a><span class="kw">def</span> encode_file_to_bin(tokenizer, text_path, out_bin_path, dtype<span class="op">=</span>np.uint16):</span>
<span id="cb33-2"><a href="#cb33-2"></a>    total_bytes <span class="op">=</span> os.path.getsize(text_path)</span>
<span id="cb33-3"><a href="#cb33-3"></a></span>
<span id="cb33-4"><a href="#cb33-4"></a>    <span class="cf">with</span> <span class="bu">open</span>(text_path, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f_in, <span class="bu">open</span>(out_bin_path, <span class="st">"wb"</span>) <span class="im">as</span> f_out:</span>
<span id="cb33-5"><a href="#cb33-5"></a>        p_bar <span class="op">=</span> tqdm(total<span class="op">=</span>total_bytes, desc<span class="op">=</span><span class="st">"Encoding to binary"</span>, unit<span class="op">=</span><span class="st">"B"</span>, unit_scale<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-6"><a href="#cb33-6"></a></span>
<span id="cb33-7"><a href="#cb33-7"></a>        <span class="cf">for</span> line <span class="kw">in</span> f_in:</span>
<span id="cb33-8"><a href="#cb33-8"></a>            token_ids <span class="op">=</span> tokenizer.encode(line)          <span class="co"># 1) æŠŠä¸€è¡Œæ–‡æœ¬ç¼–ç æˆ token ids</span></span>
<span id="cb33-9"><a href="#cb33-9"></a>            arr <span class="op">=</span> np.array(token_ids, dtype<span class="op">=</span>dtype)      <span class="co"># 2) è½¬æˆ numpy æ•°ç»„ï¼ˆæ›´é€‚åˆå†™äºŒè¿›åˆ¶ï¼‰</span></span>
<span id="cb33-10"><a href="#cb33-10"></a>            arr.tofile(f_out)                           <span class="co"># 3) ç›´æ¥ä»¥äºŒè¿›åˆ¶å†™å…¥ .bin æ–‡ä»¶</span></span>
<span id="cb33-11"><a href="#cb33-11"></a></span>
<span id="cb33-12"><a href="#cb33-12"></a>            p_bar.update(<span class="bu">len</span>(line.encode(<span class="st">"utf-8"</span>)))     </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æ ¹æ®æˆ‘ä»¬çš„å®ç°ï¼Œåªéœ€è¦ä¸åˆ°30minså°±å¯ä»¥è®­ç»ƒå®ŒBPEã€‚</p>
<p>åœ¨è¿™é‡Œ <code>.bin</code> é‡Œä¸ä¿å­˜è¡Œè¾¹ç•Œ/æ ·æœ¬è¾¹ç•Œ è®­ç»ƒæ—¶æŠŠå®ƒå½“ä½œä¸€ä¸ªé•¿åºåˆ—åš next-token predictionï¼ˆGPT é£æ ¼ï¼‰ï¼Œç”¨ block samplingï¼›</p>
<div class="question foldable">
<div class="question-header foldable-header">
<p>Question 1: ä¸ºä»€ä¹ˆç”¨uint16å°±å¯ä»¥äº†å‘¢ï¼Ÿ</p>
</div>
<div class="question-container foldable-content">
<p>åº”ä¸ºåœ¨BPEçš„è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°†vocab sizeè®¾ç½®ä¸º 10,000 æˆ–è€… 32,000 è¿œè¿œå°äº uint16çš„æœ€å¤§å€¼ 65,535å› æ­¤ç”¨uint16æ˜¯å®‰å…¨çš„ã€‚</p>
</div>
</div>
<p>æˆ‘ä»¬é€šè¿‡è¿è¡Œä»¥ä¸‹ä»£ç æ¥å®ŒæˆTinyStoryçš„Tokenizationä¸ä¿å­˜ï¼š</p>
<div class="sourceCode" id="cb34" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1"></a><span class="ex">uv</span> run python ./train_bpe.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>åœ¨è®­ç»ƒå®Œä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åˆ°çš„ä¸€ä¸‹çš„directory</p>
<div class="sourceCode" id="cb35" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb35-1"><a href="#cb35-1"></a>datasets/</span>
<span id="cb35-2"><a href="#cb35-2"></a>â””â”€â”€ tiny_stories/</span>
<span id="cb35-3"><a href="#cb35-3"></a>    â”œâ”€â”€ eval.bin</span>
<span id="cb35-4"><a href="#cb35-4"></a>    â”œâ”€â”€ merges.txt</span>
<span id="cb35-5"><a href="#cb35-5"></a>    â”œâ”€â”€ special_tokens.txt</span>
<span id="cb35-6"><a href="#cb35-6"></a>    â”œâ”€â”€ train.bin</span>
<span id="cb35-7"><a href="#cb35-7"></a>    â””â”€â”€ vocab.json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>å¦‚æœå¤§å®¶ä¸æƒ³è®­ç»ƒTokenizerï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½æˆ‘è®­ç»ƒå®Œçš„æ–‡ä»¶ï¼Œåªéœ€åœ¨ <code>asssignment1-basics</code> çš„ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹ä¸¤è¡Œï¼š</p>
<div class="sourceCode" id="cb36" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1"></a><span class="ex">pip</span> install <span class="at">-U</span> huggingface_hub</span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="ex">hf</span> download YuYangZhang/TinyStory-Tokenized  <span class="at">--repo-type</span> dataset <span class="at">--local-dir</span> datasets/tiny_stories</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è¿™æ®µä»£ç ä¼šè‡ªåŠ¨ä»hugging faceä¸Šä¸‹è½½æ•°æ®ï¼Œå¹¶ä¸”ä¿å­˜è‡³ä»¥ä¸Šçš„directoryã€‚</p>
</div>
</div>
</section>
<section id="part-01-summary" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="part-01-summary"><span class="header-section-number">2.10</span> Part 01 Summary</h2>
<p>æ€»çš„æ¥è¯´ï¼ŒPart 01 ç›¸æ¯”å¤§å®¶æ›´æœŸå¾…çš„ã€ŒLLM è®­ç»ƒä¸æ¨¡å‹ç»“æ„ã€éƒ¨åˆ†ï¼Œæ›´åå‘<strong>å·¥ç¨‹å®ç°ä¸æ€§èƒ½ä¼˜åŒ–</strong>ï¼šé€šè¿‡åˆé€‚çš„æ•°æ®ç»“æ„ä¸ç®—æ³•è®¾è®¡ï¼ˆä¾‹å¦‚ heapã€ç´¢å¼•è¡¨ã€åŒå‘é“¾è¡¨ã€å¹¶è¡Œç»Ÿè®¡ç­‰ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸æ”¹å˜ç®—æ³•(<a href="#algo-bpe" class="quarto-xref">Algorithm 1</a>) çš„å‰æä¸‹ï¼ŒæŠŠ BPE çš„è®­ç»ƒä¸æ¨ç†é€Ÿåº¦æå‡ä¸€ä¸ªæ•°é‡çº§ã€‚</p>
<p>å¾ˆå¤šè¯»è€…ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰ä¼šè§‰å¾—è¿™ä¸€éƒ¨åˆ†â€œåˆé•¿åˆç»•â€ï¼Œä¸»è¦åŸå› å¾€å¾€ä¸æ˜¯å†…å®¹æœ¬èº«æœ‰å¤šéš¾ï¼Œè€Œæ˜¯å¯¹è¿™äº›å·¥ç¨‹ç»†èŠ‚è¿˜ä¸å¤Ÿç†Ÿæ‚‰ï¼šä¸€æ—¦æŠŠæ•°æ®ç»“æ„çš„ä½œç”¨ã€æ›´æ–°èŒƒå›´ã€ä»¥åŠ stale check çš„é€»è¾‘ä¸²èµ·æ¥ï¼Œæ•´ä½“ä¼šæ¸…æ™°å¾ˆå¤šã€‚æ‰€ä»¥å¦‚æœä½ ç¬¬ä¸€æ¬¡è¯»å®Œä»ç„¶è§‰å¾—æœ‰ç‚¹ä¹±ï¼Œè¿™æ˜¯éå¸¸æ­£å¸¸çš„â€”â€” <span class="hilite-pink">è¯·ä¸è¦æ°”é¦</span> , ç²¾å½©çš„éƒ¨åˆ†è¿˜æ­£è¦å¼€å§‹ï¼</p>
<p><strong>Tokenization æ˜¯è®­ç»ƒ LLM çš„ç¬¬ä¸€æ­¥</strong>ã€‚çœŸæ­£ç†è§£è¿™éƒ¨åˆ†ï¼Œä¼šç›´æ¥å¸®åŠ©ä½ åœ¨åç»­æ›´é¡ºç•…åœ°æŒæ¡ï¼š</p>
<ul>
<li>å¦‚ä½•è¿›è¡Œæ•°æ®åŠ è½½ä¸é‡‡æ ·ï¼ˆä¾‹å¦‚ <code>.bin</code> + <code>memmap</code>ï¼‰</li>
<li>å¦‚ä½•é«˜æ•ˆåœ° <code>encode / decode</code></li>
<li>ä»¥åŠåœ¨æ›´è¿›é˜¶çš„è¯é¢˜é‡Œï¼Œå¦‚ä½•å›´ç»• tokenizer ä¸åºåˆ—è¡¨ç¤ºå»æ‰©å±•æ¨¡å‹çš„ context length</li>
</ul>
<p>ä¸‹ä¸€éƒ¨åˆ†æˆ‘ä»¬å°†æŠŠ tokenizer ç”Ÿæˆçš„äºŒè¿›åˆ¶æ•°æ®æ¥å…¥è®­ç»ƒ pipelineï¼Œè¿›å…¥çœŸæ­£çš„ model training ç¯èŠ‚ã€‚</p>
</section>
</section>
<section id="part-02-language-model-implementation" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Part 02: Language Model Implementation</h1>
<p>åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨æˆ‘ä»¬åœ¨ç¬¬ä¸€éƒ¨åˆ†ä¸­å®ç°çš„BPEè¿›è¡Œtokenizationã€‚æˆ‘ä»¬å°†ä½¿ç”¨PyTorchæ¥å®šä¹‰å’Œè®­ç»ƒæ¨¡å‹ã€‚</p>
<p>å¯¹äºTransformer-Decoderæ¨¡å‹ä¸ç†Ÿæ‚‰çš„åŒå­¦ï¼Œæˆ‘éå¸¸æ¨è Andrej Karpathy çš„ä¸‹é¢è¿™ä¸ªè§†é¢‘ï¼š</p>
<div id="fig-gpt2-implementation-video" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gpt2-implementation-video-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<iframe width="100%" height="600" src="https://www.youtube.com/embed/l8pRSuU81PU?si=k_vFn8tse1QE7Njj" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gpt2-implementation-video-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: åœ¨è§†é¢‘ä¸­ï¼ŒAndrej Karpathy è¯¦ç»†è®²è§£äº†GPT-2çš„å®ç°ç»†èŠ‚ï¼Œ åŒ…æ‹¬:Transformerçš„æ¶æ„è®¾è®¡ã€æ³¨æ„åŠ›æœºåˆ¶ã€ä½ç½®ç¼–ç ç­‰å†…å®¹ã€‚åœ¨ç†è§£äº†GPT-2çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½çš„ç†è§£Assignment 01 çš„å†…å®¹ã€‚
</figcaption>
</figure>
</div>
<p>ä¸‹å›¾æ˜¯Transformer Language Modelçš„æ•´ä½“æ¶æ„æ¦‚è§ˆï¼š</p>
<div id="fig-transformer-lm-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-transformer-lm-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/ass01-transformer-lm-overview.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-transformer-lm-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Transformer Language Model æ•´ä½“æ¶æ„æ¦‚è§ˆ
</figcaption>
</figure>
</div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹ä¸»è¦ç”±ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ç»„æˆï¼š</p>
<ol type="1">
<li>Embedding Layer: å°†è¾“å…¥çš„token IDsè½¬åŒ–ä¸ºdense vectorsã€‚</li>
<li>Transformer Blocks: åŒ…å«å¤šå±‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç¥ç»ç½‘ç»œ</li>
<li>Normalization Layer: ä½¿ç”¨RMS-Normå¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚</li>
<li>Multi-Head Self-Attention: å®ç°è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹å…³æ³¨è¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†ã€‚</li>
<li>Feed-Forward Network: ç”±ä¸¤ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•°ç»„æˆ</li>
<li>Output Layer: å°†Transformerçš„è¾“å‡ºæ˜ å°„å›è¯æ±‡è¡¨å¤§å°çš„logitsï¼Œç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªtokenã€‚</li>
</ol>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä¸€æ­¥æ­¥å®ç°è¿™ä¸ªæ¨¡å‹çš„å„ä¸ªæ¨¡å—ã€‚é¦–å…ˆï¼Œå®ç°çš„æ˜¯Linear Module.</p>
<section id="linear-module" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="linear-module"><span class="header-section-number">3.1</span> Linear Module</h2>
<p>Linear Module åŸºæœ¬æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œçš„èµ·å§‹ç‚¹ï¼Œå®ƒçš„å®šä¹‰å¦‚ä¸‹:</p>
<p><span id="eq-linear-module"><span class="math display">\[
y = Wx
\tag{1}\]</span></span></p>
<p>å…¶ä¸­ <span class="math inline">\(W \in \mathbb{R}^{d_{\text{out}}  \times d_{\text{in}}}\)</span> , <span class="math inline">\(x \in \mathbb{R}^{d_{\text{in}} \times 1}\)</span> , <span class="math inline">\(y \in \mathbb{R}^{d_{\text{out}} \times 1}\)</span></p>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p>NOTE</p>
</div>
<div class="note-container foldable-content">
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®ç°çš„ Linear Module ä¸ä»»åŠ¡ä¸­è¦æ±‚çš„ç•¥æœ‰ä¸åŒï¼Œ ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹ä¸¤ç‚¹ï¼š</p>
<ol type="1">
<li>æˆ‘ä»¬å°† weight çš„ shape è®¾ä¸º (in_features, out_features)ï¼Œ è¿™æ ·åœ¨ forward çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ <code>@</code> è¿ç®—ç¬¦è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œä»£ç æ›´ç®€æ´ã€‚</li>
<li>æˆ‘ä»¬å°† bias è®¾ä¸ºå¯é€‰é¡¹ï¼Œé»˜è®¤ä¸ä½¿ç”¨ biasï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°æ¨¡æ‹Ÿ Transformer ä¸­çš„ Linear Layerã€‚</li>
</ol>
</div>
</div>
<div class="sourceCode" id="cb37" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="kw">class</span> Linear(nn.Module):</span>
<span id="cb37-2"><a href="#cb37-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb37-3"><a href="#cb37-3"></a>        <span class="va">self</span>,</span>
<span id="cb37-4"><a href="#cb37-4"></a>        in_features,</span>
<span id="cb37-5"><a href="#cb37-5"></a>        out_features,</span>
<span id="cb37-6"><a href="#cb37-6"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb37-7"><a href="#cb37-7"></a>        dtype: torch.dtype <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb37-8"><a href="#cb37-8"></a>        bias: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb37-9"><a href="#cb37-9"></a>    ):</span>
<span id="cb37-10"><a href="#cb37-10"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb37-11"><a href="#cb37-11"></a></span>
<span id="cb37-12"><a href="#cb37-12"></a>        <span class="va">self</span>.in_features <span class="op">=</span> in_features</span>
<span id="cb37-13"><a href="#cb37-13"></a>        <span class="va">self</span>.out_features <span class="op">=</span> out_features</span>
<span id="cb37-14"><a href="#cb37-14"></a></span>
<span id="cb37-15"><a href="#cb37-15"></a>        <span class="va">self</span>.weight <span class="op">=</span> nn.Parameter(torch.empty((in_features, out_features), device<span class="op">=</span>device, dtype<span class="op">=</span>dtype))</span>
<span id="cb37-16"><a href="#cb37-16"></a>        <span class="va">self</span>.bias <span class="op">=</span> nn.Parameter(torch.empty(out_features, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)) <span class="cf">if</span> bias <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb37-17"><a href="#cb37-17"></a>        <span class="va">self</span>._init_weight()</span>
<span id="cb37-18"><a href="#cb37-18"></a></span>
<span id="cb37-19"><a href="#cb37-19"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb37-20"><a href="#cb37-20"></a>        o <span class="op">=</span> x <span class="op">@</span> <span class="va">self</span>.weight</span>
<span id="cb37-21"><a href="#cb37-21"></a></span>
<span id="cb37-22"><a href="#cb37-22"></a>        <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb37-23"><a href="#cb37-23"></a>            o <span class="op">=</span> o <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb37-24"><a href="#cb37-24"></a></span>
<span id="cb37-25"><a href="#cb37-25"></a>        <span class="cf">return</span> o</span>
<span id="cb37-26"><a href="#cb37-26"></a>    </span>
<span id="cb37-27"><a href="#cb37-27"></a>    <span class="kw">def</span> _init_weight(<span class="va">self</span>):</span>
<span id="cb37-28"><a href="#cb37-28"></a>        mean <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb37-29"><a href="#cb37-29"></a>        std <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> (<span class="va">self</span>.in_features <span class="op">+</span> <span class="va">self</span>.out_features) <span class="op">**</span> <span class="fl">0.5</span>)</span>
<span id="cb37-30"><a href="#cb37-30"></a>        torch.nn.init.trunc_normal_(<span class="va">self</span>.weight, mean<span class="op">=</span>mean, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span> <span class="op">*</span> std, b<span class="op">=</span><span class="dv">3</span> <span class="op">*</span> std)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>å…¶ä¸­ <code>_init_weight()</code> æ˜¯åˆå§‹åŒ–çš„æ–¹æ³•ï¼Œ åœ¨Assignment 1 ä¸­ä¸ºï¼š</p>
<p><span class="math display">\[
\mathcal{N}\left( \mu = 0, \sigma^{2}=\frac{2}{d_{\text{in}} + d_{\text{out}}} \right)
\quad  \text{truncated at}  [-3\sigma, 3\sigma ]
\]</span></p>
<p>è¿™ç§åˆå§‹åŒ–çš„æ–¹å¼æ˜¯æœ€å¸¸è§çš„ï¼Œä¹Ÿæ˜¯æ¯”è¾ƒrobustçš„ï¼Œå½“ç„¶ï¼Œå¤§å®¶è¿˜å¯ä»¥å°è¯•ä¸åŒçš„åˆå§‹åŒ–çš„æ–¹å¼, ä¾‹å¦‚<a href="https://www.geeksforgeeks.org/deep-learning/xavier-initialization/">Xavier-initialization</a>ï¼Œ <a href="https://www.geeksforgeeks.org/deep-learning/kaiming-initialization-in-deep-learning/">Kaiming-initialization</a>ç­‰ã€‚</p>
</section>
<section id="embedding-model" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="embedding-model"><span class="header-section-number">3.2</span> Embedding Model</h2>
<p>è®°å¾—æˆ‘ä»¬åœ¨å‰é¢ç¬¬ä¸€ç« èŠ‚ï¼Œå®ç°äº†BPEçš„Tokenizationï¼Œå›é¡¾ä¸€ä¸‹ï¼Œ</p>
<div class="tldr foldable is-open">
<div class="tldr-header foldable-header">
<p>TL;DR: BPE Tokenization</p>
</div>
<div class="tldr-container foldable-content">
<p>Tokenizationçš„æ­¥éª¤å°±æ˜¯æŠŠæ–‡å­—ï¼Œè½¬åŒ–æˆä¸€ä¸ªä¸ªçš„IDsã€‚ ä½†æ˜¯è¿™ä¸ªIDsæ˜¯ä¸èƒ½è¢«æ¨¡å‹å¤„ç†çš„ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬åŒ–æˆä¸€ä¸ªä¸ªçš„Dense Vectorï¼Œè¿™ä¸ªå°±æ˜¯æ‰€è°“çš„ Embeddingã€‚</p>
</div>
</div>
<p>Embedding çš„æ•°å­¦å®šä¹‰å¦‚ä¸‹ï¼š <span id="eq-embedding-module"><span class="math display">\[
\text{Embedding}(x) = W_{e}[x]
\tag{2}\]</span></span></p>
<p>å…¶ä¸­ <span class="math inline">\(W_{e} \in \mathbb{R}^{V \times d_{\text{model}}}\)</span> æ˜¯ Embedding çŸ©é˜µï¼Œ<span class="math inline">\(V\)</span> æ˜¯è¯æ±‡è¡¨çš„å¤§å°ï¼Œ<span class="math inline">\(d_{\text{model}}\)</span> æ˜¯æ¨¡å‹çš„éšè—ç»´åº¦ï¼Œ<span class="math inline">\(x \in \mathbb{N}^{B \times L}\)</span> æ˜¯è¾“å…¥çš„token IDsï¼Œ <span class="math inline">\(B\)</span> æ˜¯batch sizeï¼Œ<span class="math inline">\(L\)</span>æ˜¯åºåˆ—é•¿åº¦ã€‚</p>
<p>ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<div class="sourceCode" id="cb38" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="kw">class</span> Embedding(nn.Module):</span>
<span id="cb38-2"><a href="#cb38-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb38-3"><a href="#cb38-3"></a>        <span class="va">self</span>,</span>
<span id="cb38-4"><a href="#cb38-4"></a>        num_embeddings: <span class="bu">int</span>,</span>
<span id="cb38-5"><a href="#cb38-5"></a>        embedding_dim: <span class="bu">int</span>,</span>
<span id="cb38-6"><a href="#cb38-6"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb38-7"><a href="#cb38-7"></a>        dtype: torch.dtype <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb38-8"><a href="#cb38-8"></a>    ):</span>
<span id="cb38-9"><a href="#cb38-9"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb38-10"><a href="#cb38-10"></a></span>
<span id="cb38-11"><a href="#cb38-11"></a>        <span class="va">self</span>.num_embeddings <span class="op">=</span> num_embeddings</span>
<span id="cb38-12"><a href="#cb38-12"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb38-13"><a href="#cb38-13"></a></span>
<span id="cb38-14"><a href="#cb38-14"></a>        <span class="va">self</span>.weight <span class="op">=</span> nn.Parameter(torch.empty((num_embeddings, embedding_dim), device<span class="op">=</span>device, dtype<span class="op">=</span>dtype))</span>
<span id="cb38-15"><a href="#cb38-15"></a></span>
<span id="cb38-16"><a href="#cb38-16"></a>        <span class="va">self</span>._init_weight()</span>
<span id="cb38-17"><a href="#cb38-17"></a></span>
<span id="cb38-18"><a href="#cb38-18"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb38-19"><a href="#cb38-19"></a>        B, L <span class="op">=</span> x.shape  <span class="co"># x: (B, L)</span></span>
<span id="cb38-20"><a href="#cb38-20"></a>        out <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B*L,)</span></span>
<span id="cb38-21"><a href="#cb38-21"></a>        out <span class="op">=</span> <span class="va">self</span>.weight.index_select(<span class="dv">0</span>, out)  <span class="co"># (B*L, D)</span></span>
<span id="cb38-22"><a href="#cb38-22"></a>        out <span class="op">=</span> out.reshape(B, L, <span class="va">self</span>.embedding_dim)  <span class="co"># (B, L, D)</span></span>
<span id="cb38-23"><a href="#cb38-23"></a></span>
<span id="cb38-24"><a href="#cb38-24"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>å¾ˆç®€å•çš„ä¹Ÿå¾ˆç›´è§‚ï¼Œå®ƒçš„æƒé‡åˆå§‹åŒ–çš„æ–¹å¼ä¸ºï¼š</p>
<p><span class="math display">\[
\mathcal{N}\left( \mu = 0, \sigma^{2}=1 \right)
\quad  \text{truncated at}  [-3, 3]
\]</span></p>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p>NOTE</p>
</div>
<div class="note-container foldable-content">
<p>å…¶å®åœ¨<code>forward</code>ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ <code>self.weight[x]</code> è¿™ä¸€è¡Œä»£ç ï¼Œå°±å¯ä»¥å®ç° Embedding çš„åŠŸèƒ½ï¼Œ ä½†æ˜¯ä¸ºäº†æ›´æ¸…æ™°åœ°å±•ç¤º Embedding çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† <code>index_select()</code> æ¥å®ç°ã€‚</p>
</div>
</div>
</section>
<section id="rms-norm" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="rms-norm"><span class="header-section-number">3.3</span> RMS-Norm</h2>
<p>åœ¨ç°ä»£çš„Language Modelä¸­ï¼Œå¸¸è§çš„Normalizationçš„æ–¹æ³•æ˜¯ <strong>RMS-Norm</strong><span class="citation" data-cites="RootMeanSquare2019zhang">(<a href="#ref-RootMeanSquare2019zhang" role="doc-biblioref">Zhang and Sennrich 2019</a>)</span>ï¼Œ å…¶æ•°å­¦å®šä¹‰å¦‚ä¸‹ï¼š</p>
<p><span class="math display">\[
\begin{split}
\text{RMSNorm}(a_{i}) &amp;= \frac{a_{i}}{\text{RMS}(a)} g_{i} \\
\text{where} \quad  \text{RMS}(a) &amp;= \sqrt{ \frac{1}{d_{\text{model}}} \sum_{i=1}^{d_{\text{model}}}a_{i}^{2}  + \epsilon}
\end{split}
\]</span></p>
<p>å…¶ä¸­ <span class="math inline">\(g\)</span> æ˜¯<strong>å¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°</strong>ï¼Œå®ƒçš„ç»´åº¦ä¸è¾“å…¥ <span class="math inline">\(a\)</span> ç›¸åŒï¼Œ<span class="math inline">\(\epsilon\)</span> æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ•°å€¼ï¼Œé˜²æ­¢é™¤ä»¥0ã€‚</p>
<p>å®ç°RMS-Normçš„æ–¹å¼ä¹Ÿå¾ˆç®€å•ï¼Œä¸è¿‡æœ‰ä¸€ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹å°±æ˜¯ï¼šå¦‚æœæˆ‘ä»¬ç”¨äº†Mixed Precision Trainingï¼Œå½“ç”¨ <code>sqrt()</code> æ—¶ï¼Œ å¯èƒ½ä¼šå¯¼è‡´Underflowï¼Œä¸ºäº†é¿å…è¿™ä¸€ç‚¹ï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°† activation upcaståˆ° <code>float32</code>ï¼Œ ç»“æŸçš„æ—¶å€™å†è¿”å›åŸæ¥çš„æ•°æ®ç±»å‹ã€‚å…·ä½“çš„è¯·çœ‹ä»£ç ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/norm.py</strong></pre>
</div>
<div class="sourceCode" id="cb39" data-filename="cs336_basics/modules/norm.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a><span class="kw">class</span> RMSNorm(nn.Module):</span>
<span id="cb39-2"><a href="#cb39-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb39-3"><a href="#cb39-3"></a>        <span class="va">self</span>,</span>
<span id="cb39-4"><a href="#cb39-4"></a>        d_model: <span class="bu">int</span>,</span>
<span id="cb39-5"><a href="#cb39-5"></a>        eps: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-5</span>,</span>
<span id="cb39-6"><a href="#cb39-6"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb39-7"><a href="#cb39-7"></a>        dtype: torch.dtype <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb39-8"><a href="#cb39-8"></a>    ):</span>
<span id="cb39-9"><a href="#cb39-9"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb39-10"><a href="#cb39-10"></a></span>
<span id="cb39-11"><a href="#cb39-11"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb39-12"><a href="#cb39-12"></a>        <span class="va">self</span>.eps <span class="op">=</span> eps</span>
<span id="cb39-13"><a href="#cb39-13"></a></span>
<span id="cb39-14"><a href="#cb39-14"></a>        <span class="va">self</span>.weight <span class="op">=</span> nn.Parameter(torch.ones(d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype))</span>
<span id="cb39-15"><a href="#cb39-15"></a></span>
<span id="cb39-16"><a href="#cb39-16"></a>    <span class="kw">def</span> _rms(<span class="va">self</span>, x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb39-17"><a href="#cb39-17"></a>        <span class="cf">return</span> torch.sqrt(torch.mean(x<span class="op">**</span><span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="va">self</span>.eps)</span>
<span id="cb39-18"><a href="#cb39-18"></a></span>
<span id="cb39-19"><a href="#cb39-19"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb39-20"><a href="#cb39-20"></a>        input_dtype <span class="op">=</span> x.dtype</span>
<span id="cb39-21"><a href="#cb39-21"></a>        x <span class="op">=</span> x.to(torch.float32)</span>
<span id="cb39-22"><a href="#cb39-22"></a></span>
<span id="cb39-23"><a href="#cb39-23"></a>        rms <span class="op">=</span> <span class="va">self</span>._rms(x)</span>
<span id="cb39-24"><a href="#cb39-24"></a>        x_normed <span class="op">=</span> x <span class="op">/</span> rms</span>
<span id="cb39-25"><a href="#cb39-25"></a></span>
<span id="cb39-26"><a href="#cb39-26"></a>        <span class="cf">return</span> (x_normed <span class="op">*</span> <span class="va">self</span>.weight).to(input_dtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Normalizationçš„ä½ç½®ä¹Ÿæ˜¯å¾ˆæœ‰è®²ç©¶çš„ï¼Œåœ¨ç°ä»£çš„LMä¸­ï¼Œé€šå¸¸ç”¨<strong>Pre-Norm</strong>ï¼Œè¿™ä¸€éƒ¨åˆ†ï¼Œç­‰æˆ‘ä»¬ä»‹ç»å®Œäº†æ‰€æœ‰çš„æ¨¡å—ä¹‹åå†æ¥ä»‹ç»ã€‚</p>
</section>
<section id="pointwise-feed-forward-network" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="pointwise-feed-forward-network"><span class="header-section-number">3.4</span> PointWise Feed Forward Network</h2>
<p>åœ¨åŸå§‹ Transformer <span class="citation" data-cites="AttentionAllYou2023vaswani">(<a href="#ref-AttentionAllYou2023vaswani" role="doc-biblioref">Vaswani et al. 2023</a>)</span>é‡Œï¼ŒFFN æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„ä¸¤å±‚ç»“æ„ï¼š<code>Linear â†’ ReLU â†’ Linear</code>ï¼Œå¹¶ä¸”ä¸­é—´éšå±‚ç»´åº¦é€šå¸¸å– <code>d_ff = 4 * d_model</code>ã€‚ä½†åˆ°äº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚ Llama 3ã€Qwen 2.5ï¼‰ï¼ŒFFN çš„è®¾è®¡å‡ºç°äº†ä¸¤ä¸ªå‡ ä¹â€œæ ‡é…â€çš„å˜åŒ–ï¼š</p>
<ol type="1">
<li><strong>æ¢æ¿€æ´»å‡½æ•°</strong></li>
<li><strong>å¼•å…¥é—¨æ§ï¼ˆgatingï¼‰æœºåˆ¶</strong>ã€‚</li>
</ol>
<p>ä¸€ä¸ªå…¸å‹ä»£è¡¨å°±æ˜¯ <strong>SwiGLU</strong>ï¼šå®ƒæŠŠ <u>SiLU/Swish çš„å¹³æ»‘æ¿€æ´»å’Œ GLU çš„é—¨æ§ç›¸ä¹˜ç»“åˆèµ·æ¥</u>ï¼Œå¹¶ä¸”å¾ˆå¤šå®ç°ä¼šåƒ PaLMã€LLaMA ä¸€æ ·<strong>å»æ‰çº¿æ€§å±‚ bias</strong>ï¼ˆæ›´ç®€æ´ã€ä¹Ÿæ›´è´´è¿‘ä¸»æµè®­ç»ƒé…æ–¹ï¼‰ã€‚</p>
<p>å…ˆçœ‹ SiLUï¼ˆä¹Ÿå¸¸å« Swishï¼‰ï¼Œå®šä¹‰å¾ˆç®€å•ï¼š</p>
<p><span id="eq-silu"><span class="math display">\[
\mathrm{SiLU}(x)=x\cdot\sigma(x)=\frac{x}{1+e^{-x}}
\tag{3}\]</span></span></p>
<p>å®ƒå’Œ ReLU ä¸€æ ·èƒ½æä¾›éçº¿æ€§ï¼Œä½†åœ¨ 0 é™„è¿‘æ˜¯<strong>å¹³æ»‘çš„</strong>ï¼Œæ¢¯åº¦è¡Œä¸ºæ›´è¿ç»­ã€‚å†çœ‹ GLUï¼Œå®ƒç”¨ä¸€ä¸ª sigmoid åˆ†æ”¯å……å½“â€œé—¨â€ï¼Œå»è°ƒèŠ‚å¦ä¸€æ¡çº¿æ€§åˆ†æ”¯ï¼š</p>
<p><span id="eq-glu"><span class="math display">\[
\mathrm{GLU}(x, W_1, W_2)=\sigma(W_1x)\odot (W_2x)
\tag{4}\]</span></span></p>
<p>ç›´è§‰ä¸Šï¼Œè¿™ç§é—¨æ§èƒ½ç»™æ¢¯åº¦æä¾›ä¸€æ¡æ›´â€œçº¿æ€§â€çš„é€šè·¯ï¼ŒåŒæ—¶ä¿ç•™éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ã€‚æŠŠä¸¤è€…æ‹¼èµ·æ¥å°±æ˜¯ SwiGLUåœ¨ FFN ä¸­çš„å†™æ³•ï¼š <span id="eq-swiglu-ffn"><span class="math display">\[
\mathrm{FFN}(x)=W_2\big(\mathrm{SiLU}(W_1x)\odot (W_3x)\big)
\tag{5}\]</span></span></p>
<p>å…¶ä¸­<span class="math inline">\(x\in\mathbb{R}^{d_\text{model}}\)</span>ï¼Œ<span class="math inline">\(W_1,W_3\in\mathbb{R}^{d_\text{ff}\times d_\text{model}}\)</span>, <span class="math inline">\(W_2\in\mathbb{R}^{d_\text{model}\times d_\text{ff}}\)</span>ã€‚å®è·µé‡Œå¸¸è§çš„ç»éªŒè®¾å®šæ˜¯ <span class="math inline">\(d_\text{ff}=\frac{8}{3}d_\text{model}\)</span></p>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œç›¸æ¯”æ—©æœŸçš„ <code>4x</code>ï¼Œç°ä»£ LLM ç»å¸¸ç”¨ä¸€ä¸ªæ›´â€œæ€§ä»·æ¯”â€æ›´å¥½çš„å®½åº¦é…åˆé—¨æ§ç»“æ„ã€‚Shazeer <span class="citation" data-cites="GLUVariantsImprove2020shazeer">(<a href="#ref-GLUVariantsImprove2020shazeer" role="doc-biblioref">Shazeer 2020</a>)</span> çš„å®éªŒä¹Ÿè¡¨æ˜ï¼ŒSwiGLU å¾€å¾€èƒ½åœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šä¼˜äº ReLU æˆ–ä»… SiLUï¼ˆæ— é—¨æ§ï¼‰çš„åŸºçº¿â€”â€”å½“ç„¶ï¼Œæœ€ç»ˆè¿˜æ˜¯è¦å›åˆ°å®éªŒï¼šåœ¨åç»­å¯¹æ¯”ä¸åŒ FFN å˜ä½“æ—¶ï¼Œä½ ä¼šæ›´ç›´è§‚åœ°çœ‹åˆ°è¿™äº›è®¾è®¡åœ¨ lossã€æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæŒ‡æ ‡ä¸Šçš„å·®å¼‚ã€‚</p>
<div id="fig-different-activation-functions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-different-activation-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/ass01-act-fns.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-activation-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: ä¸åŒæ¿€æ´»å‡½æ•°æ ·å­
</figcaption>
</figure>
</div>
<p>ä»£ç çš„å®ç°è¿˜æ˜¯å¾ˆç®€å•çš„ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/ffn.py</strong></pre>
</div>
<div class="sourceCode" id="cb40" data-filename="cs336_basics/modules/ffn.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a><span class="kw">def</span> silu(x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb40-2"><a href="#cb40-2"></a>    <span class="cf">return</span> x <span class="op">*</span> torch.sigmoid(x)</span>
<span id="cb40-3"><a href="#cb40-3"></a></span>
<span id="cb40-4"><a href="#cb40-4"></a></span>
<span id="cb40-5"><a href="#cb40-5"></a><span class="kw">class</span> FFN(nn.Module):</span>
<span id="cb40-6"><a href="#cb40-6"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb40-7"><a href="#cb40-7"></a>        <span class="va">self</span>,</span>
<span id="cb40-8"><a href="#cb40-8"></a>        d_model: <span class="bu">int</span>,</span>
<span id="cb40-9"><a href="#cb40-9"></a>        d_ff: <span class="bu">int</span>,</span>
<span id="cb40-10"><a href="#cb40-10"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb40-11"><a href="#cb40-11"></a>        dtype: torch.dtype <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb40-12"><a href="#cb40-12"></a>    ):</span>
<span id="cb40-13"><a href="#cb40-13"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb40-14"><a href="#cb40-14"></a></span>
<span id="cb40-15"><a href="#cb40-15"></a>        <span class="im">from</span> cs336_basics.modules.linear <span class="im">import</span> Linear</span>
<span id="cb40-16"><a href="#cb40-16"></a></span>
<span id="cb40-17"><a href="#cb40-17"></a>        <span class="va">self</span>.up <span class="op">=</span> Linear(d_model, d_ff, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb40-18"><a href="#cb40-18"></a>        <span class="va">self</span>.down <span class="op">=</span> Linear(d_ff, d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb40-19"><a href="#cb40-19"></a>        <span class="va">self</span>.gate <span class="op">=</span> Linear(d_model, d_ff, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb40-20"><a href="#cb40-20"></a></span>
<span id="cb40-21"><a href="#cb40-21"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb40-22"><a href="#cb40-22"></a>        <span class="cf">return</span> <span class="va">self</span>.down(silu(<span class="va">self</span>.up(x)) <span class="op">*</span> <span class="va">self</span>.gate(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="rope" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="rope"><span class="header-section-number">3.5</span> RoPE</h2>
<p>Transformer æœ¬èº«å¯¹åºåˆ—çš„é¡ºåºå¹¶ä¸æ•æ„Ÿï¼Œå› æ­¤éœ€è¦æŠŠ<strong>ä½ç½®ä¿¡æ¯</strong>æ³¨å…¥åˆ°æ³¨æ„åŠ›æœºåˆ¶é‡Œã€‚é™¤äº†å¸¸è§çš„ç»å¯¹ä½ç½®ç¼–ç ï¼ˆabsolute PEï¼‰ï¼Œç°ä»£ LLM æ›´å¸¸ç”¨çš„ä¸€ç±»æ–¹æ³•æ˜¯ <strong>Rotary Position Embeddingsï¼ˆRoPE)</strong> <span class="citation" data-cites="RoFormerEnhancedTransformer2023su">(<a href="#ref-RoFormerEnhancedTransformer2023su" role="doc-biblioref">Su et al. 2023</a>)</span>ï¼šå®ƒä¸æ˜¯æŠŠä½ç½®å‘é‡â€œåŠ åˆ° embedding ä¸Šâ€ï¼Œè€Œæ˜¯å¯¹ <strong>Q/K å‘é‡åšæŒ‰ç»´åº¦æˆå¯¹çš„æ—‹è½¬</strong>ï¼Œä»è€Œè®©æ³¨æ„åŠ›å¤©ç„¶å…·å¤‡ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p>
<p>RoPEçš„æ€æƒ³ä¹Ÿå¾ˆç®€å•ï¼šå¯¹ç¬¬ <span class="math inline">\(i\)</span> ä¸ª token çš„ queryï¼š <span id="eq-rope-q"><span class="math display">\[
q^{(i)} = W_q x^{(i)} \in \mathbb{R}^d
\tag{6}\]</span></span></p>
<p>RoPE ä¼šä¹˜ä¸Šä¸€ä¸ªä½ç½®ç›¸å…³çš„æ—‹è½¬çŸ©é˜µ <span class="math inline">\(R_{i}\)</span>: <span id="eq-rope-q-rotated"><span class="math display">\[
q'^{(i)} = R_i q^{(i)} = R_i W_q x^{(i)}
\tag{7}\]</span></span></p>
<p>å…¶ä¸­ <span class="math inline">\(R_i\)</span> ä¼šæŠŠå‘é‡æŒ‰ç»´åº¦ä¸¤ä¸¤åˆ†ç»„ï¼š<span class="math inline">\((q_{1},q_{2}), (q_{3},q_{4}), \dots\)</span>ï¼ŒæŠŠæ¯ä¸€å¯¹çœ‹ä½œä¸€ä¸ª 2D å‘é‡ï¼Œåœ¨å¹³é¢é‡Œæ—‹è½¬ä¸€ä¸ªè§’åº¦ <span class="math inline">\(\theta_{i,k}\)</span>ã€‚</p>
<div id="fig-illustration-of-rope" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-illustration-of-rope-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/rope.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-illustration-of-rope-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: RoPE æ—‹è½¬ç¤ºæ„å›¾ï¼šå¯¹æ¯ä¸€å¯¹ç»´åº¦ <span class="math inline">\((q_{2k-1}, q_{2k})\)</span>ï¼ŒæŒ‰ä½ç½® <span class="math inline">\(i\)</span> æ—‹è½¬è§’åº¦ <span class="math inline">\(\theta_{i,k}\)</span>ã€‚
</figcaption>
</figure>
</div>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹å¦‚ä½•å®šä¹‰æ—‹è½¬è§’åº¦ <span class="math inline">\(\theta_{i,k}\)</span>ï¼Œä»¥åŠå¦‚ä½•æ„å»ºæ—‹è½¬çŸ©é˜µ <span class="math inline">\(R_i\)</span>ã€‚</p>
<hr>
<p><tag style="color:blue">å®šä¹‰æ—‹è½¬è§’åº¦ <span class="math inline">\(\theta_{i,k}\)</span> </tag><br></p>
<p>æ ¹æ®RoPE<span class="citation" data-cites="RoFormerEnhancedTransformer2023su">(<a href="#ref-RoFormerEnhancedTransformer2023su" role="doc-biblioref">Su et al. 2023</a>)</span>çš„è®¾å®šï¼Œ å¯¹ç¬¬ <span class="math inline">\(k\)</span> å¯¹ç»´åº¦ <span class="math inline">\(k \in \{1,\dots, d/2\}\)</span>ï¼Œæ—‹è½¬è§’åº¦å®šä¹‰ä¸ºï¼š <span id="eq-rope-rotation-angle"><span class="math display">\[
\theta_{i,k} = i \cdot \Theta^{-\frac{2k-2}{d}}
\tag{8}\]</span></span></p>
<p>è¿™é‡Œ <span class="math inline">\(\Theta\)</span> æ˜¯ä¸€ä¸ªå¸¸æ•°æˆ‘ä»¬é€šå¸¸æŠŠ <span class="math inline">\(\Theta\)</span> è®¾ä¸º 10,000ï¼Œè¿™æ ·ç¬¬ <span class="math inline">\(k\)</span> å¯¹ç»´åº¦çš„é¢‘ç‡æ˜¯ <span class="math inline">\(\frac{1}{10000^{(2k-2)/d}}\)</span>ï¼Œå’Œ Transformer ç»å¯¹ä½ç½®ç¼–ç é‡Œçš„é¢‘ç‡è®¾è®¡æ˜¯ä¸€è‡´çš„ã€‚</p>
<div class="sourceCode" id="cb41" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>inv_freq <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (<span class="dv">10000</span> <span class="op">**</span> (torch.arange(<span class="dv">0</span>, d_model, <span class="dv">2</span>).<span class="bu">float</span>() <span class="op">/</span> d_model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>ç›´è§‰ä¸Šï¼š</p>
<ul>
<li>ä¸åŒç»´åº¦å¯¹åº”ä¸åŒâ€œæ—‹è½¬é¢‘ç‡â€ï¼ˆåƒä¸€ç»„ä¸åŒæ³¢é•¿çš„æ­£å¼¦/ä½™å¼¦ï¼‰</li>
<li>ä½ç½®è¶Šé åï¼Œæ—‹è½¬è§’åº¦è¶Šå¤§, ç”¨äºç¼–ç æ›´é•¿è·ç¦»çš„ç›¸å¯¹ä½ç½®å…³ç³»</li>
<li>æœ€ç»ˆè®©æ³¨æ„åŠ›å¯ä»¥é€šè¿‡ Q/K çš„ç›¸å¯¹æ—‹è½¬ï¼Œç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯</li>
</ul>
<hr>
<p><tag style="color:blue">å®šä¹‰æ—‹è½¬å— <span class="math inline">\(R^i_k\)</span> </tag><br></p>
<p>å…¶ä¸­ï¼Œæ¯ä¸€å¯¹ç»´åº¦ <span class="math inline">\((q_{2k-1}, q_{2k})\)</span> å¯¹åº”ä¸€ä¸ª <span class="math inline">\(2\times 2\)</span> æ—‹è½¬å—ï¼š <span id="eq-rope-rotation-block"><span class="math display">\[
R^i_k =
\begin{bmatrix}
\cos(\theta_{i,k}) &amp; -\sin(\theta_{i,k}) \\
\sin(\theta_{i,k}) &amp; \cos(\theta_{i,k})
\end{bmatrix}
\tag{9}\]</span></span></p>
<hr>
<p><tag style="color:blue">æ•´ä½“æ—‹è½¬çŸ©é˜µ <span class="math inline">\(R_i\)</span> </tag><br></p>
<p>æ•´ä½“ <span class="math inline">\(R_i\)</span> æ˜¯ä¸€ä¸ª <span class="math inline">\(d\times d\)</span> çš„å—å¯¹è§’çŸ©é˜µï¼Œç”± <span class="math inline">\(d/2\)</span> ä¸ª<span class="math inline">\(2\times 2\)</span> å—ç»„æˆï¼ˆå…¶å®ƒä½ç½®ä¸º 0ï¼‰ã€‚æ•°å­¦ä¸Šå†™æˆï¼š</p>
<p><span id="eq-rope-rotation-matrix"><span class="math display">\[
R_i=
\begin{bmatrix}
R^i_1 &amp; 0      &amp; 0      &amp; \cdots &amp; 0 \\
0     &amp; R^i_2  &amp; 0      &amp; \cdots &amp; 0 \\
0     &amp; 0      &amp; R^i_3  &amp; \cdots &amp; 0 \\
\vdots&amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0     &amp; 0      &amp; 0      &amp; \cdots &amp; R^i_{d/2}
\end{bmatrix}
\tag{10}\]</span></span></p>
<hr>
<p>è¿™æ ·ï¼Œå¯¹äºç¬¬ <span class="math inline">\(j\)</span> ä¸ª token çš„ key å‘é‡ <span class="math inline">\(k^{(j)}\)</span>ï¼ŒRoPE ä¹Ÿä¼šåšç±»ä¼¼çš„æ—‹è½¬ï¼š</p>
<p><span id="eq-rope-k-rotated"><span class="math display">\[
k'^{(j)} = R_j k^{(j)}
\tag{11}\]</span></span></p>
<p>è¿™æ ·åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° <span class="math inline">\(q'^{(i)} \cdot k'^{(j)}\)</span> æ—¶ï¼Œä½ç½®å·®å¼‚ä¼šä»¥â€œç›¸å¯¹æ—‹è½¬â€çš„å½¢å¼ä½“ç°å‡ºæ¥ï¼Œè¿™ä¹Ÿæ˜¯ RoPE åœ¨é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸­éå¸¸å¸¸ç”¨çš„åŸå› ä¹‹ä¸€ã€‚</p>
<p><span id="eq-rope-attention-score"><span class="math display">\[
q'^{(i)} \cdot k'^{(j)} = (R_i q^{(i)}) \cdot (R_j k^{(j)}) = q^{(i)} \cdot (R_i^T R_j k^{(j)})
\tag{12}\]</span></span></p>
<section id="rope-çš„å®ç°ç»†èŠ‚" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="rope-çš„å®ç°ç»†èŠ‚"><span class="header-section-number">3.5.1</span> RoPE çš„å®ç°ç»†èŠ‚</h3>
<p>RoPE å±‚<strong>æ²¡æœ‰å¯å­¦ä¹ å‚æ•°</strong>ã€‚ä¸ºäº†æ•ˆç‡ï¼Œé€šå¸¸ä¼šï¼š</p>
<ul>
<li>é¢„è®¡ç®—æ‰€æœ‰ <span class="math inline">\(\cos(\theta_{i,k})\)</span> ä¸ <span class="math inline">\(\sin(\theta_{i,k})\)</span></li>
<li>ä½œä¸º buffer ç¼“å­˜åœ¨æ¨¡å—é‡Œï¼Œè€Œä¸æ˜¯ <code>nn.Parameter</code>ï¼ˆå› ä¸ºå®ƒä»¬æ˜¯å›ºå®šçš„ï¼‰</li>
<li>ç”šè‡³å¯ä»¥è®©æ‰€æœ‰ Transformer å±‚å…±äº«åŒä¸€ä¸ª RoPE æ¨¡å—ï¼ˆè·¨å±‚å¤ç”¨ç¼“å­˜ï¼‰</li>
</ul>
<p>å®ç°ä¸Šå¸¸ç”¨ï¼š</p>
<ul>
<li><code>self.register_buffer(..., persistent=False)</code> æ¥ä¿å­˜é¢„è®¡ç®—å¥½çš„ sin/cosï¼ˆä¸è¿› state_dict æˆ–ä¸ä½œä¸ºå¯è®­ç»ƒå‚æ•°ï¼‰</li>
<li>åªè¦åºåˆ—é•¿åº¦/ç»´åº¦ä¸å˜ï¼Œè¿™äº›å€¼å¯ä»¥åœ¨ä¸åŒ batchã€ä¸åŒ layer é—´å¤ç”¨</li>
</ul>
<p>ä¸è¿‡ï¼Œåœ¨å®é™…å®ç° RoPE æ—‹è½¬æ—¶ï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦æ˜¾å¼æ„å»ºå¤§å—å¯¹è§’çŸ©é˜µ <span class="math inline">\(R_i\)</span>ï¼Œè€Œæ˜¯æŠŠå‘é‡æŒ‰ 2 ç»´ä¸€ç»„é…å¯¹ <span class="math inline">\((x_{2k-1}, x_{2k})\)</span> ï¼Œå¯¹æ¯ä¸€ç»„åšä¸€ä¸ªå¹³é¢æ—‹è½¬ï¼š</p>
<p><span class="math display">\[
R_{\Theta,m}^{d} \mathbf{x}
=
\begin{pmatrix}
x_1\\
x_2\\
x_3\\
x_4\\
\vdots\\
x_{d-1}\\
x_d
\end{pmatrix}
\otimes
\begin{pmatrix}
\cos(m\theta_{1})\\
\cos(m\theta_{1})\\
\cos(m\theta_{2})\\
\cos(m\theta_{2})\\
\vdots\\
\cos\!\big(m\theta_{d/2}\big)\\
\cos\!\big(m\theta_{d/2}\big)
\end{pmatrix}
+
\begin{pmatrix}
- x_2\\
x_1\\
- x_4\\
x_3\\
\vdots\\
- x_d\\
x_{d-1}
\end{pmatrix}
\otimes
\begin{pmatrix}
\sin(m\theta_{1})\\
\sin(m\theta_{1})\\
\sin(m\theta_{2})\\
\sin(m\theta_{2})\\
\vdots\\
\sin\!\big(m\theta_{d/2}\big)\\
\sin\!\big(m\theta_{d/2}\big)
\end{pmatrix}
=
\begin{pmatrix}
x_1 \cos(m\theta_{1}) - x_2 \sin(m\theta_{1})\\
x_2 \cos(m\theta_{1}) + x_1 \sin(m\theta_{1})\\
x_3 \cos(m\theta_{2}) - x_4 \sin(m\theta_{2})\\
x_4 \cos(m\theta_{2}) + x_3 \sin(m\theta_{2})\\
\vdots\\
x_{d-1} \cos(m\theta_{d/2}) - x_d \sin(m\theta_{d/2})\\
x_d \cos(m\theta_{d/2}) + x_{d-1} \sin(m\theta_{d/2})
\end{pmatrix}
\]</span></p>
<p>ä»£ç çš„å®ç°ä¹Ÿå¾ˆç®€å•ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/rope.py</strong></pre>
</div>
<div class="sourceCode" id="cb42" data-filename="cs336_basics/modules/rope.py" data-code-line-numbers="15,20,21,22,31,32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a><span class="kw">class</span> RoPEEmbedding(nn.Module):</span>
<span id="cb42-2"><a href="#cb42-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb42-3"><a href="#cb42-3"></a>        <span class="va">self</span>,</span>
<span id="cb42-4"><a href="#cb42-4"></a>        theta: <span class="bu">float</span>,</span>
<span id="cb42-5"><a href="#cb42-5"></a>        d_k: <span class="bu">int</span>,</span>
<span id="cb42-6"><a href="#cb42-6"></a>        max_seq_len: <span class="bu">int</span>,</span>
<span id="cb42-7"><a href="#cb42-7"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb42-8"><a href="#cb42-8"></a>    ):</span>
<span id="cb42-9"><a href="#cb42-9"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb42-10"><a href="#cb42-10"></a></span>
<span id="cb42-11"><a href="#cb42-11"></a>        <span class="va">self</span>.theta <span class="op">=</span> theta</span>
<span id="cb42-12"><a href="#cb42-12"></a>        <span class="va">self</span>.d_k <span class="op">=</span> d_k</span>
<span id="cb42-13"><a href="#cb42-13"></a>        <span class="va">self</span>.max_seq_len <span class="op">=</span> max_seq_len</span>
<span id="cb42-14"><a href="#cb42-14"></a></span>
<span id="cb42-15"><a href="#cb42-15"></a>        inv_freq <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (theta <span class="op">**</span> (torch.arange(<span class="dv">0</span>, d_k, <span class="dv">2</span>, device<span class="op">=</span>device, dtype<span class="op">=</span>torch.float32) <span class="op">/</span> d_k)) </span>
<span id="cb42-16"><a href="#cb42-16"></a></span>
<span id="cb42-17"><a href="#cb42-17"></a>        <span class="va">self</span>.register_buffer(<span class="st">"inv_freq"</span>, inv_freq, persistent<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb42-18"><a href="#cb42-18"></a></span>
<span id="cb42-19"><a href="#cb42-19"></a>    <span class="kw">def</span> _rotate_half(<span class="va">self</span>, x):</span>
<span id="cb42-20"><a href="#cb42-20"></a>        x <span class="op">=</span> einops.rearrange(x, <span class="st">"... (d j) -&gt; ... d j"</span>, j<span class="op">=</span><span class="dv">2</span>) </span>
<span id="cb42-21"><a href="#cb42-21"></a>        x1, x2 <span class="op">=</span> x.unbind(dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb42-22"><a href="#cb42-22"></a>        <span class="cf">return</span> einops.rearrange(torch.stack((<span class="op">-</span>x2, x1), dim<span class="op">=-</span><span class="dv">1</span>), <span class="st">"... d j-&gt; ... (d j)"</span>) </span>
<span id="cb42-23"><a href="#cb42-23"></a></span>
<span id="cb42-24"><a href="#cb42-24"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor, token_positions: <span class="bu">int</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb42-25"><a href="#cb42-25"></a>        <span class="cf">if</span> token_positions <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb42-26"><a href="#cb42-26"></a>            seq_len <span class="op">=</span> x.shape[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb42-27"><a href="#cb42-27"></a>            token_positions <span class="op">=</span> torch.arange(seq_len, device<span class="op">=</span>x.device)</span>
<span id="cb42-28"><a href="#cb42-28"></a>            token_positions <span class="op">=</span> token_positions.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb42-29"><a href="#cb42-29"></a></span>
<span id="cb42-30"><a href="#cb42-30"></a>        theta <span class="op">=</span> torch.einsum(<span class="st">"...i , j -&gt; ... i j"</span>, token_positions, <span class="va">self</span>.inv_freq)</span>
<span id="cb42-31"><a href="#cb42-31"></a>        cos <span class="op">=</span> torch.cos(theta).repeat_interleave(<span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb42-32"><a href="#cb42-32"></a>        sin <span class="op">=</span> torch.sin(theta).repeat_interleave(<span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb42-33"><a href="#cb42-33"></a></span>
<span id="cb42-34"><a href="#cb42-34"></a>        x_rotated <span class="op">=</span> (x <span class="op">*</span> cos) <span class="op">+</span> (<span class="va">self</span>._rotate_half(x) <span class="op">*</span> sin)</span>
<span id="cb42-35"><a href="#cb42-35"></a>        <span class="cf">return</span> x_rotated</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="note foldable is-open">
<div class="note-header foldable-header">
<p>NOTE: RoPE in Open Source Project</p>
</div>
<div class="note-container foldable-content">
<p>åœ¨é˜…è¯»å…¶ä»–LLMçš„æºä»£ç æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šç¢°åˆ°ä»¥ä¸‹å½¢å¼çš„å®ç°ï¼š</p>
<div class="sourceCode" id="cb43" data-code-line-numbers="2,3,13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="kw">def</span> rotate_half(x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb43-2"><a href="#cb43-2"></a>    x1, x2 <span class="op">=</span> x.chunk(<span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb43-3"><a href="#cb43-3"></a>    <span class="cf">return</span> torch.cat((<span class="op">-</span>x2, x1), dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb43-4"><a href="#cb43-4"></a></span>
<span id="cb43-5"><a href="#cb43-5"></a></span>
<span id="cb43-6"><a href="#cb43-6"></a><span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor, token_positions: <span class="bu">int</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb43-7"><a href="#cb43-7"></a>    <span class="cf">if</span> token_positions <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb43-8"><a href="#cb43-8"></a>        seq_len <span class="op">=</span> x.shape[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb43-9"><a href="#cb43-9"></a>        token_positions <span class="op">=</span> torch.arange(seq_len, device<span class="op">=</span>x.device)</span>
<span id="cb43-10"><a href="#cb43-10"></a>        token_positions <span class="op">=</span> token_positions.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb43-11"><a href="#cb43-11"></a></span>
<span id="cb43-12"><a href="#cb43-12"></a>    theta <span class="op">=</span> torch.einsum(<span class="st">"...i , j -&gt; ... i j"</span>, token_positions, <span class="va">self</span>.inv_freq)</span>
<span id="cb43-13"><a href="#cb43-13"></a>    theta <span class="op">=</span> torch.cat([theta, theta], dim<span class="op">=-</span><span class="dv">1</span>) </span>
<span id="cb43-14"><a href="#cb43-14"></a>    cos <span class="op">=</span> torch.cos(theta)</span>
<span id="cb43-15"><a href="#cb43-15"></a>    sin <span class="op">=</span> torch.sin(theta)</span>
<span id="cb43-16"><a href="#cb43-16"></a>    x_rotated <span class="op">=</span> (x <span class="op">*</span> cos) <span class="op">+</span> (<span class="va">self</span>._rotate_half(x) <span class="op">*</span> sin)</span>
<span id="cb43-17"><a href="#cb43-17"></a>    <span class="cf">return</span> x_rotated</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>è¿™æ®µå®ç°<strong>çœ‹èµ·æ¥å’Œè®ºæ–‡é‡Œçš„ <span class="math inline">\(R_i\)</span> å—å¯¹è§’çŸ©é˜µå…¬å¼ä¸ä¸€æ ·</strong>ï¼šè®ºæ–‡å†™çš„æ˜¯â€œæ¯ä¸¤ç»´ä¸€ç»„åš 2D æ—‹è½¬â€ï¼Œè€Œè¿™é‡ŒæŠŠå‘é‡æ‹†æˆä¸¤åŠ <code>(x1, x2)</code>ï¼Œå†ç”¨ <code>rotate_half</code> åšæ‹¼æ¥ï¼Œåƒæ˜¯åœ¨â€œæ•´ä½“æ¢ä½â€ã€‚</p>
<p><span class="math display">\[
\operatorname{rotate\_half}(x) = (-x_{\text{second half}},\ x_{\text{first half}})
\]</span></p>
<p>è¿™å¯¹åº”çš„å°±æ˜¯â€œäºŒç»´æ—‹è½¬é‡Œé‚£ä¸ªæŠŠ <span class="math inline">\((a,b)\)</span> å˜æˆ <span class="math inline">\((-b,a)\)</span>â€çš„æ“ä½œï¼Œåªä¸è¿‡å®ƒæŠŠé…å¯¹æ–¹å¼ä»è®ºæ–‡å¸¸è§çš„â€œ(1,2)(3,4)â€¦é‚»æ¥é…å¯¹â€ï¼Œæ¢æˆäº†â€œ(å‰åŠ, ååŠ) çš„é…å¯¹â€ã€‚ åªè¦ cos/sin çš„é‡å¤æ–¹å¼ å’Œ rotate çš„é…å¯¹æ–¹å¼ ä¸€è‡´ï¼Œé…å¯¹æ˜¯é‚»æ¥è¿˜æ˜¯å‰ååŠï¼Œæœ¬è´¨éƒ½åœ¨åšåŒä¸€ä¸ª block-rotationã€‚</p>
<p>è¿™ä¸¤ç§åªæ˜¯<strong>åæ ‡é‡æ’ï¼ˆpermutationï¼‰</strong>ä¸åŒï¼šå­˜åœ¨ä¸€ä¸ªç½®æ¢çŸ©é˜µ Pï¼Œä½¿å¾—</p>
<p><span class="math display">\[
R_{\text{half-split}} = P^\top R_{\text{adjacent}} P
\]</span></p>
<p>å‡ ä½•ä¸Šä»ç„¶æ˜¯å¯¹æ¯ä¸ª 2D å­ç©ºé—´åšæ—‹è½¬ï¼Œæ‰€ä»¥ä¸€æ ·å¯è¡Œã€‚</p>
</div>
</div>
<p>å½“ç„¶ï¼Œé™¤äº†ä¸Šé¢çš„è¿™ç§å½¢å¼ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æ„é€ Complex Numberçš„å½¢å¼æ¥å®ŒæˆVectorçš„æ—‹è½¬ï¼Œåœ¨è¿™é‡Œå°±ä¸å±•å¼€äº†ã€‚æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒLLaMAçš„<a href="https://github.com/meta-llama/llama/blob/main/llama/model.py#L132">Inference Code</a>ã€‚</p>
</section>
</section>
<section id="multi-headed-attention" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="multi-headed-attention"><span class="header-section-number">3.6</span> Multi-Headed Attention</h2>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å®ç°Transformerä¸­ï¼Œæœ€é‡è¦ä¹Ÿæ˜¯ç›¸å¯¹æ¯”è¾ƒå¤æ‚çš„éƒ¨åˆ†ï¼ŒAttentionï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ä»€ä¹ˆæ˜¯Scaled Dot Product Attention</p>
<section id="scaled-dot-product-attention" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="scaled-dot-product-attention"><span class="header-section-number">3.6.1</span> Scaled Dot-Product Attention</h3>
<p>åœ¨ Transformer<span class="citation" data-cites="AttentionAllYou2023vaswani">(<a href="#ref-AttentionAllYou2023vaswani" role="doc-biblioref">Vaswani et al. 2023</a>)</span>ä¸­ï¼Œæœ€æ ¸å¿ƒçš„è®¡ç®—ä¹‹ä¸€å°±æ˜¯ <strong>scaled dot-product attention</strong>ã€‚å®ƒå¯ä»¥çœ‹ä½œï¼š</p>
<ol type="1">
<li>è®¡ç®— query å’Œ key çš„ç›¸ä¼¼åº¦ï¼ˆæ‰“åˆ†ï¼‰ï¼Œ</li>
<li>æŠŠè¿™äº›åˆ†æ•°(logits)å½’ä¸€åŒ–æˆæ¦‚ç‡åˆ†å¸ƒï¼Œ</li>
<li>æœ€åç”¨è¿™ä¸ªåˆ†å¸ƒå¯¹ value åšåŠ æƒæ±‚å’Œã€‚</li>
</ol>
<p>é¦–å…ˆæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•å°†åˆ†æ•°(logits)å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬éœ€è¦ç”¨åˆ°çš„å°±æ˜¯ Softmax å‡½æ•°</p>
<section id="softmax-function" class="level4" data-number="3.6.1.1">
<h4 data-number="3.6.1.1" class="anchored" data-anchor-id="softmax-function"><span class="header-section-number">3.6.1.1</span> Softmax Function</h4>
<p>Softmax çš„å®šä¹‰æ˜¯ï¼š</p>
<p><span id="eq-softmax"><span class="math display">\[
\mathrm{softmax}(v)_i=\frac{\exp(v_i)}{\sum_{j=1}^{n}\exp(v_j)}
\tag{13}\]</span></span></p>
<p>ç›´è§‰ä¸Šï¼Œsoftmax ä¼šæŠŠä»»æ„å®æ•°å‘é‡å˜æˆä¸€ä¸ª<strong>éè´Ÿã€å’Œä¸º 1</strong> çš„åˆ†å¸ƒï¼Œå› æ­¤å¸¸ç”¨äºæ³¨æ„åŠ›é‡Œçš„â€œæƒé‡å½’ä¸€åŒ–â€ã€‚ ç„¶è€Œï¼Œç›´æ¥ç®— softmax æœ‰ä¸€ä¸ª <tag style="color:orange">å¸¸è§æ•°å€¼é—®é¢˜</tag>ï¼šå½“ <span class="math inline">\(v_i\)</span> å¾ˆå¤§æ—¶ï¼Œ<span class="math inline">\(\exp(v_i)\)</span> å¯èƒ½æº¢å‡ºå˜æˆ <code>inf</code>ï¼Œä»è€Œå¯¼è‡´ <code>inf/inf = NaN</code>ã€‚ ä»”ç»†è§‚å¯Ÿæˆ‘ä»¬å¯ä»¥å‘ç°<strong>softmax å¯¹æ‰€æœ‰è¾“å…¥åŒæ—¶åŠ åŒä¸€ä¸ªå¸¸æ•°ä¸å˜</strong>ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹ä»»æ„å¸¸æ•° <span class="math inline">\(c\)</span>ï¼š</p>
<p><span id="eq-softmax-shift-invariance"><span class="math display">\[
\mathrm{softmax}(v)=\mathrm{softmax}(v+c).
\tag{14}\]</span></span></p>
<p>è¯æ˜å¾ˆç®€å•ï¼šåˆ†å­åˆ†æ¯éƒ½ä¼šå¤šä¹˜ä¸€ä¸ª <span class="math inline">\(\exp(c)\)</span>ï¼Œä¼šæŠµæ¶ˆæ‰ã€‚å› æ­¤å·¥ç¨‹å®ç°é‡Œé€šå¸¸å–ï¼š</p>
<p><span id="eq-softmax-shift-choice"><span class="math display">\[
c=-\max_i v_i,
\tag{15}\]</span></span></p>
<p>ä¹Ÿå°±æ˜¯æŠŠæœ€å¤§å€¼å‡åˆ° 0ï¼Œè¿™æ · <span class="math inline">\(\exp(\cdot)\)</span> çš„æœ€å¤§è¾“å…¥ä¸º 0ï¼Œä¸ä¼šçˆ†æ‰ï¼š</p>
<p><span id="eq-softmax-stable"><span class="math display">\[
\mathrm{softmax}(v)_i
=
\frac{\exp(v_i-\max(v))}{\sum_j \exp(v_j-\max(v))}.
\tag{16}\]</span></span></p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/attention.py</strong></pre>
</div>
<div class="sourceCode" id="cb44" data-filename="cs336_basics/modules/attention.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="kw">def</span> stable_softmax(</span>
<span id="cb44-2"><a href="#cb44-2"></a>    logits: torch.Tensor,</span>
<span id="cb44-3"><a href="#cb44-3"></a>    dim: <span class="bu">int</span> <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb44-4"><a href="#cb44-4"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb44-5"><a href="#cb44-5"></a>    max_logits <span class="op">=</span> torch.<span class="bu">max</span>(logits, dim<span class="op">=</span>dim, keepdim<span class="op">=</span><span class="va">True</span>).values</span>
<span id="cb44-6"><a href="#cb44-6"></a>    exp_logits <span class="op">=</span> torch.exp(logits <span class="op">-</span> max_logits)</span>
<span id="cb44-7"><a href="#cb44-7"></a>    sum_exp_logits <span class="op">=</span> torch.<span class="bu">sum</span>(exp_logits, dim<span class="op">=</span>dim, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-8"><a href="#cb44-8"></a>    softmax <span class="op">=</span> exp_logits <span class="op">/</span> sum_exp_logits</span>
<span id="cb44-9"><a href="#cb44-9"></a>    <span class="cf">return</span> softmax</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="scaled-dot-product-attention-1" class="level4" data-number="3.6.1.2">
<h4 data-number="3.6.1.2" class="anchored" data-anchor-id="scaled-dot-product-attention-1"><span class="header-section-number">3.6.1.2</span> Scaled Dot Product Attention</h4>
<p>æ¥ç€ï¼Œæˆ‘ä»¬æ¥çœ‹Scaled Dot-Product Attentionï¼Œ å…¶æ•°å­¦å®šä¹‰ä¸ºï¼š</p>
<p><span id="eq-scaled-dot-product-attention"><span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V,
\tag{17}\]</span></span></p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(Q\in\mathbb{R}^{n\times d_k}\)</span>ï¼š<span class="math inline">\(n\)</span> ä¸ª query</li>
<li><span class="math inline">\(K\in\mathbb{R}^{m\times d_k}\)</span>ï¼š<span class="math inline">\(m\)</span> ä¸ª key</li>
<li><span class="math inline">\(V\in\mathbb{R}^{m\times d_v}\)</span>ï¼š<span class="math inline">\(m\)</span> ä¸ª valueï¼ˆä¸ key ä¸€ä¸€å¯¹åº”ï¼‰</li>
</ul>
<p>è¿™é‡Œçš„ <span class="math inline">\(\frac{1}{\sqrt{d_k}}\)</span> æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„ç¼©æ”¾é¡¹ï¼šå½“ <span class="math inline">\(d_k\)</span> å˜å¤§æ—¶ï¼Œç‚¹ç§¯çš„æ–¹å·®ä¼šå˜å¤§ï¼Œsoftmax ä¼šæ›´å®¹æ˜“é¥±å’Œï¼ˆå˜å¾—æç«¯å°–é”ï¼‰ï¼Œç¼©æ”¾èƒ½è®©è®­ç»ƒæ›´ç¨³å®šã€‚</p>
<blockquote class="blockquote">
<p>We suspect that for large values of <span class="math inline">\(d_k\)</span>, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by <span class="math inline">\(\frac{1}{\sqrt{d_k}}\)</span>. <cite> Attention Is All You Need, p.&nbsp;4</cite></p>
</blockquote>
<p>æˆ‘ä»¬æ¥çœ‹ä¸‹é¢çš„å›¾ï¼Œå±•ç¤ºäº†ä¸åŒç¼©æ”¾å› å­å¯¹ softmax åˆ†å¸ƒçš„å½±å“ï¼š</p>
<div id="fig-attention-scaling-factor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-attention-scaling-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/attention-scaling-factor.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention-scaling-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Attention ä¸­çš„ç¼©æ”¾å› å­å¯¹ softmax åˆ†å¸ƒçš„å½±å“ï¼Œ å½“<span class="math inline">\(d_k\)</span> è¾ƒå¤§æ—¶ï¼Œç¼©æ”¾èƒ½é˜²æ­¢ softmax è¿‡äºå°–é”ã€‚
</figcaption>
</figure>
</div>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹ä»£ç å®ç°ï¼š</p>
<div class="sourceCode" id="cb45" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="kw">def</span> scaled_dot_product_attention(</span>
<span id="cb45-2"><a href="#cb45-2"></a>    query: torch.Tensor,</span>
<span id="cb45-3"><a href="#cb45-3"></a>    key: torch.Tensor,</span>
<span id="cb45-4"><a href="#cb45-4"></a>    value: torch.Tensor,</span>
<span id="cb45-5"><a href="#cb45-5"></a>    mask: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb45-6"><a href="#cb45-6"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb45-7"><a href="#cb45-7"></a>    d_k <span class="op">=</span> query.size(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb45-8"><a href="#cb45-8"></a>    scores <span class="op">=</span> torch.matmul(query, key.transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)) <span class="op">/</span> (d_k<span class="op">**</span><span class="fl">0.5</span>)</span>
<span id="cb45-9"><a href="#cb45-9"></a></span>
<span id="cb45-10"><a href="#cb45-10"></a>    <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb45-11"><a href="#cb45-11"></a>        scores <span class="op">=</span> scores.masked_fill(mask <span class="op">==</span> <span class="dv">0</span>, <span class="bu">float</span>(<span class="st">"-inf"</span>))</span>
<span id="cb45-12"><a href="#cb45-12"></a></span>
<span id="cb45-13"><a href="#cb45-13"></a>    attn_weights <span class="op">=</span> stable_softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-14"><a href="#cb45-14"></a>    output <span class="op">=</span> torch.matmul(attn_weights, value)</span>
<span id="cb45-15"><a href="#cb45-15"></a>    <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°æœ‰ä¸€ä¸ªMaskingï¼Œè¿™ä¸ªmaskçš„ä½œç”¨æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</p>
</section>
<section id="causal-masking" class="level4" data-number="3.6.1.3">
<h4 data-number="3.6.1.3" class="anchored" data-anchor-id="causal-masking"><span class="header-section-number">3.6.1.3</span> Causal Masking</h4>
<p>åœ¨å¾ˆå¤šåœºæ™¯ä¸‹æˆ‘ä»¬éœ€è¦ maskï¼ˆä¾‹å¦‚ causal LM ä¸­ä¸å…è®¸çœ‹æœªæ¥ tokenï¼Œæˆ– padding ä½ç½®ä¸å‚ä¸æ³¨æ„åŠ›ï¼‰ã€‚mask çš„å½¢çŠ¶æ˜¯ï¼š</p>
<p><span class="math display">\[
M =
\begin{bmatrix}
True &amp; False &amp; \cdots &amp; False \\
True &amp; True  &amp; \cdots &amp; False \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
True &amp; True  &amp; \cdots &amp; True
\end{bmatrix}
\]</span></p>
<p>æ³¨æ„è¿™é‡Œæœ‰ä¸ªå°çº¦å®šï¼ˆå®¹æ˜“æ··æ·†ï¼‰ï¼š</p>
<ul>
<li><strong>True è¡¨ç¤ºå…è®¸ attendï¼ˆä¿¡æ¯æµé€šï¼‰</strong><br>
</li>
<li><strong>False è¡¨ç¤ºä¸å…è®¸ attendï¼ˆéœ€è¦å±è”½ï¼‰</strong></li>
</ul>
<div id="fig-causal-mask-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-causal-mask-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/causal_mask.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-causal-mask-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Causal Mask ç¤ºä¾‹å›¾
</figcaption>
</figure>
</div>
<p>è®¡ç®—ä¸Šï¼Œæˆ‘ä»¬ä¸ä¼šçœŸçš„åˆ æ‰è¢«å±è”½çš„ key/valueï¼ˆé‚£æ ·æ•ˆç‡ä½ï¼‰ï¼Œè€Œæ˜¯åœ¨ softmax ä¹‹å‰çš„æ‰“åˆ†çŸ©é˜µä¸ŠåŠ¨æ‰‹è„šï¼šå¯¹æ‰€æœ‰ mask ä¸º False çš„ä½ç½®åŠ ä¸Š <span class="math inline">\(-\infty\)</span>ï¼š</p>
<p><span id="eq-attention-masking"><span class="math display">\[
S_{ij}=
\begin{cases}
S_{ij}, &amp; M_{ij}=\mathrm{True}\\
-\infty, &amp; M_{ij}=\mathrm{False}
\end{cases}
\tag{18}\]</span></span></p>
<p>è¿™æ · softmax åï¼š</p>
<p><span id="eq-exp-minus-infinity"><span class="math display">\[
\exp(-\infty)=0
\tag{19}\]</span></span></p>
<p>å¯¹åº”æƒé‡ä¸¥æ ¼ä¸º 0ï¼Œè¢«å±è”½çš„ä½ç½®è‡ªç„¶ä¸ä¼šå¯¹è¾“å‡ºäº§ç”Ÿè´¡çŒ®ã€‚æœ€ç»ˆè¾“å‡ºæ˜¯ï¼š</p>
<p><span id="eq-attention-masked-output"><span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}(S)V
\tag{20}\]</span></span></p>
<p>åœ¨è¯­è¨€æ¨¡å‹é‡Œï¼Œtoken <span class="math inline">\(i\)</span> é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ—¶ä¸åº”è¯¥è®¿é—® <span class="math inline">\(i\)</span> ä¹‹åçš„ token è¡¨ç¤ºï¼Œå¦åˆ™ä¼šæ³„éœ²ç­”æ¡ˆï¼Œè®­ç»ƒç›®æ ‡ä¼šè¢«â€œä½œå¼Šâ€è½»æ˜“å®Œæˆã€‚ å®ç°ä¸Šå¯ä»¥ç”¨</p>
<ol type="1">
<li><code>torch.triu</code>ï¼ˆä¸Šä¸‰è§’ï¼‰æ„é€  False åŒºåŸŸï¼Œ</li>
<li>ç”¨å¹¿æ’­æ¯”è¾ƒ <code>j &lt;= i</code>ã€‚</li>
</ol>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/attention.py</strong></pre>
</div>
<div class="sourceCode" id="cb46" data-filename="cs336_basics/modules/attention.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="co"># åˆ©ç”¨ torch.tril åˆ›å»ºå› æœæ©ç </span></span>
<span id="cb46-2"><a href="#cb46-2"></a><span class="kw">def</span> _create_causal_mask(<span class="va">self</span>, seq_len: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb46-3"><a href="#cb46-3"></a>    mask <span class="op">=</span> torch.tril(torch.ones(seq_len, seq_len, device<span class="op">=</span>device)).<span class="bu">bool</span>()</span>
<span id="cb46-4"><a href="#cb46-4"></a>    <span class="cf">return</span> mask.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb46-5"><a href="#cb46-5"></a></span>
<span id="cb46-6"><a href="#cb46-6"></a><span class="co"># åˆ©ç”¨å¹¿æ’­æ¯”è¾ƒåˆ›å»ºå› æœæ©ç </span></span>
<span id="cb46-7"><a href="#cb46-7"></a><span class="kw">def</span> _create_causal_mask(<span class="va">self</span>, seq_len: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb46-8"><a href="#cb46-8"></a>    positions <span class="op">=</span> torch.arange(seq_len, device<span class="op">=</span>device)</span>
<span id="cb46-9"><a href="#cb46-9"></a>    mask <span class="op">=</span> positions.unsqueeze(<span class="dv">0</span>) <span class="op">&lt;=</span> positions.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb46-10"><a href="#cb46-10"></a>    <span class="cf">return</span> mask.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb46-11"><a href="#cb46-11"></a></span>
<span id="cb46-12"><a href="#cb46-12"></a><span class="kw">def</span> scaled_dot_product_attention(</span>
<span id="cb46-13"><a href="#cb46-13"></a>    query: torch.Tensor,</span>
<span id="cb46-14"><a href="#cb46-14"></a>    key: torch.Tensor,</span>
<span id="cb46-15"><a href="#cb46-15"></a>    value: torch.Tensor,</span>
<span id="cb46-16"><a href="#cb46-16"></a>    mask: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb46-17"><a href="#cb46-17"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb46-18"><a href="#cb46-18"></a>    ...</span>
<span id="cb46-19"><a href="#cb46-19"></a></span>
<span id="cb46-20"><a href="#cb46-20"></a>    <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb46-21"><a href="#cb46-21"></a>        scores <span class="op">=</span> scores.masked_fill(mask <span class="op">==</span> <span class="dv">0</span>, <span class="bu">float</span>(<span class="st">"-inf"</span>))</span>
<span id="cb46-22"><a href="#cb46-22"></a></span>
<span id="cb46-23"><a href="#cb46-23"></a>    ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-tldr">
<p><strong>Attention çš„æœ¬è´¨</strong>:</p>
<p>æ˜¯â€œç›¸ä¼¼åº¦æ‰“åˆ† + softmax å½’ä¸€åŒ– + å¯¹ V åŠ æƒæ±‚å’Œâ€ã€‚å·¥ç¨‹å®ç°æ—¶è¦ç‰¹åˆ«æ³¨æ„ softmax çš„æ•°å€¼ç¨³å®šæ€§ï¼ˆå‡æœ€å¤§å€¼ï¼‰å’Œ maskingï¼ˆsoftmax å‰åŠ  <span class="math inline">\(-\infty\)</span>ï¼‰ï¼Œè¿™ä¸¤ç‚¹å‡ ä¹å†³å®šäº†æ³¨æ„åŠ›å®ç°æ˜¯å¦ç¨³å®šã€æ˜¯å¦é«˜æ•ˆã€‚</p>
</div>
</section>
</section>
<section id="multi-headed-attention-1" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="multi-headed-attention-1"><span class="header-section-number">3.6.2</span> Multi Headed Attention</h3>
<p>åœ¨å®ç°äº†å•ä¸ªAttentionæ¨¡å—ä¹‹åï¼Œæˆ‘ä»¬çœ‹çœ‹è¿™äº›å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·ï¼Œå®ç°æˆ‘ä»¬çš„Multi Headed Attention</p>
<blockquote class="blockquote">
<p>Instead of performing a single attention function with <span class="math inline">\(d_{\text{model}}\)</span>-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to <span class="math inline">\(d_k\)</span>, <span class="math inline">\(d_k\)</span> and <span class="math inline">\(d_v\)</span> dimensions, respectively. <cite> Attention Is All You Need, p.&nbsp;4</cite></p>
</blockquote>
<p>Multi-head attention çš„å®šä¹‰æ˜¯ï¼š</p>
<p><span id="eq-multi-head-attention"><span class="math display">\[
\mathrm{MultiHead}(Q,K,V) = \mathrm{Concat}(\mathrm{head}_1,\dots,\mathrm{head}_h)
\tag{21}\]</span></span></p>
<p>å…¶ä¸­æ¯ä¸ª head éƒ½æ˜¯ä¸€æ¬¡æ ‡å‡† scaled dot-product attention (<a href="#eq-scaled-dot-product-attention" class="quarto-xref">Equation&nbsp;17</a>)ï¼š</p>
<p><span id="eq-multi-head-head-i"><span class="math display">\[
\mathrm{head}_i = \mathrm{Attention}(Q_i, K_i, V_i)
\tag{22}\]</span></span></p>
<p>è¿™é‡Œçš„ <span class="math inline">\(Q_i, K_i, V_i\)</span> æ˜¯æŠŠ <span class="math inline">\(Q,K,V\)</span> æ²¿ embedding ç»´åº¦åˆ‡åˆ†å¾—åˆ°çš„ç¬¬ <span class="math inline">\(i\)</span> ä¸ª sliceï¼ˆæ¯ä¸ª head çš„ç»´åº¦æ˜¯ <span class="math inline">\(d_k\)</span> æˆ– <span class="math inline">\(d_v\)</span>ï¼‰ã€‚</p>
<p>åœ¨ self-attention åœºæ™¯ä¸­ï¼Œ<span class="math inline">\(Q,K,V\)</span> éƒ½ç”±åŒä¸€ä¸ªè¾“å…¥ <span class="math inline">\(x\)</span> æŠ•å½±å¾—åˆ°ï¼š</p>
<p><span id="eq-multi-head-self-attention"><span class="math display">\[
\mathrm{MultiHeadSelfAttention}(x) = W_O \cdot \mathrm{MultiHead}(W_Q x,\; W_K x,\; W_V x)
\tag{23}\]</span></span></p>
<p>å¯å­¦ä¹ å‚æ•°ä¸ºï¼š</p>
<p><span id="eq-mha-parameters"><span class="math display">\[
W_Q \in \mathbb{R}^{h d_k \times d_{\text{model}}},\quad
W_K \in \mathbb{R}^{h d_k \times d_{\text{model}}},\quad
W_V \in \mathbb{R}^{h d_v \times d_{\text{model}}},\quad
W_O \in \mathbb{R}^{d_{\text{model}} \times h d_v}.
\tag{24}\]</span></span></p>
<p>ä¸€ä¸ªå¾ˆé‡è¦çš„å·¥ç¨‹è§†è§’æ˜¯ï¼šå› ä¸ºåé¢ä¼šæŠŠè¾“å‡ºç»´åº¦ reshape æˆ <span class="math inline">\((h,\text{head\_dim})\)</span>ï¼Œæ‰€ä»¥ä½ å¯ä»¥æŠŠ <span class="math inline">\(W_Q,W_K,W_V\)</span> çœ‹æˆâ€œæ¯ä¸ª head å„æœ‰ä¸€ä»½æŠ•å½±çŸ©é˜µâ€ï¼Œåªä¸è¿‡å®ƒä»¬åœ¨å®ç°ä¸Šè¢«æ‹¼åˆ°åŒä¸€ä¸ªå¤§çŸ©é˜µé‡Œã€‚</p>
</section>
<section id="shape-transformations-in-attention" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="shape-transformations-in-attention"><span class="header-section-number">3.6.3</span> Shape Transformations in Attention</h3>
<p>åœ¨ç»§ç»­å®Œæˆ MHA ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆç†æ¸…æ¥š shape å˜åŒ–ã€‚å‡è®¾ï¼š</p>
<ul>
<li>è¾“å…¥ <span class="math inline">\(x\)</span> çš„ shape æ˜¯ <code>(batch_size, seq_len, d_model)</code></li>
<li>head æ•°é‡æ˜¯ <code>num_heads</code></li>
<li>æ¯ä¸ª head çš„ç»´åº¦æ˜¯ <code>d_k = d_model // num_heads</code></li>
</ul>
<p>é‚£ä¹ˆï¼Œè®¡ç®— <span class="math inline">\(Q,K,V\)</span> çš„çº¿æ€§æŠ•å½±åï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬ reshape æˆ <code>(batch_size, num_heads, seq_len, d_k)</code>ï¼Œä»¥ä¾¿æ¯ä¸ª head ç‹¬ç«‹è®¡ç®—æ³¨æ„åŠ›ã€‚å®ç°ä¸Šé€šå¸¸ç”¨ä»¥ä¸‹ä¸¤æ­¥ï¼š</p>
<ol type="1">
<li>å…ˆç”¨ <code>view()</code> æŠŠæœ€åä¸€ç»´æ‹†æˆ <code>(num_heads, d_k)</code>ï¼Œå˜æˆ <code>(batch_size, seq_len, num_heads, d_k)</code></li>
<li>å†ç”¨ <code>transpose()</code> æŠŠ <code>num_heads</code> ç»´åº¦ç§»åˆ°ç¬¬äºŒç»´ï¼Œå˜æˆ <code>(batch_size, num_heads, seq_len, d_k)</code></li>
</ol>
<p>ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æˆ‘ä»¬çš„scores:</p>
<div class="sourceCode" id="cb47" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb47-1"><a href="#cb47-1"></a>Q (batch_size, seq_len, num_heads, d_k) @ K^T (batch_size, num_heads, d_k, seq_len)  -&gt; Score (batch_size, num_heads, seq_len, seq_len)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>softmax å’Œ maskï¼Œä¸ä¼šæ”¹å˜ shapeï¼Œæœ€åå¯¹ V åšåŠ æƒæ±‚å’Œåï¼Œè¾“å‡º shape æ˜¯ <code>(batch_size, num_heads, seq_len, d_k)</code>ã€‚æœ€åä¸€æ­¥æ˜¯æŠŠå¤šå¤´è¾“å‡ºæ‹¼å›åŸå§‹ç»´åº¦ï¼š</p>
<ol type="1">
<li>å…ˆç”¨ <code>transpose()</code> æŠŠ <code>num_heads</code> ç»´åº¦ç§»å›ç¬¬ä¸‰ç»´ï¼Œå˜æˆ <code>(batch_size, seq_len, num_heads, d_k)</code></li>
<li>å†ç”¨ <code>contiguous().view()</code> æŠŠæœ€åä¸¤ç»´æ‹¼å›å»ï¼Œå˜æˆ <code>(batch_size, seq_len, d_model)</code>ã€‚</li>
<li>æœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚ <span class="math inline">\(W_O\)</span> æŠ•å½±å›åŸå§‹ç»´åº¦ã€‚</li>
<li>æœ€ç»ˆè¾“å‡º shape æ˜¯ <code>(batch_size, seq_len, d_model)</code>ã€‚</li>
</ol>
<div class="sourceCode" id="cb48" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb48-1"><a href="#cb48-1"></a>x : (B, S, D)</span>
<span id="cb48-2"><a href="#cb48-2"></a>    +--&gt; Q = x W_Q : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)</span>
<span id="cb48-3"><a href="#cb48-3"></a>    |</span>
<span id="cb48-4"><a href="#cb48-4"></a>    +--&gt; K = x W_K : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)</span>
<span id="cb48-5"><a href="#cb48-5"></a>    |</span>
<span id="cb48-6"><a href="#cb48-6"></a>    +--&gt; V = x W_V : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)</span>
<span id="cb48-7"><a href="#cb48-7"></a></span>
<span id="cb48-8"><a href="#cb48-8"></a>             K^T : (B,H,d_k,S)</span>
<span id="cb48-9"><a href="#cb48-9"></a>scores = Q @ K^T  -----------------&gt; scores : (B,H,S,S)</span>
<span id="cb48-10"><a href="#cb48-10"></a>        (B,H,S,d_k) @ (B,H,d_k,S)</span>
<span id="cb48-11"><a href="#cb48-11"></a></span>
<span id="cb48-12"><a href="#cb48-12"></a>scores / sqrt(d_k) ----------------&gt; (B,H,S,S)</span>
<span id="cb48-13"><a href="#cb48-13"></a>+ mask (add -inf) -----------------&gt; (B,H,S,S)</span>
<span id="cb48-14"><a href="#cb48-14"></a>softmax (last dim) ----------------&gt; attn : (B,H,S,S)</span>
<span id="cb48-15"><a href="#cb48-15"></a></span>
<span id="cb48-16"><a href="#cb48-16"></a>out_heads = attn @ V  -------------&gt; out_heads : (B,H,S,d_k)</span>
<span id="cb48-17"><a href="#cb48-17"></a>            (B,H,S,S) @ (B,H,S,d_k)</span>
<span id="cb48-18"><a href="#cb48-18"></a></span>
<span id="cb48-19"><a href="#cb48-19"></a>transpose(1,2) --------------------&gt; (B,S,H,d_k)</span>
<span id="cb48-20"><a href="#cb48-20"></a>contiguous().view(B,S,D) ----------&gt; out : (B,S,D)</span>
<span id="cb48-21"><a href="#cb48-21"></a>W_O (Linear) ----------------------&gt; y : (B,S,D)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rope-in-attention" class="level3" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="rope-in-attention"><span class="header-section-number">3.6.4</span> RoPE in Attention</h3>
<p>åœ¨ä½¿ç”¨ RoPE çš„ç‰ˆæœ¬ä¸­ï¼Œéœ€è¦å¯¹ <strong>Q å’Œ K</strong> åšåŒæ ·çš„ä½ç½®æ—‹è½¬ï¼š</p>
<ul>
<li>å¯¹æ¯ä¸ª head çš„ <span class="math inline">\(Q\)</span> åº”ç”¨ RoPE</li>
<li>å¯¹æ¯ä¸ª head çš„ <span class="math inline">\(K\)</span> åº”ç”¨ RoPE</li>
<li><strong>ä¸è¦</strong>å¯¹ <span class="math inline">\(V\)</span> åº”ç”¨ RoPE</li>
</ul>
<p>åŸå› æ˜¯ï¼šRoPE å½±å“çš„æ˜¯â€œç›¸ä¼¼åº¦æ‰“åˆ†â€ï¼ˆ<span class="math inline">\(QK^\top\)</span>ï¼‰çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼›è€Œ <span class="math inline">\(V\)</span> æ˜¯è¢«åŠ æƒæ±‡èšçš„å†…å®¹æœ¬èº«ï¼Œé€šå¸¸ä¸éœ€è¦åšæ—‹è½¬ã€‚</p>
<p>å¦å¤–ï¼ŒRoPE çš„ä¸€ä¸ªå®ç°ç»†èŠ‚æ˜¯ï¼šåœ¨ multi-head ä¸­ï¼Œhead ç»´å¯ä»¥è§†ä¸º batch ç»´æ¥å¤„ç†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒåŒä¸€ä¸ªä½ç½® <span class="math inline">\(i\)</span> å¯¹åº”çš„æ—‹è½¬ï¼ˆcos/sinï¼‰åº”è¯¥å¯¹ <strong>æ‰€æœ‰ head å…±äº«</strong>ï¼Œæ¯ä¸ª head ç‹¬ç«‹åš attentionï¼Œä½†æ—‹è½¬è§„åˆ™ä¸€è‡´ã€‚</p>
<p>æœ‰äº†è¿™äº›æ¨¡å—ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†æœ€ç»ˆçš„MHA</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/modules/attention.py</strong></pre>
</div>
<div class="sourceCode" id="cb49" data-filename="cs336_basics/modules/attention.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a><span class="kw">class</span> MHA(nn.Module):</span>
<span id="cb49-2"><a href="#cb49-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb49-3"><a href="#cb49-3"></a>        <span class="va">self</span>,</span>
<span id="cb49-4"><a href="#cb49-4"></a>        d_model: <span class="bu">int</span>,</span>
<span id="cb49-5"><a href="#cb49-5"></a>        num_heads: <span class="bu">int</span>,</span>
<span id="cb49-6"><a href="#cb49-6"></a>        use_rope: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb49-7"><a href="#cb49-7"></a>        theta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">10000.0</span>,</span>
<span id="cb49-8"><a href="#cb49-8"></a>        max_seq_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2048</span>,</span>
<span id="cb49-9"><a href="#cb49-9"></a>        device: torch.device <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb49-10"><a href="#cb49-10"></a>        dtype: torch.dtype <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb49-11"><a href="#cb49-11"></a>    ):</span>
<span id="cb49-12"><a href="#cb49-12"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb49-13"><a href="#cb49-13"></a></span>
<span id="cb49-14"><a href="#cb49-14"></a>        <span class="im">from</span> cs336_basics.modules.linear <span class="im">import</span> Linear</span>
<span id="cb49-15"><a href="#cb49-15"></a>        <span class="im">from</span> cs336_basics.modules.rope <span class="im">import</span> RoPEEmbedding</span>
<span id="cb49-16"><a href="#cb49-16"></a></span>
<span id="cb49-17"><a href="#cb49-17"></a>        <span class="cf">assert</span> d_model <span class="op">%</span> num_heads <span class="op">==</span> <span class="dv">0</span>, <span class="st">"d_model must be divisible by num_heads"</span></span>
<span id="cb49-18"><a href="#cb49-18"></a></span>
<span id="cb49-19"><a href="#cb49-19"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb49-20"><a href="#cb49-20"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb49-21"><a href="#cb49-21"></a>        <span class="va">self</span>.d_k <span class="op">=</span> d_model <span class="op">//</span> num_heads</span>
<span id="cb49-22"><a href="#cb49-22"></a></span>
<span id="cb49-23"><a href="#cb49-23"></a>        <span class="va">self</span>.q_linear <span class="op">=</span> Linear(d_model, d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb49-24"><a href="#cb49-24"></a>        <span class="va">self</span>.k_linear <span class="op">=</span> Linear(d_model, d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb49-25"><a href="#cb49-25"></a>        <span class="va">self</span>.v_linear <span class="op">=</span> Linear(d_model, d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb49-26"><a href="#cb49-26"></a>        <span class="va">self</span>.out_linear <span class="op">=</span> Linear(d_model, d_model, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb49-27"><a href="#cb49-27"></a></span>
<span id="cb49-28"><a href="#cb49-28"></a>        <span class="va">self</span>.use_rope <span class="op">=</span> use_rope</span>
<span id="cb49-29"><a href="#cb49-29"></a>        <span class="cf">if</span> use_rope:</span>
<span id="cb49-30"><a href="#cb49-30"></a>            <span class="va">self</span>.rope <span class="op">=</span> RoPEEmbedding(</span>
<span id="cb49-31"><a href="#cb49-31"></a>                theta<span class="op">=</span>theta,</span>
<span id="cb49-32"><a href="#cb49-32"></a>                d_k<span class="op">=</span><span class="va">self</span>.d_k,</span>
<span id="cb49-33"><a href="#cb49-33"></a>                max_seq_len<span class="op">=</span>max_seq_len,</span>
<span id="cb49-34"><a href="#cb49-34"></a>                device<span class="op">=</span>device,</span>
<span id="cb49-35"><a href="#cb49-35"></a>            )</span>
<span id="cb49-36"><a href="#cb49-36"></a></span>
<span id="cb49-37"><a href="#cb49-37"></a>    <span class="kw">def</span> _create_causal_mask(<span class="va">self</span>, seq_len: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb49-38"><a href="#cb49-38"></a>        mask <span class="op">=</span> torch.tril(torch.ones(seq_len, seq_len, device<span class="op">=</span>device)).<span class="bu">bool</span>()</span>
<span id="cb49-39"><a href="#cb49-39"></a>        <span class="cf">return</span> mask.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb49-40"><a href="#cb49-40"></a></span>
<span id="cb49-41"><a href="#cb49-41"></a>    <span class="kw">def</span> forward(</span>
<span id="cb49-42"><a href="#cb49-42"></a>        <span class="va">self</span>,</span>
<span id="cb49-43"><a href="#cb49-43"></a>        x: torch.Tensor,</span>
<span id="cb49-44"><a href="#cb49-44"></a>        token_positions: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb49-45"><a href="#cb49-45"></a>    ) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb49-46"><a href="#cb49-46"></a>        batch_size, seq_len, _ <span class="op">=</span> x.size()</span>
<span id="cb49-47"><a href="#cb49-47"></a>        causal_mask <span class="op">=</span> <span class="va">self</span>._create_causal_mask(seq_len, x.device)</span>
<span id="cb49-48"><a href="#cb49-48"></a></span>
<span id="cb49-49"><a href="#cb49-49"></a>        Q <span class="op">=</span> <span class="va">self</span>.q_linear(x).view(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_heads, <span class="va">self</span>.d_k).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb49-50"><a href="#cb49-50"></a>        K <span class="op">=</span> <span class="va">self</span>.k_linear(x).view(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_heads, <span class="va">self</span>.d_k).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb49-51"><a href="#cb49-51"></a>        V <span class="op">=</span> <span class="va">self</span>.v_linear(x).view(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_heads, <span class="va">self</span>.d_k).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb49-52"><a href="#cb49-52"></a></span>
<span id="cb49-53"><a href="#cb49-53"></a>        <span class="cf">if</span> <span class="va">self</span>.use_rope:</span>
<span id="cb49-54"><a href="#cb49-54"></a>            Q, K <span class="op">=</span> <span class="va">self</span>.rope(Q, token_positions), <span class="va">self</span>.rope(K, token_positions)</span>
<span id="cb49-55"><a href="#cb49-55"></a></span>
<span id="cb49-56"><a href="#cb49-56"></a>        attn_output <span class="op">=</span> scaled_dot_product_attention(Q, K, V, mask<span class="op">=</span>causal_mask)</span>
<span id="cb49-57"><a href="#cb49-57"></a></span>
<span id="cb49-58"><a href="#cb49-58"></a>        attn_output <span class="op">=</span> attn_output.transpose(<span class="dv">1</span>, <span class="dv">2</span>).contiguous().view(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.d_model)</span>
<span id="cb49-59"><a href="#cb49-59"></a></span>
<span id="cb49-60"><a href="#cb49-60"></a>        output <span class="op">=</span> <span class="va">self</span>.out_linear(attn_output)</span>
<span id="cb49-61"><a href="#cb49-61"></a></span>
<span id="cb49-62"><a href="#cb49-62"></a>        <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="transformer-block" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="transformer-block"><span class="header-section-number">3.7</span> Transformer Block</h2>
<p>æœ‰äº†è¿™äº›æ¨¡å—ï¼Œæˆ‘ä»¬å°±å¯ä»¥å’Œæ­ç§¯æœ¨ä¸€æ ·ï¼Œæ­å»ºæˆ‘ä»¬Transformer</p>
<p>å¯¹è¾“å…¥ <span class="math inline">\(x\)</span>ï¼Œç¬¬ä¸€å±‚çš„æ›´æ–°è§„åˆ™æ˜¯ï¼š</p>
<p><span id="eq-transformer-block-mha"><span class="math display">\[
y = x + \mathrm{MHA}(\mathrm{RMSNorm}(x)).
\tag{25}\]</span></span></p>
<p>è¿™å¥è¯å¯ä»¥æ‹†å¼€ç†è§£ä¸ºä¸‰æ­¥ï¼š</p>
<ul>
<li><strong>(1) å½’ä¸€åŒ–ï¼š</strong>å…ˆæŠŠè¾“å…¥ <span class="math inline">\(x\)</span> åš RMSNormï¼Œå¾—åˆ°æ›´ç¨³å®šçš„è¾“å…¥åˆ†å¸ƒ<br>
</li>
<li><strong>(2) ä¸»æ“ä½œï¼š</strong>æŠŠå½’ä¸€åŒ–åçš„å‘é‡é€å…¥ MHAï¼Œè®¡ç®—æ³¨æ„åŠ›è¾“å‡º<br>
</li>
<li><strong>(3) æ®‹å·®ï¼š</strong>æŠŠæ³¨æ„åŠ›è¾“å‡ºåŠ å›åŸè¾“å…¥ <span class="math inline">\(x\)</span>ï¼Œå½¢æˆ <span class="math inline">\(y\)</span></li>
</ul>
<section id="sec-pre-norm" class="level4" data-number="3.7.0.1">
<h4 data-number="3.7.0.1" class="anchored" data-anchor-id="sec-pre-norm"><span class="header-section-number">3.7.0.1</span> Pre-Norm</h4>
<p>è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨çš„æ˜¯ <strong>Pre-Norm</strong> ç»“æ„ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªå­å±‚ï¼ˆMHA æˆ– FFNï¼‰å‰åšå½’ä¸€åŒ–ã€‚Pre-Normç›¸å¯¹äº Post-Normï¼ˆå…ˆåšå­å±‚å†å½’ä¸€åŒ–ï¼‰æœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š</p>
<ol type="1">
<li><strong>è®­ç»ƒæ›´ç¨³å®š</strong>ï¼šPre-Norm å¯ä»¥ç¼“è§£æ·±å±‚ Transformer çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—è®­ç»ƒæ›´ç¨³å®šã€‚</li>
<li><strong>æ›´æ·±çš„æ¨¡å‹</strong>ï¼šPre-Norm å…è®¸æˆ‘ä»¬è®­ç»ƒæ›´æ·±çš„ Transformerï¼Œå› ä¸ºæ¯ä¸ªå­å±‚çš„è¾“å…¥éƒ½ç»è¿‡å½’ä¸€åŒ–ï¼Œå‡å°‘äº†å†…éƒ¨åå˜é‡åç§»ã€‚ 3ï¼Œ <strong>å¯¹Learning Rateæ›´ä¸æ•æ„Ÿ</strong>ï¼šPre-Norm ç»“æ„å¯¹å­¦ä¹ ç‡çš„é€‰æ‹©ä¸é‚£ä¹ˆæ•æ„Ÿï¼Œå…è®¸ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡è¿›è¡Œè®­ç»ƒã€‚</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Difference nomralization structures">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Difference nomralization structures
</div>
</div>
<div class="callout-body-container callout-body">
<p>å½“ç„¶ï¼Œé™¤äº†Pre-Normä¹‹å¤–ï¼Œç°åœ¨ä¹Ÿæœ‰ä¸€äº›å˜ä½“ç»“æ„ï¼Œæ¯”å¦‚ Hybrid Norm<span class="citation" data-cites="HybridNormStableEfficient2025zhuo">(<a href="#ref-HybridNormStableEfficient2025zhuo" role="doc-biblioref">Zhuo et al. 2025</a>)</span>ï¼ˆç»“åˆ Pre-Norm å’Œ Post-Norm çš„ä¼˜ç‚¹ï¼‰ ä¸‹å›¾æ¯”è¾ƒå±•ç¤ºäº†ä¸åŒå½’ä¸€åŒ–ç»“æ„ï¼š</p>
<div id="fig-hybird-norm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hybird-norm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/hybird-norm.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hybird-norm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: æ¯”è¾ƒä¸åŒçš„Normalizationçš„ç»“æ„ï¼Œa) Post-Norm ç»“æ„ï¼›b) Pre-Norm ç»“æ„ï¼› c) å¸¦ QK-Norm çš„ Pre-Norm ç»“æ„ï¼›d) HybridNorm ç»“æ„
</figcaption>
</figure>
</div>
</div>
</div>
<p>Transformer Block çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/model.py</strong></pre>
</div>
<div class="sourceCode" id="cb50" data-filename="cs336_basics/model.py" data-code-line-numbers="22,23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a><span class="kw">class</span> TransformerBlock(nn.Module):</span>
<span id="cb50-2"><a href="#cb50-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config: ModelConfig):</span>
<span id="cb50-3"><a href="#cb50-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb50-4"><a href="#cb50-4"></a></span>
<span id="cb50-5"><a href="#cb50-5"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb50-6"><a href="#cb50-6"></a></span>
<span id="cb50-7"><a href="#cb50-7"></a>        <span class="va">self</span>.mha <span class="op">=</span> MHA(</span>
<span id="cb50-8"><a href="#cb50-8"></a>            d_model<span class="op">=</span>config.d_model,</span>
<span id="cb50-9"><a href="#cb50-9"></a>            num_heads<span class="op">=</span>config.num_heads,</span>
<span id="cb50-10"><a href="#cb50-10"></a>            use_rope<span class="op">=</span>config.use_rope,</span>
<span id="cb50-11"><a href="#cb50-11"></a>            theta<span class="op">=</span>config.rope_theta,</span>
<span id="cb50-12"><a href="#cb50-12"></a>            max_seq_len<span class="op">=</span>config.max_seq_len,</span>
<span id="cb50-13"><a href="#cb50-13"></a>        )</span>
<span id="cb50-14"><a href="#cb50-14"></a>        <span class="va">self</span>.ffn <span class="op">=</span> FFN(</span>
<span id="cb50-15"><a href="#cb50-15"></a>            d_model<span class="op">=</span>config.d_model,</span>
<span id="cb50-16"><a href="#cb50-16"></a>            d_ff<span class="op">=</span>config.d_ff,</span>
<span id="cb50-17"><a href="#cb50-17"></a>        )</span>
<span id="cb50-18"><a href="#cb50-18"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> RMSNorm(config.d_model)</span>
<span id="cb50-19"><a href="#cb50-19"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> RMSNorm(config.d_model)</span>
<span id="cb50-20"><a href="#cb50-20"></a></span>
<span id="cb50-21"><a href="#cb50-21"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor, token_positions: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb50-22"><a href="#cb50-22"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.mha(<span class="va">self</span>.norm1(x), token_positions<span class="op">=</span>token_positions) </span>
<span id="cb50-23"><a href="#cb50-23"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.ffn(<span class="va">self</span>.norm2(x)) </span>
<span id="cb50-24"><a href="#cb50-24"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="output-layer" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="output-layer"><span class="header-section-number">3.8</span> Output Layer</h2>
<p>åœ¨å †å å®Œè‹¥å¹²ä¸ª Transformer blocks ä¹‹åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°æ¯ä¸ªä½ç½®çš„æœ€ç»ˆ hidden statesï¼š</p>
<p><span id="eq-transformer-output-states"><span class="math display">\[
H \in \mathbb{R}^{B \times T \times d_{\text{model}}}
\tag{26}\]</span></span></p>
<p>æ¥ä¸‹æ¥éœ€è¦ä¸€ä¸ª <strong>Output Layerï¼ˆLM Headï¼‰</strong> æŠŠ hidden states æ˜ å°„åˆ°è¯è¡¨å¤§å°çš„ logitsï¼š</p>
<p><span id="eq-output-layer"><span class="math display">\[
\mathrm{logits} = H W_{\text{out}}
\tag{27}\]</span></span></p>
<p>å…¶ä¸­ï¼š</p>
<p><span id="eq-output-layer-weights"><span class="math display">\[
W_{\text{out}} \in \mathbb{R}^{d_{\text{model}} \times |\mathcal{V}|}, \quad
\mathrm{logits} \in \mathbb{R}^{B \times T \times |\mathcal{V}|}.
\tag{28}\]</span></span></p>
<p>åœ¨å¾ˆå¤šç°ä»£ LLM ä¸­ï¼Œé€šå¸¸è¿˜ä¼šåœ¨è¾“å‡ºå±‚å‰åŠ ä¸€ä¸ªæœ€ç»ˆå½’ä¸€åŒ–ï¼ˆåŒæ ·æ˜¯ Pre-Norm é£æ ¼ï¼‰ï¼š</p>
<p><span id="eq-output-layer-with-norm"><span class="math display">\[
\mathrm{logits} = \mathrm{RMSNorm}(H)\, W_{\text{out}}.
\tag{29}\]</span></span></p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/model.py</strong></pre>
</div>
<div class="sourceCode" id="cb51" data-filename="cs336_basics/model.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="kw">class</span> OutputLayer(nn.Module):</span>
<span id="cb51-2"><a href="#cb51-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, vocab_size, use_norm: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb51-3"><a href="#cb51-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb51-4"><a href="#cb51-4"></a>        <span class="va">self</span>.linear <span class="op">=</span> Linear(d_model, vocab_size)</span>
<span id="cb51-5"><a href="#cb51-5"></a>        <span class="va">self</span>.norm <span class="op">=</span> RMSNorm(d_model) <span class="cf">if</span> use_norm <span class="cf">else</span> nn.Identity()</span>
<span id="cb51-6"><a href="#cb51-6"></a></span>
<span id="cb51-7"><a href="#cb51-7"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb51-8"><a href="#cb51-8"></a>        x <span class="op">=</span> <span class="va">self</span>.norm(x)</span>
<span id="cb51-9"><a href="#cb51-9"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear(x)</span>
<span id="cb51-10"><a href="#cb51-10"></a>        <span class="cf">return</span> logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="weight-tying" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="weight-tying"><span class="header-section-number">3.8.1</span> Weight Tying</h3>
<p>å¦‚æœæ¨¡å‹é‡Œæœ‰ token embedding çŸ©é˜µ <span class="math inline">\(E \in \mathbb{R}^{|\mathcal{V}|\times d_{\text{model}}}\)</span>ï¼Œé‚£ä¹ˆå¸¸è§çš„åšæ³•æ˜¯ <strong>å…±äº«è¾“å…¥ embedding å’Œè¾“å‡ºæŠ•å½±æƒé‡</strong>ï¼ˆweight tyingï¼‰ï¼š</p>
<p><span id="eq-weight-tying"><span class="math display">\[
W_{\text{out}} = E^\top.
\tag{30}\]</span></span></p>
<p>è¿™æ ·å¯ä»¥å‡å°‘å‚æ•°é‡ï¼Œå¹¶ä¸”ç»å¸¸å¸¦æ¥æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ä¸æ³›åŒ–æ•ˆæœã€‚</p>
</section>
</section>
<section id="full-transformer-model" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="full-transformer-model"><span class="header-section-number">3.9</span> Full Transformer Model</h2>
<p>å½“æˆ‘ä»¬å®ç°å®Œ embeddingã€Transformer blockï¼ˆMHA + FFNï¼‰ã€ä»¥åŠè¾“å‡ºå±‚ä¹‹åï¼Œå°±å¯ä»¥æŒ‰ç…§ <a href="#fig-transformer-lm-overview" class="quarto-xref">Figure&nbsp;2</a> çš„é«˜å±‚ç»“æ„æŠŠæ•´ä¸ªè¯­è¨€æ¨¡å‹ä¸²èµ·æ¥äº†ã€‚æ•´ä½“æµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä¸‰æ­¥ï¼š</p>
<ol type="1">
<li>Token Embeddingï¼šæŠŠ token id æ˜ å°„åˆ°å‘é‡è¡¨ç¤º</li>
<li>å †å  num_layers ä¸ª Transformer Blocks</li>
<li>&nbsp;Output Layersï¼šæ˜ å°„åˆ°è¯è¡¨åˆ†å¸ƒ</li>
</ol>
<p>å…·ä½“çš„ä»£ç å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/model.py</strong></pre>
</div>
<div class="sourceCode" id="cb52" data-filename="cs336_basics/model.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a><span class="kw">class</span> TransformerLM(nn.Module):</span>
<span id="cb52-2"><a href="#cb52-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config: ModelConfig):</span>
<span id="cb52-3"><a href="#cb52-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb52-4"><a href="#cb52-4"></a></span>
<span id="cb52-5"><a href="#cb52-5"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb52-6"><a href="#cb52-6"></a></span>
<span id="cb52-7"><a href="#cb52-7"></a>        <span class="va">self</span>.token_embedding <span class="op">=</span> nn.Embedding(config.vocab_size, config.d_model)</span>
<span id="cb52-8"><a href="#cb52-8"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList([TransformerBlock(config) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(config.num_layers)])</span>
<span id="cb52-9"><a href="#cb52-9"></a>        <span class="va">self</span>.final_norm <span class="op">=</span> RMSNorm(config.d_model)</span>
<span id="cb52-10"><a href="#cb52-10"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> OutputLayer(config.d_model, config.vocab_size, use_norm<span class="op">=</span>config.use_final_norm)</span>
<span id="cb52-11"><a href="#cb52-11"></a></span>
<span id="cb52-12"><a href="#cb52-12"></a>        <span class="cf">if</span> config.tie_weights:</span>
<span id="cb52-13"><a href="#cb52-13"></a>            <span class="va">self</span>._tie_weights()</span>
<span id="cb52-14"><a href="#cb52-14"></a></span>
<span id="cb52-15"><a href="#cb52-15"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor, token_positions: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb52-16"><a href="#cb52-16"></a>        x <span class="op">=</span> <span class="va">self</span>.token_embedding(x)</span>
<span id="cb52-17"><a href="#cb52-17"></a></span>
<span id="cb52-18"><a href="#cb52-18"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb52-19"><a href="#cb52-19"></a>            x <span class="op">=</span> layer(x, token_positions<span class="op">=</span>token_positions)</span>
<span id="cb52-20"><a href="#cb52-20"></a></span>
<span id="cb52-21"><a href="#cb52-21"></a>        x <span class="op">=</span> <span class="va">self</span>.final_norm(x)</span>
<span id="cb52-22"><a href="#cb52-22"></a>        logits <span class="op">=</span> <span class="va">self</span>.output_layer(x)</span>
<span id="cb52-23"><a href="#cb52-23"></a>        <span class="cf">return</span> logits</span>
<span id="cb52-24"><a href="#cb52-24"></a></span>
<span id="cb52-25"><a href="#cb52-25"></a>    <span class="kw">def</span> _tie_weights(<span class="va">self</span>):</span>
<span id="cb52-26"><a href="#cb52-26"></a>        <span class="va">self</span>.output_layer.linear.weight <span class="op">=</span> <span class="va">self</span>.token_embedding.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>token ids â†’ embedding å¾—åˆ° <span class="math inline">\(X_0\)</span> â†’ ç»è¿‡ <span class="math inline">\(L\)</span> ä¸ª Transformer blocks å¾—åˆ° <span class="math inline">\(H\)</span> â†’ è¾“å‡ºå¤´ï¼ˆnorm + linear + softmaxï¼‰å¾—åˆ°è¯è¡¨åˆ†å¸ƒï¼Œç”¨äº next-token predictionã€‚</p>
</section>
<section id="part-02-summary" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="part-02-summary"><span class="header-section-number">3.10</span> Part 02 Summary</h2>
<p>æ€»çš„æ¥è¯´ï¼ŒPart 02 å°±æ˜¯åœ¨ Part 01 çš„ Tokenization ä¹‹åï¼ŒæŠŠâ€œèƒ½è®­ç»ƒçš„è¯­è¨€æ¨¡å‹â€çœŸæ­£æ­èµ·æ¥ï¼šæˆ‘ä»¬ä»æœ€åŸºç¡€çš„ Linear / Embedding å‡ºå‘ï¼Œé€æ­¥å®ç° RMSNormï¼ˆPre-Normï¼‰ã€ç°ä»£ LLM å¸¸ç”¨çš„ SwiGLU-FFNã€å†åˆ°æœ€æ ¸å¿ƒä¹Ÿæœ€å®¹æ˜“å†™é”™çš„ (RoPE + Causal) Multi-Head Self-Attentionï¼Œæœ€ç»ˆåƒæ­ç§¯æœ¨ä¸€æ ·ç»„è£…å‡ºå®Œæ•´çš„ TransformerBlockï¼Œå¹¶ä¸²è”æˆ TransformerLMï¼Œé€šè¿‡ Output Layer è¾“å‡º vocabulary logits ç”¨äº next-token predictionã€‚</p>
<p>è¿™ä¸€éƒ¨åˆ†æœ€å€¼å¾—è®°ä½çš„å·¥ç¨‹è¦ç‚¹æœ‰ä¸‰ç±»ï¼š</p>
<ul>
<li>ç¨³å®šæ€§ï¼ˆstabilityï¼‰ï¼š Softmax çš„æ•°å€¼ç¨³å®šï¼ˆå‡ maxï¼‰ã€Pre-Normï¼ˆRMSNorm æ”¾åœ¨å­å±‚å‰ï¼‰ã€ä»¥åŠ causal mask é˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²ï¼Œéƒ½æ˜¯â€œè®­ç»ƒèƒ½ä¸èƒ½è·‘èµ·æ¥â€çš„å…³é”®ã€‚</li>
<li>æ•ˆç‡ï¼ˆefficiencyï¼‰ï¼š Q/K/V æŠ•å½±åº”å½“æ˜¯ 3 æ¬¡çŸ©é˜µä¹˜æ³•ï¼ˆæ›´è¿›ä¸€æ­¥å¯ä»¥åˆæˆ 1 æ¬¡ï¼‰ï¼Œmask ç”¨ â€œsoftmax å‰åŠ  -â€ è€Œä¸æ˜¯åˆ‡å­åºåˆ—ï¼ŒRoPE ç”¨é¢„è®¡ç®—çš„ sin/cos buffer å¤ç”¨è·¨ batch/è·¨å±‚ï¼Œé¿å…æ˜¾å¼æ„é€  <span class="math inline">\(d\times d\)</span> æ—‹è½¬çŸ©é˜µã€‚</li>
<li>ç»“æ„ï¼ˆarchitectureï¼‰ï¼š ç°ä»£ LLM çš„ Block åŸºæœ¬éƒ½éµå¾ª â€œRMSNorm â†’ MHA/FFN â†’ Residualâ€ çš„ Pre-Norm æ¨¡å¼ï¼›FFN å¸¸ç”¨ SwiGLUï¼ˆæ¿€æ´» + gatingï¼‰ï¼›RoPE åªä½œç”¨åœ¨ Q/Kï¼ˆä¸ä½œç”¨åœ¨ Vï¼‰ï¼›æœ€åå†æ¥ä¸€ä¸ªè¾“å‡ºå¤´ï¼ˆå¯é€‰ final norm / weight tyingï¼‰æŠŠ hidden states æ˜ å°„åˆ°è¯è¡¨åˆ†å¸ƒã€‚</li>
</ul>
</section>
</section>
<section id="part-03-optimizer-training-code" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Part 03: Optimizer &amp; Training Code</h1>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å®ç°è®­ç»ƒè¯­è¨€æ¨¡å‹æ‰€éœ€çš„ç¬¬ä¸‰éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯å®šä¹‰æˆ‘ä»¬çš„<strong>Loss Function</strong>ï¼Œä»¥åŠ<strong>Optimizer</strong>å’Œ<strong>Learning Rate Scheduler</strong>ã€‚</p>
<section id="loss-perplexity" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="loss-perplexity"><span class="header-section-number">4.1</span> Loss &amp; Perplexity</h2>
<p>æˆ‘ä»¬å…ˆæ¥å®šä¹‰æˆ‘ä»¬çš„Loss Function,åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ï¼ŒLoss Functionï¼ˆæŸå¤±å‡½æ•°ï¼‰ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹ä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ã€‚å¯¹äºè¯­è¨€æ¨¡å‹ï¼Œå¸¸ç”¨çš„æŸå¤±å‡½æ•°æ˜¯<strong>äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropy Lossï¼‰</strong>ã€‚</p>
<section id="cross-entropy-loss" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="cross-entropy-loss"><span class="header-section-number">4.1.1</span> Cross Entropy Loss</h3>
<p>åœ¨ç°ä»£å¸¸è§çš„è¯­è¨€æ¨¡å‹æ˜¯<strong>Next-Token Prediction</strong>æ¨¡å‹ï¼Œå…¶è®­ç»ƒç›®æ ‡æ˜¯<strong>é¢„æµ‹ä¸‹ä¸€ä¸ªtoken</strong>ï¼Œä¹Ÿå°±æ˜¯ç»™å®šå‰é¢ <span class="math inline">\(t\)</span> ä¸ª tokenï¼Œé¢„æµ‹ç¬¬ <span class="math inline">\(t+1\)</span> ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒï¼š</p>
<p><span id="eq-next-token-prediction"><span class="math display">\[
P(x_{t+1} | x_1, x_2, \ldots, x_t)
\tag{31}\]</span></span></p>
<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªé•¿åº¦ä¸º <span class="math inline">\(T\)</span> çš„è®­ç»ƒåºåˆ— <span class="math inline">\((x_1, x_2, \ldots, x_T)\)</span>ï¼Œé‚£ä¹ˆæ¨¡å‹çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æ•´ä¸ªåºåˆ—çš„è”åˆæ¦‚ç‡ï¼š <span id="eq-sequence-probability"><span class="math display">\[
P(x_1, x_2, \ldots, x_T) = \prod_{t=1}^{T} P(x_t | x_1, x_2, \ldots, x_{t-1})
\tag{32}\]</span></span></p>
<p>ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨<strong>äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropy Lossï¼‰</strong>æ¥è¡¡é‡æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚</p>
<p>Cross Entropy Loss å¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š</p>
<p><span id="eq-cross-entropy-loss"><span class="math display">\[
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \ln(p_{i,c})
\tag{33}\]</span></span></p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(N\)</span> æ˜¯æ ·æœ¬æ•°é‡ï¼ˆåœ¨è¯­è¨€æ¨¡å‹ä¸­é€šå¸¸æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„ token æ•°é‡ï¼‰</li>
<li><span class="math inline">\(C\)</span> æ˜¯ç±»åˆ«æ•°é‡ï¼ˆè¯è¡¨å¤§å°ï¼‰</li>
<li><span class="math inline">\(y_{i,c}\)</span> æ˜¯æ ·æœ¬ <span class="math inline">\(i\)</span> çš„çœŸå®æ ‡ç­¾çš„ one-hot ç¼–ç ï¼ˆå¦‚æœæ ·æœ¬ <span class="math inline">\(i\)</span> çš„çœŸå®ç±»åˆ«æ˜¯ <span class="math inline">\(c^*\)</span>ï¼Œåˆ™ <span class="math inline">\(y_{i,c^*} = 1\)</span>ï¼Œå…¶ä»–ç±»åˆ«ä¸º 0ï¼‰</li>
<li><span class="math inline">\(p_{i,c}\)</span> æ˜¯æ¨¡å‹å¯¹æ ·æœ¬ <span class="math inline">\(i\)</span> é¢„æµ‹ä¸ºç±»åˆ« <span class="math inline">\(c\)</span>çš„æ¦‚ç‡ã€‚</li>
</ul>
<p>å®ç°è¿™ä¸ªæŸå¤±å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šç»“åˆ softmax ä¸€èµ·ä½¿ç”¨ï¼Œå› ä¸ºæ¨¡å‹è¾“å‡ºçš„ logits éœ€è¦å…ˆç»è¿‡ softmax è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/loss.py</strong></pre>
</div>
<div class="sourceCode" id="cb53" data-filename="cs336_basics/loss.py" data-code-line-numbers="7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a><span class="kw">def</span> cross_entropy(logits: torch.Tensor, labels: torch.Tensor):</span>
<span id="cb53-2"><a href="#cb53-2"></a>    logits <span class="op">=</span> logits <span class="op">-</span> torch.<span class="bu">max</span>(logits, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>).values</span>
<span id="cb53-3"><a href="#cb53-3"></a>    log_probs <span class="op">=</span> logits <span class="op">-</span> torch.log(torch.<span class="bu">sum</span>(torch.exp(logits), dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb53-4"><a href="#cb53-4"></a></span>
<span id="cb53-5"><a href="#cb53-5"></a>    labels <span class="op">=</span> labels.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb53-6"><a href="#cb53-6"></a></span>
<span id="cb53-7"><a href="#cb53-7"></a>    loss <span class="op">=</span> log_probs.gather(<span class="dv">1</span>, labels).squeeze(<span class="dv">1</span>) </span>
<span id="cb53-8"><a href="#cb53-8"></a>    loss <span class="op">=</span> <span class="op">-</span>loss.mean()</span>
<span id="cb53-9"><a href="#cb53-9"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>å…¶ä¸­ <code>log_probs.gather(1, labels)</code> è¿™ä¸€è¡Œä»£ç çš„ä½œç”¨æ˜¯ä» <code>log_probs</code> å¼ é‡ä¸­æå–å‡ºæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„çœŸå®æ ‡ç­¾çš„å¯¹æ•°æ¦‚ç‡å€¼ã€‚å…·ä½“æ¥è¯´ï¼š</p>
<ul>
<li><code>log_probs</code> çš„ shape æ˜¯ <code>(N, C)</code>ï¼Œè¡¨ç¤º <span class="math inline">\(N\)</span> ä¸ªæ ·æœ¬åœ¨ <span class="math inline">\(C\)</span> ä¸ªç±»åˆ«ä¸Šçš„å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒã€‚</li>
<li><code>labels</code> çš„ shape æ˜¯ <code>(N, 1)</code>ï¼Œè¡¨ç¤ºæ¯ä¸ªæ ·æœ¬çš„çœŸå®ç±»åˆ«ç´¢å¼•ã€‚</li>
<li><code>gather(1, labels)</code> ä¼šæ ¹æ® <code>labels</code> ä¸­çš„ç´¢å¼•ï¼Œä» <code>log_probs</code> çš„ç¬¬äºŒç»´ï¼ˆç±»åˆ«ç»´åº¦ï¼‰ä¸­æå–å¯¹åº”çš„å¯¹æ•°æ¦‚ç‡å€¼ï¼Œç»“æœçš„ shape æ˜¯ <code>(N, 1)</code>ã€‚</li>
</ul>
<p>åœ¨ä½¿ç”¨è¿™ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†æ¨¡å‹çš„è¾“å‡º logits å’Œå¯¹åº”çš„çœŸå®æ ‡ç­¾å±•å¼€æˆä¸€ç»´å‘é‡ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥ç®€åŒ–è®¡ç®—è¿‡ç¨‹ï¼Œä½¿å¾—æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹éƒ½è¢«è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„æ ·æœ¬ï¼Œä»è€Œæ–¹ä¾¿åœ°è®¡ç®—æ•´ä½“çš„æŸå¤±ã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/train_engine.py</strong></pre>
</div>
<div class="sourceCode" id="cb54" data-filename="cs336_basics/train_engine.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a>logits <span class="op">=</span> model(inputs)</span>
<span id="cb54-2"><a href="#cb54-2"></a>logits <span class="op">=</span> logits.view(<span class="op">-</span><span class="dv">1</span>, logits.size(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb54-3"><a href="#cb54-3"></a>targets <span class="op">=</span> targets.view(<span class="op">-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="perplexity" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="perplexity"><span class="header-section-number">4.1.2</span> Perplexity</h3>
<p>åœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œé™¤äº†äº¤å‰ç†µæŸå¤±ï¼Œæˆ‘ä»¬è¿˜å¸¸ç”¨ä¸€ä¸ªæŒ‡æ ‡å«åš<strong>å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰</strong>æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å›°æƒ‘åº¦è¡¡é‡çš„æ˜¯æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„é¢„æµ‹èƒ½åŠ›ï¼Œ<strong>æ•°å€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹è¶Šå¥½</strong>ã€‚ å®ƒçš„å®šä¹‰å¦‚ä¸‹ï¼š</p>
<p><span id="eq-perplexity"><span class="math display">\[
\mathrm{PPL} = \exp\left(\frac{1}{N} \sum_{i=1}^{N} \mathcal{L}_i\right)
\tag{34}\]</span></span></p>
<p>å®ƒæ˜¯äº¤å‰ç†µæŸå¤±çš„æŒ‡æ•°å½¢å¼ï¼Œå…¶ä¸­ <span class="math inline">\(\mathcal{L}_i\)</span> æ˜¯ç¬¬ <span class="math inline">\(i\)</span> ä¸ªæ ·æœ¬çš„äº¤å‰ç†µæŸå¤±ï¼Œ<span class="math inline">\(N\)</span> æ˜¯æ ·æœ¬æ€»æ•°ï¼Œ ä¹Ÿå°±æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„ token æ•°é‡ã€‚ å®ƒçš„ç›´è§‚æ„ä¹‰æ˜¯ï¼š<u>æ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª token æ—¶ï¼Œå¹³å‡æ¯ä¸ª token æœ‰å¤šå°‘ç§å¯èƒ½çš„é€‰æ‹©ã€‚</u> æˆ‘ä»¬å±•å¼€PPLçš„å®šä¹‰ï¼š</p>
<p><span id="eq-perplexity-expanded"><span class="math display">\[
\mathrm{PPL} = \exp\left(-\frac{1}{N} \sum_{i=1}^{N} \ln(p_{i,c^*})\right) = \left(\prod_{i=1}^{N} \frac{1}{p_{i,c^*}}\right)^{\frac{1}{N}}
\tag{35}\]</span></span></p>
<p>PPL ç­‰ä»·äºâ€œæ¨¡å‹ç»™çœŸå® token çš„æ¦‚ç‡ pâ€çš„å€’æ•° 1/p çš„å‡ ä½•å¹³å‡ï¼Œæ‰€ä»¥è¶Šå°è¡¨ç¤ºæ¨¡å‹å¹³å‡ç»™çœŸå€¼çš„æ¦‚ç‡è¶Šå¤§ã€‚</p>
<p>è¿™ä¸ªçœ‹èµ·æ¥å¾ˆæŠ½è±¡ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…·ä½“ä¾‹å­ï¼š å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„è¯è¡¨ï¼Œåªæœ‰ 4 ä¸ª tokenï¼š<code>{A, B, C, D}</code>ã€‚ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªæµ‹è¯•åºåˆ— <code>A B C D</code>ï¼Œæ¨¡å‹åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹æ¦‚ç‡å¦‚ä¸‹ï¼š</p>
<ul>
<li>é¢„æµ‹ <code>B</code> çš„æ¦‚ç‡ï¼š0.5</li>
<li>é¢„æµ‹ <code>C</code> çš„æ¦‚ç‡ï¼š0.25</li>
<li>é¢„æµ‹ <code>D</code> çš„æ¦‚ç‡ï¼š0.1</li>
</ul>
<p>é‚£ä¹ˆï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è¿™ä¸ªåºåˆ—çš„å›°æƒ‘åº¦ï¼š <span id="eq-perplexity-example"><span class="math display">\[
\mathrm{PPL} = \exp\left(-\frac{1}{3} (\ln(0.5) + \ln(0.25) + \ln(0.1))\right) \approx 4.64
\tag{36}\]</span></span></p>
<p>è¿™æ„å‘³ç€ï¼Œæ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª token æ—¶ï¼Œå¹³å‡æ¯ä¸ª token æœ‰å¤§çº¦ 4.64 ç§å¯èƒ½çš„é€‰æ‹©ã€‚ å› ä¸ºè¯è¡¨åªæœ‰ 4 ä¸ª tokenï¼Œè¿™ä¸ªå›°æƒ‘åº¦è¡¨æ˜æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›è¿˜ä¸å¤Ÿå¥½ã€‚</p>
<p>ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/loss.py</strong></pre>
</div>
<div class="sourceCode" id="cb55" data-filename="cs336_basics/loss.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a><span class="kw">def</span> perplexity(loss: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb55-2"><a href="#cb55-2"></a>    <span class="cf">return</span> torch.exp(loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="optimizer-learning-rate-scheduler" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="optimizer-learning-rate-scheduler"><span class="header-section-number">4.2</span> Optimizer &amp; Learning Rate Scheduler</h2>
<p>æœ‰äº†Loss Functionä¹‹åï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥è¦å®šä¹‰<strong>Optimizer</strong>å’Œ<strong>Learning Rate Scheduler</strong>ï¼Œæ¥æŒ‡å¯¼æ¨¡å‹å‚æ•°çš„æ›´æ–°ã€‚</p>
<section id="adamw" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="adamw"><span class="header-section-number">4.2.1</span> AdamW</h3>
<p>åœ¨è¿™ä¸ªä½œä¸šä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ AdamW<span class="citation" data-cites="DecoupledWeightDecay2019loshchilov">(<a href="#ref-DecoupledWeightDecay2019loshchilov" role="doc-biblioref">Loshchilov and Hutter 2019</a>)</span> ä½œä¸ºä¼˜åŒ–å™¨ã€‚AdamW æ˜¯ Adam ä¼˜åŒ–å™¨çš„ä¸€ä¸ªå˜ä½“ï¼Œå®ƒé€šè¿‡å°†æƒé‡è¡°å‡ï¼ˆweight decayï¼‰ä¸æ¢¯åº¦æ›´æ–°è§£è€¦æ¥æ”¹å–„æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Adamæ˜¯ä»€ä¹ˆï¼Œ Adam æ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œå®ƒç»“åˆäº†åŠ¨é‡ï¼ˆMomentumï¼‰å’ŒRMSPropçš„æ€æƒ³ï¼Œé€šè¿‡è®¡ç®—æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆå‡å€¼ï¼‰å’ŒäºŒé˜¶çŸ©ä¼°è®¡ï¼ˆæœªä¸­å¿ƒåŒ–çš„æ–¹å·®ï¼‰æ¥è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚Adam å¯¹æ¯ä¸ªå‚æ•° <span class="math inline">\(\theta\)</span> éƒ½ç»´æŠ¤ä¸¤ä»½çŠ¶æ€ï¼ˆstateï¼‰ï¼š</p>
<ul>
<li>ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰ <span class="math inline">\(m_t\)</span>ï¼šæ¢¯åº¦çš„æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼ˆç±»ä¼¼ momentumï¼‰</li>
<li>äºŒé˜¶çŸ© <span class="math inline">\(v_t\)</span>ï¼šæ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼ˆåˆ»ç”»æ¢¯åº¦å°ºåº¦ï¼‰</li>
</ul>
<p>å®ƒä»¬çš„æ›´æ–°è§„åˆ™å¦‚ä¸‹ï¼š</p>
<p><span id="eq-adam-updates"><span class="math display">\[
\begin{split}
m_t &amp;= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
v_t &amp;= \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \\
\theta_t &amp;= \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \\
\end{split}
\tag{37}\]</span></span></p>
<p>å…¶ä¸­ï¼Œ<span class="math inline">\(g_t\)</span> æ˜¯å½“å‰æ¢¯åº¦ï¼Œ<span class="math inline">\(\beta_1\)</span> å’Œ <span class="math inline">\(\beta_2\)</span> æ˜¯æ§åˆ¶æ»‘åŠ¨å¹³å‡çš„è¶…å‚æ•°ï¼Œ<span class="math inline">\(\alpha\)</span> æ˜¯å­¦ä¹ ç‡ï¼Œ<span class="math inline">\(\epsilon\)</span> æ˜¯é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°ã€‚<span class="math inline">\(\hat{m}_t\)</span> å’Œ <span class="math inline">\(\hat{v}_t\)</span> æ˜¯åå·®ä¿®æ­£åçš„ä¼°è®¡ï¼š</p>
<p><span id="eq-adam-bias-correction"><span class="math display">\[
\begin{split}
\hat{m}_t &amp;= \frac{m_t}{1 - \beta_1^t} \\
\hat{v}_t &amp;= \frac{v_t}{1 - \beta_2^t} \\
\end{split}
\tag{38}\]</span></span></p>
<p>åœ¨ Adam ä¸­ï¼Œæƒé‡è¡°å‡ï¼ˆweight decayï¼‰é€šå¸¸ä¼šè¢«å®ç°æˆ L2 æ­£åˆ™ï¼šä¹Ÿå°±æ˜¯åœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥ <span class="math inline">\(\frac{\lambda}{2}\|\theta\|^2\)</span>ï¼Œ æŸå¤±å‡½æ•°å˜ä¸º<span class="math inline">\(\mathcal{L} = \mathcal{L}_{\text{original}} + \frac{\lambda}{2}\|\theta\|^2\)</span>, å…¶å¯¹åº”çš„æ¢¯åº¦é¢å¤–å¤šä¸€é¡¹ <span class="math inline">\(\lambda \theta\)</span>ã€‚å› æ­¤ï¼Œæ¢¯åº¦ä¼šå˜æˆï¼š</p>
<p><span id="eq-adam-l2-regularization"><span class="math display">\[
g_t \leftarrow g_t + \lambda \theta_{t-1}
\tag{39}\]</span></span></p>
<p>å¦‚æœç›´æ¥æŠŠè¿™ä¸ªä¿®æ”¹åçš„æ¢¯åº¦å¸¦å…¥ Adam çš„æ›´æ–°è§„åˆ™, æˆ‘ä»¬ä¼šå¾—åˆ°ï¼š</p>
$$
<span class="math display">\[\begin{split}
m_t &amp;= \beta_1 m_{t-1} + (1 - \beta_1) (g_t + \lambda \theta_{t-1}) \\
v_t &amp;= \beta_2 v_{t-1} + (1 - \beta_2) (g_t + \lambda \theta_{t-1})^2 \\
\theta_t &amp;= \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \\
        &amp;= \theta_{t-1} - \alpha


\end{split}\]</span>
<p>$${#eq-adam-with-l2}</p>
<p>ç›´è§‰ä¸Šï¼Œweight decay æƒ³åšçš„äº‹æƒ…å¾ˆç®€å•ï¼šæ¯ä¸€æ­¥éƒ½æŠŠå‚æ•°å¾€ 0 æ‹‰ä¸€ç‚¹ï¼Œå³è®©å‚æ•°è§„æ¨¡å—æ§ã€æå‡æ³›åŒ–, ä¹Ÿå°±æ˜¯è¯´ï¼Œä¹Ÿå°±æ˜¯è¡°å‡é¡¹ åªæ˜¯ä¸€æ¡ç‹¬ç«‹çš„çº¿æ€§æ”¶ç¼©ï¼Œä¸è¢«ä»»ä½•è‡ªé€‚åº”ç¼©æ”¾å½±å“ã€‚ ä½†åœ¨ Adam é‡Œï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚</p>
<p>åœ¨ Adam é‡Œï¼Œæ›´æ–°ä¼šè¢« <span class="math inline">\(\sqrt{\hat v_t}\)</span> è¿›è¡Œâ€œæŒ‰ç»´åº¦ç¼©æ”¾â€ã€‚è¿™æ„å‘³ç€ï¼š</p>
<ul>
<li>æ­£åˆ™é¡¹ <span class="math inline">\(\lambda \theta\)</span> ä¹Ÿä¼šè¿›å…¥ <span class="math inline">\(\hat m_t\)</span>, <span class="math inline">\(\hat v_t\)</span> çš„è®¡ç®—</li>
<li>è¿›è€Œå®ƒä¹Ÿä¼šè¢« ç¼©æ”¾</li>
<li>ç»“æœï¼šä¸åŒå‚æ•°ç»´åº¦çš„è¡°å‡å¼ºåº¦ä¸ä¸€è‡´ï¼ˆæŸäº›ç»´åº¦å‡ ä¹ä¸è¡°å‡ï¼ŒæŸäº›ç»´åº¦è¡°å‡è¿‡å¼ºï¼‰</li>
</ul>
<p>æ¢å¥è¯è¯´ï¼šåœ¨ Adam è¿™ç§è‡ªé€‚åº”ä¼˜åŒ–å™¨é‡Œï¼Œâ€œL2 æ­£åˆ™ â‰  ä½ ä»¥ä¸ºçš„ weight decayâ€ã€‚<span class="citation" data-cites="DecoupledWeightDecay2019loshchilov">(<a href="#ref-DecoupledWeightDecay2019loshchilov" role="doc-biblioref">Loshchilov and Hutter 2019</a>)</span> çš„æ ¸å¿ƒè§‚å¯Ÿå°±æ˜¯ï¼šå¦‚æœæˆ‘ä»¬æƒ³è¦çœŸæ­£å®ç°â€œæŠŠå‚æ•°å¾€ 0 æ‹‰â€çš„æ­£åˆ™åŒ–æ•ˆæœï¼Œå°±åº”è¯¥æŠŠå®ƒä» Adam çš„æ¢¯åº¦æ›´æ–°ä¸­æ‹†å‡ºæ¥ã€‚</p>
<p>AdamW çš„ç®—æ³•å¦‚ä»¥ä¸‹æ‰€ç¤ºï¼š</p>
<div id="fig-adamw-alg" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adamw-alg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/ass01-AdamW-alg.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adamw-alg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: AdamW ç®—æ³•
</figcaption>
</figure>
</div>
<p>å¯ä»¥çœ‹åˆ°ï¼ŒAdamW æŠŠ weight decay ä»æ¢¯åº¦æ›´æ–°ä¸­è§£è€¦å‡ºæ¥ï¼Œç›´æ¥åœ¨å‚æ•°æ›´æ–°æ—¶åšçº¿æ€§æ”¶ç¼©ï¼š <span id="eq-adamw-update"><span class="math display">\[
\theta_t = \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} - \alpha \lambda \theta_{t-1}
\tag{40}\]</span></span> è¿™æ ·å°±ä¿è¯äº† weight decay çš„æ•ˆæœæ˜¯ä¸€è‡´çš„ï¼Œä¸ä¼šè¢«è‡ªé€‚åº”ç¼©æ”¾å½±å“ã€‚</p>
<p>ç†è§£äº† AdamW çš„åŸç†åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å®ƒçš„ä»£ç å®ç°ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/optim.py</strong></pre>
</div>
<div class="sourceCode" id="cb56" data-filename="cs336_basics/optim.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a><span class="kw">class</span> AdamW(torch.optim.Optimizer):</span>
<span id="cb56-2"><a href="#cb56-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb56-3"><a href="#cb56-3"></a>        <span class="va">self</span>,</span>
<span id="cb56-4"><a href="#cb56-4"></a>        params: Iterable[torch.nn.Parameter],</span>
<span id="cb56-5"><a href="#cb56-5"></a>        lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-3</span>,</span>
<span id="cb56-6"><a href="#cb56-6"></a>        betas: <span class="bu">tuple</span>[<span class="bu">float</span>, <span class="bu">float</span>] <span class="op">=</span> (<span class="fl">0.9</span>, <span class="fl">0.999</span>),</span>
<span id="cb56-7"><a href="#cb56-7"></a>        eps: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-8</span>,</span>
<span id="cb56-8"><a href="#cb56-8"></a>        weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-2</span>,</span>
<span id="cb56-9"><a href="#cb56-9"></a>    ):</span>
<span id="cb56-10"><a href="#cb56-10"></a>        <span class="cf">if</span> lr <span class="op">&lt;</span> <span class="fl">0.0</span>:</span>
<span id="cb56-11"><a href="#cb56-11"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid learning rate: </span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-12"><a href="#cb56-12"></a>        <span class="cf">if</span> eps <span class="op">&lt;=</span> <span class="fl">0.0</span>:</span>
<span id="cb56-13"><a href="#cb56-13"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid epsilon value: </span><span class="sc">{</span>eps<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-14"><a href="#cb56-14"></a>        <span class="cf">if</span> weight_decay <span class="op">&lt;</span> <span class="fl">0.0</span>:</span>
<span id="cb56-15"><a href="#cb56-15"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid weight_decay value: </span><span class="sc">{</span>weight_decay<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-16"><a href="#cb56-16"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(betas, <span class="bu">tuple</span>) <span class="kw">or</span> <span class="bu">len</span>(betas) <span class="op">!=</span> <span class="dv">2</span>:</span>
<span id="cb56-17"><a href="#cb56-17"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"betas must be a tuple of length 2, got: </span><span class="sc">{</span>betas<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-18"><a href="#cb56-18"></a>        beta1, beta2 <span class="op">=</span> betas</span>
<span id="cb56-19"><a href="#cb56-19"></a>        <span class="cf">if</span> <span class="kw">not</span> (<span class="fl">0.0</span> <span class="op">&lt;=</span> beta1 <span class="op">&lt;</span> <span class="fl">1.0</span>):</span>
<span id="cb56-20"><a href="#cb56-20"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid beta1 value: </span><span class="sc">{</span>beta1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-21"><a href="#cb56-21"></a>        <span class="cf">if</span> <span class="kw">not</span> (<span class="fl">0.0</span> <span class="op">&lt;=</span> beta2 <span class="op">&lt;</span> <span class="fl">1.0</span>):</span>
<span id="cb56-22"><a href="#cb56-22"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid beta2 value: </span><span class="sc">{</span>beta2<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-23"><a href="#cb56-23"></a></span>
<span id="cb56-24"><a href="#cb56-24"></a>        defaults <span class="op">=</span> <span class="bu">dict</span>(lr<span class="op">=</span>lr, betas<span class="op">=</span>betas, eps<span class="op">=</span>eps, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb56-25"><a href="#cb56-25"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(params, defaults)</span>
<span id="cb56-26"><a href="#cb56-26"></a></span>
<span id="cb56-27"><a href="#cb56-27"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb56-28"><a href="#cb56-28"></a>    <span class="kw">def</span> step(<span class="va">self</span>, closure: Optional[<span class="bu">callable</span>] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb56-29"><a href="#cb56-29"></a>        <span class="co">"""Performs a single optimization step."""</span></span>
<span id="cb56-30"><a href="#cb56-30"></a>        loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb56-31"><a href="#cb56-31"></a>        <span class="cf">if</span> closure <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb56-32"><a href="#cb56-32"></a>            <span class="cf">with</span> torch.enable_grad():</span>
<span id="cb56-33"><a href="#cb56-33"></a>                loss <span class="op">=</span> closure()</span>
<span id="cb56-34"><a href="#cb56-34"></a></span>
<span id="cb56-35"><a href="#cb56-35"></a>        <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups:</span>
<span id="cb56-36"><a href="#cb56-36"></a>            lr: <span class="bu">float</span> <span class="op">=</span> group[<span class="st">"lr"</span>]</span>
<span id="cb56-37"><a href="#cb56-37"></a>            beta1, beta2 <span class="op">=</span> group[<span class="st">"betas"</span>]</span>
<span id="cb56-38"><a href="#cb56-38"></a>            eps: <span class="bu">float</span> <span class="op">=</span> group[<span class="st">"eps"</span>]</span>
<span id="cb56-39"><a href="#cb56-39"></a>            weight_decay: <span class="bu">float</span> <span class="op">=</span> group[<span class="st">"weight_decay"</span>]</span>
<span id="cb56-40"><a href="#cb56-40"></a></span>
<span id="cb56-41"><a href="#cb56-41"></a>            <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">"params"</span>]:</span>
<span id="cb56-42"><a href="#cb56-42"></a>                <span class="cf">if</span> p.grad <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb56-43"><a href="#cb56-43"></a>                    <span class="cf">continue</span></span>
<span id="cb56-44"><a href="#cb56-44"></a></span>
<span id="cb56-45"><a href="#cb56-45"></a>                grad <span class="op">=</span> p.grad</span>
<span id="cb56-46"><a href="#cb56-46"></a>                <span class="cf">if</span> grad.is_sparse:</span>
<span id="cb56-47"><a href="#cb56-47"></a>                    <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">"AdamW does not support sparse gradients"</span>)</span>
<span id="cb56-48"><a href="#cb56-48"></a></span>
<span id="cb56-49"><a href="#cb56-49"></a>                state <span class="op">=</span> <span class="va">self</span>.state[p]</span>
<span id="cb56-50"><a href="#cb56-50"></a>                <span class="cf">if</span> <span class="bu">len</span>(state) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb56-51"><a href="#cb56-51"></a>                    state[<span class="st">"step"</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb56-52"><a href="#cb56-52"></a>                    state[<span class="st">"exp_avg"</span>] <span class="op">=</span> torch.zeros_like(p, memory_format<span class="op">=</span>torch.preserve_format)</span>
<span id="cb56-53"><a href="#cb56-53"></a>                    state[<span class="st">"exp_avg_sq"</span>] <span class="op">=</span> torch.zeros_like(p, memory_format<span class="op">=</span>torch.preserve_format)</span>
<span id="cb56-54"><a href="#cb56-54"></a></span>
<span id="cb56-55"><a href="#cb56-55"></a>                exp_avg <span class="op">=</span> state[<span class="st">"exp_avg"</span>]</span>
<span id="cb56-56"><a href="#cb56-56"></a>                exp_avg_sq <span class="op">=</span> state[<span class="st">"exp_avg_sq"</span>]</span>
<span id="cb56-57"><a href="#cb56-57"></a></span>
<span id="cb56-58"><a href="#cb56-58"></a>                state[<span class="st">"step"</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb56-59"><a href="#cb56-59"></a>                t <span class="op">=</span> state[<span class="st">"step"</span>]</span>
<span id="cb56-60"><a href="#cb56-60"></a></span>
<span id="cb56-61"><a href="#cb56-61"></a>                <span class="co"># Update biased first and second moment estimates</span></span>
<span id="cb56-62"><a href="#cb56-62"></a>                exp_avg.mul_(beta1).add_(grad, alpha<span class="op">=</span>(<span class="fl">1.0</span> <span class="op">-</span> beta1))</span>
<span id="cb56-63"><a href="#cb56-63"></a>                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value<span class="op">=</span>(<span class="fl">1.0</span> <span class="op">-</span> beta2))</span>
<span id="cb56-64"><a href="#cb56-64"></a></span>
<span id="cb56-65"><a href="#cb56-65"></a>                <span class="co"># Bias correction</span></span>
<span id="cb56-66"><a href="#cb56-66"></a>                bias_correction1 <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> beta1<span class="op">**</span>t</span>
<span id="cb56-67"><a href="#cb56-67"></a>                bias_correction2 <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> beta2<span class="op">**</span>t</span>
<span id="cb56-68"><a href="#cb56-68"></a></span>
<span id="cb56-69"><a href="#cb56-69"></a>                <span class="co"># Compute step size</span></span>
<span id="cb56-70"><a href="#cb56-70"></a>                step_size <span class="op">=</span> lr <span class="op">/</span> bias_correction1</span>
<span id="cb56-71"><a href="#cb56-71"></a></span>
<span id="cb56-72"><a href="#cb56-72"></a>                <span class="co"># Denominator: sqrt(v_hat) + eps</span></span>
<span id="cb56-73"><a href="#cb56-73"></a>                denom <span class="op">=</span> (exp_avg_sq <span class="op">/</span> bias_correction2).sqrt().add_(eps)</span>
<span id="cb56-74"><a href="#cb56-74"></a></span>
<span id="cb56-75"><a href="#cb56-75"></a>                <span class="co"># Decoupled weight decay</span></span>
<span id="cb56-76"><a href="#cb56-76"></a>                <span class="cf">if</span> weight_decay <span class="op">!=</span> <span class="fl">0.0</span>:</span>
<span id="cb56-77"><a href="#cb56-77"></a>                    p.mul_(<span class="fl">1.0</span> <span class="op">-</span> lr <span class="op">*</span> weight_decay)</span>
<span id="cb56-78"><a href="#cb56-78"></a></span>
<span id="cb56-79"><a href="#cb56-79"></a>                <span class="co"># Parameter update</span></span>
<span id="cb56-80"><a href="#cb56-80"></a>                p.addcdiv_(exp_avg, denom, value<span class="op">=-</span>step_size)</span>
<span id="cb56-81"><a href="#cb56-81"></a></span>
<span id="cb56-82"><a href="#cb56-82"></a>        <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="cosine-annealing-learning-rate-scheduler" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="cosine-annealing-learning-rate-scheduler"><span class="header-section-number">4.2.2</span> Cosine Annealing Learning Rate Scheduler</h3>
<p>æœ‰äº†ä¼˜åŒ–å™¨ä¹‹åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ª<strong>Learning Rate Scheduler</strong>æ¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ã€‚åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ<strong>æœ€åˆé€‚çš„å­¦ä¹ ç‡ä¼šéšé˜¶æ®µå˜åŒ–</strong>ï¼š</p>
<ul>
<li><strong>è®­ç»ƒæ—©æœŸ</strong>ï¼šæ¨¡å‹è¿˜æ²¡å­¦åˆ°ä¸œè¥¿ï¼Œå‚æ•°ç¦»ç›®æ ‡å¾ˆè¿œ
<ul>
<li>ç”¨ <strong>æ›´å¤§çš„å­¦ä¹ ç‡</strong>ï¼Œæ›´æ–°æ›´å¿«ï¼Œloss ä¸‹é™æ›´å¿«</li>
</ul></li>
<li><strong>è®­ç»ƒåæœŸ</strong>ï¼šæ¨¡å‹æ¥è¿‘æ”¶æ•›
<ul>
<li>ç”¨ <strong>æ›´å°çš„å­¦ä¹ ç‡</strong>ï¼Œé¿å…åœ¨æœ€ä¼˜ç‚¹é™„è¿‘éœ‡è¡ï¼Œæå‡ç¨³å®šæ€§ä¸æœ€ç»ˆæ•ˆæœ</li>
</ul></li>
</ul>
<p>å› æ­¤æˆ‘ä»¬éœ€è¦Learning Rate Scheduleræ¥åœ¨ä¸åŒæ—¶æœŸè°ƒæ•´ä¸åŒçš„Learning Rateã€‚ä¸€ä¸ªå¸¸è§çš„Learning Rate Schedulerå«åš <strong>Cosine Annealing Scheduler</strong>ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p>
<div class="callout-paper">
<p>å®ƒæŠŠå­¦ä¹ ç‡ <span class="math inline">\(\alpha_t\)</span> åˆ†æˆ <strong>ä¸‰æ®µ</strong>ï¼š</p>
<ol type="1">
<li>Warm-Up: ä» 0 çº¿æ€§æå‡åˆ° <span class="math inline">\(\alpha_{\text{max}}\)</span> ï¼ˆé˜²æ­¢ä¸€å¼€å§‹æ¢¯åº¦å¤ªä¹±ï¼Œç›´æ¥å¤§ LR ä¼šä¸ç¨³å®šï¼‰</li>
<li>Cosine Annealing: ä» <span class="math inline">\(\alpha_{\max}\)</span> <strong>å¹³æ»‘é™åˆ°</strong> <span class="math inline">\(\alpha_{\min}\)</span> ï¼ˆä¸‹é™è¿‡ç¨‹æ›´å¹³æ»‘ï¼Œæ¯”â€œçªç„¶é™å­¦ä¹ ç‡â€æ›´ç¨³ï¼‰</li>
<li>Post-Annealing: ä¿æŒ<span class="math inline">\(\alpha_{\min}\)</span> ä¸å˜ ï¼ˆè®©è®­ç»ƒåœ¨ä½ LR ä¸‹æ…¢æ…¢ç²¾ä¿®ï¼ˆfine-tune é£æ ¼ï¼‰ï¼‰</li>
</ol>
</div>
<p>æˆ‘ä»¬å…ˆæ¥å®šä¹‰å‡ ä¸ªç¬¦å·ï¼š</p>
<div>
<div id="tbl-symbols-lr-scheduler" class="hover quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[20,80]">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-symbols-lr-scheduler-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table">
<colgroup>
<col style="width: 20%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">ç¬¦å·</th>
<th style="text-align: left;">å«ä¹‰</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(t\)</span></td>
<td style="text-align: left;">å½“å‰è®­ç»ƒ stepï¼ˆè¿­ä»£æ¬¡æ•°ï¼‰</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\alpha_{\max}\)</span></td>
<td style="text-align: left;">æœ€å¤§å­¦ä¹ ç‡ï¼ˆå³°å€¼ï¼‰</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\alpha_{\min}\)</span></td>
<td style="text-align: left;">æœ€å°/æœ€ç»ˆå­¦ä¹ ç‡</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(T_w\)</span></td>
<td style="text-align: left;">warm-up çš„æ­¥æ•°ï¼ˆé¢„çƒ­å¤šä¹…ï¼‰</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(T_c\)</span></td>
<td style="text-align: left;">Cosine Annealingç»“æŸçš„æ­¥æ•°ï¼ˆåˆ°è¿™ä¸ª step å­¦ä¹ ç‡é™åˆ° <span class="math inline">\(\alpha_{\min}\)</span>ï¼‰</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\alpha_t\)</span></td>
<td style="text-align: left;">å½“å‰å­¦ä¹ ç‡</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-symbols-lr-scheduler-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: ç¬¦å·è¯´æ˜
</figcaption>
</figure>
</div>
</div>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ä¸€ä¸‹å¦‚ä½•è°ƒæ•´è¿™ä¸‰ä¸ªä¸åŒçš„é˜¶æ®µï¼š</p>
<hr>
<p>é˜¶æ®µ1: Warm-Up</p>
<p>å½“ <span class="math inline">\(t &lt; T_{w}\)</span> æ—¶ï¼Œæˆ‘ä»¬çº¿æ€§å¢é•¿åˆ° <span class="math inline">\(\alpha_{\text{max}}\)</span></p>
<p><span id="eq-lr-warmup"><span class="math display">\[
\alpha_t=\frac{t}{T_w}\alpha_{\max}
\tag{41}\]</span></span></p>
<hr>
<p>é˜¶æ®µ2: Cosine Annealing</p>
<p>è¿™ä¸ªæ˜¯ç›¸å¯¹å¤æ‚çš„é˜¶æ®µï¼Œåœ¨è¿™ä¸ªé˜¶æ®µæˆ‘ä»¬çš„å­¦ä¹ ç‡ç”¨ä½™å¼¦æ›²çº¿ä¸‹é™ï¼š</p>
<p><span id="eq-lr-cosine-annealing"><span class="math display">\[
\alpha_t=\alpha_{\min}+\frac{1}{2}\left(1+\cos\left(\frac{t-T_w}{T_c-T_w}\pi\right)\right)(\alpha_{\max}-\alpha_{\min})
\tag{42}\]</span></span></p>
<p>è¿™ä¸ªå¼å­åšäº†ä¸¤ä»¶äº‹ï¼š</p>
<ul>
<li>ç”¨ <span class="math inline">\(\cos(\cdot)\)</span> äº§ç”Ÿä¸€ä¸ªä» <strong>1 å¹³æ»‘åˆ° -1</strong> çš„æ›²çº¿</li>
<li>å†æŠŠå®ƒæ˜ å°„æˆä¸€ä¸ªä» <span class="math inline">\(\alpha_{\max}\)</span> <strong>å¹³æ»‘åˆ°</strong> <span class="math inline">\(\alpha_{\min}\)</span> çš„å­¦ä¹ ç‡</li>
</ul>
<p>æˆ‘ä»¬æŸ¥çœ‹ä¸€ä¸‹ä¸¤ä¸ªç«¯ç‚¹ï¼š</p>
<ul>
<li>å½“ <span class="math inline">\(t = T_{w}\)</span>: <span class="math inline">\(\cos(0) = 1\)</span>, <span class="math inline">\(\alpha_{t} = \alpha_{\min} +\alpha_{\max} - \alpha_{\min} = \alpha_{\max}\)</span></li>
<li>å½“ <span class="math inline">\(t = T_{c}\)</span>: <span class="math inline">\(\cos(\pi) = -1\)</span>, <span class="math inline">\(\alpha_{t} = \alpha_{\min} +0 = \alpha_{\min}\)</span></li>
</ul>
<hr>
<p>é˜¶æ®µ3: Post-Annealing</p>
<p>å½“ <span class="math inline">\(t \geq T_{c}\)</span> æ—¶ï¼Œæˆ‘ä»¬å°† <span class="math inline">\(\alpha_{t}\)</span> è®¾å®šä¸º <span class="math inline">\(\alpha_{\min}\)</span>ï¼Œä¸”ä¿æŒä¸å˜.</p>
<p>ä»£ç å®ç°ä¹Ÿå¾ˆç®€å•ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/optim.py</strong></pre>
</div>
<div class="sourceCode" id="cb57" data-filename="cs336_basics/optim.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a><span class="kw">def</span> cosine_annealing_lr(</span>
<span id="cb57-2"><a href="#cb57-2"></a>    t: <span class="bu">int</span>,</span>
<span id="cb57-3"><a href="#cb57-3"></a>    alpha_max: <span class="bu">float</span>,</span>
<span id="cb57-4"><a href="#cb57-4"></a>    alpha_min: <span class="bu">float</span>,</span>
<span id="cb57-5"><a href="#cb57-5"></a>    Tw: <span class="bu">int</span>,</span>
<span id="cb57-6"><a href="#cb57-6"></a>    Tc: <span class="bu">int</span>,</span>
<span id="cb57-7"><a href="#cb57-7"></a>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb57-8"><a href="#cb57-8"></a>    <span class="co"># Warm-up</span></span>
<span id="cb57-9"><a href="#cb57-9"></a>    <span class="cf">if</span> Tw <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> t <span class="op">&lt;</span> Tw:</span>
<span id="cb57-10"><a href="#cb57-10"></a>        <span class="cf">return</span> (t <span class="op">/</span> Tw) <span class="op">*</span> alpha_max</span>
<span id="cb57-11"><a href="#cb57-11"></a></span>
<span id="cb57-12"><a href="#cb57-12"></a>    <span class="co"># Cosine annealing (including the exact boundary t==Tw)</span></span>
<span id="cb57-13"><a href="#cb57-13"></a>    <span class="cf">if</span> t <span class="op">&lt;=</span> Tc:</span>
<span id="cb57-14"><a href="#cb57-14"></a>        <span class="co"># If Tc == Tw, there is no annealing window; at t==Tw return alpha_max.</span></span>
<span id="cb57-15"><a href="#cb57-15"></a>        <span class="cf">if</span> Tc <span class="op">==</span> Tw:</span>
<span id="cb57-16"><a href="#cb57-16"></a>            <span class="cf">return</span> alpha_max</span>
<span id="cb57-17"><a href="#cb57-17"></a></span>
<span id="cb57-18"><a href="#cb57-18"></a>        progress <span class="op">=</span> (t <span class="op">-</span> Tw) <span class="op">/</span> (Tc <span class="op">-</span> Tw)  <span class="co"># in [0, 1]</span></span>
<span id="cb57-19"><a href="#cb57-19"></a>        <span class="cf">return</span> alpha_min <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> math.cos(math.pi <span class="op">*</span> progress)) <span class="op">*</span> (alpha_max <span class="op">-</span> alpha_min)</span>
<span id="cb57-20"><a href="#cb57-20"></a></span>
<span id="cb57-21"><a href="#cb57-21"></a>    <span class="co"># Post-annealing</span></span>
<span id="cb57-22"><a href="#cb57-22"></a>    <span class="cf">return</span> alpha_min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-cos-annealing" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cos-annealing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/ass01-cos-annealing.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cos-annealing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Figure: Cosine Annealing Learning Rate Scheduler Example <br> total_steps = 10000 , alpha_max = 0.001 , alpha_min = 1e-4 , Tw = 500 , Tc = total_steps // 2
</figcaption>
</figure>
</div>
</section>
<section id="gradient-clipping" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="gradient-clipping"><span class="header-section-number">4.2.3</span> Gradient Clipping</h3>
<p>åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæœ‰æ—¶ä¼šé‡åˆ°æŸäº› <strong>â€œç‰¹åˆ«éš¾/ç‰¹åˆ«æç«¯â€ çš„è®­ç»ƒæ ·æœ¬</strong>ï¼Œå®ƒä»¬ä¼šè®©æ¨¡å‹äº§ç”Ÿ <strong>éå¸¸å¤§çš„æ¢¯åº¦</strong>ã€‚å¦‚æœç›´æ¥ç”¨è¿™ç§æ¢¯åº¦æ›´æ–°å‚æ•°ï¼Œå¯èƒ½ä¼šå¯¼è‡´ï¼š</p>
<ul>
<li>Loss Spike: Loss çªç„¶çˆ†ç‚¸ï¼ˆæ•°å€¼ä¸ç¨³å®šï¼‰</li>
<li>å‚æ•°æ›´æ–°æ­¥å­å¤ªå¤§ï¼Œå¯¼è‡´è®­ç»ƒå‘æ•£</li>
<li>è®­ç»ƒæ›²çº¿æŠ–åŠ¨çš„å¾ˆå‰å®³ï¼Œéš¾ä»¥æ”¶æ•›</li>
</ul>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®è·µä¸­å¸¸ç”¨ Gradient Clippingã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³éå¸¸ç®€å•ï¼š ::: {.callout-paper} æŠŠæ‰€æœ‰å‚æ•°çš„æ¢¯åº¦åˆèµ·æ¥ï¼Œè§†ä¸ºä¸€ä¸ªå‘é‡<span class="math inline">\(g\)</span>, è®¡ç®—å®ƒçš„ L2-Norm <span class="math inline">\(\|g\|_{2}\)</span>,æˆ‘ä»¬å¯ä»¥å°†å…¶ç†è§£ä¸ºæ•´ä½“æ¢¯åº¦çš„å¼ºåº¦/æ€»èƒ½é‡, ç„¶åè®¾å®šä¸€ä¸ªé˜ˆå€¼ <span class="math inline">\(M\)</span>ï¼ˆæœ€å¤§å…è®¸çš„æ¢¯åº¦èŒƒæ•°ï¼‰ :::</p>
<p>å› æ­¤ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§æƒ…å†µï¼š</p>
<ol type="1">
<li><span class="math inline">\(\|g\|_{2} \leq M\)</span>: è¯´æ˜æ¢¯åº¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œç›´æ¥ä¿æŒåŸæ ·ã€‚</li>
<li><span class="math inline">\(\|g\|_{2} &gt; M\)</span>: è¯´æ˜è¿™ä¸ªæ¢¯åº¦è¿‡å¤§ï¼Œå¯èƒ½ä¼šé€ æˆé—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬ç­‰æ¯”ä¾‹ç¼©å°æ›´æ–°è¿™ä¸ªæ¢¯åº¦, ç¼©å°çš„ç³»æ•°æ˜¯ <span class="math inline">\(\frac{M}{\|g\|_{2} + \epsilon}\)</span>. æ›´æ–°åçš„æ¢¯åº¦ä¸ºï¼š</li>
</ol>
<p><span id="eq-gradient-clipping"><span class="math display">\[
g \leftarrow g \cdot \frac{M}{\|g\|_2 + \epsilon}
\tag{43}\]</span></span></p>
<p>é€šè¿‡è¿™ç§ç¼©æ”¾çš„æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ï¼š</p>
<ul>
<li><strong>æ–¹å‘ä¸å˜</strong>ï¼šè£å‰ªä¸ä¼šæ”¹å˜æ¢¯åº¦çš„æ–¹å‘ï¼ˆåªæ˜¯æ•´ä½“ç¼©æ”¾ï¼‰</li>
<li><strong>æ­¥å­å˜å°</strong>ï¼šå½“æ¢¯åº¦å¤ªå¤§æ—¶ï¼Œç›¸å½“äºå¼ºè¡Œè®©æ›´æ–°ä¸è¦è·¨å¤ªå¤§æ­¥</li>
<li><strong>æ›´ç¨³å®š</strong>ï¼šå°¤å…¶å¯¹ RNNã€Transformer æˆ–è®­ç»ƒæ—©æœŸå¾ˆå¸¸è§çš„â€œæ¢¯åº¦çˆ†ç‚¸â€é—®é¢˜å¾ˆæœ‰å¸®åŠ©</li>
</ul>
<p>ä»£ç å®ç°ä¹Ÿå¾ˆç®€å•ï¼Œç›´è§‚ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/optim.py</strong></pre>
</div>
<div class="sourceCode" id="cb58" data-filename="cs336_basics/optim.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a></span>
<span id="cb58-2"><a href="#cb58-2"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb58-3"><a href="#cb58-3"></a><span class="kw">def</span> gradient_clip(</span>
<span id="cb58-4"><a href="#cb58-4"></a>    parameters: Iterable[torch.nn.Parameter],</span>
<span id="cb58-5"><a href="#cb58-5"></a>    max_l2_norm: <span class="bu">float</span>,</span>
<span id="cb58-6"><a href="#cb58-6"></a>    eps: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-6</span>,</span>
<span id="cb58-7"><a href="#cb58-7"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb58-8"><a href="#cb58-8"></a>    <span class="co"># Calculate L2-Norm</span></span>
<span id="cb58-9"><a href="#cb58-9"></a>    total_norm <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb58-10"><a href="#cb58-10"></a>    <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb58-11"><a href="#cb58-11"></a>        <span class="cf">if</span> p.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-12"><a href="#cb58-12"></a>            param_norm <span class="op">=</span> p.grad.data.norm(<span class="dv">2</span>)</span>
<span id="cb58-13"><a href="#cb58-13"></a>            total_norm <span class="op">+=</span> param_norm.item() <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb58-14"><a href="#cb58-14"></a>    total_norm <span class="op">=</span> total_norm<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb58-15"><a href="#cb58-15"></a></span>
<span id="cb58-16"><a href="#cb58-16"></a>    <span class="co"># Update gradient value accroding to the factor</span></span>
<span id="cb58-17"><a href="#cb58-17"></a>    clip_coef <span class="op">=</span> max_l2_norm <span class="op">/</span> (total_norm <span class="op">+</span> eps)</span>
<span id="cb58-18"><a href="#cb58-18"></a>    <span class="cf">if</span> clip_coef <span class="op">&lt;</span> <span class="fl">1.0</span>:</span>
<span id="cb58-19"><a href="#cb58-19"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb58-20"><a href="#cb58-20"></a>            <span class="cf">if</span> p.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-21"><a href="#cb58-21"></a>                p.grad.data.mul_(clip_coef)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="put-together" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="put-together"><span class="header-section-number">4.2.4</span> Put Together</h3>
<p>æœ‰äº†è¿™ä¸‰ä¸ªä¼˜åŒ–çš„ç»„ä»¶ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠå®ƒä»¬æ”¾åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ­¥éª¤ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/train_engine.py</strong></pre>
</div>
<div class="sourceCode" id="cb59" data-filename="cs336_basics/train_engine.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a>inputs, targets <span class="op">=</span> data_loading_sequential(</span>
<span id="cb59-2"><a href="#cb59-2"></a>    x<span class="op">=</span>x,</span>
<span id="cb59-3"><a href="#cb59-3"></a>    batch_size<span class="op">=</span>train_config.batch_size,</span>
<span id="cb59-4"><a href="#cb59-4"></a>    context_length<span class="op">=</span>model.config.max_seq_len,</span>
<span id="cb59-5"><a href="#cb59-5"></a>    device<span class="op">=</span>train_config.device,</span>
<span id="cb59-6"><a href="#cb59-6"></a>    state<span class="op">=</span>state,</span>
<span id="cb59-7"><a href="#cb59-7"></a>)</span>
<span id="cb59-8"><a href="#cb59-8"></a></span>
<span id="cb59-9"><a href="#cb59-9"></a><span class="co"># Forward pass</span></span>
<span id="cb59-10"><a href="#cb59-10"></a><span class="cf">with</span> ctx:</span>
<span id="cb59-11"><a href="#cb59-11"></a>    logits <span class="op">=</span> model(inputs)</span>
<span id="cb59-12"><a href="#cb59-12"></a>    logits <span class="op">=</span> logits.view(<span class="op">-</span><span class="dv">1</span>, logits.size(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb59-13"><a href="#cb59-13"></a>    targets <span class="op">=</span> targets.view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb59-14"><a href="#cb59-14"></a>    loss <span class="op">=</span> cross_entropy(logits, targets)</span>
<span id="cb59-15"><a href="#cb59-15"></a></span>
<span id="cb59-16"><a href="#cb59-16"></a><span class="co"># Backward pass and optimization step</span></span>
<span id="cb59-17"><a href="#cb59-17"></a>optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb59-18"><a href="#cb59-18"></a>loss.backward()</span>
<span id="cb59-19"><a href="#cb59-19"></a><span class="co"># Gradient clipping</span></span>
<span id="cb59-20"><a href="#cb59-20"></a>gradient_clip(model.parameters(), max_l2_norm<span class="op">=</span>train_config.max_grad_norm)</span>
<span id="cb59-21"><a href="#cb59-21"></a></span>
<span id="cb59-22"><a href="#cb59-22"></a><span class="co"># Learning rate scheduling</span></span>
<span id="cb59-23"><a href="#cb59-23"></a>lr <span class="op">=</span> cosine_annealing_lr(</span>
<span id="cb59-24"><a href="#cb59-24"></a>    t<span class="op">=</span>step,</span>
<span id="cb59-25"><a href="#cb59-25"></a>    alpha_max<span class="op">=</span>train_config.max_lr,</span>
<span id="cb59-26"><a href="#cb59-26"></a>    alpha_min<span class="op">=</span>train_config.min_lr,</span>
<span id="cb59-27"><a href="#cb59-27"></a>    Tw<span class="op">=</span>train_config.warmup_steps,</span>
<span id="cb59-28"><a href="#cb59-28"></a>    Tc<span class="op">=</span>train_config.num_steps <span class="op">-</span> train_config.warmup_steps,</span>
<span id="cb59-29"><a href="#cb59-29"></a>)</span>
<span id="cb59-30"><a href="#cb59-30"></a><span class="cf">for</span> param_group <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb59-31"><a href="#cb59-31"></a>    param_group[<span class="st">"lr"</span>] <span class="op">=</span> lr</span>
<span id="cb59-32"><a href="#cb59-32"></a>optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="dataloader" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="dataloader"><span class="header-section-number">4.3</span> Dataloader</h2>
<p>æœ‰äº†æ¨¡å‹å’Œä¼˜åŒ–å™¨ä¹‹åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ª<strong>æ•°æ®åŠ è½½å™¨ï¼ˆDataloaderï¼‰</strong>æ¥æä¾›è®­ç»ƒæ•°æ®ã€‚åœ¨è¯­è¨€æ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œæ•°æ®é€šå¸¸æ˜¯æ–‡æœ¬åºåˆ—ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›æ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚è¿˜è®°å¾—ä¹‹å‰æˆ‘ä»¬åœ¨ Part 01 è®²è¿‡çš„ Tokenization å—ï¼Ÿæˆ‘ä»¬éœ€è¦å…ˆæŠŠæ–‡æœ¬è½¬æ¢ä¸º token idsï¼Œç„¶åå†ç»„ç»‡æˆé€‚åˆæ¨¡å‹è¾“å…¥çš„æ‰¹æ¬¡ã€‚æˆ‘ä»¬å·²ç»è®­ç»ƒå®ŒTokenizerï¼Œå¹¶ä¸”æŠŠæ–‡æœ¬è½¬æ¢æˆäº†token idsçš„å½¢å¼ä¿å­˜åœ¨<code>.bin</code>æ–‡ä»¶ä¸­ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°æ®åŠ è½½å™¨æ¥ä»è¿™äº›token idsä¸­æå–å‡ºè®­ç»ƒæ ·æœ¬ã€‚</p>
<p>åœ¨è¿™ä¸ªä½œä¸šä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„<strong>é¡ºåºé‡‡æ ·ï¼ˆsequential samplingï¼‰</strong>æ–¹æ³•æ¥åŠ è½½æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¼šä» token ids ä¸­æŒ‰é¡ºåºæå–å‡ºé•¿åº¦ä¸º <code>context_length</code> çš„å­åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œç›®æ ‡æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚æˆ‘ä»¬ä¼šä¸æ–­åœ°ä»æ•°æ®ä¸­æå–è¿™æ ·çš„å­åºåˆ—ï¼Œç›´åˆ°è¾¾åˆ°æŒ‡å®šçš„æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ã€‚</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>ä½œä¸šä¸­ç”¨çš„æ˜¯Random Samplingï¼Œä¹Ÿå°±æ˜¯éšæœºæŒ‡å®šèµ·ç‚¹ï¼Œç„¶åæˆªå–context lengthé•¿åº¦çš„åºåˆ—ä½œä¸ºè¾“å…¥ã€‚</p>
</div>
</div>
<p>ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/data.py</strong></pre>
</div>
<div class="sourceCode" id="cb60" data-filename="cs336_basics/data.py" data-code-line-numbers="1,2,3,4,6,36,45,46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a>original_data <span class="op">=</span> np.memmap( </span>
<span id="cb60-2"><a href="#cb60-2"></a>    train_config.train_data_path, </span>
<span id="cb60-3"><a href="#cb60-3"></a>    dtype<span class="op">=</span>np.uint16, </span>
<span id="cb60-4"><a href="#cb60-4"></a>    mode<span class="op">=</span><span class="st">"r+"</span>, </span>
<span id="cb60-5"><a href="#cb60-5"></a>)</span>
<span id="cb60-6"><a href="#cb60-6"></a>x_t <span class="op">=</span> torch.from_numpy(original_data) </span>
<span id="cb60-7"><a href="#cb60-7"></a></span>
<span id="cb60-8"><a href="#cb60-8"></a><span class="kw">def</span> get_batch_sequential(</span>
<span id="cb60-9"><a href="#cb60-9"></a>    x_t: torch.Tensor <span class="op">|</span> np.ndarray,</span>
<span id="cb60-10"><a href="#cb60-10"></a>    batch_size: <span class="bu">int</span>,</span>
<span id="cb60-11"><a href="#cb60-11"></a>    context_length: <span class="bu">int</span>,</span>
<span id="cb60-12"><a href="#cb60-12"></a>    device: <span class="bu">str</span> <span class="op">|</span> torch.device,</span>
<span id="cb60-13"><a href="#cb60-13"></a>    state: BatchState,</span>
<span id="cb60-14"><a href="#cb60-14"></a>    <span class="op">*</span>,</span>
<span id="cb60-15"><a href="#cb60-15"></a>    stride: <span class="bu">int</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb60-16"><a href="#cb60-16"></a>):</span>
<span id="cb60-17"><a href="#cb60-17"></a>    <span class="cf">if</span> stride <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb60-18"><a href="#cb60-18"></a>        stride <span class="op">=</span> context_length</span>
<span id="cb60-19"><a href="#cb60-19"></a></span>
<span id="cb60-20"><a href="#cb60-20"></a>    n <span class="op">=</span> x_t.numel()</span>
<span id="cb60-21"><a href="#cb60-21"></a>    max_start <span class="op">=</span> n <span class="op">-</span> context_length <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb60-22"><a href="#cb60-22"></a>    <span class="cf">if</span> max_start <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb60-23"><a href="#cb60-23"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Sequence too short: n=</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">, context_length=</span><span class="sc">{</span>context_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb60-24"><a href="#cb60-24"></a></span>
<span id="cb60-25"><a href="#cb60-25"></a>    <span class="co"># Avoid per-sample modulo wrap. If we would run off the end, reset cursor.</span></span>
<span id="cb60-26"><a href="#cb60-26"></a>    last_start <span class="op">=</span> state.pos <span class="op">+</span> (batch_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> stride</span>
<span id="cb60-27"><a href="#cb60-27"></a>    end <span class="op">=</span> last_start <span class="op">+</span> context_length <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb60-28"><a href="#cb60-28"></a>    <span class="cf">if</span> end <span class="op">&gt;</span> n:</span>
<span id="cb60-29"><a href="#cb60-29"></a>        state.pos <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb60-30"><a href="#cb60-30"></a>        last_start <span class="op">=</span> (batch_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> stride</span>
<span id="cb60-31"><a href="#cb60-31"></a>        end <span class="op">=</span> last_start <span class="op">+</span> context_length <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb60-32"><a href="#cb60-32"></a></span>
<span id="cb60-33"><a href="#cb60-33"></a>    base <span class="op">=</span> x_t[state.pos : end]  <span class="co"># 1D contiguous slice</span></span>
<span id="cb60-34"><a href="#cb60-34"></a></span>
<span id="cb60-35"><a href="#cb60-35"></a>    <span class="co"># 2D views: (B, T). Strides are in *elements* for PyTorch tensors.</span></span>
<span id="cb60-36"><a href="#cb60-36"></a>    inputs <span class="op">=</span> base.as_strided(size<span class="op">=</span>(batch_size, context_length), stride<span class="op">=</span>(stride, <span class="dv">1</span>)) </span>
<span id="cb60-37"><a href="#cb60-37"></a>    targets <span class="op">=</span> base[<span class="dv">1</span>:].as_strided(size<span class="op">=</span>(batch_size, context_length), stride<span class="op">=</span>(stride, <span class="dv">1</span>)) <span class="co">#&lt;&lt; </span></span>
<span id="cb60-38"><a href="#cb60-38"></a></span>
<span id="cb60-39"><a href="#cb60-39"></a>    state.pos <span class="op">+=</span> batch_size <span class="op">*</span> stride</span>
<span id="cb60-40"><a href="#cb60-40"></a></span>
<span id="cb60-41"><a href="#cb60-41"></a>    <span class="co"># Transfer + cast (cast happens AFTER transfer =&gt; cheaper for CPU)</span></span>
<span id="cb60-42"><a href="#cb60-42"></a>    <span class="cf">if</span> (<span class="bu">isinstance</span>(device, torch.device) <span class="kw">and</span> device.<span class="bu">type</span> <span class="op">==</span> <span class="st">"cuda"</span>) <span class="kw">or</span> (</span>
<span id="cb60-43"><a href="#cb60-43"></a>        <span class="bu">isinstance</span>(device, <span class="bu">str</span>) <span class="kw">and</span> <span class="st">"cuda"</span> <span class="kw">in</span> device.lower()</span>
<span id="cb60-44"><a href="#cb60-44"></a>    ):</span>
<span id="cb60-45"><a href="#cb60-45"></a>        inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>).<span class="bu">long</span>() </span>
<span id="cb60-46"><a href="#cb60-46"></a>        targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>).<span class="bu">long</span>() </span>
<span id="cb60-47"><a href="#cb60-47"></a>    <span class="cf">else</span>:</span>
<span id="cb60-48"><a href="#cb60-48"></a>        inputs <span class="op">=</span> inputs.<span class="bu">long</span>().to(device)</span>
<span id="cb60-49"><a href="#cb60-49"></a>        targets <span class="op">=</span> targets.<span class="bu">long</span>().to(device)</span>
<span id="cb60-50"><a href="#cb60-50"></a></span>
<span id="cb60-51"><a href="#cb60-51"></a>    <span class="cf">return</span> inputs, targets</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªéƒ¨åˆ†å¯èƒ½æ˜¯è®­ç»ƒæ—¶é—´ç“¶é¢ˆï¼Œå› ä¸ºæ•°æ®åŠ è½½å’Œé¢„å¤„ç†å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œå°¤å…¶æ˜¯å½“æ•°æ®é‡å¾ˆå¤§æ—¶ã€‚ æˆ‘ä»¬è¿ç”¨äº†ä»¥ä¸‹å‡ ä¸ªæŠ€å·§æ¥æå‡æ•°æ®åŠ è½½æ•ˆç‡ï¼š</p>
<ul>
<li>ä½¿ç”¨ <code>np.memmap</code> æ¥å†…å­˜æ˜ å°„æ•°æ®æ–‡ä»¶ï¼Œè¿™æ ·å¯ä»¥é¿å…ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªæ•°æ®é›†åˆ°å†…å­˜ä¸­ï¼ŒèŠ‚çœå†…å­˜ç©ºé—´ã€‚</li>
<li>ä½¿ç”¨ <code>as_strided</code> æ¥åˆ›å»ºè¾“å…¥å’Œç›®æ ‡çš„è§†å›¾ï¼Œé¿å…äº†æ•°æ®çš„å¤åˆ¶ï¼Œæé«˜äº†æ•ˆç‡ã€‚</li>
<li>ä½¿ç”¨éé˜»å¡çš„æ•°æ®ä¼ è¾“ï¼ˆ<code>non_blocking=True</code>ï¼‰æ¥åŠ é€Ÿæ•°æ®ä» CPU åˆ° GPU çš„ä¼ è¾“ã€‚</li>
</ul>
</section>
<section id="checkpoint" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="checkpoint"><span class="header-section-number">4.4</span> Checkpoint</h2>
<p>åœ¨è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ—¶ä¸æ—¶çš„ä¿æŒ Checkpoint, ä¸ºä»€ä¹ˆå‘¢ï¼Ÿå› ä¸ºè®­ç»ƒæ¨¡å‹ä¸åªæ˜¯â€œæŠŠ loss è®­åˆ°ä½â€è¿™ä¹ˆç®€å•ï¼Œæˆ‘ä»¬è¿˜ç»å¸¸éœ€è¦ï¼š</p>
<ul>
<li><strong>ä¸­é€”æ¢å¤è®­ç»ƒ</strong>ï¼šæ¯”å¦‚è®­ç»ƒè·‘åˆ°ä¸€åŠæœºå™¨æ–­äº†ã€ä½œä¸šè¶…æ—¶ã€æ„å¤–é€€å‡ºï¼Œ</li>
<li><strong>ä¿ç•™ä¸­é—´æ¨¡å‹</strong>ï¼šæ–¹ä¾¿ä¹‹ååˆ†æè®­ç»ƒè¿‡ç¨‹ã€æ¯”è¾ƒä¸åŒé˜¶æ®µçš„æ¨¡å‹ã€åšä¸åŒé˜¶æ®µçš„é‡‡æ ·ï¼Œ Exponemtial Moving Average (EMA) ç­‰ç­‰</li>
</ul>
<p>Checkpoint çš„ç›®æ ‡æ˜¯ï¼š<strong>è®©ä½ èƒ½ä»ä¸­æ–­å¤„æ— ç¼ç»§ç»­è®­ç»ƒ</strong>ã€‚</p>
<p>å› æ­¤è‡³å°‘è¦å­˜è¿™ä¸‰ç±»ä¸œè¥¿ï¼š</p>
<ol type="1">
<li><strong>æ¨¡å‹å‚æ•°ï¼ˆmodel weightsï¼‰</strong>
<ul>
<li>æ²¡æœ‰å®ƒï¼Œå°±æ²¡æœ‰æ¨¡å‹æœ¬ä½“äº†</li>
</ul></li>
<li><strong>ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer stateï¼‰</strong>
<ul>
<li>ä¾‹å¦‚ AdamW çš„ä¸€é˜¶/äºŒé˜¶åŠ¨é‡ï¼ˆmoment estimatesï¼‰</li>
<li>ä¸å­˜ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢å¤åè®­ç»ƒè½¨è¿¹ä¼šå˜ï¼ˆå› ä¸ºåŠ¨é‡æ²¡äº†ï¼‰</li>
</ul></li>
<li><strong>å½“å‰è¿­ä»£æ­¥æ•°ï¼ˆiteration / stepï¼‰</strong>
<ul>
<li>ç”¨æ¥æ¢å¤å­¦ä¹ ç‡ schedule</li>
<li>å¦åˆ™å­¦ä¹ ç‡ä¼šä»å¤´å¼€å§‹æˆ–é”™ä½</li>
</ul></li>
</ol>
<p>å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb61" data-filename="cs336_basics/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1"></a><span class="kw">def</span> save_checkpoint(</span>
<span id="cb61-2"><a href="#cb61-2"></a>    model: torch.nn.Module,</span>
<span id="cb61-3"><a href="#cb61-3"></a>    optimizer,</span>
<span id="cb61-4"><a href="#cb61-4"></a>    iteration,</span>
<span id="cb61-5"><a href="#cb61-5"></a>    out: <span class="bu">str</span> <span class="op">|</span> os.PathLike <span class="op">|</span> typing.BinaryIO <span class="op">|</span> typing.IO[<span class="bu">bytes</span>],</span>
<span id="cb61-6"><a href="#cb61-6"></a>    verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb61-7"><a href="#cb61-7"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb61-8"><a href="#cb61-8"></a>    state <span class="op">=</span> {</span>
<span id="cb61-9"><a href="#cb61-9"></a>        <span class="st">"model_state_dict"</span>: model.state_dict(),</span>
<span id="cb61-10"><a href="#cb61-10"></a>        <span class="st">"optimizer_state_dict"</span>: optimizer.state_dict(),</span>
<span id="cb61-11"><a href="#cb61-11"></a>        <span class="st">"iteration"</span>: iteration,</span>
<span id="cb61-12"><a href="#cb61-12"></a>    }</span>
<span id="cb61-13"><a href="#cb61-13"></a></span>
<span id="cb61-14"><a href="#cb61-14"></a>    torch.save(state, out)</span>
<span id="cb61-15"><a href="#cb61-15"></a></span>
<span id="cb61-16"><a href="#cb61-16"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb61-17"><a href="#cb61-17"></a>        print_color(<span class="ss">f"Checkpoint saved to </span><span class="sc">{</span>out<span class="sc">}</span><span class="ss">"</span>, <span class="st">"blue"</span>)</span>
<span id="cb61-18"><a href="#cb61-18"></a></span>
<span id="cb61-19"><a href="#cb61-19"></a></span>
<span id="cb61-20"><a href="#cb61-20"></a><span class="kw">def</span> load_checkpoint(</span>
<span id="cb61-21"><a href="#cb61-21"></a>    src: <span class="bu">str</span> <span class="op">|</span> os.PathLike <span class="op">|</span> typing.BinaryIO <span class="op">|</span> typing.IO[<span class="bu">bytes</span>], model, optimizer, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb61-22"><a href="#cb61-22"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb61-23"><a href="#cb61-23"></a>    state <span class="op">=</span> torch.load(src, map_location<span class="op">=</span>get_device())</span>
<span id="cb61-24"><a href="#cb61-24"></a></span>
<span id="cb61-25"><a href="#cb61-25"></a>    model.load_state_dict(state[<span class="st">"model_state_dict"</span>])</span>
<span id="cb61-26"><a href="#cb61-26"></a>    optimizer.load_state_dict(state[<span class="st">"optimizer_state_dict"</span>])</span>
<span id="cb61-27"><a href="#cb61-27"></a></span>
<span id="cb61-28"><a href="#cb61-28"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb61-29"><a href="#cb61-29"></a>        print_color(<span class="ss">f"Checkpoint loaded from </span><span class="sc">{</span>src<span class="sc">}</span><span class="ss">"</span>, <span class="st">"blue"</span>)</span>
<span id="cb61-30"><a href="#cb61-30"></a></span>
<span id="cb61-31"><a href="#cb61-31"></a>    <span class="cf">return</span> state[<span class="st">"iteration"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-looping" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="training-looping"><span class="header-section-number">4.5</span> Training Looping</h2>
<p>æœ€åï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰çš„ç»„ä»¶æ”¾åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/train_engine.py</strong></pre>
</div>
<div class="sourceCode" id="cb62" data-filename="cs336_basics/train_engine.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a><span class="kw">def</span> train(model: torch.nn.Module, optimizer: torch.optim.Optimizer, train_config: TrainingConfig):</span>
<span id="cb62-2"><a href="#cb62-2"></a>    tokenizer <span class="op">=</span> load_tokenizer_from_dir(train_config.dataset_dir)</span>
<span id="cb62-3"><a href="#cb62-3"></a></span>
<span id="cb62-4"><a href="#cb62-4"></a>    <span class="co"># Load training dataset</span></span>
<span id="cb62-5"><a href="#cb62-5"></a>    original_data <span class="op">=</span> np.memmap(</span>
<span id="cb62-6"><a href="#cb62-6"></a>        train_config.train_data_path,</span>
<span id="cb62-7"><a href="#cb62-7"></a>        dtype<span class="op">=</span>np.uint16,</span>
<span id="cb62-8"><a href="#cb62-8"></a>        mode<span class="op">=</span><span class="st">"r+"</span>,</span>
<span id="cb62-9"><a href="#cb62-9"></a>    )</span>
<span id="cb62-10"><a href="#cb62-10"></a>    x <span class="op">=</span> torch.from_numpy(original_data)</span>
<span id="cb62-11"><a href="#cb62-11"></a></span>
<span id="cb62-12"><a href="#cb62-12"></a>    best_eval_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb62-13"><a href="#cb62-13"></a>    ctx <span class="op">=</span> get_ctx(train_config.use_mixed_precision, train_config.device)</span>
<span id="cb62-14"><a href="#cb62-14"></a></span>
<span id="cb62-15"><a href="#cb62-15"></a>    <span class="co"># Training loop</span></span>
<span id="cb62-16"><a href="#cb62-16"></a>    state <span class="op">=</span> BatchState(pos<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb62-17"><a href="#cb62-17"></a>    <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(train_config.num_steps):</span>
<span id="cb62-18"><a href="#cb62-18"></a>        <span class="co"># inputs, targets = dataloader</span></span>
<span id="cb62-19"><a href="#cb62-19"></a>        inputs, targets <span class="op">=</span> data_loading_sequential(</span>
<span id="cb62-20"><a href="#cb62-20"></a>            x<span class="op">=</span>x,</span>
<span id="cb62-21"><a href="#cb62-21"></a>            batch_size<span class="op">=</span>train_config.batch_size,</span>
<span id="cb62-22"><a href="#cb62-22"></a>            context_length<span class="op">=</span>model.config.max_seq_len,</span>
<span id="cb62-23"><a href="#cb62-23"></a>            device<span class="op">=</span>train_config.device,</span>
<span id="cb62-24"><a href="#cb62-24"></a>            state<span class="op">=</span>state,</span>
<span id="cb62-25"><a href="#cb62-25"></a>        )</span>
<span id="cb62-26"><a href="#cb62-26"></a></span>
<span id="cb62-27"><a href="#cb62-27"></a>        <span class="co"># Forward pass</span></span>
<span id="cb62-28"><a href="#cb62-28"></a>        <span class="cf">with</span> ctx:</span>
<span id="cb62-29"><a href="#cb62-29"></a>            logits <span class="op">=</span> model(inputs)</span>
<span id="cb62-30"><a href="#cb62-30"></a>            logits <span class="op">=</span> logits.view(<span class="op">-</span><span class="dv">1</span>, logits.size(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb62-31"><a href="#cb62-31"></a>            targets <span class="op">=</span> targets.view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb62-32"><a href="#cb62-32"></a>            loss <span class="op">=</span> cross_entropy(logits, targets)</span>
<span id="cb62-33"><a href="#cb62-33"></a></span>
<span id="cb62-34"><a href="#cb62-34"></a>        <span class="co"># Backward pass and optimization step</span></span>
<span id="cb62-35"><a href="#cb62-35"></a>        optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb62-36"><a href="#cb62-36"></a>        loss.backward()</span>
<span id="cb62-37"><a href="#cb62-37"></a>        <span class="co"># Gradient clipping</span></span>
<span id="cb62-38"><a href="#cb62-38"></a>        gradient_clip(model.parameters(), max_l2_norm<span class="op">=</span>train_config.max_grad_norm)</span>
<span id="cb62-39"><a href="#cb62-39"></a></span>
<span id="cb62-40"><a href="#cb62-40"></a>        <span class="co"># Learning rate scheduling</span></span>
<span id="cb62-41"><a href="#cb62-41"></a>        lr <span class="op">=</span> cosine_annealing_lr(</span>
<span id="cb62-42"><a href="#cb62-42"></a>            t<span class="op">=</span>step,</span>
<span id="cb62-43"><a href="#cb62-43"></a>            alpha_max<span class="op">=</span>train_config.max_lr,</span>
<span id="cb62-44"><a href="#cb62-44"></a>            alpha_min<span class="op">=</span>train_config.min_lr,</span>
<span id="cb62-45"><a href="#cb62-45"></a>            Tw<span class="op">=</span>train_config.warmup_steps,</span>
<span id="cb62-46"><a href="#cb62-46"></a>            Tc<span class="op">=</span>train_config.num_steps <span class="op">-</span> train_config.warmup_steps,</span>
<span id="cb62-47"><a href="#cb62-47"></a>        )</span>
<span id="cb62-48"><a href="#cb62-48"></a>        <span class="cf">for</span> param_group <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb62-49"><a href="#cb62-49"></a>            param_group[<span class="st">"lr"</span>] <span class="op">=</span> lr</span>
<span id="cb62-50"><a href="#cb62-50"></a>        optimizer.step()</span>
<span id="cb62-51"><a href="#cb62-51"></a></span>
<span id="cb62-52"><a href="#cb62-52"></a>        <span class="co"># Logging</span></span>
<span id="cb62-53"><a href="#cb62-53"></a>        <span class="cf">if</span> train_config.wandb_logging:</span>
<span id="cb62-54"><a href="#cb62-54"></a>            wandb.log(</span>
<span id="cb62-55"><a href="#cb62-55"></a>                {</span>
<span id="cb62-56"><a href="#cb62-56"></a>                    <span class="st">"train/loss"</span>: loss.item(),</span>
<span id="cb62-57"><a href="#cb62-57"></a>                    <span class="st">"train/perplexity"</span>: perplexity(loss).item(),</span>
<span id="cb62-58"><a href="#cb62-58"></a>                    <span class="st">"train/lr"</span>: lr,</span>
<span id="cb62-59"><a href="#cb62-59"></a>                },</span>
<span id="cb62-60"><a href="#cb62-60"></a>                step<span class="op">=</span>step <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb62-61"><a href="#cb62-61"></a>            )</span>
<span id="cb62-62"><a href="#cb62-62"></a></span>
<span id="cb62-63"><a href="#cb62-63"></a>        print_color(</span>
<span id="cb62-64"><a href="#cb62-64"></a>            <span class="ss">f"Step </span><span class="sc">{</span>step <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>train_config<span class="sc">.</span>num_steps<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">, LR: </span><span class="sc">{</span>lr<span class="sc">:.6f}</span><span class="ss">"</span>, <span class="st">"green"</span></span>
<span id="cb62-65"><a href="#cb62-65"></a>        )</span>
<span id="cb62-66"><a href="#cb62-66"></a></span>
<span id="cb62-67"><a href="#cb62-67"></a>        <span class="cf">if</span> train_config.eval_log_interval <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> (step <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> train_config.eval_log_interval <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb62-68"><a href="#cb62-68"></a>            <span class="co"># Cleanup</span></span>
<span id="cb62-69"><a href="#cb62-69"></a>            <span class="kw">del</span> inputs, targets, logits, loss</span>
<span id="cb62-70"><a href="#cb62-70"></a>            clear_memory()</span>
<span id="cb62-71"><a href="#cb62-71"></a></span>
<span id="cb62-72"><a href="#cb62-72"></a>            print_color(<span class="st">"Evaluating model..."</span>, <span class="st">"blue"</span>)</span>
<span id="cb62-73"><a href="#cb62-73"></a>            eval_loss, eval_perplexity <span class="op">=</span> eval_model(model, train_config, step <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb62-74"><a href="#cb62-74"></a>            wandb.log(</span>
<span id="cb62-75"><a href="#cb62-75"></a>                {</span>
<span id="cb62-76"><a href="#cb62-76"></a>                    <span class="st">"eval/loss"</span>: eval_loss.item(),</span>
<span id="cb62-77"><a href="#cb62-77"></a>                    <span class="st">"eval/perplexity"</span>: eval_perplexity.item(),</span>
<span id="cb62-78"><a href="#cb62-78"></a>                },</span>
<span id="cb62-79"><a href="#cb62-79"></a>                step<span class="op">=</span>step <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb62-80"><a href="#cb62-80"></a>            )</span>
<span id="cb62-81"><a href="#cb62-81"></a>            print_color(</span>
<span id="cb62-82"><a href="#cb62-82"></a>                <span class="ss">f"Eval Loss: </span><span class="sc">{</span>eval_loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">, Eval Perplexity: </span><span class="sc">{</span>eval_perplexity<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>, <span class="st">"blue"</span></span>
<span id="cb62-83"><a href="#cb62-83"></a>            )</span>
<span id="cb62-84"><a href="#cb62-84"></a>            <span class="cf">if</span> eval_loss <span class="op">&lt;</span> best_eval_loss:</span>
<span id="cb62-85"><a href="#cb62-85"></a>                best_eval_loss <span class="op">=</span> eval_loss</span>
<span id="cb62-86"><a href="#cb62-86"></a>                print_color(<span class="ss">f"New best eval loss: </span><span class="sc">{</span>best_eval_loss<span class="sc">:.4f}</span><span class="ss">"</span>, <span class="st">"yellow"</span>)</span>
<span id="cb62-87"><a href="#cb62-87"></a>                out_path <span class="op">=</span> os.path.join(</span>
<span id="cb62-88"><a href="#cb62-88"></a>                    train_config.save_checkpoint_dir,</span>
<span id="cb62-89"><a href="#cb62-89"></a>                    train_config.model_name,</span>
<span id="cb62-90"><a href="#cb62-90"></a>                    <span class="ss">f"best_model_step_</span><span class="sc">{</span>step <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">.pt"</span>,</span>
<span id="cb62-91"><a href="#cb62-91"></a>                )</span>
<span id="cb62-92"><a href="#cb62-92"></a>                save_checkpoint(</span>
<span id="cb62-93"><a href="#cb62-93"></a>                    model<span class="op">=</span>model,</span>
<span id="cb62-94"><a href="#cb62-94"></a>                    optimizer<span class="op">=</span>optimizer,</span>
<span id="cb62-95"><a href="#cb62-95"></a>                    iteration<span class="op">=</span>step <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb62-96"><a href="#cb62-96"></a>                    out<span class="op">=</span>out_path,</span>
<span id="cb62-97"><a href="#cb62-97"></a>                    verbose<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb62-98"><a href="#cb62-98"></a>                )</span>
<span id="cb62-99"><a href="#cb62-99"></a></span>
<span id="cb62-100"><a href="#cb62-100"></a>        <span class="co"># Sample generation</span></span>
<span id="cb62-101"><a href="#cb62-101"></a>        <span class="cf">if</span> train_config.sampling_log_interval <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> (step <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> train_config.sampling_log_interval <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb62-102"><a href="#cb62-102"></a>            generated_outputs <span class="op">=</span> generate(</span>
<span id="cb62-103"><a href="#cb62-103"></a>                model<span class="op">=</span>model,</span>
<span id="cb62-104"><a href="#cb62-104"></a>                prompt<span class="op">=</span><span class="st">"Once upon a time"</span>,</span>
<span id="cb62-105"><a href="#cb62-105"></a>                tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb62-106"><a href="#cb62-106"></a>                max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb62-107"><a href="#cb62-107"></a>                top_k<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb62-108"><a href="#cb62-108"></a>                temperature<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb62-109"><a href="#cb62-109"></a>            )</span>
<span id="cb62-110"><a href="#cb62-110"></a>            generated_text <span class="op">=</span> generated_outputs[<span class="st">"generated_text"</span>]</span>
<span id="cb62-111"><a href="#cb62-111"></a>            print_color(<span class="ss">f"Generated text at step </span><span class="sc">{</span>step <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>, <span class="st">"cyan"</span>)</span>
<span id="cb62-112"><a href="#cb62-112"></a>            <span class="bu">print</span>(<span class="st">"Once upon a time"</span>, end<span class="op">=</span><span class="st">""</span>)</span>
<span id="cb62-113"><a href="#cb62-113"></a>            print_color(<span class="ss">f"</span><span class="sc">{</span>generated_text<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>, <span class="st">"cyan"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="part-04-generation" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Part 04: Generation</h1>
<p>è®­ç»ƒå®Œæ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥ç”Ÿæˆæ–‡æœ¬ã€‚åœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œæ–‡æœ¬ç”Ÿæˆé€šå¸¸æ˜¯é€šè¿‡<strong>é‡‡æ ·ï¼ˆsamplingï¼‰</strong>çš„æ–¹å¼æ¥å®ç°çš„ã€‚ç»™å®šä¸€ä¸ªåˆå§‹çš„ä¸Šä¸‹æ–‡ï¼ˆpromptï¼‰ï¼Œæ¨¡å‹ä¼šæ ¹æ®å½“å‰çš„ä¸Šä¸‹æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åä»è¿™ä¸ªåˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ª tokenï¼ŒåŠ å…¥åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œé‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°ç”ŸæˆæŒ‡å®šé•¿åº¦çš„æ–‡æœ¬ã€‚</p>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹é‡‡æ ·çš„åŸºæœ¬æµç¨‹ï¼š</p>
<ol type="1">
<li><strong>è¾“å…¥ä¸Šä¸‹æ–‡</strong>ï¼šç»™å®šä¸€ä¸ªåˆå§‹çš„æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ˆpromptï¼‰ï¼Œå°†å…¶è½¬æ¢ä¸º token idsã€‚</li>
<li><strong>å¾ªç¯ç”Ÿæˆ</strong>ï¼šå¯¹äºæ¯ä¸€æ­¥ç”Ÿæˆï¼š
<ul>
<li>ä½¿ç”¨æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
<li>æ ¹æ®<strong>é‡‡æ ·ç­–ç•¥</strong>ä»æ¦‚ç‡åˆ†å¸ƒä¸­é€‰æ‹©ä¸‹ä¸€ä¸ª tokenã€‚</li>
<li>å°†é€‰ä¸­çš„ token åŠ å…¥åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ã€‚</li>
<li>é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°ç”ŸæˆæŒ‡å®šæ•°é‡çš„ tokenã€‚</li>
</ul></li>
<li><strong>è¾“å‡ºç”Ÿæˆæ–‡æœ¬</strong>ï¼šå°†ç”Ÿæˆçš„ token ids è½¬æ¢å›æ–‡æœ¬ï¼Œè¾“å‡ºæœ€ç»ˆç”Ÿæˆçš„æ–‡æœ¬ã€‚</li>
</ol>
<p>ç”¨ä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/generation.py</strong></pre>
</div>
<div class="sourceCode" id="cb63" data-filename="cs336_basics/generation.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb63-2"><a href="#cb63-2"></a><span class="kw">def</span> generate(</span>
<span id="cb63-3"><a href="#cb63-3"></a>    model: torch.nn.Module,</span>
<span id="cb63-4"><a href="#cb63-4"></a>    prompt: torch.Tensor <span class="op">|</span> <span class="bu">str</span>,</span>
<span id="cb63-5"><a href="#cb63-5"></a>    tokenizer: BPETokenizer,</span>
<span id="cb63-6"><a href="#cb63-6"></a>    max_new_tokens: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span>,</span>
<span id="cb63-7"><a href="#cb63-7"></a>    top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">0</span>,</span>
<span id="cb63-8"><a href="#cb63-8"></a>    top_p: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>,</span>
<span id="cb63-9"><a href="#cb63-9"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb63-10"><a href="#cb63-10"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb63-11"><a href="#cb63-11"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb63-12"><a href="#cb63-12"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(prompt, <span class="bu">str</span>):</span>
<span id="cb63-13"><a href="#cb63-13"></a>        out <span class="op">=</span> tokenizer.encode(prompt)</span>
<span id="cb63-14"><a href="#cb63-14"></a>        input_ids <span class="op">=</span> out.ids <span class="cf">if</span> <span class="bu">hasattr</span>(out, <span class="st">"ids"</span>) <span class="cf">else</span> out  <span class="co"># List[int]</span></span>
<span id="cb63-15"><a href="#cb63-15"></a>        input_ids <span class="op">=</span> torch.tensor(input_ids, dtype<span class="op">=</span>torch.<span class="bu">long</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb63-16"><a href="#cb63-16"></a>    <span class="cf">else</span>:</span>
<span id="cb63-17"><a href="#cb63-17"></a>        input_ids <span class="op">=</span> prompt.unsqueeze(<span class="dv">0</span>)  <span class="co"># Add batch dimension</span></span>
<span id="cb63-18"><a href="#cb63-18"></a></span>
<span id="cb63-19"><a href="#cb63-19"></a>    input_ids <span class="op">=</span> input_ids.to(model.device)</span>
<span id="cb63-20"><a href="#cb63-20"></a>    input_len <span class="op">=</span> input_ids.shape[<span class="dv">1</span>]</span>
<span id="cb63-21"><a href="#cb63-21"></a></span>
<span id="cb63-22"><a href="#cb63-22"></a>    <span class="cf">with</span> torch.amp.autocast(<span class="st">"cuda"</span>, enabled<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb63-23"><a href="#cb63-23"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_new_tokens):</span>
<span id="cb63-24"><a href="#cb63-24"></a>            logits <span class="op">=</span> model(input_ids)</span>
<span id="cb63-25"><a href="#cb63-25"></a>            next_token_logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :].<span class="bu">float</span>()  <span class="co"># Get logits for the last token</span></span>
<span id="cb63-26"><a href="#cb63-26"></a></span>
<span id="cb63-27"><a href="#cb63-27"></a>            <span class="co"># Sample from the distribution</span></span>
<span id="cb63-28"><a href="#cb63-28"></a>            <span class="cf">assert</span> temperature <span class="op">&gt;</span> <span class="fl">0.0</span>, <span class="st">"Temperature must be positive."</span></span>
<span id="cb63-29"><a href="#cb63-29"></a>            <span class="cf">assert</span> top_p <span class="op">==</span> <span class="fl">0.0</span> <span class="kw">or</span> top_k <span class="op">==</span> <span class="dv">0</span>, <span class="st">"Only one of top_p or top_k should be set."</span></span>
<span id="cb63-30"><a href="#cb63-30"></a>            next_token_logits <span class="op">=</span> next_token_logits <span class="op">/</span> temperature</span>
<span id="cb63-31"><a href="#cb63-31"></a></span>
<span id="cb63-32"><a href="#cb63-32"></a>            <span class="cf">if</span> top_k <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb63-33"><a href="#cb63-33"></a>                next_token_id <span class="op">=</span> top_k_sampling(next_token_logits, top_k)</span>
<span id="cb63-34"><a href="#cb63-34"></a>            <span class="cf">elif</span> top_p <span class="op">&gt;</span> <span class="fl">0.0</span>:</span>
<span id="cb63-35"><a href="#cb63-35"></a>                next_token_id <span class="op">=</span> top_p_sampling(next_token_logits, top_p)</span>
<span id="cb63-36"><a href="#cb63-36"></a>            <span class="cf">else</span>:</span>
<span id="cb63-37"><a href="#cb63-37"></a>                next_token_id <span class="op">=</span> next_token_logits.argmax(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)  <span class="co"># Greedy if no sampling</span></span>
<span id="cb63-38"><a href="#cb63-38"></a></span>
<span id="cb63-39"><a href="#cb63-39"></a>            <span class="cf">if</span> next_token_id.item() <span class="op">==</span> tokenizer.eos_token_id:</span>
<span id="cb63-40"><a href="#cb63-40"></a>                <span class="cf">break</span>  <span class="co"># Stop if EOS token is generated</span></span>
<span id="cb63-41"><a href="#cb63-41"></a>            input_ids <span class="op">=</span> torch.cat([input_ids, next_token_id], dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># Append to input_ids</span></span>
<span id="cb63-42"><a href="#cb63-42"></a></span>
<span id="cb63-43"><a href="#cb63-43"></a>    input_ids <span class="op">=</span> input_ids.squeeze(<span class="dv">0</span>)  <span class="co"># Remove batch dimension</span></span>
<span id="cb63-44"><a href="#cb63-44"></a>    all_text <span class="op">=</span> tokenizer.decode(input_ids.tolist())</span>
<span id="cb63-45"><a href="#cb63-45"></a>    generated_ids <span class="op">=</span> input_ids[input_len:]</span>
<span id="cb63-46"><a href="#cb63-46"></a>    generated_text <span class="op">=</span> tokenizer.decode(generated_ids.tolist())</span>
<span id="cb63-47"><a href="#cb63-47"></a></span>
<span id="cb63-48"><a href="#cb63-48"></a>    model.train()</span>
<span id="cb63-49"><a href="#cb63-49"></a>    <span class="cf">return</span> {</span>
<span id="cb63-50"><a href="#cb63-50"></a>        <span class="st">"all_text"</span>: all_text,</span>
<span id="cb63-51"><a href="#cb63-51"></a>        <span class="st">"generated_text"</span>: generated_text,</span>
<span id="cb63-52"><a href="#cb63-52"></a>        <span class="st">"generated_ids"</span>: generated_ids,</span>
<span id="cb63-53"><a href="#cb63-53"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>å…¶ä¸­ä¸åŒçš„é‡‡æ ·è¿‡ç¨‹ï¼Œä¼šç”Ÿæˆä¸åŒé£æ ¼çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å‡ ç§å¸¸ç”¨çš„é‡‡æ ·æ–¹æ³•ï¼š</p>
<p>æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å¸¸ç”¨çš„é‡‡æ ·æ–¹æ³•ï¼š - Greedy Sampling - Top-K Sampling - Top-P (Nucleus) Sampling</p>
<section id="greedy-sampling" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="greedy-sampling"><span class="header-section-number">5.1</span> Greedy Sampling</h2>
<p>Greedy Sampling æ˜¯æœ€ç®€å•çš„ä¸€ç§é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ token ä½œä¸ºä¸‹ä¸€ä¸ª tokenã€‚è™½ç„¶è¿™ç§æ–¹æ³•ç®€å•ä¸”é«˜æ•ˆï¼Œä½†å®ƒå¯èƒ½ä¼šå¯¼è‡´ç”Ÿæˆçš„æ–‡æœ¬ç¼ºä¹å¤šæ ·æ€§å’Œåˆ›é€ æ€§ï¼Œå› ä¸ºå®ƒæ€»æ˜¯é€‰æ‹©æœ€å¯èƒ½çš„é€‰é¡¹ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/generation.py</strong></pre>
</div>
<div class="sourceCode" id="cb64" data-filename="cs336_basics/generation.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1"></a>next_token_id <span class="op">=</span> next_token_logits.argmax(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="top-k-sampling" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="top-k-sampling"><span class="header-section-number">5.2</span> Top-K Sampling</h2>
<p>Top-K Sampling æ˜¯ä¸€ç§æ”¹è¿›çš„é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ K ä¸ª tokenï¼Œç„¶åä»è¿™ K ä¸ª token ä¸­æ ¹æ®å®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ã€‚è¿™æ ·å¯ä»¥å¢åŠ ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼ŒåŒæ—¶ä»ç„¶ä¿æŒä¸€å®šçš„è´¨é‡ã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/generation.py</strong></pre>
</div>
<div class="sourceCode" id="cb65" data-filename="cs336_basics/generation.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a><span class="kw">def</span> top_k_sampling(</span>
<span id="cb65-2"><a href="#cb65-2"></a>    logits: torch.Tensor,</span>
<span id="cb65-3"><a href="#cb65-3"></a>    top_k: <span class="bu">int</span>,</span>
<span id="cb65-4"><a href="#cb65-4"></a>):</span>
<span id="cb65-5"><a href="#cb65-5"></a>    <span class="cf">if</span> top_k <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb65-6"><a href="#cb65-6"></a>        <span class="co"># sample from full distribution</span></span>
<span id="cb65-7"><a href="#cb65-7"></a>        probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb65-8"><a href="#cb65-8"></a>        <span class="cf">return</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb65-9"><a href="#cb65-9"></a></span>
<span id="cb65-10"><a href="#cb65-10"></a>    <span class="co"># 1. keep only top-k logits</span></span>
<span id="cb65-11"><a href="#cb65-11"></a>    top_k_logits, top_k_indices <span class="op">=</span> torch.topk(logits, top_k, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb65-12"><a href="#cb65-12"></a></span>
<span id="cb65-13"><a href="#cb65-13"></a>    filtered_logits <span class="op">=</span> torch.full_like(logits, <span class="bu">float</span>(<span class="st">"-inf"</span>))</span>
<span id="cb65-14"><a href="#cb65-14"></a>    filtered_logits.scatter_(dim<span class="op">=-</span><span class="dv">1</span>, index<span class="op">=</span>top_k_indices, src<span class="op">=</span>top_k_logits)</span>
<span id="cb65-15"><a href="#cb65-15"></a></span>
<span id="cb65-16"><a href="#cb65-16"></a>    <span class="co"># 2. softmax over filtered logits</span></span>
<span id="cb65-17"><a href="#cb65-17"></a>    probs <span class="op">=</span> F.softmax(filtered_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb65-18"><a href="#cb65-18"></a></span>
<span id="cb65-19"><a href="#cb65-19"></a>    <span class="co"># 3. sample</span></span>
<span id="cb65-20"><a href="#cb65-20"></a>    next_token <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-21"><a href="#cb65-21"></a></span>
<span id="cb65-22"><a href="#cb65-22"></a>    <span class="cf">return</span> next_token</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="top-p-sampling" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="top-p-sampling"><span class="header-section-number">5.3</span> Top-P Sampling</h2>
<p>Top-P Samplingï¼ˆä¹Ÿç§°ä¸º Nucleus Samplingï¼‰æ˜¯ä¸€ç§æ›´çµæ´»çš„é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©ç´¯è®¡æ¦‚ç‡è¾¾åˆ° P çš„æœ€å° token é›†åˆï¼Œç„¶åä»è¿™ä¸ªé›†åˆä¸­æ ¹æ®å®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ã€‚è¿™æ ·å¯ä»¥åŠ¨æ€è°ƒæ•´å€™é€‰ token çš„æ•°é‡ï¼Œæ—¢ä¿è¯äº†å¤šæ ·æ€§ï¼Œåˆé¿å…äº†é€‰æ‹©è¿‡äºç½•è§çš„ tokenã€‚</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/generation.py</strong></pre>
</div>
<div class="sourceCode" id="cb66" data-filename="cs336_basics/generation.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a><span class="kw">def</span> top_p_sampling(logits: torch.Tensor, top_p: <span class="bu">float</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb66-2"><a href="#cb66-2"></a>    <span class="co">"""</span></span>
<span id="cb66-3"><a href="#cb66-3"></a><span class="co">    logits: (B, V)</span></span>
<span id="cb66-4"><a href="#cb66-4"></a><span class="co">    returns: (B,) sampled token ids</span></span>
<span id="cb66-5"><a href="#cb66-5"></a><span class="co">    """</span></span>
<span id="cb66-6"><a href="#cb66-6"></a>    <span class="cf">assert</span> <span class="fl">0.0</span> <span class="op">&lt;</span> top_p <span class="op">&lt;=</span> <span class="fl">1.0</span></span>
<span id="cb66-7"><a href="#cb66-7"></a></span>
<span id="cb66-8"><a href="#cb66-8"></a>    <span class="co"># sort</span></span>
<span id="cb66-9"><a href="#cb66-9"></a>    sorted_logits, sorted_indices <span class="op">=</span> torch.sort(logits, dim<span class="op">=-</span><span class="dv">1</span>, descending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb66-10"><a href="#cb66-10"></a>    sorted_probs <span class="op">=</span> F.softmax(sorted_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb66-11"><a href="#cb66-11"></a>    cumulative_probs <span class="op">=</span> torch.cumsum(sorted_probs, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb66-12"><a href="#cb66-12"></a></span>
<span id="cb66-13"><a href="#cb66-13"></a>    <span class="co"># mask tokens with cumulative prob &gt; top_p (but keep at least 1 token)</span></span>
<span id="cb66-14"><a href="#cb66-14"></a>    sorted_indices_to_remove <span class="op">=</span> cumulative_probs <span class="op">&gt;</span> top_p</span>
<span id="cb66-15"><a href="#cb66-15"></a>    sorted_indices_to_remove[..., <span class="dv">1</span>:] <span class="op">=</span> sorted_indices_to_remove[..., :<span class="op">-</span><span class="dv">1</span>].clone()</span>
<span id="cb66-16"><a href="#cb66-16"></a>    sorted_indices_to_remove[..., <span class="dv">0</span>] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb66-17"><a href="#cb66-17"></a></span>
<span id="cb66-18"><a href="#cb66-18"></a>    <span class="co"># scatter mask back to original vocab positions</span></span>
<span id="cb66-19"><a href="#cb66-19"></a>    indices_to_remove <span class="op">=</span> torch.zeros_like(logits, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb66-20"><a href="#cb66-20"></a>    indices_to_remove.scatter_(dim<span class="op">=-</span><span class="dv">1</span>, index<span class="op">=</span>sorted_indices, src<span class="op">=</span>sorted_indices_to_remove)</span>
<span id="cb66-21"><a href="#cb66-21"></a></span>
<span id="cb66-22"><a href="#cb66-22"></a>    filtered_logits <span class="op">=</span> logits.masked_fill(indices_to_remove, <span class="bu">float</span>(<span class="st">"-inf"</span>))</span>
<span id="cb66-23"><a href="#cb66-23"></a></span>
<span id="cb66-24"><a href="#cb66-24"></a>    probs <span class="op">=</span> F.softmax(filtered_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb66-25"><a href="#cb66-25"></a>    next_token <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-26"><a href="#cb66-26"></a></span>
<span id="cb66-27"><a href="#cb66-27"></a>    <span class="cf">return</span> next_token</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="temperature" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="temperature"><span class="header-section-number">5.4</span> Temperature</h2>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è°ƒæ•´ <strong>temperature</strong> æ¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚Temperature æ˜¯ä¸€ä¸ªæ­£æ•°ï¼Œé€šå¸¸åœ¨ <span class="math display">\[ (0, \infty) \]</span> èŒƒå›´å†…ã€‚å®ƒé€šè¿‡ç¼©æ”¾ logits æ¥å½±å“æ¦‚ç‡åˆ†å¸ƒï¼š</p>
<ul>
<li>å½“ temperature &lt; 1 æ—¶ï¼Œæ¦‚ç‡åˆ†å¸ƒä¼šå˜å¾—æ›´é™¡å³­ï¼Œæ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©é«˜æ¦‚ç‡çš„ tokenï¼Œç”Ÿæˆçš„æ–‡æœ¬æ›´ç¡®å®šæ€§ã€‚</li>
<li>å½“ temperature &gt; 1 æ—¶ï¼Œæ¦‚ç‡åˆ†å¸ƒä¼šå˜å¾—æ›´å¹³å¦ï¼Œæ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©ä½æ¦‚ç‡çš„ tokenï¼Œç”Ÿæˆçš„æ–‡æœ¬æ›´å…·å¤šæ ·æ€§å’Œåˆ›é€ æ€§ã€‚</li>
</ul>
<p>æ•°å­¦ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡é™¤ä»¥ temperature æ¥è°ƒæ•´ logitsï¼š</p>
<p><span id="eq-temperature-softmax"><span class="math display">\[
\mathrm{softmax}_i(\mathbf{z};T)
=\frac{\exp\left(\frac{z_i}{T}\right)}
{\sum_{j}\exp\left(\frac{z_j}{T}\right)}
\tag{44}\]</span></span></p>
<div id="fig-temperature-sampling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-temperature-sampling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/temperature-sampling.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-temperature-sampling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Temperature å¯¹é‡‡æ ·åˆ†å¸ƒçš„å½±å“ç¤ºæ„å›¾
</figcaption>
</figure>
</div>
</section>
<section id="part-04-summary" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="part-04-summary"><span class="header-section-number">5.5</span> Part 04 Summary</h2>
<p>åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚æˆ‘ä»¬è®¨è®ºäº†å‡ ç§å¸¸ç”¨çš„é‡‡æ ·æ–¹æ³•ï¼ŒåŒ…æ‹¬ Greedy Samplingã€Top-K Sampling å’Œ Top-P Samplingï¼Œå¹¶ä»‹ç»äº†å¦‚ä½•é€šè¿‡è°ƒæ•´ temperature æ¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚é€šè¿‡è¿™äº›æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–ä¸”æœ‰è¶£çš„æ–‡æœ¬å†…å®¹ã€‚</p>
<div>
<div id="tbl-sampling-methods" class="hover quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[20,40,20,20]">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-sampling-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table">
<colgroup>
<col style="width: 20%">
<col style="width: 40%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Sampling Method</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Pros</th>
<th style="text-align: center;">Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Greedy Sampling</td>
<td style="text-align: center;">é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ token</td>
<td style="text-align: center;">ç®€å•é«˜æ•ˆ</td>
<td style="text-align: center;">å¯èƒ½ç¼ºä¹å¤šæ ·æ€§ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜</td>
</tr>
<tr class="even">
<td style="text-align: left;">Top-K Sampling</td>
<td style="text-align: center;">ä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token ä¸­é‡‡æ ·, <strong>Kè¶Šå¤§å¤šæ ·æ€§è¶Šé«˜</strong></td>
<td style="text-align: center;">å¢åŠ å¤šæ ·æ€§</td>
<td style="text-align: center;">éœ€è¦é€‰æ‹©åˆé€‚çš„ K å€¼ï¼Œé€šå¸¸ K å€¼åœ¨ 10 åˆ° 50 ä¹‹é—´</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Top-P Sampling</td>
<td style="text-align: center;">ä»ç´¯è®¡æ¦‚ç‡è¾¾åˆ° P çš„ token é›†åˆä¸­é‡‡æ ·ï¼Œ<strong>Pè¶Šå¤§å¤šæ ·æ€§è¶Šé«˜</strong></td>
<td style="text-align: center;">åŠ¨æ€è°ƒæ•´å€™é€‰ token æ•°é‡</td>
<td style="text-align: center;">éœ€è¦é€‰æ‹©åˆé€‚çš„ P å€¼ï¼Œé€šå¸¸ P å€¼åœ¨ 0.8 åˆ° 0.9 ä¹‹é—´</td>
</tr>
<tr class="even">
<td style="text-align: left;">Temperature Adjustment</td>
<td style="text-align: center;">é€šè¿‡è°ƒæ•´ temperature æ§åˆ¶éšæœºæ€§ï¼Œ<strong>temperature è¶Šå¤§å¤šæ ·æ€§è¶Šé«˜</strong></td>
<td style="text-align: center;">çµæ´»æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§</td>
<td style="text-align: center;">éœ€è¦é€‰æ‹©åˆé€‚çš„ temperature å€¼ï¼Œ é€šå¸¸åœ¨ 0.7 åˆ° 1.0 ä¹‹é—´</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-sampling-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: æ€»ç»“ä¸åŒé‡‡æ ·æ–¹æ³•çš„ä¼˜ç¼ºç‚¹
</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="part-05-experiments" class="level1 page-columns page-full" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Part 05: Experiments</h1>
<p>ç»ˆäºï¼Œæˆ‘ä»¬å®Œæˆäº†æ¨¡å‹çš„è®­ç»ƒå’Œç”Ÿæˆéƒ¨åˆ†ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å®éªŒç»“æœã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªå°å‹çš„ GPT-like æ¨¡å‹ï¼Œæ¨¡å‹é…ç½®å¦‚ä¸‹ï¼š</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>cs336_basics/configs.py</strong></pre>
</div>
<div class="sourceCode" id="cb67" data-filename="cs336_basics/configs.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a><span class="at">@dataclass</span></span>
<span id="cb67-2"><a href="#cb67-2"></a><span class="kw">class</span> ModelConfig:</span>
<span id="cb67-3"><a href="#cb67-3"></a>    vocab_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb67-4"><a href="#cb67-4"></a>    max_seq_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb67-5"><a href="#cb67-5"></a></span>
<span id="cb67-6"><a href="#cb67-6"></a>    d_model: <span class="bu">int</span> <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb67-7"><a href="#cb67-7"></a>    d_ff: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1344</span></span>
<span id="cb67-8"><a href="#cb67-8"></a></span>
<span id="cb67-9"><a href="#cb67-9"></a>    num_heads: <span class="bu">int</span> <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb67-10"><a href="#cb67-10"></a>    num_layers: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb67-11"><a href="#cb67-11"></a></span>
<span id="cb67-12"><a href="#cb67-12"></a>    dropout: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb67-13"><a href="#cb67-13"></a></span>
<span id="cb67-14"><a href="#cb67-14"></a>    use_rms_norm: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb67-15"><a href="#cb67-15"></a>    pre_norm: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb67-16"><a href="#cb67-16"></a></span>
<span id="cb67-17"><a href="#cb67-17"></a>    <span class="co"># Special token IDs</span></span>
<span id="cb67-18"><a href="#cb67-18"></a>    eos_token_id: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb67-19"><a href="#cb67-19"></a></span>
<span id="cb67-20"><a href="#cb67-20"></a>    <span class="co"># RoPE</span></span>
<span id="cb67-21"><a href="#cb67-21"></a>    use_rope: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb67-22"><a href="#cb67-22"></a>    rope_theta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">10000.0</span></span>
<span id="cb67-23"><a href="#cb67-23"></a></span>
<span id="cb67-24"><a href="#cb67-24"></a>    <span class="co"># Others</span></span>
<span id="cb67-25"><a href="#cb67-25"></a>    tie_weights: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb67-26"><a href="#cb67-26"></a>    use_final_norm: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb67-27"><a href="#cb67-27"></a></span>
<span id="cb67-28"><a href="#cb67-28"></a><span class="at">@dataclass</span></span>
<span id="cb67-29"><a href="#cb67-29"></a><span class="kw">class</span> TrainingConfig:</span>
<span id="cb67-30"><a href="#cb67-30"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb67-31"><a href="#cb67-31"></a>    num_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10_000</span></span>
<span id="cb67-32"><a href="#cb67-32"></a>    dataset_dir: <span class="bu">str</span> <span class="op">=</span> <span class="st">"datasets/tiny_stories"</span></span>
<span id="cb67-33"><a href="#cb67-33"></a>    train_data_path: <span class="bu">str</span> <span class="op">=</span> <span class="st">"datasets/tiny_stories/train.bin"</span></span>
<span id="cb67-34"><a href="#cb67-34"></a>    eval_data_path: <span class="bu">str</span> <span class="op">=</span> <span class="st">"datasets/tiny_stories/eval.bin"</span></span>
<span id="cb67-35"><a href="#cb67-35"></a></span>
<span id="cb67-36"><a href="#cb67-36"></a>    <span class="co"># Optimizer related parameters</span></span>
<span id="cb67-37"><a href="#cb67-37"></a>    betas: <span class="bu">tuple</span> <span class="op">=</span> field(default<span class="op">=</span>(<span class="fl">0.9</span>, <span class="fl">0.98</span>))</span>
<span id="cb67-38"><a href="#cb67-38"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb67-39"><a href="#cb67-39"></a>    max_lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">3e-4</span></span>
<span id="cb67-40"><a href="#cb67-40"></a>    min_lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb67-41"><a href="#cb67-41"></a>    warmup_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb67-42"><a href="#cb67-42"></a>    max_grad_norm: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb67-43"><a href="#cb67-43"></a></span>
<span id="cb67-44"><a href="#cb67-44"></a>    <span class="co"># Logging &amp; checkpointing</span></span>
<span id="cb67-45"><a href="#cb67-45"></a>    wandb_logging: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb67-46"><a href="#cb67-46"></a>    eval_log_interval: <span class="bu">int</span> <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb67-47"><a href="#cb67-47"></a>    sampling_log_interval: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb67-48"><a href="#cb67-48"></a></span>
<span id="cb67-49"><a href="#cb67-49"></a>    <span class="co"># Others:</span></span>
<span id="cb67-50"><a href="#cb67-50"></a>    model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">"tiny_stories_transformer"</span></span>
<span id="cb67-51"><a href="#cb67-51"></a>    save_checkpoint_dir: <span class="bu">str</span> <span class="op">=</span> <span class="st">"checkpoints"</span></span>
<span id="cb67-52"><a href="#cb67-52"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb67-53"><a href="#cb67-53"></a>    debug_mode: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb67-54"><a href="#cb67-54"></a>    use_mixed_precision: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb67-55"><a href="#cb67-55"></a>    seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2025</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªH100 GPUè¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒäº†10Kæ­¥ï¼ŒBatch Sizeä¸º256ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è®­ç»ƒç»“æœã€‚</p>
<section id="plots" class="level2 page-columns page-full" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="plots"><span class="header-section-number">6.1</span> Plots</h2>
<div class="column-page">
<div id="fig-learning-curve" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-learning-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/train_loss.png" class="img-fluid figure-img"></p>
<figcaption>Training Loss</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/Train_Perplexity.png" class="img-fluid figure-img"></p>
<figcaption>Training Perplexity</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/eval_loss.png" class="img-fluid figure-img"></p>
<figcaption>Evaluation Loss</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/eval_perp.png" class="img-fluid figure-img"></p>
<figcaption>Evaluation Perplexity</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-learning-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Loss å’Œ Perplexity æ›²çº¿æ˜¾ç¤º
</figcaption>
</figure>
</div>
</div>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å®Œæˆäº†10Kæ­¥çš„è®­ç»ƒä¹‹åï¼Œæ¨¡å‹çš„è®­ç»ƒæŸå¤±å’Œè¯„ä¼°æŸå¤±éƒ½æœ‰äº†æ˜æ˜¾çš„ä¸‹é™ï¼Œå›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ä¹Ÿæœ‰äº†æ˜¾è‘—çš„æå‡ã€‚è¿™è¡¨æ˜æ¨¡å‹å·²ç»å­¦ä¼šäº†ä¸€äº›è¯­è¨€æ¨¡å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚æœ€åçš„ç»“æœï¼š</p>
<div class="sourceCode" id="cb68" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb68-1"><a href="#cb68-1"></a>eval/loss:0.7857699394226074</span>
<span id="cb68-2"><a href="#cb68-2"></a>eval/perplexity:2.194427490234375</span>
<span id="cb68-3"><a href="#cb68-3"></a>train/loss:0.7850267291069031</span>
<span id="cb68-4"><a href="#cb68-4"></a>train/perplexity:2.192465543746948</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š</p>
<div id="fig-generated-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generated-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/generated-text.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generated-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: ç”Ÿæˆæ–‡æœ¬ç¤ºä¾‹, prompt=â€œOnce upon a timeâ€, <code>max_new_tokens</code>=256, <code>top_k</code>=50, <code>temperature</code>=0.8
</figcaption>
</figure>
</div>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç”Ÿæˆçš„å¥å­ï¼Œæœ‰ä¸€å®šçš„è¿è´¯æ€§ï¼Œ ä½†æ˜¯æ•…äº‹å¹¶ä¸æ˜¯å®Œæ•´çš„ï¼Œä¸”æœ‰ä¸€å®šçš„é€»è¾‘æ··ä¹±ã€‚è¿™æ˜¯å› ä¸ºæ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œè®­ç»ƒæ­¥æ•°æœ‰é™ï¼Œæ— æ³•å®Œå…¨æ•æ‰åˆ°å¤æ‚çš„è¯­è¨€ç»“æ„å’Œæ•…äº‹æƒ…èŠ‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹å‡ ç§æ–¹å¼æ¥æå‡ç”Ÿæˆæ•ˆæœï¼š</p>
<ol type="1">
<li>å¢åŠ è®­ç»ƒçš„stepsï¼šç°åœ¨æ˜¯10Kï¼Œå¦‚æœå¢åŠ åˆ°15Kï¼Œ20Kï¼Œæ•ˆæœåº”è¯¥ä¼šæ›´å¥½</li>
<li>å¢å¤§Batch Sizeï¼šç›¸å¯¹çš„æ¥è¯´ï¼ŒBatch Sizeè¶Šå¤§ï¼ŒNoiseå°±è¶Šå°ï¼Œè®­ç»ƒå°±æ›´åŠ ç¨³å½“</li>
<li>å¢åŠ Context Lengthï¼šå½“å‰çš„Context Lengthæ˜¯256ï¼Œå°†å…¶å¢å¤§åˆ°512ï¼Œæˆ–è€…æ›´å¤§ï¼Œå¯ä»¥è¦†ç›–ä¸€ä¸ªæ•´ä¸ªå®Œæ•´çš„æ•…äº‹ç»“æ„ã€‚</li>
</ol>
</section>
</section>
<section id="summary" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Summary</h1>
<p>æ­å–œå¤§å®¶ğŸ‰ğŸ‰ï¼ï¼ç»è¿‡ä¸æ‡ˆçš„åŠªåŠ›ï¼Œç»ˆäºå®Œæˆäº†è¿™ä¸ªAssignmentï¼Œåœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬äº†è§£ä»€ä¹ˆæ˜¯BPE Tokenizerï¼ŒTransformer Language Model çš„æ¶æ„ï¼ŒLMçš„è®­ç»ƒæµç¨‹ï¼Œä»¥åŠæˆåŠŸåœ¨æœ€åç”Ÿæˆäº†ä¸€æ®µè¿˜ä¸é”™çš„å°æ•…äº‹ï¼Œç»™è‡ªå·±é¼“æŒğŸ‘ğŸ‘ï¼ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬çš„æ—…ç¨‹æ‰åˆšåˆšå¼€å§‹ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è¦ä¸æ–­çš„ä¼˜åŒ–è¿™ä¸ªLanguage Modelã€‚æ¯”å¦‚:</p>
<ul>
<li>Flash Attentionçš„å®ç°ï¼Œå¯ä»¥è®©LMåœ¨ä¸€ä¸ªGPUä¸­è·‘çš„æ›´å¿«ï¼Œ</li>
<li>Parallelismå¯ä»¥è®©LMç”¨å¤šæ¡è…¿è·‘æ­¥</li>
<li>å¹¶ä¸”æˆ‘ä»¬è¿˜ä¼šäº†è§£ä¸åŒçš„Evaluationçš„æ–¹æ³•ç­‰ã€‚</li>
</ul>
<p>ä½†æ˜¯ï¼Œç›®å‰ä¸ºæ­¢ï¼Œå·²ç»åšçš„å¾ˆå¥½äº†ï¼Œè¯·åšæŒä¸‹å»ã€‚</p>
</section>
<section id="in-the-end" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> In the End</h1>
<p>æœ€åï¼Œæ„Ÿè°¢ä½ ä¸€è·¯åšæŒåˆ°è¿™é‡Œï¼åˆ›ä½œä¸æ˜“ï¼Œå¦‚æœä½ è§‰å¾—å†…å®¹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿è¯·æˆ‘<strong>å–æ¯å’–å•¡/æ”¯ä»˜å®çº¢åŒ…</strong>ï¼Œæ”¯æŒæˆ‘ç»§ç»­åˆ›ä½œï¼ä½ ä»¬çš„æ”¯æŒæ˜¯æˆ‘æœ€å¤§çš„åŠ¨åŠ›ï¼ :) <br></p>
<p><img src="../../../style/AliPay.jpg" class="img-fluid" width="300"></p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-DecoupledWeightDecay2019loshchilov" class="csl-entry" role="listitem">
Loshchilov, Ilya, and Frank Hutter. 2019. <span>â€œDecoupled <span>Weight Decay Regularization</span>.â€</span> January 4, 2019. <a href="https://doi.org/10.48550/arXiv.1711.05101">https://doi.org/10.48550/arXiv.1711.05101</a>.
</div>
<div id="ref-NeuralMachineTranslation2016sennrich" class="csl-entry" role="listitem">
Sennrich, Rico, Barry Haddow, and Alexandra Birch. 2016. <span>â€œNeural <span>Machine Translation</span> of <span>Rare Words</span> with <span>Subword Units</span>.â€</span> June 10, 2016. <a href="https://doi.org/10.48550/arXiv.1508.07909">https://doi.org/10.48550/arXiv.1508.07909</a>.
</div>
<div id="ref-GLUVariantsImprove2020shazeer" class="csl-entry" role="listitem">
Shazeer, Noam. 2020. <span>â€œ<span>GLU Variants Improve Transformer</span>.â€</span> February 12, 2020. <a href="https://doi.org/10.48550/arXiv.2002.05202">https://doi.org/10.48550/arXiv.2002.05202</a>.
</div>
<div id="ref-RoFormerEnhancedTransformer2023su" class="csl-entry" role="listitem">
Su, Jianlin, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. 2023. <span>â€œ<span>RoFormer</span>: <span>Enhanced Transformer</span> with <span>Rotary Position Embedding</span>.â€</span> November 8, 2023. <a href="https://doi.org/10.48550/arXiv.2104.09864">https://doi.org/10.48550/arXiv.2104.09864</a>.
</div>
<div id="ref-AttentionAllYou2023vaswani" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. <span>â€œAttention <span>Is All You Need</span>.â€</span> August 2, 2023. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>.
</div>
<div id="ref-RootMeanSquare2019zhang" class="csl-entry" role="listitem">
Zhang, Biao, and Rico Sennrich. 2019. <span>â€œRoot <span>Mean Square Layer Normalization</span>.â€</span> October 16, 2019. <a href="https://doi.org/10.48550/arXiv.1910.07467">https://doi.org/10.48550/arXiv.1910.07467</a>.
</div>
<div id="ref-HybridNormStableEfficient2025zhuo" class="csl-entry" role="listitem">
Zhuo, Zhijian, Yutao Zeng, Ya Wang, Sijun Zhang, Jian Yang, Xiaoqing Li, Xun Zhou, and Jinwen Ma. 2025. <span>â€œ<span>HybridNorm</span>: <span>Towards Stable</span> and <span>Efficient Transformer Training</span> via <span>Hybrid Normalization</span>.â€</span> December 8, 2025. <a href="https://doi.org/10.48550/arXiv.2503.04598">https://doi.org/10.48550/arXiv.2503.04598</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/sta210-s22\.github\.io\/website\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark_dimmed">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "YYZhang2025/YYZhang2025.github.io";
    script.dataset.repoId = "R_kgDOQlDTcQ";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOQlDTcc4C2MRz";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../posts/CS336/Lecture16&amp;17/lec16.html" class="pagination-link" aria-label="Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../posts/CS336/Ass02/ass02.html" class="pagination-link" aria-label="Assignment 02: Flash Attention &amp; Parallelism">
        <span class="nav-page-text">Assignment 02: Flash Attention &amp; Parallelism</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Â© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with â¤ï¸ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize,
          commentDelimiter: el.dataset.commentDelimiter,
          lineNumber: el.dataset.lineNumber.toLowerCase() === "true",
          lineNumberPunc: el.dataset.lineNumberPunc,
          noEnd: el.dataset.noEnd.toLowerCase() === "true",
          titlePrefix: el.dataset.captionPrefix
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




<script src="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>