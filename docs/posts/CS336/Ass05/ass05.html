<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="在Assignment 05 我们将会实现SFT， Expert Iteration以及GRPO算法，对Qwen2.5-Math-1.5B模型进行微调，以提升其在MATH数据集上的表现。通过这些算法的实现，我们将深入理解LLM的对齐方法，并掌握如何应用这些技术来改进大型语言模型的性能。">

<title>Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO &amp; DPO – Learning Note</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c61ca1b0a9f27cb683675ea1929ac2e3.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-c0eab5a31fbea23c8affb95fb4fbb9c0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c61ca1b0a9f27cb683675ea1929ac2e3.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
<script>
    MathJax = {
        loader: {
        load: ['[tex]/boldsymbol']
        },
        tex: {
        tags: "all",
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true,
        packages: {
            '[+]': ['boldsymbol']
        }
        }
    };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script>
document.addEventListener("DOMContentLoaded", function () {
  document.querySelectorAll(".foldable-header").forEach(header => {
    header.addEventListener("click", () => {
      const block = header.closest(".foldable");
      if (block) {
        block.classList.toggle("is-open");
      }
    });

    // 可访问性（键盘）
    header.setAttribute("tabindex", "0");
    header.addEventListener("keydown", e => {
      if (e.key === "Enter" || e.key === " ") {
        e.preventDefault();
        header.click();
      }
    });
  });
});
</script>
    <style type="text/css">
    .ps-root .ps-algorithm {
      border-top: 2px solid;
      border-bottom: 2px solid;
    }
    .pseudocode-container {
      text-align: left;
    }
    </style>
  
      <style type="text/css">
      .ps-algorithm > .ps-line {
        text-align: left;
      }
      </style>
    

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO &amp; DPO</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/sta210-s22" title="GitHub organization" class="quarto-navigation-tool px-1" aria-label="GitHub organization"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Stanford CS336: LLM from Scratch</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture01/lec01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 01: Introduction &amp; BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture02/lec02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 02: PyTorch Basics &amp; Resource Accounts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture03/lec03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 03: Transformer LM Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture04/lec04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 04: MoE Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture05&amp;06/lec05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 05&amp;06: GPU Optimization, Triton &amp; FlashAttention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture07&amp;08/lec07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 07&amp;08: Parallelism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture9&amp;11/lec9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 09&amp;11: Scaling Laws</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture10/lec10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 10: Inference &amp; Deployment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture12/lec12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 12: Evaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture13&amp;14/lec13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 13&amp;14: Data Collection &amp; Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture15/lec15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture16&amp;17/lec16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">100 AI Papers</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/01-transformer/Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision Transformer</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#dataset-preparation-model-download" id="toc-dataset-preparation-model-download" class="nav-link active" data-scroll-target="#dataset-preparation-model-download"><span class="header-section-number">1</span> Dataset Preparation &amp; Model Download</a></li>
  <li><a href="#zero-shot-evaluation-vllm" id="toc-zero-shot-evaluation-vllm" class="nav-link" data-scroll-target="#zero-shot-evaluation-vllm"><span class="header-section-number">2</span> Zero-Shot Evaluation &amp; vLLM</a>
  <ul>
  <li><a href="#vllm" id="toc-vllm" class="nav-link" data-scroll-target="#vllm"><span class="header-section-number">2.1</span> vLLM</a></li>
  </ul></li>
  <li><a href="#supervised-fine-tuning" id="toc-supervised-fine-tuning" class="nav-link" data-scroll-target="#supervised-fine-tuning"><span class="header-section-number">3</span> Supervised Fine Tuning</a>
  <ul>
  <li><a href="#tokenize-prompt-and-output" id="toc-tokenize-prompt-and-output" class="nav-link" data-scroll-target="#tokenize-prompt-and-output"><span class="header-section-number">3.1</span> Tokenize Prompt and Output</a></li>
  <li><a href="#per-token-entropy" id="toc-per-token-entropy" class="nav-link" data-scroll-target="#per-token-entropy"><span class="header-section-number">3.2</span> Per Token Entropy</a></li>
  <li><a href="#getting-log-probs-from-model" id="toc-getting-log-probs-from-model" class="nav-link" data-scroll-target="#getting-log-probs-from-model"><span class="header-section-number">3.3</span> Getting Log Probs from Model</a></li>
  <li><a href="#masked-normalize" id="toc-masked-normalize" class="nav-link" data-scroll-target="#masked-normalize"><span class="header-section-number">3.4</span> Masked Normalize</a></li>
  <li><a href="#sft-micro-batch-training-step" id="toc-sft-micro-batch-training-step" class="nav-link" data-scroll-target="#sft-micro-batch-training-step"><span class="header-section-number">3.5</span> SFT Micro-batch Training Step</a></li>
  <li><a href="#sft-trainer" id="toc-sft-trainer" class="nav-link" data-scroll-target="#sft-trainer"><span class="header-section-number">3.6</span> SFT Trainer</a></li>
  <li><a href="#sft-experiment" id="toc-sft-experiment" class="nav-link" data-scroll-target="#sft-experiment"><span class="header-section-number">3.7</span> SFT Experiment</a></li>
  </ul></li>
  <li><a href="#expert-iteration" id="toc-expert-iteration" class="nav-link" data-scroll-target="#expert-iteration"><span class="header-section-number">4</span> Expert Iteration</a>
  <ul>
  <li><a href="#ei-experiment" id="toc-ei-experiment" class="nav-link" data-scroll-target="#ei-experiment"><span class="header-section-number">4.1</span> EI Experiment</a></li>
  </ul></li>
  <li><a href="#grpo" id="toc-grpo" class="nav-link" data-scroll-target="#grpo"><span class="header-section-number">5</span> GRPO</a>
  <ul>
  <li><a href="#grpo-experiment" id="toc-grpo-experiment" class="nav-link" data-scroll-target="#grpo-experiment"><span class="header-section-number">5.1</span> GRPO Experiment</a></li>
  <li><a href="#other-experiments" id="toc-other-experiments" class="nav-link" data-scroll-target="#other-experiments"><span class="header-section-number">5.2</span> Other Experiments</a>
  <ul>
  <li><a href="#learning-rate-tuning" id="toc-learning-rate-tuning" class="nav-link" data-scroll-target="#learning-rate-tuning"><span class="header-section-number">5.2.1</span> Learning Rate Tuning</a></li>
  <li><a href="#effect-of-baseline" id="toc-effect-of-baseline" class="nav-link" data-scroll-target="#effect-of-baseline"><span class="header-section-number">5.2.2</span> Effect of Baseline</a></li>
  <li><a href="#length-normalization" id="toc-length-normalization" class="nav-link" data-scroll-target="#length-normalization"><span class="header-section-number">5.2.3</span> Length Normalization</a></li>
  <li><a href="#normalization-with-group-std" id="toc-normalization-with-group-std" class="nav-link" data-scroll-target="#normalization-with-group-std"><span class="header-section-number">5.2.4</span> Normalization with group std</a></li>
  <li><a href="#off-policy-vs.-on-policy" id="toc-off-policy-vs.-on-policy" class="nav-link" data-scroll-target="#off-policy-vs.-on-policy"><span class="header-section-number">5.2.5</span> Off-Policy vs.&nbsp;On-Policy</a></li>
  <li><a href="#off-policy-clipping" id="toc-off-policy-clipping" class="nav-link" data-scroll-target="#off-policy-clipping"><span class="header-section-number">5.2.6</span> Off Policy Clipping</a></li>
  <li><a href="#different-prompts" id="toc-different-prompts" class="nav-link" data-scroll-target="#different-prompts"><span class="header-section-number">5.2.7</span> Different Prompts</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#dpo" id="toc-dpo" class="nav-link" data-scroll-target="#dpo"><span class="header-section-number">6</span> DPO</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO &amp; DPO</h1>
</div>

<div>
  <div class="description">
    在Assignment 05 我们将会实现SFT， Expert Iteration以及GRPO算法，对Qwen2.5-Math-1.5B模型进行微调，以提升其在MATH数据集上的表现。通过这些算法的实现，我们将深入理解LLM的对齐方法，并掌握如何应用这些技术来改进大型语言模型的性能。
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="dataset-preparation-model-download" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Dataset Preparation &amp; Model Download</h1>
<div class="tldr foldable is-open">
<div class="tldr-header foldable-header">
<p>TL;DR: 快速版</p>
</div>
<div class="tldr-container foldable-content">
<p>只需将运行以下命令，We are ready to GO！！！</p>
<p>下载代码</p>
<div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">git</span> clone https://github.com/YYZhang2025/Stanford-CS336.git</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="bu">cd</span> Stanford-CS336/assignment5-alignment</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>安装依赖，下载数据集和模型</p>
<div class="sourceCode" id="cb2" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="ex">pip</span> install uv </span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="ex">uv</span> sync <span class="at">--no-install-package</span> flash-attn</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="ex">uv</span> sync</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="bu">source</span> .venv/bin/activate</span>
<span id="cb2-5"><a href="#cb2-5"></a></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="ex">hf</span> download YuYangZhang/Reasoning-Dataset  <span class="at">--repo-type</span> dataset <span class="at">--local-dir</span> data</span>
<span id="cb2-7"><a href="#cb2-7"></a></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="ex">python</span> download_model.py <span class="dt">\</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>  <span class="at">--repo-id</span> Qwen/Qwen2.5-Math-1.5B <span class="dt">\</span></span>
<span id="cb2-10"><a href="#cb2-10"></a>  <span class="at">--save-dir</span> models/Qwen2.5-Math-1.5B <span class="dt">\</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>  <span class="at">--method</span> snapshot <span class="at">--no-symlinks</span> <span class="at">--verify</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>我们先来下载模型权重，只需一个命令：</p>
<div class="sourceCode" id="cb3" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="ex">python</span> download_model.py <span class="dt">\</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>  <span class="at">--repo-id</span> Qwen/Qwen2.5-Math-1.5B <span class="dt">\</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  <span class="at">--save-dir</span> models/Qwen2.5-Math-1.5B <span class="dt">\</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>  <span class="at">--method</span> snapshot <span class="at">--no-symlinks</span> <span class="at">--verify</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>通过上面的命令，我们就可以把Qwen2.5-Math-1.5B模型下载到<code>models/Qwen2.5-Math-1.5B</code>目录下。</p>
<hr>
<p>在这个Assignment中，我们将会用到Math Dataset，不过Assignment中，由于版权问题，并没有提供完整的数据，因此我们需要自行下载数据集，在这个Assignment中，我们主要会用到以下两个数据集：</p>
<ul>
<li><strong>GSM8K Dataset</strong>：一个包含8,500多个高中水平数学问题的数据集，专注于逐步推理和解决方案生成。（这个数据集在Assignment中已经提供 <code>data/gsm8k</code>）</li>
<li><strong>MATH Dataset</strong>: 这个数据集包含12,500多个高中和大学水平的数学问题，涵盖多个主题和难度级别 <a href="https://huggingface.co/datasets/nlile/hendrycks-MATH-benchmark">Link</a>。</li>
</ul>
<p>我们现在下载MATH:</p>
<div class="sourceCode" id="cb4" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">hf</span> download nlile/hendrycks-MATH-benchmark <span class="dt">\</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span class="at">--repo-type</span> dataset <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span class="at">--local-dir</span> ./data/hendrycks-MATH-benchmark</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="fu">mv</span> ./data/hendrycks-MATH-benchmark  ./data/math</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>接下来，我们来预处理一下这些数据集，因为不同的数据集格式不一样，我们需要把他们处理成统一的格式， 以便我们后续的训练。先来看<code>GSM8K</code>数据集的格式：</p>
<div class="sourceCode" id="cb5" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1"></a><span class="fu">{</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span class="dt">"question"</span><span class="fu">:</span> <span class="st">"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?"</span><span class="fu">,</span> </span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span class="dt">"answer"</span><span class="fu">:</span> <span class="st">"Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.</span><span class="ch">\n</span><span class="st">Natalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.</span><span class="ch">\n</span><span class="st">#### 72"</span><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>每个样本包含 <code>question</code> 和 <code>answer</code> 两个字段，我们需要把他们处理成 <code>prompt</code> 和 <code>cot</code> 的格式，并且提取出里面的答案：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/dataset_utils/gsm8k.py</strong></pre>
</div>
<div class="sourceCode" id="cb6" data-filename="assignment5-alignment/cs336_alignment/dataset_utils/gsm8k.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">def</span> extract_gsm8k_answer(answer: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb6-2"><a href="#cb6-2"></a>    ANS_RE <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r"####</span><span class="dv">\s</span><span class="op">*</span><span class="kw">(</span><span class="pp">[</span><span class="ch">\-</span><span class="pp">0-9</span><span class="ch">\.\,</span><span class="pp">]</span><span class="op">+</span><span class="kw">)</span><span class="vs">"</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a>    match <span class="op">=</span> ANS_RE.search(answer)</span>
<span id="cb6-4"><a href="#cb6-4"></a>    <span class="cf">if</span> match:</span>
<span id="cb6-5"><a href="#cb6-5"></a>        <span class="cf">return</span> match.group(<span class="dv">1</span>).strip().replace(<span class="st">","</span>, <span class="st">""</span>)</span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span class="cf">return</span> <span class="st">"[invalid]"</span></span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a></span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="kw">def</span> process_row(row: Dict[<span class="bu">str</span>, Any]):</span>
<span id="cb6-10"><a href="#cb6-10"></a>    problem <span class="op">=</span> row[<span class="st">"question"</span>]</span>
<span id="cb6-11"><a href="#cb6-11"></a>    cot <span class="op">=</span> row[<span class="st">"answer"</span>]</span>
<span id="cb6-12"><a href="#cb6-12"></a>    clean_cot <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">*</span><span class="ch">\n</span><span class="vs">####</span><span class="dv">\s</span><span class="op">*</span><span class="vs">-</span><span class="op">?</span><span class="dv">\d</span><span class="op">+</span>(?:<span class="ch">\.</span><span class="dv">\d</span><span class="op">+</span>)<span class="op">?</span><span class="dv">\s</span><span class="op">*</span><span class="dv">$</span><span class="vs">"</span>, <span class="st">""</span>, cot)</span>
<span id="cb6-13"><a href="#cb6-13"></a>    answer <span class="op">=</span> extract_gsm8k_answer(row[<span class="st">"answer"</span>])</span>
<span id="cb6-14"><a href="#cb6-14"></a></span>
<span id="cb6-15"><a href="#cb6-15"></a>    clean_cot <span class="op">=</span> wrap_cot_with_answer(clean_cot, answer)</span>
<span id="cb6-16"><a href="#cb6-16"></a></span>
<span id="cb6-17"><a href="#cb6-17"></a>    <span class="cf">return</span> problem, <span class="bu">str</span>(clean_cot), <span class="bu">str</span>(answer).lower() <span class="cf">if</span> answer <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>在预处理之后，我们会把数据集处理成下面的格式：</p>
<div class="sourceCode" id="cb7" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1"></a><span class="fu">{</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>  <span class="dt">"question"</span><span class="fu">:</span> <span class="st">"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?"</span><span class="fu">,</span> </span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span class="dt">"cot"</span><span class="fu">:</span> <span class="st">"Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.</span><span class="ch">\n</span><span class="st">Natalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.</span><span class="ch">\n</span><span class="st">&lt;/think&gt; &lt;answer&gt;72&lt;/answer&gt;"</span><span class="fu">,</span> </span>
<span id="cb7-4"><a href="#cb7-4"></a>  <span class="dt">"answer"</span><span class="fu">:</span> <span class="st">"72"</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>类似地，我们也需要对MATH数据集进行预处理，MATH数据集的格式如下：</p>
<div class="sourceCode" id="cb8" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1"></a><span class="fu">{</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>  <span class="dt">"problem"</span><span class="fu">:</span> <span class="st">"How many vertical asymptotes does the graph of $y=</span><span class="ch">\\</span><span class="st">frac{2}{x^2+x-6}$ have?"</span><span class="fu">,</span> </span>
<span id="cb8-3"><a href="#cb8-3"></a>  <span class="dt">"solution"</span><span class="fu">:</span> <span class="st">"The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $</span><span class="ch">\\</span><span class="st">boxed{2}$ vertical asymptotes."</span><span class="fu">,</span> </span>
<span id="cb8-4"><a href="#cb8-4"></a>  <span class="dt">"answer"</span><span class="fu">:</span> <span class="st">"2"</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/dataset_utils/math.py</strong></pre>
</div>
<div class="sourceCode" id="cb9" data-filename="assignment5-alignment/cs336_alignment/dataset_utils/math.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">def</span> process_row(row: Dict[<span class="bu">str</span>, Any]):</span>
<span id="cb9-2"><a href="#cb9-2"></a>    problem <span class="op">=</span> row[<span class="st">"problem"</span>]</span>
<span id="cb9-3"><a href="#cb9-3"></a>    cot <span class="op">=</span> row[<span class="st">"solution"</span>]</span>
<span id="cb9-4"><a href="#cb9-4"></a></span>
<span id="cb9-5"><a href="#cb9-5"></a>    <span class="cf">if</span> row[<span class="st">"answer"</span>] <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb9-6"><a href="#cb9-6"></a>        answer <span class="op">=</span> extract_final_answer_from_text(cot)</span>
<span id="cb9-7"><a href="#cb9-7"></a>    <span class="cf">else</span>:</span>
<span id="cb9-8"><a href="#cb9-8"></a>        answer <span class="op">=</span> row[<span class="st">"answer"</span>]</span>
<span id="cb9-9"><a href="#cb9-9"></a>        cot <span class="op">=</span> wrap_cot_with_answer(cot, answer)</span>
<span id="cb9-10"><a href="#cb9-10"></a></span>
<span id="cb9-11"><a href="#cb9-11"></a>    <span class="cf">return</span> problem, <span class="bu">str</span>(cot), <span class="bu">str</span>(answer).lower() <span class="cf">if</span> answer <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>在处理之后，我们会把MATH数据集处理成下面的格式：</p>
<div class="sourceCode" id="cb10" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1"></a><span class="fu">{</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>  <span class="dt">"question"</span><span class="fu">:</span> <span class="st">"How many vertical asymptotes does the graph of $y=</span><span class="ch">\\</span><span class="st">frac{2}{x^2+x-6}$ have?"</span><span class="fu">,</span> </span>
<span id="cb10-3"><a href="#cb10-3"></a>  <span class="dt">"cot"</span><span class="fu">:</span> <span class="st">"The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $</span><span class="ch">\\</span><span class="st">boxed{2}$ vertical asymptotes.</span><span class="ch">\n</span><span class="st">&lt;/think&gt; &lt;answer&gt;2&lt;/answer&gt;"</span><span class="fu">,</span> </span>
<span id="cb10-4"><a href="#cb10-4"></a>  <span class="dt">"answer"</span><span class="fu">:</span> <span class="st">"2"</span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>具体的细节，看<code>assignment5-alignment/cs336_alignment/dataset_utils</code> 文件夹下的代码。以及 <code>assignment5-alignment/preprocess.py</code> 这个脚本。在这里就不赘述了。处理完之后，我们会有：</p>
<div class="sourceCode" id="cb11" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb11-1"><a href="#cb11-1"></a>data/</span>
<span id="cb11-2"><a href="#cb11-2"></a>├── alpaca_eval/</span>
<span id="cb11-3"><a href="#cb11-3"></a>├── gsm8k/</span>
<span id="cb11-4"><a href="#cb11-4"></a>├── math/</span>
<span id="cb11-5"><a href="#cb11-5"></a>├── mmlu/</span>
<span id="cb11-6"><a href="#cb11-6"></a>├── pre-processed/</span>
<span id="cb11-7"><a href="#cb11-7"></a>│   ├── gsm8k/</span>
<span id="cb11-8"><a href="#cb11-8"></a>│   │   ├── test.jsonl</span>
<span id="cb11-9"><a href="#cb11-9"></a>│   │   └── train.jsonl</span>
<span id="cb11-10"><a href="#cb11-10"></a>│   └── math/</span>
<span id="cb11-11"><a href="#cb11-11"></a>│       ├── test.jsonl</span>
<span id="cb11-12"><a href="#cb11-12"></a>│       └── train.jsonl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>当然，大家也可以选择直接使用我已经处理好的数据集， 直接从<a href="https://huggingface.co/datasets/YuYangZhang/Reasoning-Dataset">这里</a>下载即可。或者使用下面的命令：</p>
<div class="sourceCode" id="cb12" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1"></a><span class="ex">hf</span> download YuYangZhang/Reasoning-Dataset  <span class="at">--repo-type</span> dataset <span class="at">--local-dir</span> data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="zero-shot-evaluation-vllm" class="level1 page-columns page-full" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Zero-Shot Evaluation &amp; vLLM</h1>
<section id="vllm" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="vllm"><span class="header-section-number">2.1</span> vLLM</h2>
<p>在这个Assignment中，我们会使用vLLM 来进行模型的推理， 以便我们可以更快的进行评估和训练。 以下几个方法：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/vllm_utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb13" data-filename="assignment5-alignment/cs336_alignment/vllm_utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">def</span> init_vllm(model_id: <span class="bu">str</span>, device: <span class="bu">str</span>, seed: <span class="bu">int</span>, gpu_memory_utilization: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.85</span>):</span>
<span id="cb13-2"><a href="#cb13-2"></a>    vllm_set_random_seed(seed)</span>
<span id="cb13-3"><a href="#cb13-3"></a>    world_size_patch <span class="op">=</span> patch(<span class="st">"torch.distributed.get_world_size"</span>, return_value<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a>    profiling_patch <span class="op">=</span> patch(</span>
<span id="cb13-5"><a href="#cb13-5"></a>        <span class="st">"vllm.worker.worker.Worker._assert_memory_footprint_increased_during_profiling"</span>, return_value<span class="op">=</span><span class="va">None</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>    )</span>
<span id="cb13-7"><a href="#cb13-7"></a>    <span class="cf">with</span> world_size_patch, profiling_patch:</span>
<span id="cb13-8"><a href="#cb13-8"></a>        <span class="cf">return</span> LLM(</span>
<span id="cb13-9"><a href="#cb13-9"></a>            model<span class="op">=</span>model_id,</span>
<span id="cb13-10"><a href="#cb13-10"></a>            device<span class="op">=</span>device,</span>
<span id="cb13-11"><a href="#cb13-11"></a>            dtype<span class="op">=</span>torch.bfloat16,</span>
<span id="cb13-12"><a href="#cb13-12"></a>            enable_prefix_caching<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-13"><a href="#cb13-13"></a>            gpu_memory_utilization<span class="op">=</span>gpu_memory_utilization,</span>
<span id="cb13-14"><a href="#cb13-14"></a>        )</span>
<span id="cb13-15"><a href="#cb13-15"></a></span>
<span id="cb13-16"><a href="#cb13-16"></a><span class="kw">def</span> load_policy_into_vllm_instance(policy: PreTrainedModel, llm: LLM):</span>
<span id="cb13-17"><a href="#cb13-17"></a>    state_dict <span class="op">=</span> policy.state_dict()</span>
<span id="cb13-18"><a href="#cb13-18"></a>    llm_model <span class="op">=</span> llm.llm_engine.model_executor.driver_worker.model_runner.model</span>
<span id="cb13-19"><a href="#cb13-19"></a>    llm_model.load_weights(state_dict.items())</span>
<span id="cb13-20"><a href="#cb13-20"></a>  </span>
<span id="cb13-21"><a href="#cb13-21"></a><span class="kw">def</span> generate_responses(vllm: LLM, prompts: <span class="bu">list</span>[<span class="bu">str</span>], sampling_params) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">str</span>]:</span>
<span id="cb13-22"><a href="#cb13-22"></a>    outputs <span class="op">=</span> vllm.generate(</span>
<span id="cb13-23"><a href="#cb13-23"></a>        prompts,</span>
<span id="cb13-24"><a href="#cb13-24"></a>        sampling_params<span class="op">=</span>sampling_params,</span>
<span id="cb13-25"><a href="#cb13-25"></a>    )</span>
<span id="cb13-26"><a href="#cb13-26"></a>    responses <span class="op">=</span> [output.outputs[<span class="dv">0</span>].text <span class="cf">for</span> output <span class="kw">in</span> outputs]</span>
<span id="cb13-27"><a href="#cb13-27"></a>    <span class="cf">return</span> responses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>当我们需要使用vLLM进行推理时，我们只需要先初始化vLLM实例， 之后把模型权重load进去， 最后调用<code>generate_responses</code>函数即可完成推理：</p>
<div class="sourceCode" id="cb14" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>vllm <span class="op">=</span> init_vllm(</span>
<span id="cb14-2"><a href="#cb14-2"></a>    model_id<span class="op">=</span>MODEL_NAME,</span>
<span id="cb14-3"><a href="#cb14-3"></a>    device<span class="op">=</span><span class="bu">str</span>(get_device(rank<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb14-4"><a href="#cb14-4"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb14-5"><a href="#cb14-5"></a>    gpu_memory_utilization<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb14-6"><a href="#cb14-6"></a>)</span>
<span id="cb14-7"><a href="#cb14-7"></a>sampling_params <span class="op">=</span> SamplingParams(</span>
<span id="cb14-8"><a href="#cb14-8"></a>    max_tokens<span class="op">=</span><span class="dv">1024</span>, temperature<span class="op">=</span><span class="dv">1</span>, top_p<span class="op">=</span><span class="dv">1</span>, stop<span class="op">=</span>[<span class="st">"&lt;/answer&gt;"</span>], include_stop_str_in_output<span class="op">=</span><span class="va">True</span></span>
<span id="cb14-9"><a href="#cb14-9"></a>)</span>
<span id="cb14-10"><a href="#cb14-10"></a>load_policy_into_vllm_instance(policy, vllm)</span>
<span id="cb14-11"><a href="#cb14-11"></a>responses <span class="op">=</span> generate_responses(</span>
<span id="cb14-12"><a href="#cb14-12"></a>    vllm,</span>
<span id="cb14-13"><a href="#cb14-13"></a>    prompts,</span>
<span id="cb14-14"><a href="#cb14-14"></a>    sampling_params<span class="op">=</span>sampling_params,</span>
<span id="cb14-15"><a href="#cb14-15"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>接下来，我们先来评估一下Qwen2.5-Math-1.5B在MATH和GSM8K数据集上的表现， 具体的评估代码在 <code>assignment5-alignment/eval.py</code> 以及 <code>assignment5-alignment/cs336_alignment/eval.py</code>， 运行下面的命令即可：</p>
<div class="sourceCode" id="cb15" data-code-line-numbers=""><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1"></a><span class="ex">python</span> eval.py  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>来看一下评估结果：</p>
<div class="column-page">
<div id="tbl-kl-mc-estimation" class="hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-kl-mc-estimation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table">
<colgroup>
<col style="width: 17%">
<col style="width: 5%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 26%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>dataset_path</th>
<th>total</th>
<th>answer_correct</th>
<th>format_correct</th>
<th>reward_1</th>
<th>formatted_but_answer_wrong</th>
<th>answer_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>math/train.jsonl</td>
<td>12000</td>
<td>359</td>
<td>2038</td>
<td>359</td>
<td>1679</td>
<td>0.029</td>
</tr>
<tr class="even">
<td>math/test.jsonl</td>
<td>500</td>
<td>13</td>
<td>77</td>
<td>13</td>
<td>64</td>
<td>0.026</td>
</tr>
<tr class="odd">
<td>gsm8k/train.jsonl</td>
<td>7473</td>
<td>232</td>
<td>1433</td>
<td>232</td>
<td>1201</td>
<td>0.031</td>
</tr>
<tr class="even">
<td>gsm8k/test.jsonl</td>
<td>1319</td>
<td>41</td>
<td>258</td>
<td>41</td>
<td>217</td>
<td>0.031</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-kl-mc-estimation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Qwen2.5-Math-1.5B Zero-Shot Evaluation Results on MATH and GSM8K Datasets
</figcaption>
</figure>
</div>
</div>
<p>可以看到，在<a href="https://en.wikipedia.org/wiki/Zero-shot_learning">Zero-Shot</a>的情况下，Qwen2.5-Math-1.5B在MATH和GSM8K数据集上的表现都非常差，只有大约2.6%到3.1%的准确率。这也符合预期，因为Qwen2.5-Math-1.5B虽然是一个强大的语言模型，但在没有经过专门微调的情况下，其在复杂数学问题上的表现仍然有限。</p>
</section>
</section>
<section id="supervised-fine-tuning" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Supervised Fine Tuning</h1>
<p>首先第一个算法就是Supervised Fine Tuning（SFT）。在 Alignment 训练里，SFT 往往被看作“第一阶段”：用人工标注的高质量数据，把 base model 从“会说话”推到“更像助理、更会按指令做事”。在Post-Training中主要起到一个 <span class="hilite-teal">warm-start</span> 的作用。为之后的Reinforcement Learning 算法做一个铺垫，这样做的主要目的有两个：</p>
<ol type="1">
<li>Warm-start：让模型先变“像助理”</li>
</ol>
<p>base model 可能会乱格式、跑题、答非所问。SFT 直接用示范数据教它： • 看到 prompt 该怎么组织输出 • 该不该写推理、怎么写 • 最终答案要放到 <answer> 里 这会显著提高 format correctness / instruction following，也是你评估表里最先能被拉起来的指标。</answer></p>
<ol start="2" type="1">
<li>稳定、样本效率高（比 RL 好训）</li>
</ol>
<p>SFT 就是最大似然/交叉熵，训练目标明确、梯度稳定、收敛更可控： • 不需要 reward model • 不需要 rollout、优势估计、clip/KL 等一堆超参 • 同样计算量下，通常比 RL 更“省事、省算力”</p>
<ol start="3" type="1">
<li>学会“正确的输出分布”，减少 RL 的探索难度</li>
</ol>
<p>RL 只给“好/不好”的信号（甚至只有最终对错），如果模型一开始输出很乱，RL 会非常难学、方差很大。 SFT 先把策略带到一个合理区域，RL 才更容易在此基础上做提升（例如提升正确率、减少啰嗦、对齐偏好）。</p>
<ol start="4" type="1">
<li>用 response_mask 只优化回答，不逼模型“背 prompt”</li>
</ol>
<p>你写的 response_mask 很关键：SFT 把 prompt 当条件，只在 response token 上算 loss： • 避免模型花 capacity 去重建 prompt • 训练信号更聚焦在“该怎么回答” 这在长 prompt/长上下文时特别重要。</p>
<ol start="5" type="1">
<li>提供“行为先验”，防止 RL 训练崩坏</li>
</ol>
<p>在 PPO/GRPO 里经常会担心 reward hacking、模式坍塌、输出退化。 SFT 提供一个强先验：即使 RL 更新过猛，KL/参考模型通常也把它拉回 SFT 附近，让训练更稳。</p>
<p>SFT的算法如下</p>
<div id="algo-sft" class="pseudocode-container quarto-float" data-no-end="false" data-comment-delimiter="#" data-caption-prefix="Algorithm" data-line-number-punc=":" data-pseudocode-number="1" data-line-number="true" data-indent-size="1.2em">
<div class="pseudocode">
\begin{algorithm} \caption{Supervised Fine-Tuning (SFT)} \begin{algorithmic} \Require Initial policy model $\pi_{\theta_{\text{init}}}$ \Require SFT dataset $\mathcal{D}$ (prompt–response pairs) \Require Number of SFT steps $n_{\text{sft\_steps}}$ \Require Learning rate $\alpha$ \State $\pi_{\theta} \gets \pi_{\theta_{\text{init}}}$ \For{$\text{step} = 1$ \textbf{to} $n_{\text{sft\_steps}}$} \State Sample a minibatch $\mathcal{D}_b = \{(x_j, y_j)\}_{j=1}^{B}$ from $\mathcal{D}$ \Comment{$x$: prompt/question, $y$: target response} \State $\mathcal{L}_{\text{CE}}(\theta) \gets -\mathbb{E}_{(x,y)\sim \mathcal{D}_b}\left[\sum_{t=1}^{|y|}\log \pi_{\theta}(y_t \mid x, y_{&lt;t})\right]$ \Comment{Teacher-forcing cross-entropy / NLL} \State $\theta \gets \theta - \alpha \nabla_{\theta}\mathcal{L}_{\text{CE}}(\theta)$ \EndFor \State \Return $\pi_{\theta}$ \end{algorithmic} \end{algorithm}
</div>
</div>
<p>其实，SFT 可以视作一个<strong>Imitation Learning</strong>，其过程就是</p>
<ol type="1">
<li>给定一个Prompt <span class="math inline">\(P\)</span>， 以及一个对应的Response <span class="math inline">\(R\)</span>，</li>
<li>将Prompt传入模型，我们希望可以模型可以根据这个Prompt， 来生成出与对应Response 一样的回答。</li>
</ol>
<p>这个也就是用过 Maximize Likelihood 来学习，也就是最小化Loss Function，在这个情景中，也就是 Cross Entropy Loss。 <span id="eq-sft-loss"><span class="math display">\[
\mathcal{L}_{\text{SFT}}(\theta) = - \sum_{t=1}^{|R|} \log p_\theta(R_t \mid P, R_{&lt;t})
\tag{1}\]</span></span></p>
<p>接下来，让我们先定义一些helper 函数，来帮我们完成这一系列：</p>
<section id="tokenize-prompt-and-output" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="tokenize-prompt-and-output"><span class="header-section-number">3.1</span> Tokenize Prompt and Output</h2>
<p>首先我们要定义的第一个函数就是 <code>tokenize_prompt_and_output()</code>, 它的作用，顾名思义，就是接收一系列的prompts，和 Response，并且tokenize他们，并且返回他们的ids。不过，需要注意的一点，也是很重要的一点就是，<span class="hilite-pink">我们要同时返回Response Mask</span>。 我们先来看看这个Response Mask的作用是什么：</p>
<hr>
<p>假如我们有一个 <span class="math inline">\(q\)</span> 和 <span class="math inline">\(o\)</span>, 我们将它并在一起，得到了我们的函数 <span class="math inline">\([q, o ]\)</span>, 我们将整段传入Model，在没有Response Mask的情况下，模型就是对所有的token计算loss，这样模型就会被迫去预测：</p>
<ol type="1">
<li>prompt 里的下一个 token（本质是在“复述/重建 prompt”）</li>
<li>output 里的 token（这才是我们真正关心的）</li>
</ol>
<p>但是在SFT训练的阶段， prompt 是输入条件，我们并不希望优化模型去“背 prompt 的分布”，只希望它在给定 prompt 后生成正确输出。所以用 response_mask 把 loss 限定在 output token 上： <span class="hilite-pink">训练信号只来自回答部分</span>。当然，除此之外，Response Mask还对应着pad tokens 举个直观的例子：</p>
<p>假设输入是：</p>
<ul>
<li>q: “2+2=?”</li>
<li>o: “4”</li>
</ul>
<p>拼接后 token 序列是：<code>[q_tokens][o_tokens][pad...]</code></p>
<p>response_mask 会像这样：</p>
<ul>
<li>q_tokens → False False False …</li>
<li>o_tokens → True True …</li>
<li>pad → False False …</li>
</ul>
<div class="sourceCode" id="cb16" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb16-1"><a href="#cb16-1"></a>Tokens:        [ 2 , + , 2 , = , ? , 4 , &lt;pad&gt; , &lt;pad&gt; ]</span>
<span id="cb16-2"><a href="#cb16-2"></a>Response_mask: [ F , F , F , F , F , T ,   F   ,   F   ] </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>结果：loss 只在 “4” 的 token 上算，prompt 部分完全不参与。</p>
<p>我们来看看代码是怎么实现的：</p>
<p>首先第一步自然是Tokenize Prompts和Response：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb17" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>prompt_tokens <span class="op">=</span> tokenizer(</span>
<span id="cb17-2"><a href="#cb17-2"></a>    prompt_strs,</span>
<span id="cb17-3"><a href="#cb17-3"></a>    add_special_tokens<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-4"><a href="#cb17-4"></a>    padding<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-5"><a href="#cb17-5"></a>    truncation<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-6"><a href="#cb17-6"></a>    return_attention_mask<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-7"><a href="#cb17-7"></a>)</span>
<span id="cb17-8"><a href="#cb17-8"></a></span>
<span id="cb17-9"><a href="#cb17-9"></a>output_tokens <span class="op">=</span> tokenizer(</span>
<span id="cb17-10"><a href="#cb17-10"></a>    output_strs,</span>
<span id="cb17-11"><a href="#cb17-11"></a>    add_special_tokens<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-12"><a href="#cb17-12"></a>    padding<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-13"><a href="#cb17-13"></a>    truncation<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-14"><a href="#cb17-14"></a>    return_attention_mask<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-15"><a href="#cb17-15"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>注意! 在这里，我们并不会返回<code>Tensor</code> 返回的是List， 并且List里面每个元素的长度是不一样的，</p>
<p>接下来， 我们把这两个List中的内容 concat 在一起，得到 <code>[q, o]</code>， 并且计算出我们的Response Mask</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb18" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>input_ids <span class="op">=</span> []</span>
<span id="cb18-2"><a href="#cb18-2"></a>response_mask <span class="op">=</span> []</span>
<span id="cb18-3"><a href="#cb18-3"></a></span>
<span id="cb18-4"><a href="#cb18-4"></a><span class="cf">for</span> p_ids, o_ids <span class="kw">in</span> <span class="bu">zip</span>(prompt_tokens[<span class="st">"input_ids"</span>], output_tokens[<span class="st">"input_ids"</span>]):</span>
<span id="cb18-5"><a href="#cb18-5"></a>    combined_ids <span class="op">=</span> p_ids <span class="op">+</span> o_ids</span>
<span id="cb18-6"><a href="#cb18-6"></a>    input_ids.append(combined_ids)</span>
<span id="cb18-7"><a href="#cb18-7"></a></span>
<span id="cb18-8"><a href="#cb18-8"></a>    mask <span class="op">=</span> ([<span class="va">False</span>] <span class="op">*</span> <span class="bu">len</span>(p_ids)) <span class="op">+</span> ([<span class="va">True</span>] <span class="op">*</span> <span class="bu">len</span>(o_ids))</span>
<span id="cb18-9"><a href="#cb18-9"></a>    response_mask.append(mask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>到目前为止，input_ids 和 response_mask 里面的<u>内容长度不一样长</u>，所以我们要将它Pad 到同样的长度，这样才可以传入模型：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb19" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>MAX_LEN <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(ids) <span class="cf">for</span> ids <span class="kw">in</span> input_ids)</span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="co"># 151643 for Qwen/Qwen2.5-Math-1.5B</span></span>
<span id="cb19-3"><a href="#cb19-3"></a>pad_id <span class="op">=</span> tokenizer.pad_token_id <span class="cf">if</span> tokenizer.pad_token_id <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> tokenizer.eos_token_id</span>
<span id="cb19-4"><a href="#cb19-4"></a></span>
<span id="cb19-5"><a href="#cb19-5"></a><span class="kw">def</span> pad_to(x, value):</span>
<span id="cb19-6"><a href="#cb19-6"></a>    <span class="cf">return</span> x <span class="op">+</span> [value] <span class="op">*</span> (MAX_LEN <span class="op">-</span> <span class="bu">len</span>(x))</span>
<span id="cb19-7"><a href="#cb19-7"></a></span>
<span id="cb19-8"><a href="#cb19-8"></a>full <span class="op">=</span> torch.tensor([pad_to(x, pad_id) <span class="cf">for</span> x <span class="kw">in</span> input_ids], dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb19-9"><a href="#cb19-9"></a>response_mask <span class="op">=</span> torch.tensor([pad_to(x, <span class="va">False</span>) <span class="cf">for</span> x <span class="kw">in</span> response_mask], dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>接下来就构建我们的input和labels， Labels中记录的是inputs中的下一个：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb20" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>input_ids <span class="op">=</span> full[:, :<span class="op">-</span><span class="dv">1</span>].contiguous()</span>
<span id="cb20-2"><a href="#cb20-2"></a>labels <span class="op">=</span> full[:, <span class="dv">1</span>:].contiguous()</span>
<span id="cb20-3"><a href="#cb20-3"></a>response_mask <span class="op">=</span> response_mask[:, <span class="dv">1</span>:].contiguous()</span>
<span id="cb20-4"><a href="#cb20-4"></a></span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a><span class="cf">return</span> {</span>
<span id="cb20-7"><a href="#cb20-7"></a>        <span class="st">"input_ids"</span>: input_ids,</span>
<span id="cb20-8"><a href="#cb20-8"></a>        <span class="st">"labels"</span>: labels,</span>
<span id="cb20-9"><a href="#cb20-9"></a>        <span class="st">"response_mask"</span>: response_mask,</span>
<span id="cb20-10"><a href="#cb20-10"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>需要注意的是， Response Mask中是Labels中的mask，而不是inputs_ids中的mask。</p>
<div class="tldr foldable is-open">
<div class="tldr-header foldable-header">
<p>TL;DR: Tokenization &amp; Prompts</p>
</div>
<div class="tldr-container foldable-content">
<p>在这里函数中，我们主要做两件事情：</p>
<ol type="1">
<li>Tokenize Prompt 和 Output，这里的Prompt是我们添加了Template之后</li>
<li>Concat Tokenized Prompt， Output一起，并且生成Response Mask</li>
<li>Padding到相同的长度</li>
<li>将Concat之后的内容移一位，得到inputs和labels</li>
</ol>
</div>
</div>
</section>
<section id="per-token-entropy" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="per-token-entropy"><span class="header-section-number">3.2</span> Per Token Entropy</h2>
<p>对于每一个位置<span class="math inline">\(t\)</span>, 模型会给出一下个token的分布，也就是 <span class="math inline">\(p_{t}(x) = \text{softmax}(\text{logits}_{t})\)</span>, Entropy定义为：</p>
<p><span id="eq-entropy"><span class="math display">\[
H(p) = - \sum_{x \in \mathcal{X}} p(x) \log p(x)
\tag{2}\]</span></span></p>
<ul>
<li><strong>Entropy 高</strong>： 分布更“平”，模型不那么确定（探索更强）（对于Category Distribution，<span class="math inline">\(p(x) = \frac{1}{| x| }\)</span> 有最高的Entropy</li>
<li><strong>Entropy 低</strong>：分布更“尖”，模型更确定（可能变得过度自信、模式坍缩（model collapse）</li>
</ul>
<p>在 RL 里如果你看到 entropy 很快掉到很低，常见含义是：</p>
<ul>
<li>策略变得太确定（exploration 变差）</li>
<li>训练可能开始“钻 reward 漏洞”或输出单一模板</li>
<li>学习可能不稳定（尤其和 KL/clip 配合不当时）</li>
</ul>
<p>计算entropy也很简单的，</p>
<p><span id="eq-entropy-compute"><span class="math display">\[
\begin{split}
\ell &amp;= \text{logits} \\
\log p &amp;= \log\text{softmax}(\ell) \\
p &amp;= \exp(\log p) \\
H(p) &amp;= - \sum_{x \in \mathcal{X}} p(x) \log p(x)
\end{split}
\tag{3}\]</span></span></p>
<p>用上面的公式，我们可以定义一个函数 <code>compute_entropy</code> 来计算entropy：</p>
<div class="sourceCode" id="cb21" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="kw">def</span> compute_entropy(logits: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb21-2"><a href="#cb21-2"></a>    <span class="co">"""</span></span>
<span id="cb21-3"><a href="#cb21-3"></a><span class="co">    Compute the entropy of the probability distribution defined by the logits.</span></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co">    """</span></span>
<span id="cb21-5"><a href="#cb21-5"></a>    log_probs <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb21-6"><a href="#cb21-6"></a>    probs <span class="op">=</span> torch.exp(log_probs)</span>
<span id="cb21-7"><a href="#cb21-7"></a>    entropy <span class="op">=</span> <span class="op">-</span>torch.<span class="bu">sum</span>(probs <span class="op">*</span> log_probs, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb21-8"><a href="#cb21-8"></a></span>
<span id="cb21-9"><a href="#cb21-9"></a>    <span class="cf">return</span> entropy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="getting-log-probs-from-model" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="getting-log-probs-from-model"><span class="header-section-number">3.3</span> Getting Log Probs from Model</h2>
<p>接下来，我们来定义另一个Helper Function <code>get_response_log_probs</code> 它的作用是：<strong>把“模型对每个位置真实 token 的条件概率”算出来（以 log 形式），并按 token 粒度返回</strong> 可能现在理解这个有点困难，在之后SFT 和 RL 的算法中，我们会具体讲解一下的。在这里，我们先定义一下这个函数 我们知道，SFT 的Loss <a href="#eq-sft-loss" class="quarto-xref">Equation&nbsp;1</a> 中需要用到 <span class="math inline">\(\log p_\theta(R_t \mid P, R_{&lt;t})\)</span>， 也就是模型在位置<span class="math inline">\(t\)</span>上， 对真实token <span class="math inline">\(R_t\)</span>的log prob。 因此，我们需要定义一个函数来计算这个值：</p>
<div class="sourceCode" id="cb22" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="kw">def</span> get_response_log_probs(</span>
<span id="cb22-2"><a href="#cb22-2"></a>    model, input_ids: torch.Tensor, labels: torch.Tensor, return_token_entropy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-3"><a href="#cb22-3"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">str</span>, torch.Tensor]:</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>对于模型输出 <span class="math inline">\(f_{\theta}(x)\)</span>, 其输出的是Logits，也就是没有normalized的distribution，我们第一步自然是利用softmax来将其变为分布， 之后我们再根据我们需要的label，作为索引，来提取出我们需要的log-probs</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb23" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers="10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">def</span> get_response_log_probs(</span>
<span id="cb23-2"><a href="#cb23-2"></a>    model, </span>
<span id="cb23-3"><a href="#cb23-3"></a>    input_ids: torch.Tensor, <span class="co"># （B, T）</span></span>
<span id="cb23-4"><a href="#cb23-4"></a>    labels: torch.Tensor, <span class="co"># （B, T）</span></span>
<span id="cb23-5"><a href="#cb23-5"></a>    return_token_entropy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-6"><a href="#cb23-6"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">str</span>, torch.Tensor]:</span>
<span id="cb23-7"><a href="#cb23-7"></a>    logits <span class="op">=</span> model(input_ids<span class="op">=</span>input_ids).logits <span class="co"># (B, T, V)</span></span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a>    logp <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb23-10"><a href="#cb23-10"></a>    log_probs <span class="op">=</span> logp.gather(<span class="op">-</span><span class="dv">1</span>, labels.unsqueeze(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>) </span>
<span id="cb23-11"><a href="#cb23-11"></a></span>
<span id="cb23-12"><a href="#cb23-12"></a>    res <span class="op">=</span> {</span>
<span id="cb23-13"><a href="#cb23-13"></a>        <span class="st">"log_probs"</span>: log_probs,</span>
<span id="cb23-14"><a href="#cb23-14"></a>    }</span>
<span id="cb23-15"><a href="#cb23-15"></a>    <span class="cf">if</span> return_token_entropy:</span>
<span id="cb23-16"><a href="#cb23-16"></a>        entropy <span class="op">=</span> compute_entropy(logits)</span>
<span id="cb23-17"><a href="#cb23-17"></a>        res[<span class="st">"token_entropy"</span>] <span class="op">=</span> entropy</span>
<span id="cb23-18"><a href="#cb23-18"></a>    <span class="cf">return</span> res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>这个函数最关键的部分就是第10行， 通过 <code>gather</code> 函数，我们可以根据labels，来提取出我们需要的log_probs。<code>logp</code>的shape是(B, T, V)， 其中B是Batch Size， T是Sequence Length， V是Vocabulary Size，而labels的shape是(B, T)， 因此通过 <code>gather</code> 函数，我们可以得到每个位置上，真实token的log_probs， 最终得到的<code>log_probs</code> shape是 (B, T)， 也就是我们想要的结果。</p>
<div class="warning foldable is-open">
<div class="warning-header foldable-header">
<p>WARNING: About Response Mask</p>
</div>
<div class="warning-container foldable-content">
<p>我们在这一步，并没用用到Response Mask，也就是说，这个函数会返回所有位置的Log Probs， 包括Prompt部分和Pad部分。我们需要在之后的Loss计算中 <code>masked_normalize</code>，使用Response Mask来Mask掉Prompt和Pad部分。</p>
</div>
</div>
<p>因此，在SFT 中，Log Probs 我们通过 <code>log_probs.sum(dim=-1)</code> 可以计算出Loss，当然，在做这个计算之前，我们还需要Mask掉Prompts，我们接下去来实现它：</p>
</section>
<section id="masked-normalize" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="masked-normalize"><span class="header-section-number">3.4</span> Masked Normalize</h2>
<p>接下来，我们来实现 <code>masked_normalize</code> 函数， 这个函数的作用是：<strong>根据Mask，对Tensor进行Mask，并且进行Normalize</strong></p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/utils.py</strong></pre>
</div>
<div class="sourceCode" id="cb24" data-filename="assignment5-alignment/cs336_alignment/algs/utils.py" data-code-line-numbers=""><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="kw">def</span> masked_normalize(</span>
<span id="cb24-2"><a href="#cb24-2"></a>    tensor: torch.Tensor, <span class="co"># (B, T)</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>    mask: torch.Tensor,  <span class="co"># (B, T)</span></span>
<span id="cb24-4"><a href="#cb24-4"></a>    normalize_constant: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>, </span>
<span id="cb24-5"><a href="#cb24-5"></a>    dim: <span class="bu">int</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb24-7"><a href="#cb24-7"></a>    <span class="cf">assert</span> tensor.shape <span class="op">==</span> mask.shape, <span class="st">"Tensor and mask must have the same shape"</span></span>
<span id="cb24-8"><a href="#cb24-8"></a></span>
<span id="cb24-9"><a href="#cb24-9"></a>    masked_f <span class="op">=</span> mask.type_as(tensor)</span>
<span id="cb24-10"><a href="#cb24-10"></a>    masked_tensor <span class="op">=</span> tensor <span class="op">*</span> masked_f</span>
<span id="cb24-11"><a href="#cb24-11"></a>    masked_sum <span class="op">=</span> torch.<span class="bu">sum</span>(masked_tensor, dim<span class="op">=</span>dim) <span class="cf">if</span> dim <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> torch.<span class="bu">sum</span>(masked_tensor)</span>
<span id="cb24-12"><a href="#cb24-12"></a></span>
<span id="cb24-13"><a href="#cb24-13"></a>    <span class="cf">return</span> masked_sum <span class="op">/</span> normalize_constant</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>这个函数很简单，首先我们会根据Mask来Mask掉Tensor中不需要的部分， 之后我们会对剩下的部分进行Sum， 最后我们会根据normalize_constant来进行Normalize。 传入masked_normalize的tensor，一般是Log Probs， 这样我们就可以计算出Masked Log Probs的和, 也就是我们想要的Loss。其中我认为一个很巧妙的设计是 <code>normalize_constant</code> 和 <code>dim</code> 参数， 通过这两个参数，我们可以灵活的控制我们想要的Normalize方式， 以及想要Sum的维度， 比如：</p>
<ul>
<li>如果我们想要计算Batch中所有Token的Loss，我们可以传入 <code>dim=None</code>， 并且 <code>normalize_constant = mask.sum()</code>， 这样我们就可以得到Batch中所有Token的平均Loss。 (Token Level Loss)</li>
<li>如果我们想要计算Batch中每个Sequence的Loss，我们可以传入 <code>dim=-1</code>， 并且 <code>normalize_constant = mask.sum(dim = -1)</code>， 这样我们就可以得到Batch中每个Sequence的Loss。 (Sequence Level Loss)</li>
</ul>
</section>
<section id="sft-micro-batch-training-step" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="sft-micro-batch-training-step"><span class="header-section-number">3.5</span> SFT Micro-batch Training Step</h2>
<p>有了这些Helper Functions，我们可以来实现SFT的训练, 由于Qwen2.5-Math-1.5B的模型比较大， 我们不能完全实现Batch Size较大的，因此，我们需要通过<a href="https://www.hopsworks.ai/dictionary/gradient-accumulation">Gradient Accumulation</a>的技术，来使得训练变得可能，我们先来定义一小步：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/sft.py</strong></pre>
</div>
<div class="sourceCode" id="cb25" data-filename="assignment5-alignment/cs336_alignment/algs/sft.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="kw">def</span> sft_microbatch_train_step(</span>
<span id="cb25-2"><a href="#cb25-2"></a>    policy_log_probs: torch.Tensor,</span>
<span id="cb25-3"><a href="#cb25-3"></a>    response_mask: torch.Tensor,</span>
<span id="cb25-4"><a href="#cb25-4"></a>    gradient_accumulation_steps: <span class="bu">int</span>,</span>
<span id="cb25-5"><a href="#cb25-5"></a>    normalize_constant: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb25-6"><a href="#cb25-6"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[torch.Tensor, <span class="bu">dict</span>[<span class="bu">str</span>, torch.Tensor]]:</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>其实很简单，这个函数就做两件事情：</p>
<ol type="1">
<li>计算Loss</li>
<li>Backward 计算Gradient</li>
</ol>
<p><span id="eq-sft-batch-sum-loss"><span class="math display">\[
\mathcal{L}_{\text{SFT}}^{\text{batch-sum}}
=
-\sum_{i=1}^{B}\sum_{t=1}^{T}
m^{(i)}_t\;
\log p_\theta\!\big(y^{(i)}_t \mid x^{(i)}_{&lt;t}\big)
\tag{4}\]</span></span></p>
<p>其中 <span class="math inline">\(m_{t}^{(i)}\)</span> 表示的是Mask值</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/sft.py</strong></pre>
</div>
<div class="sourceCode" id="cb26" data-filename="assignment5-alignment/cs336_alignment/algs/sft.py" data-code-line-numbers="9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>loss_unscaled <span class="op">=</span> masked_normalize(</span>
<span id="cb26-2"><a href="#cb26-2"></a>    policy_log_probs,</span>
<span id="cb26-3"><a href="#cb26-3"></a>    response_mask,</span>
<span id="cb26-4"><a href="#cb26-4"></a>    normalize_constant<span class="op">=</span>normalize_constant,</span>
<span id="cb26-5"><a href="#cb26-5"></a>    dim<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb26-6"><a href="#cb26-6"></a>) <span class="co"># 我们可以看到， dim=-1， 而且 normalize_constant = 1.0， 也就是Sequence Level Loss</span></span>
<span id="cb26-7"><a href="#cb26-7"></a></span>
<span id="cb26-8"><a href="#cb26-8"></a>loss_unscaled <span class="op">=</span> <span class="op">-</span>loss_unscaled.mean()</span>
<span id="cb26-9"><a href="#cb26-9"></a>loss_scaled <span class="op">=</span> loss_unscaled <span class="op">/</span> gradient_accumulation_steps </span>
<span id="cb26-10"><a href="#cb26-10"></a>loss_scaled.backward()</span>
<span id="cb26-11"><a href="#cb26-11"></a></span>
<span id="cb26-12"><a href="#cb26-12"></a>metadata <span class="op">=</span> {</span>
<span id="cb26-13"><a href="#cb26-13"></a>    <span class="st">"loss_unscaled"</span>: loss_unscaled.detach(),</span>
<span id="cb26-14"><a href="#cb26-14"></a>}</span>
<span id="cb26-15"><a href="#cb26-15"></a><span class="cf">return</span> loss_scaled.detach(), metadata</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Gradient Accumulation的实现也很简单， 我们只需要在计算Loss之后， 除以 <code>gradient_accumulation_steps</code> 即可。 这样我们就可以在之后的SFT Trainer中， 实现Gradient Accumulation的功能了。</p>
</section>
<section id="sft-trainer" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="sft-trainer"><span class="header-section-number">3.6</span> SFT Trainer</h2>
<p>有了这些Helper Functions，我们就可以定义我们的SFT Trainer了。相当的直观</p>
<div class="sourceCode" id="cb27" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">class</span> SFTTrainer:</span>
<span id="cb27-2"><a href="#cb27-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb27-3"><a href="#cb27-3"></a>        <span class="va">self</span>,</span>
<span id="cb27-4"><a href="#cb27-4"></a>        model: PreTrainedModel,</span>
<span id="cb27-5"><a href="#cb27-5"></a>        train_config: SFTTrainingConfig,</span>
<span id="cb27-6"><a href="#cb27-6"></a>        device: torch.device,</span>
<span id="cb27-7"><a href="#cb27-7"></a>        dataset_dir_base: <span class="bu">str</span> <span class="op">=</span> <span class="st">"./data/pre-processed"</span>,</span>
<span id="cb27-8"><a href="#cb27-8"></a>    ): </span>
<span id="cb27-9"><a href="#cb27-9"></a>        ...</span>
<span id="cb27-10"><a href="#cb27-10"></a>    </span>
<span id="cb27-11"><a href="#cb27-11"></a>    <span class="kw">def</span> train_step(</span>
<span id="cb27-12"><a href="#cb27-12"></a>        <span class="va">self</span>,</span>
<span id="cb27-13"><a href="#cb27-13"></a>    ) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">float</span>, <span class="bu">float</span>]: </span>
<span id="cb27-14"><a href="#cb27-14"></a>        ... </span>
<span id="cb27-15"><a href="#cb27-15"></a>        </span>
<span id="cb27-16"><a href="#cb27-16"></a>    <span class="kw">def</span> train(<span class="va">self</span>, vllm<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb27-17"><a href="#cb27-17"></a>        ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>在这里就不过多的赘述了，有需要的同学请自行查看代码 <a href="https://github.com/YYZhang2025/Stanford-CS336/blob/main/assignment5-alignment/cs336_alignment/algs/sft.py"><code>assignment5-alignment/cs336_alignment/algs/sft.py</code></a> 以及它的训练代码 <a href="https://github.com/YYZhang2025/Stanford-CS336/blob/main/assignment5-alignment/train_sft.py"><code>assignment5-alignment/train_sft.py</code></a></p>
</section>
<section id="sft-experiment" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="sft-experiment"><span class="header-section-number">3.7</span> SFT Experiment</h2>
<p>接下来我们来看看SFT 的训练结果：</p>
<div id="fig-rlhf-vs-rlvr" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rlhf-vs-rlvr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-rlhf-vs-rlvr" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-sft-accuracy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-sft-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/sft-accuracy.png" class="img-fluid figure-img" data-ref-parent="fig-rlhf-vs-rlvr">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-sft-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Accuracy
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-rlhf-vs-rlvr" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-sft-format" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-sft-format-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/sft-format.png" class="img-fluid figure-img" data-ref-parent="fig-rlhf-vs-rlvr">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-sft-format-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Format Reward
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rlhf-vs-rlvr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Result of SFT on Qwen2.5-Math-1.5B
</figcaption>
</figure>
</div>
<p>可以看到，经过SFT训练之后，模型在MATH, GSM8K数据集上的表现都有了显著的提升，尤其是在Format Reward上，提升非常明显，这也符合我们之前提到的SFT的作用， 让模型变得更像助理，更会按指令做事。并且Accuracy也有了显著的提升， 这也说明SFT在提升模型能力方面是有效的。</p>
</section>
</section>
<section id="expert-iteration" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Expert Iteration</h1>
<div id="algo-ei" class="pseudocode-container quarto-float" data-no-end="false" data-comment-delimiter="#" data-caption-prefix="Algorithm" data-line-number-punc=":" data-pseudocode-number="2" data-line-number="true" data-indent-size="1.2em">
<div class="pseudocode">
\begin{algorithm} \caption{Expert Iteration (EI)} \begin{algorithmic} \Require Initial policy model $\pi_{\theta_{\text{init}}}$ \Require Reward function $R(q, o)$ \Require Task question set $\mathcal{D}$ \Require Number of EI steps $n_{\text{ei\_steps}}$ \Require Number of samples per prompt $G$ \State $\pi_{\theta} \gets \pi_{\theta_{\text{init}}}$ \For{$\text{step} = 1$ \textbf{to} $n_{\text{ei\_steps}}$} \State Sample a batch of questions $\mathcal{D}_b \subset \mathcal{D}$ \State $\pi_{\theta_{\text{old}}} \gets \pi_{\theta}$ \Comment{freeze current policy as expert} \For{\textbf{each} question $q \in \mathcal{D}_b$} \State Sample $G$ candidate outputs $\{o^{(i)}\}_{i=1}^G \sim \pi_{\theta_{\text{old}}}(\cdot \mid q)$ \State Compute rewards $\{r^{(i)}\}_{i=1}^G$, where $r^{(i)} = R(q, o^{(i)})$ \EndFor \State $\mathcal{D}_{\text{sft}} \gets \{(q, o^{(i)}) \mid r^{(i)} &gt; 0\}$ \Comment{keep only correct / high-reward samples} \State $\pi_{\theta} \gets \text{SFT}(\pi_{\theta}, \mathcal{D}_{\text{sft}})$ \Comment{Algorithm 1: supervised fine-tuning on filtered data} \EndFor \State \Return $\pi_{\theta}$ \end{algorithmic} \end{algorithm}
</div>
</div>
<p>Expert Iteration, 在SFT的基础上，只多了几步采样的步骤，通过这几个步骤，我们可以得到更多的Prompt-Reponse Paris， 以便我们更好的训练SFT。同时，里面的Functions，我们也可以在GRPO中复用，可以看作是为GRPO做好准备。</p>
<p>在这里，采样的时候，我们会先重复 prompts 和 answers， 以便我们可以对每个prompt采样多个response：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/ei.py</strong></pre>
</div>
<div class="sourceCode" id="cb28" data-filename="assignment5-alignment/cs336_alignment/algs/ei.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="kw">def</span> get_ei_batch(</span>
<span id="cb28-2"><a href="#cb28-2"></a>    prompts: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb28-3"><a href="#cb28-3"></a>    answers: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb28-4"><a href="#cb28-4"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">512</span>,</span>
<span id="cb28-5"><a href="#cb28-5"></a>    num_responses_per_prompt: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span>,</span>
<span id="cb28-6"><a href="#cb28-6"></a>):</span>
<span id="cb28-7"><a href="#cb28-7"></a>    random_index <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(prompts)), k<span class="op">=</span>batch_size)</span>
<span id="cb28-8"><a href="#cb28-8"></a>    random_prompts <span class="op">=</span> [prompts[i] <span class="cf">for</span> i <span class="kw">in</span> random_index]</span>
<span id="cb28-9"><a href="#cb28-9"></a>    random_answers <span class="op">=</span> [answers[i] <span class="cf">for</span> i <span class="kw">in</span> random_index]</span>
<span id="cb28-10"><a href="#cb28-10"></a></span>
<span id="cb28-11"><a href="#cb28-11"></a>    all_prompts <span class="op">=</span> []</span>
<span id="cb28-12"><a href="#cb28-12"></a>    <span class="cf">for</span> prompt <span class="kw">in</span> random_prompts:</span>
<span id="cb28-13"><a href="#cb28-13"></a>        all_prompts.extend([prompt] <span class="op">*</span> num_responses_per_prompt)</span>
<span id="cb28-14"><a href="#cb28-14"></a>    all_true_answers <span class="op">=</span> []</span>
<span id="cb28-15"><a href="#cb28-15"></a>    <span class="cf">for</span> answer <span class="kw">in</span> random_answers:</span>
<span id="cb28-16"><a href="#cb28-16"></a>        all_true_answers.extend([answer] <span class="op">*</span> num_responses_per_prompt)</span>
<span id="cb28-17"><a href="#cb28-17"></a></span>
<span id="cb28-18"><a href="#cb28-18"></a>    <span class="cf">return</span> {</span>
<span id="cb28-19"><a href="#cb28-19"></a>        <span class="st">"prompts"</span>: <span class="bu">list</span>(all_prompts),</span>
<span id="cb28-20"><a href="#cb28-20"></a>        <span class="st">"true_answers"</span>: <span class="bu">list</span>(all_true_answers),</span>
<span id="cb28-21"><a href="#cb28-21"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>有了prompts 和 answers之后， 我们就可以进行采样了， 采样的代码和之前的vLLM推理代码是一样的：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/ei.py</strong></pre>
</div>
<div class="sourceCode" id="cb29" data-filename="assignment5-alignment/cs336_alignment/algs/ei.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>sampled_responses <span class="op">=</span> generate_responses(vllm, sampled_prompts, <span class="va">self</span>.sampling_params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>之后我们就可以计算Reward， 以及过滤出高质量的Prompt-Response Pairs， 以便我们进行SFT训练：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/ei.py</strong></pre>
</div>
<div class="sourceCode" id="cb30" data-filename="assignment5-alignment/cs336_alignment/algs/ei.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>rewards_dict <span class="op">=</span> compute_rewards_from_responses(</span>
<span id="cb30-2"><a href="#cb30-2"></a>    sampled_responses,</span>
<span id="cb30-3"><a href="#cb30-3"></a>    true_answers,</span>
<span id="cb30-4"><a href="#cb30-4"></a>    reward_fn<span class="op">=</span>REWARD_FN_MAP[<span class="va">self</span>.train_config.reward_fn],</span>
<span id="cb30-5"><a href="#cb30-5"></a>)</span>
<span id="cb30-6"><a href="#cb30-6"></a></span>
<span id="cb30-7"><a href="#cb30-7"></a><span class="co"># 7. Filter responses by reward</span></span>
<span id="cb30-8"><a href="#cb30-8"></a>filtered_prompts, filtered_responses, filtered_answers <span class="op">=</span> filter_by_reward(</span>
<span id="cb30-9"><a href="#cb30-9"></a>    sampled_prompts,</span>
<span id="cb30-10"><a href="#cb30-10"></a>    sampled_responses,</span>
<span id="cb30-11"><a href="#cb30-11"></a>    true_answers,</span>
<span id="cb30-12"><a href="#cb30-12"></a>    rewards_dict,</span>
<span id="cb30-13"><a href="#cb30-13"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>具体的细节，大家可以查看代码 <a href="https://github.com/YYZhang2025/Stanford-CS336/blob/main/assignment5-alignment/cs336_alignment/algs/ei.py"><code>assignment5-alignment/cs336_alignment/algs/ei.py</code></a> 以及它的训练代码 <a href="https://github.com/YYZhang2025/Stanford-CS336/blob/main/assignment5-alignment/train_ei.py"><code>assignment5-alignment/train_ei.py</code></a></p>
<section id="ei-experiment" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="ei-experiment"><span class="header-section-number">4.1</span> EI Experiment</h2>
<p>接下来我们来看看EI 的训练结果：</p>
<div id="fig-ei-exp" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ei-exp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ei-exp" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ei-gsm8k-accuracy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ei-gsm8k-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/ei-gsm8k-accuracy.png" class="img-fluid figure-img" data-ref-parent="fig-ei-exp">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ei-gsm8k-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) GSM8K Accuracy
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ei-exp" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ei-math-accuracy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ei-math-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/ei-math-accuracy.png" class="img-fluid figure-img" data-ref-parent="fig-ei-exp">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ei-math-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Format Reward
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ei-exp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Result of EI on Qwen2.5-Math-1.5B on MATH and GSM8K Datasets
</figcaption>
</figure>
</div>
<p>可以看到，经过EI训练之后，模型在MATH, GSM8K数据集上的表现都有了显著的提升，尤其是在Accuracy上，提升非常明显，这也符合我们之前提到的EI的作用，通过采样更多的Prompt-Response Pairs，来提升模型的能力。并且Format Reward也有了显著的提升， 这也说明EI在提升模型能力方面是有效的。</p>
</section>
</section>
<section id="grpo" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> GRPO</h1>
<p>经过前两轮的热身，终于到了我们本次Assignment的重头戏：GRPO。 GRPO的算法如下：</p>
<div id="algo-grpo" class="pseudocode-container quarto-float" data-no-end="false" data-comment-delimiter="#" data-caption-prefix="Algorithm" data-line-number-punc=":" data-pseudocode-number="3" data-line-number="true" data-indent-size="1.2em">
<div class="pseudocode">
\begin{algorithm} \caption{Group Relative Policy Optimization (GRPO)} \begin{algorithmic} \Require Initial policy $\pi_{\theta_{\text{init}}}$, reward function $R$, dataset of prompts/questions $\mathcal{D}$ \State Initialize policy $\pi_\theta \leftarrow \pi_{\theta_{\text{init}}}$ \For{$\text{step}=1,\dots,n_{\text{grpo\_steps}}$} \State Sample a minibatch of questions $\mathcal{D}_b \subset \mathcal{D}$ \State Snapshot old policy $\pi_{\theta_{\text{old}}} \leftarrow \pi_\theta$ \ForAll{$q \in \mathcal{D}_b$} \State Sample $G$ candidate outputs $\{o^{(i)}\}_{i=1}^{G} \sim \pi_{\theta_{\text{old}}}(\cdot \mid q)$ \State Compute rewards $r^{(i)} \leftarrow R\!\left(q, o^{(i)}\right)$ for $i=1,\dots,G$ \State Compute group-normalized advantages $A^{(i)}$ from $\{r^{(i)}\}_{i=1}^G$ (group normalization) \For{$\text{train\_step}=1,\dots,n_{\text{train\_steps\_per\_rollout\_batch}}$} \State Update $\pi_\theta$ by maximizing the GRPO-Clip objective using $\pi_{\theta_{\text{old}}}$ and $\{(o^{(i)},A^{(i)})\}_{i=1}^G$ \EndFor \EndFor \EndFor \State \Return $\pi_\theta$ \end{algorithmic} \end{algorithm}
</div>
</div>
<p>在实现代码之前，我们先来看看GRPO的几个关键步骤：</p>
<ol type="1">
<li><strong>采样</strong>：和EI类似，我们需要对每个prompt采样多个response，以便我们可以计算reward。</li>
<li><strong>计算Reward</strong>：我们需要计算每个response的reward，以便我们可以进行后续的优化。</li>
<li><strong>计算Log Probs</strong>：我们需要计算每个response的log probs，包括Old Policy和New Policy的log probs。</li>
<li><strong>计算Advantage</strong>：我们需要计算每个response的advantage。</li>
<li><strong>计算Loss</strong>：我们需要计算GRPO的Loss，并且进行Backward。</li>
<li><strong>更新Old Policy</strong>：我们需要在每个Step结束后，更新Old Policy为当前的New Policy。</li>
</ol>
<p>我们一步一步来看。首先是采样和计算Reward，这部分和EI是一样的，我们就不赘述了，我这里采用的方法，也是先重复prompts 和 answers， 以便我们可以对每个prompt采样多个response：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/grpo.py</strong></pre>
</div>
<div class="sourceCode" id="cb31" data-filename="assignment5-alignment/cs336_alignment/algs/grpo.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="kw">def</span> sample_batch_questions(</span>
<span id="cb31-2"><a href="#cb31-2"></a>    prompts: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb31-3"><a href="#cb31-3"></a>    answers: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb31-4"><a href="#cb31-4"></a>    batch_size: <span class="bu">int</span>,</span>
<span id="cb31-5"><a href="#cb31-5"></a>    group_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb31-6"><a href="#cb31-6"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">list</span>[<span class="bu">str</span>], <span class="bu">list</span>[<span class="bu">str</span>]]:</span>
<span id="cb31-7"><a href="#cb31-7"></a>    index <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(prompts)), k<span class="op">=</span>batch_size)</span>
<span id="cb31-8"><a href="#cb31-8"></a>    sampled_prompts <span class="op">=</span> [prompts[i] <span class="cf">for</span> i <span class="kw">in</span> index]</span>
<span id="cb31-9"><a href="#cb31-9"></a>    sampled_answers <span class="op">=</span> [answers[i] <span class="cf">for</span> i <span class="kw">in</span> index]</span>
<span id="cb31-10"><a href="#cb31-10"></a></span>
<span id="cb31-11"><a href="#cb31-11"></a>    batch_prompts <span class="op">=</span> []</span>
<span id="cb31-12"><a href="#cb31-12"></a>    batch_answers <span class="op">=</span> []</span>
<span id="cb31-13"><a href="#cb31-13"></a>    <span class="cf">for</span> p, a <span class="kw">in</span> <span class="bu">zip</span>(sampled_prompts, sampled_answers):</span>
<span id="cb31-14"><a href="#cb31-14"></a>        batch_prompts.extend([p] <span class="op">*</span> group_size)</span>
<span id="cb31-15"><a href="#cb31-15"></a>        batch_answers.extend([a] <span class="op">*</span> group_size)</span>
<span id="cb31-16"><a href="#cb31-16"></a></span>
<span id="cb31-17"><a href="#cb31-17"></a>    <span class="cf">return</span> batch_prompts, batch_answers</span>
<span id="cb31-18"><a href="#cb31-18"></a></span>
<span id="cb31-19"><a href="#cb31-19"></a>rollout_responses <span class="op">=</span> generate_responses(vllm, sample_prompts, <span class="va">self</span>.sampling_params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>有了采样的responses之后， 我们就可以计算Reward了：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/grpo.py</strong></pre>
</div>
<div class="sourceCode" id="cb32" data-filename="assignment5-alignment/cs336_alignment/algs/grpo.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="kw">def</span> compute_group_normalized_rewards(</span>
<span id="cb32-2"><a href="#cb32-2"></a>    reward_fn: Callable,</span>
<span id="cb32-3"><a href="#cb32-3"></a>    rollout_responses: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb32-4"><a href="#cb32-4"></a>    repeated_ground_truths: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb32-5"><a href="#cb32-5"></a>    group_size: <span class="bu">int</span>,</span>
<span id="cb32-6"><a href="#cb32-6"></a>    advantage_eps: <span class="bu">float</span>,</span>
<span id="cb32-7"><a href="#cb32-7"></a>    normalized_by_std: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb32-8"><a href="#cb32-8"></a>):</span>
<span id="cb32-9"><a href="#cb32-9"></a>    formatted_rewards <span class="op">=</span> []</span>
<span id="cb32-10"><a href="#cb32-10"></a>    answer_correct_rewards <span class="op">=</span> []</span>
<span id="cb32-11"><a href="#cb32-11"></a>    rewards <span class="op">=</span> []</span>
<span id="cb32-12"><a href="#cb32-12"></a>    <span class="cf">for</span> response, true_answer <span class="kw">in</span> <span class="bu">zip</span>(rollout_responses, repeated_ground_truths):</span>
<span id="cb32-13"><a href="#cb32-13"></a>        reward_info <span class="op">=</span> reward_fn(response, true_answer)</span>
<span id="cb32-14"><a href="#cb32-14"></a>        rewards.append(reward_info[<span class="st">"reward"</span>])</span>
<span id="cb32-15"><a href="#cb32-15"></a>        formatted_rewards.append(reward_info[<span class="st">"format_reward"</span>])</span>
<span id="cb32-16"><a href="#cb32-16"></a>        answer_correct_rewards.append(reward_info[<span class="st">"answer_reward"</span>])</span>
<span id="cb32-17"><a href="#cb32-17"></a></span>
<span id="cb32-18"><a href="#cb32-18"></a>    advs <span class="op">=</span> []</span>
<span id="cb32-19"><a href="#cb32-19"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(rewards), group_size):</span>
<span id="cb32-20"><a href="#cb32-20"></a>        group_rewards <span class="op">=</span> rewards[i : i <span class="op">+</span> group_size]</span>
<span id="cb32-21"><a href="#cb32-21"></a>        group_rewards_tensor <span class="op">=</span> torch.tensor(group_rewards)</span>
<span id="cb32-22"><a href="#cb32-22"></a>        group_mean <span class="op">=</span> torch.mean(group_rewards_tensor)</span>
<span id="cb32-23"><a href="#cb32-23"></a>        <span class="cf">if</span> normalized_by_std:</span>
<span id="cb32-24"><a href="#cb32-24"></a>            group_std <span class="op">=</span> torch.std(group_rewards_tensor) <span class="op">+</span> advantage_eps</span>
<span id="cb32-25"><a href="#cb32-25"></a>            normalized_rewards <span class="op">=</span> (group_rewards_tensor <span class="op">-</span> group_mean) <span class="op">/</span> group_std</span>
<span id="cb32-26"><a href="#cb32-26"></a>        <span class="cf">else</span>:</span>
<span id="cb32-27"><a href="#cb32-27"></a>            normalized_rewards <span class="op">=</span> group_rewards_tensor <span class="op">-</span> group_mean</span>
<span id="cb32-28"><a href="#cb32-28"></a>        advs.extend(normalized_rewards.tolist())</span>
<span id="cb32-29"><a href="#cb32-29"></a></span>
<span id="cb32-30"><a href="#cb32-30"></a>    meta_info <span class="op">=</span> {}</span>
<span id="cb32-31"><a href="#cb32-31"></a></span>
<span id="cb32-32"><a href="#cb32-32"></a>    <span class="cf">return</span> advs, rewards, meta_info</span>
<span id="cb32-33"><a href="#cb32-33"></a>advantages, raw_rewards, metadata <span class="op">=</span> compute_group_normalized_rewards(</span>
<span id="cb32-34"><a href="#cb32-34"></a>    reward_fn<span class="op">=</span><span class="va">self</span>.reward_fn,</span>
<span id="cb32-35"><a href="#cb32-35"></a>    rollout_responses<span class="op">=</span>rollout_responses,</span>
<span id="cb32-36"><a href="#cb32-36"></a>    repeated_ground_truths<span class="op">=</span>repeated_ground_truths,</span>
<span id="cb32-37"><a href="#cb32-37"></a>    group_size<span class="op">=</span><span class="va">self</span>.train_config.group_size,</span>
<span id="cb32-38"><a href="#cb32-38"></a>    advantage_eps<span class="op">=</span><span class="va">self</span>.train_config.advantage_eps,</span>
<span id="cb32-39"><a href="#cb32-39"></a>    normalized_by_std<span class="op">=</span><span class="va">self</span>.train_config.norm_by_std,</span>
<span id="cb32-40"><a href="#cb32-40"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>在这个函数中， 我们计算了每个response的reward， 之后我们根据group size， 来计算group normalized advantages。 具体来说， 我们会将每个group中的rewards， 计算mean和std， 之后我们会根据mean和std来计算normalized rewards， 也就是advantages。 这样做的好处是， 可以减少不同group之间的reward scale差异， 使得训练更加稳定。</p>
<p>有了advantages之后， 我们就可以计算Log Probs了，</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/grpo.py</strong></pre>
</div>
<div class="sourceCode" id="cb33" data-filename="assignment5-alignment/cs336_alignment/algs/grpo.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>input_ids <span class="op">=</span> tokenized[<span class="st">"input_ids"</span>].to(<span class="va">self</span>.device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-2"><a href="#cb33-2"></a>labels <span class="op">=</span> tokenized[<span class="st">"labels"</span>].to(<span class="va">self</span>.device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-3"><a href="#cb33-3"></a>response_mask <span class="op">=</span> tokenized[<span class="st">"response_mask"</span>].to(<span class="va">self</span>.device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-4"><a href="#cb33-4"></a>ave_length <span class="op">=</span> response_mask.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">float</span>().mean().item()</span>
<span id="cb33-5"><a href="#cb33-5"></a></span>
<span id="cb33-6"><a href="#cb33-6"></a>old_log_probs <span class="op">=</span> []</span>
<span id="cb33-7"><a href="#cb33-7"></a><span class="va">self</span>.model.<span class="bu">eval</span>()</span>
<span id="cb33-8"><a href="#cb33-8"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb33-9"><a href="#cb33-9"></a>    <span class="cf">for</span> i <span class="kw">in</span> trange(<span class="dv">0</span>, input_ids.size(<span class="dv">0</span>), <span class="va">self</span>.train_config.micro_batch_size):</span>
<span id="cb33-10"><a href="#cb33-10"></a>        batch_input_ids <span class="op">=</span> input_ids[i : i <span class="op">+</span> <span class="va">self</span>.train_config.micro_batch_size]</span>
<span id="cb33-11"><a href="#cb33-11"></a>        batch_labels <span class="op">=</span> labels[i : i <span class="op">+</span> <span class="va">self</span>.train_config.micro_batch_size]</span>
<span id="cb33-12"><a href="#cb33-12"></a></span>
<span id="cb33-13"><a href="#cb33-13"></a>        <span class="cf">with</span> <span class="va">self</span>.ctx:</span>
<span id="cb33-14"><a href="#cb33-14"></a>            policy_outputs <span class="op">=</span> get_response_log_probs(</span>
<span id="cb33-15"><a href="#cb33-15"></a>                <span class="va">self</span>.model,</span>
<span id="cb33-16"><a href="#cb33-16"></a>                input_ids<span class="op">=</span>batch_input_ids,</span>
<span id="cb33-17"><a href="#cb33-17"></a>                labels<span class="op">=</span>batch_labels,</span>
<span id="cb33-18"><a href="#cb33-18"></a>                return_token_entropy<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb33-19"><a href="#cb33-19"></a>            )</span>
<span id="cb33-20"><a href="#cb33-20"></a>            batch_log_probs <span class="op">=</span> policy_outputs[<span class="st">"log_probs"</span>]</span>
<span id="cb33-21"><a href="#cb33-21"></a></span>
<span id="cb33-22"><a href="#cb33-22"></a>        old_log_probs.append(batch_log_probs.cpu())</span>
<span id="cb33-23"><a href="#cb33-23"></a>old_log_probs <span class="op">=</span> torch.cat(old_log_probs, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-24"><a href="#cb33-24"></a><span class="va">self</span>.model.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>在这里，我也用了类似于Gradient Accumulation的技术， 来计算Old Policy的Log Probs， 以便节省显存。 计算New Policy的Log Probs也是类似的， 这里就不赘述了。</p>
<p>有了Old Policy和New Policy的Log Probs之后， 我们就可以计算GRPO的Loss了：</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>assignment5-alignment/cs336_alignment/algs/grpo.py</strong></pre>
</div>
<div class="sourceCode" id="cb34" data-filename="assignment5-alignment/cs336_alignment/algs/grpo.py" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="kw">def</span> grpo_microbatch_train_step(</span>
<span id="cb34-2"><a href="#cb34-2"></a>    policy_log_probs: torch.Tensor,</span>
<span id="cb34-3"><a href="#cb34-3"></a>    response_mask: torch.Tensor,</span>
<span id="cb34-4"><a href="#cb34-4"></a>    gradient_accumulation_steps: <span class="bu">int</span>,</span>
<span id="cb34-5"><a href="#cb34-5"></a>    loss_type: Literal[<span class="st">"no_baseline"</span>, <span class="st">"reinforce_with_baseline"</span>, <span class="st">"grpo_clip"</span>],</span>
<span id="cb34-6"><a href="#cb34-6"></a>    raw_rewards: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb34-7"><a href="#cb34-7"></a>    advantages: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb34-8"><a href="#cb34-8"></a>    old_log_probs: torch.Tensor <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb34-9"><a href="#cb34-9"></a>    cliprange: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span id="cb34-10"><a href="#cb34-10"></a>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[torch.Tensor, <span class="bu">dict</span>]:</span>
<span id="cb34-11"><a href="#cb34-11"></a>    <span class="co">"""</span></span>
<span id="cb34-12"><a href="#cb34-12"></a><span class="co">    Compute the GRPO loss over microbatches for training.</span></span>
<span id="cb34-13"><a href="#cb34-13"></a><span class="co">    """</span></span>
<span id="cb34-14"><a href="#cb34-14"></a>    loss, metadata <span class="op">=</span> compute_policy_gradient_loss(</span>
<span id="cb34-15"><a href="#cb34-15"></a>        policy_log_probs<span class="op">=</span>policy_log_probs,</span>
<span id="cb34-16"><a href="#cb34-16"></a>        loss_type<span class="op">=</span>loss_type,</span>
<span id="cb34-17"><a href="#cb34-17"></a>        raw_rewards<span class="op">=</span>raw_rewards,</span>
<span id="cb34-18"><a href="#cb34-18"></a>        advantages<span class="op">=</span>advantages,</span>
<span id="cb34-19"><a href="#cb34-19"></a>        old_log_probs<span class="op">=</span>old_log_probs,</span>
<span id="cb34-20"><a href="#cb34-20"></a>        cliprange<span class="op">=</span>cliprange,</span>
<span id="cb34-21"><a href="#cb34-21"></a>    )</span>
<span id="cb34-22"><a href="#cb34-22"></a></span>
<span id="cb34-23"><a href="#cb34-23"></a>    masked_loss <span class="op">=</span> masked_mean(</span>
<span id="cb34-24"><a href="#cb34-24"></a>        tensor<span class="op">=</span>loss,</span>
<span id="cb34-25"><a href="#cb34-25"></a>        mask<span class="op">=</span>response_mask,</span>
<span id="cb34-26"><a href="#cb34-26"></a>        dim<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb34-27"><a href="#cb34-27"></a>    )</span>
<span id="cb34-28"><a href="#cb34-28"></a></span>
<span id="cb34-29"><a href="#cb34-29"></a>    masked_loss <span class="op">=</span> masked_loss.mean()</span>
<span id="cb34-30"><a href="#cb34-30"></a>    masked_loss <span class="op">=</span> masked_loss <span class="op">/</span> gradient_accumulation_steps</span>
<span id="cb34-31"><a href="#cb34-31"></a>    masked_loss.backward()</span>
<span id="cb34-32"><a href="#cb34-32"></a></span>
<span id="cb34-33"><a href="#cb34-33"></a>    <span class="cf">return</span> masked_loss, metadata</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>在这个函数中， 我们计算了GRPO的Loss， 具体来说， 我们会根据传入的loss type， 来计算不同类型的Loss， 之后我们会根据Response Mask来Mask掉不需要的部分， 最后我们会进行Backward。</p>
<p>最后， 在每个Step结束后， 我们需要更新Old Policy为当前的New Policy， 这部分代码也很简单， 直接赋值即可.</p>
<div class="highlight">
<p>其实熟悉了 GRPO 的算法之后，在回过头看这个算法实现， 你会发现， GRPO的实现其实并不复杂， 主要是把之前SFT和EI的代码进行了一些复用， 以及增加了一些新的功能， 比如计算Advantage， 以及计算不同类型的Loss。 只要理解了这些关键步骤， 实现起来其实并不难。</p>
</div>
<section id="grpo-experiment" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="grpo-experiment"><span class="header-section-number">5.1</span> GRPO Experiment</h2>
<p>接下来我们来看看GRPO 的训练结果：</p>
<div id="fig-grpo-exp" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-grpo-exp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-grpo-exp" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-grpo-gsm8k-accuracy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-grpo-gsm8k-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/grpo-accureacy.png" class="img-fluid figure-img" data-ref-parent="fig-grpo-exp">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-grpo-gsm8k-accuracy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) GRPO Accuracy
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-grpo-exp" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-grpo-gsm8k-entropy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-grpo-gsm8k-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/grpo-gsm8k-token-entropy.png" class="img-fluid figure-img" data-ref-parent="fig-grpo-exp">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-grpo-gsm8k-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) GSM8K Token Entropy
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-grpo-exp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Result of GRPO on Qwen2.5-Math-1.5B on GSM8K Dataset
</figcaption>
</figure>
</div>
</section>
<section id="other-experiments" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="other-experiments"><span class="header-section-number">5.2</span> Other Experiments</h2>
<p>在Assignment中， 我还实现了一些其他的实验， 比如不同的Reward Function， 不同的Loss Type， 以及不同的Group Size。由于时间的关系，我并没有做这些实验，不过在代码中，可以很容易的实现这些实验。</p>
<section id="learning-rate-tuning" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="learning-rate-tuning"><span class="header-section-number">5.2.1</span> Learning Rate Tuning</h3>
<p>首先第一个实验就是学习率的调节， 由于GRPO的训练比较不稳定， 因此学习率的选择非常重要。 我尝试了不同的学习率， 发现0.0001是一个比较合适的选择， 过高的学习率会导致训练不稳定， 过低的学习率会导致训练收敛慢。</p>
</section>
<section id="effect-of-baseline" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="effect-of-baseline"><span class="header-section-number">5.2.2</span> Effect of Baseline</h3>
<p>Baseline的作用是减少训练的方差， 因此我尝试了不同的Baseline， 发现使用Baseline可以显著提升训练的稳定性， 并且可以提升模型的性能。</p>
</section>
<section id="length-normalization" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="length-normalization"><span class="header-section-number">5.2.3</span> Length Normalization</h3>
<p>在计算Log Probs的时候，根据不同的Length Normalization方式， 也会对训练产生影响。 我尝试了不同的Normalization方式， 发现使用Token Level Normalization可以提升模型的性能。</p>
</section>
<section id="normalization-with-group-std" class="level3" data-number="5.2.4">
<h3 data-number="5.2.4" class="anchored" data-anchor-id="normalization-with-group-std"><span class="header-section-number">5.2.4</span> Normalization with group std</h3>
<p>在计算Advantage的时候， 我尝试了是否使用Group Std来进行Normalization，</p>
</section>
<section id="off-policy-vs.-on-policy" class="level3" data-number="5.2.5">
<h3 data-number="5.2.5" class="anchored" data-anchor-id="off-policy-vs.-on-policy"><span class="header-section-number">5.2.5</span> Off-Policy vs.&nbsp;On-Policy</h3>
<p>要想把GRPO 训练好， 还有一个很重要的点就是Off-Policy 和 On-Policy的选择。 在GRPO中， 我们使用的是On-Policy的方式， 也就是使用Old Policy来采样数据， 然后使用New Policy来进行优化。 这种方式可以提升训练的稳定性， 并且可以提升模型的性能。要想把它改成Off-Policy也是可以的， 但是需要注意一些细节， 比如Importance Sampling等。</p>
</section>
<section id="off-policy-clipping" class="level3" data-number="5.2.6">
<h3 data-number="5.2.6" class="anchored" data-anchor-id="off-policy-clipping"><span class="header-section-number">5.2.6</span> Off Policy Clipping</h3>
</section>
<section id="different-prompts" class="level3" data-number="5.2.7">
<h3 data-number="5.2.7" class="anchored" data-anchor-id="different-prompts"><span class="header-section-number">5.2.7</span> Different Prompts</h3>
<p>当然，我们还可以尝试不同的Prompts， 以便提升模型的性能。 不同的Prompt会对模型的性能产生影响， 因此选择合适的Prompt也是很重要的。当Prompts改变时，对应的Reward Function也需要相应的调整， 以便更好的适应新的Prompt。</p>
</section>
</section>
</section>
<section id="dpo" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> DPO</h1>
<p>这个部分，是Assignment05 的补充内容，其主要目的是了解DPO算法的基本思想和实现方式。 由于时间的关系， 我并没有实现DPO的完整代码， 但是我会介绍DPO的基本思想和实现方式。DPO的算法如下：</p>
<div id="algo-ei" class="pseudocode-container quarto-float" data-no-end="false" data-comment-delimiter="#" data-caption-prefix="Algorithm" data-line-number-punc=":" data-pseudocode-number="4" data-line-number="true" data-indent-size="1.2em">
<div class="pseudocode">
\begin{algorithm} \caption{Direct Preference Optimization (DPO)} \begin{algorithmic} \Require Initial policy model $\pi_{\theta_{\text{init}}}$ \Require Reference policy $\pi_{\text{ref}}$ (e.g., SFT model; fixed) \Require Preference dataset $\mathcal{D}=\{(x, y^{+}, y^{-})\}$ \Require Inverse temperature $\beta &gt; 0$ \Require Number of DPO steps $n_{\text{dpo\_steps}}$ \State $\pi_{\theta} \gets \pi_{\theta_{\text{init}}}$ \For{$\text{step} = 1$ \textbf{to} $n_{\text{dpo\_steps}}$} \State Sample a minibatch $\mathcal{B} \subset \mathcal{D}$ of triples $(x, y^{+}, y^{-})$ \For{\textbf{each} $(x, y^{+}, y^{-}) \in \mathcal{B}$} \State Compute log-likelihood ratios vs reference: \State $s^{+} \gets \log \pi_{\theta}(y^{+}\mid x) - \log \pi_{\text{ref}}(y^{+}\mid x)$ \State $s^{-} \gets \log \pi_{\theta}(y^{-}\mid x) - \log \pi_{\text{ref}}(y^{-}\mid x)$ \State Compute preference margin: \State $\Delta \gets \beta \, (s^{+} - s^{-})$ \State Compute DPO loss: \State $\ell \gets -\log \sigma(\Delta)$ \Comment{$\sigma(\cdot)$ is the logistic sigmoid} \EndFor \State Update $\theta$ by minimizing mean loss: \State $\theta \gets \theta - \eta \nabla_{\theta}\left(\frac{1}{|\mathcal{B}|}\sum_{(x,y^+,y^-)\in\mathcal{B}} \ell\right)$ \EndFor \State \Return $\pi_{\theta}$ \end{algorithmic} \end{algorithm}
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/sta210-s22\.github\.io\/website\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark_dimmed">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "YYZhang2025/YYZhang2025.github.io";
    script.dataset.repoId = "R_kgDOQlDTcQ";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOQlDTcc4C2MRz";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with ❤️ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize,
          commentDelimiter: el.dataset.commentDelimiter,
          lineNumber: el.dataset.lineNumber.toLowerCase() === "true",
          lineNumberPunc: el.dataset.lineNumberPunc,
          noEnd: el.dataset.noEnd.toLowerCase() === "true",
          titlePrefix: el.dataset.captionPrefix
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




<script src="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>