<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Lecture15ä¸»è¦æ¢³ç† LLM çš„åè®­ç»ƒï¼ˆPost-Trainingï¼‰ä¸»çº¿ï¼šä»ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„æ•°æ®ä¸ç›®æ ‡å‡½æ•°å‡ºå‘ï¼Œè§£é‡Šä¸ºä½•SFTå¯ä»¥è®©æ¨¡å‹è·å¾—ä¸€å®šçš„Instruct Followingçš„èƒ½åŠ›ï¼Œå¹¶ç³»ç»Ÿä»‹ç» RLHF çš„å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸ PPO æ›´æ–°æµç¨‹ï¼Œè¿›ä¸€æ­¥å¯¹æ¯” DPO/SimPO ç­‰å°† RL ç®€åŒ–ä¸ºç›‘ç£å­¦ä¹ çš„æ›¿ä»£æ–¹æ¡ˆã€‚æœ€åæ€»ç»“ RLHF çš„å…³é”®é£é™©ï¼ˆreward hackingã€model collapseï¼‰ï¼Œå¹¶è¯´æ˜ä¸ºä½•éœ€è¦èµ°å‘å¯éªŒè¯å¥–åŠ±çš„ RLVR æ¥æå‡æ¨ç†èƒ½åŠ›ä¸è®­ç»ƒç¨³å®šæ€§ã€‚">

<title>Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO) â€“ Learning Note</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../posts/CS336/Lecture16&amp;17/lec16.html" rel="next">
<link href="../../../posts/CS336/Lecture13&amp;14/lec13.html" rel="prev">
<link href="../../.././style/icon.avif" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-01e1ab90bb0902c54ef2dc3889c8698d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-987788bda8b0cf97ae4c62c0f40f22af.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-01e1ab90bb0902c54ef2dc3889c8698d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-E8EJCZTZG1"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-E8EJCZTZG1', { 'anonymize_ip': true});
</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
<script>
    MathJax = {
        loader: {
        load: ['[tex]/boldsymbol']
        },
        tex: {
        tags: "all",
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true,
        packages: {
            '[+]': ['boldsymbol']
        }
        }
    };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script>
document.addEventListener("DOMContentLoaded", function () {
  document.querySelectorAll(".foldable-header").forEach(header => {
    header.addEventListener("click", () => {
      const block = header.closest(".foldable");
      if (block) {
        block.classList.toggle("is-open");
      }
    });

    // å¯è®¿é—®æ€§ï¼ˆé”®ç›˜ï¼‰
    header.setAttribute("tabindex", "0");
    header.addEventListener("keydown", e => {
      if (e.key === "Enter" || e.key === " ") {
        e.preventDefault();
        header.click();
      }
    });
  });
});
</script>
    <style type="text/css">
    .ps-root .ps-algorithm {
      border-top: 2px solid;
      border-bottom: 2px solid;
    }
    .pseudocode-container {
      text-align: left;
    }
    </style>
  
      <style type="text/css">
      .ps-algorithm > .ps-line {
        text-align: left;
      }
      </style>
    

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO)</h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../.././style/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/YYZhang2025" title="GitHub organization" class="quarto-navigation-tool px-1" aria-label="GitHub organization"><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/zhang-yuyang/" title="LinkedIn" class="quarto-navigation-tool px-1" aria-label="LinkedIn"><i class="bi bi-linkedin"></i></a>
    <a href="https://yyzhang2025.github.io/posts/Blogs/blogs_index.html" title="Personal Blogs" class="quarto-navigation-tool px-1" aria-label="Personal Blogs"><i class="bi bi-globe"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">ğŸ“ 100 AI Papers with Code</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/100_Papers_index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this series</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/01-transformer/Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision Transformer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">ğŸ“ Stanford CS336: LLM from Scratch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this course</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture01/lec01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 01: Introduction &amp; BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture02/lec02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 02: PyTorch Basics &amp; Resource Accounts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture03/lec03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 03: Transformer LM Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture04/lec04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 04: MoE Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture05&amp;06/lec05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 05&amp;06: GPU Optimization, Triton &amp; FlashAttention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture07&amp;08/lec07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 07&amp;08: Parallelism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture9&amp;11/lec9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 09&amp;11: Scaling Laws</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture10/lec10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 10: Inference &amp; Deployment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture12/lec12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 12: Evaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture13&amp;14/lec13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 13&amp;14: Data Collection &amp; Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture15/lec15.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Lecture16&amp;17/lec16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass01/ass01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 01: BPE Tokenizer &amp; Transformer LM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass02/ass02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 02: Flash Attention &amp; Parallelism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/CS336/Ass05/ass05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 05: SFT &amp; GRPO</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">ğŸ“– Deep Learning Foundation &amp; Concepts</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/DLFaC/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this book</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sft" id="toc-sft" class="nav-link active" data-scroll-target="#sft"><span class="header-section-number">1</span> SFT</a>
  <ul>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset"><span class="header-section-number">1.1</span> Dataset</a>
  <ul>
  <li><a href="#flan" id="toc-flan" class="nav-link" data-scroll-target="#flan"><span class="header-section-number">1.1.1</span> FLAN</a></li>
  <li><a href="#alpaca" id="toc-alpaca" class="nav-link" data-scroll-target="#alpaca"><span class="header-section-number">1.1.2</span> Alpaca</a></li>
  <li><a href="#openassistant" id="toc-openassistant" class="nav-link" data-scroll-target="#openassistant"><span class="header-section-number">1.1.3</span> OpenAssistant</a></li>
  <li><a href="#self-annotated-dataset" id="toc-self-annotated-dataset" class="nav-link" data-scroll-target="#self-annotated-dataset"><span class="header-section-number">1.1.4</span> Self-Annotated Dataset</a></li>
  </ul></li>
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm"><span class="header-section-number">1.2</span> Algorithm</a>
  <ul>
  <li><a href="#mid-training" id="toc-mid-training" class="nav-link" data-scroll-target="#mid-training"><span class="header-section-number">1.2.1</span> Mid-Training</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#rlhf" id="toc-rlhf" class="nav-link" data-scroll-target="#rlhf"><span class="header-section-number">2</span> RLHF</a>
  <ul>
  <li><a href="#rlhf-data" id="toc-rlhf-data" class="nav-link" data-scroll-target="#rlhf-data"><span class="header-section-number">2.1</span> RLHF Data</a></li>
  <li><a href="#rlhf-algorithms" id="toc-rlhf-algorithms" class="nav-link" data-scroll-target="#rlhf-algorithms"><span class="header-section-number">2.2</span> RLHF Algorithms</a></li>
  <li><a href="#ppo" id="toc-ppo" class="nav-link" data-scroll-target="#ppo"><span class="header-section-number">2.3</span> PPO</a>
  <ul>
  <li><a href="#reinforce" id="toc-reinforce" class="nav-link" data-scroll-target="#reinforce"><span class="header-section-number">2.3.1</span> REINFORCE</a></li>
  <li><a href="#variance-reduction-with-advantage-function" id="toc-variance-reduction-with-advantage-function" class="nav-link" data-scroll-target="#variance-reduction-with-advantage-function"><span class="header-section-number">2.3.2</span> Variance Reduction with Advantage Function</a></li>
  <li><a href="#off-policy-updates" id="toc-off-policy-updates" class="nav-link" data-scroll-target="#off-policy-updates"><span class="header-section-number">2.3.3</span> Off-Policy Updates</a></li>
  <li><a href="#proximal-policy-optimization-ppo" id="toc-proximal-policy-optimization-ppo" class="nav-link" data-scroll-target="#proximal-policy-optimization-ppo"><span class="header-section-number">2.3.4</span> Proximal Policy Optimization (PPO)</a></li>
  </ul></li>
  <li><a href="#dpo" id="toc-dpo" class="nav-link" data-scroll-target="#dpo"><span class="header-section-number">2.4</span> DPO</a></li>
  <li><a href="#åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°" id="toc-åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°" class="nav-link" data-scroll-target="#åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°"><span class="header-section-number">2.5</span> åè§£â€å¾—åˆ° implied rewardï¼šreward â‰ˆ log-ratioï¼ˆå·®ä¸€ä¸ªå¸¸æ•°ï¼‰</a></li>
  <li><a href="#others" id="toc-others" class="nav-link" data-scroll-target="#others"><span class="header-section-number">2.6</span> Others</a>
  <ul>
  <li><a href="#length-normalized-dpo" id="toc-length-normalized-dpo" class="nav-link" data-scroll-target="#length-normalized-dpo"><span class="header-section-number">2.6.1</span> Length Normalized DPO</a></li>
  </ul></li>
  <li><a href="#ppo-vs.-dpo" id="toc-ppo-vs.-dpo" class="nav-link" data-scroll-target="#ppo-vs.-dpo"><span class="header-section-number">2.7</span> PPO vs.&nbsp;DPO</a></li>
  </ul></li>
  <li><a href="#things-to-watch-out-for-in-rlhf" id="toc-things-to-watch-out-for-in-rlhf" class="nav-link" data-scroll-target="#things-to-watch-out-for-in-rlhf"><span class="header-section-number">3</span> Things to watch out for in RLHF</a>
  <ul>
  <li><a href="#over-optimization" id="toc-over-optimization" class="nav-link" data-scroll-target="#over-optimization"><span class="header-section-number">3.1</span> Over-optimization</a></li>
  <li><a href="#model-collapse" id="toc-model-collapse" class="nav-link" data-scroll-target="#model-collapse"><span class="header-section-number">3.2</span> Model Collapse</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">4</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Lecture 15: LLM Alignment SFT &amp; RLHF(PPO, DPO)</h1>
</div>

<div>
  <div class="description">
    Lecture15ä¸»è¦æ¢³ç† LLM çš„åè®­ç»ƒï¼ˆ<strong>Post-Training</strong>ï¼‰ä¸»çº¿ï¼šä»ç›‘ç£å¾®è°ƒï¼ˆ<strong>SFT</strong>ï¼‰çš„æ•°æ®ä¸ç›®æ ‡å‡½æ•°å‡ºå‘ï¼Œè§£é‡Šä¸ºä½•SFTå¯ä»¥è®©æ¨¡å‹è·å¾—ä¸€å®šçš„Instruct Followingçš„èƒ½åŠ›ï¼Œå¹¶ç³»ç»Ÿä»‹ç» RLHF çš„å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸ <strong>PPO</strong> æ›´æ–°æµç¨‹ï¼Œè¿›ä¸€æ­¥å¯¹æ¯” <strong>DPO</strong>/<strong>SimPO</strong> ç­‰å°† RL ç®€åŒ–ä¸ºç›‘ç£å­¦ä¹ çš„æ›¿ä»£æ–¹æ¡ˆã€‚æœ€åæ€»ç»“ RLHF çš„å…³é”®é£é™©ï¼ˆ<strong>reward hacking</strong>ã€<strong>model collapse</strong>ï¼‰ï¼Œå¹¶è¯´æ˜ä¸ºä½•éœ€è¦èµ°å‘å¯éªŒè¯å¥–åŠ±çš„ RLVR æ¥æå‡æ¨ç†èƒ½åŠ›ä¸è®­ç»ƒç¨³å®šæ€§ã€‚
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è®­ç»ƒï¼ˆPre-Trainingï¼‰è·å¾—äº†ä¸€ä¸ªå¯ä»¥è‡ªåŠ¨è¡¥å…¨çš„LLMã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªæ˜¾ç„¶å’Œæˆ‘ä»¬ç°åœ¨ä½¿ç”¨çš„ChatGPTï¼ŒGeminiæœ‰å¾ˆå¤§çš„åŒºåˆ«ï¼Œå¦‚ä½•ä»è¿™ä¸ªGPTå˜æˆChatGPTï¼Œå°†æ˜¯æˆ‘ä»¬æ¥ä¸‹å»è¦å­¦ä¹ çš„å†…å®¹ã€‚ä¹Ÿå°±æ˜¯æ‰€è°“çš„Post-Trainingï¼Œé€šè¿‡Post-Trainingï¼Œæ¨¡å‹å¯ä»¥è¾“å‡ºåˆ¶å®šçš„å†…å®¹ï¼Œå¹¶ä¸”å˜å¾—æ›´åŠ å®‰å…¨ã€‚åœ¨è¿™èŠ‚Lectureä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šå­¦ä¹ ï¼š</p>
<ul>
<li>ä»€ä¹ˆæ˜¯SFTï¼Œå¦‚ä½•æ„å»ºDataset</li>
<li>ä»€ä¹ˆæ˜¯RLHF</li>
</ul>
<div id="fig-post-training-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-post-training-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/lec15-overview-post-training.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-post-training-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: è¯¥å›¾å±•ç¤ºäº† RLHF çš„æ•´ä½“è®­ç»ƒæµç¨‹ï¼šé¦–å…ˆç”±æˆ‘ä»¬ä¸ºç»™å®šPromptç¤ºèŒƒé«˜è´¨é‡ç­”æ¡ˆï¼Œå¯¹æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼›æ¥ç€é’ˆå¯¹åŒä¸€æç¤ºç”Ÿæˆå¤šæ¡æ¨¡å‹è¾“å‡ºï¼Œç”±äººå¯¹è¿™äº›å›ç­”è¿›è¡Œä»å¥½åˆ°åçš„æ’åºï¼Œç”¨äºè®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰ï¼›æœ€ååœ¨å®é™…è®­ç»ƒä¸­ï¼Œæ¨¡å‹é’ˆå¯¹æ–°æç¤ºç”Ÿæˆå›ç­”ï¼Œå¥–åŠ±æ¨¡å‹å¯¹å…¶æ‰“åˆ†ï¼Œå¹¶é€šè¿‡ PPO ç­‰å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¸æ–­æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨¡å‹é€æ­¥å€¾å‘äºäº§å‡ºæ›´ç¬¦åˆäººç±»åå¥½çš„ç»“æœã€‚
</figcaption>
</figure>
</div>
<section id="sft" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> SFT</h1>
<p>æˆ‘ä»¬çŸ¥é“ï¼Œè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œé¿ä¸å¼€çš„ä¸¤ä»¶äº‹å°±æ˜¯ï¼š<strong>æ•°æ®</strong>å’Œ<strong>ç®—æ³•</strong>ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±é€šè¿‡è¿™ä¸¤ä¸ªæ–¹é¢æ¥çœ‹çœ‹SFT</p>
<section id="dataset" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="dataset"><span class="header-section-number">1.1</span> Dataset</h2>
<p>SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰é˜¶æ®µç”¨çš„æ•°æ®é‡é€šå¸¸ <strong>è¿œå°äºé¢„è®­ç»ƒ</strong>ï¼Œä½†å®ƒå¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“å´æå¤§ï¼Œæ‰€ä»¥ï¼š</p>
<ul>
<li>æ•°æ®é‡Œçš„â€œç»†èŠ‚â€ä¼šè¢«æ¨¡å‹å¼ºçƒˆæ”¾å¤§ï¼šé£æ ¼ã€é•¿åº¦ã€æ ¼å¼ã€å£å»ã€æ˜¯å¦çˆ±åˆ—ç‚¹ã€æ˜¯å¦çˆ±åŠ å¼•ç”¨ã€æ˜¯å¦çˆ± emojiâ€¦â€¦éƒ½ä¼šè¢«å­¦æˆâ€œé»˜è®¤è¡Œä¸ºâ€ã€‚</li>
<li>SFT æ›´æ“…é•¿æ•™ä¼šæ¨¡å‹è¾“å‡ºçš„â€œç±»å‹ç­¾åâ€ï¼ˆtype signatureï¼‰ï¼šåƒä¸åƒèŠå¤©ã€æ˜¯ä¸æ˜¯æœ‰ç»“æ„ã€æœ‰æ²¡æœ‰ç¤¼è²Œã€ä¼šä¸ä¼šæ‹’ç»ã€‚</li>
<li>ä½† SFT ä¸ä¸€å®šå¯é åœ°æ•™ä¼šâ€œæ–°çŸ¥è¯†â€ï¼Œç”šè‡³ä¼šå¼•å…¥æ·å¾„è¡Œä¸ºï¼ˆæ¯”å¦‚ä¸ºäº†ç¬¦åˆâ€œä¸“å®¶ç­”æ¡ˆçš„å½¢å¼â€ï¼Œå»ç¼–é€ å¼•ç”¨/äº‹å®ï¼‰ã€‚</li>
</ul>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹å‡ ä¸ªSFTæ•°æ®çš„ä¾‹å­ï¼š</p>
<section id="flan" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="flan"><span class="header-section-number">1.1.1</span> FLAN</h3>
<p>FLAN<span class="citation" data-cites="FlanCollectionDesigning2023longpre">(<a href="#ref-FlanCollectionDesigning2023longpre" role="doc-biblioref">Longpre et al. 2023</a>)</span> æ•°æ®æ˜¯æŠŠå¾ˆå¤š NLP ä»»åŠ¡ç”¨â€œè‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¨¡æ¿â€è¡¨è¾¾å‡ºæ¥ï¼Œç„¶åæŠŠæ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šåš <strong>instruction tuningï¼ˆæŒ‡ä»¤å¾®è°ƒï¼‰</strong>ï¼Œä»è€Œæå‡<strong>é›¶æ ·æœ¬æ³›åŒ–</strong> FLAN ç³»åˆ—çš„å…³é”®ä¸æ˜¯åŸå§‹ä»»åŠ¡ï¼Œè€Œæ˜¯ï¼š - æŠŠæ¯ä¸ªä»»åŠ¡å†™æˆè‹¥å¹²ç§ <strong>è‡ªç„¶è¯­è¨€æ¨¡æ¿</strong>ï¼ˆinstruction + input + outputï¼‰ - æ¨¡å‹è®­ç»ƒæ—¶çœ‹åˆ°çš„æ˜¯â€œåƒèŠå¤©æŒ‡ä»¤ä¸€æ ·çš„æ–‡æœ¬â€ï¼Œä½†èƒŒåå¾ˆå¤šæ˜¯åˆ†ç±»/æŠ½å–/QA/ç”Ÿæˆç­‰ä¼ ç»Ÿä»»åŠ¡</p>
<p>è®ºæ–‡æŠŠå®ƒç§°ä¸º â€œtasks formatted with instructionsâ€ çš„ instruction tuning</p>
<div id="fig-" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/flan-example-data.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: FLAN æ•°æ®ç¤ºä¾‹ï¼šæŠŠåˆ†ç±»ä»»åŠ¡å†™æˆâ€œæŒ‡ä»¤ + è¾“å…¥ + è¾“å‡ºâ€çš„å½¢å¼
</figcaption>
</figure>
</div>
</section>
<section id="alpaca" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="alpaca"><span class="header-section-number">1.1.2</span> Alpaca</h3>
<p><a href="https://huggingface.co/datasets/tatsu-lab/alpaca"><strong>Alpaca</strong></a> æ˜¯æ–¯å¦ç¦ CRFM / Tatsu-lab åœ¨ 2023 å¹´æå‡ºçš„ä¸€ä¸ªå¯å¤ç°è·¯çº¿ï¼š<br>
ç”¨ <strong>LLaMA-7B</strong> åšåŸºåº§ï¼Œæ‹¿ä¸€ä»½<strong>ç”±æ›´å¼ºæ¨¡å‹ç”Ÿæˆçš„æŒ‡ä»¤è·Ÿéšæ•°æ®ï¼ˆ52Kï¼‰</strong>åš SFTï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªâ€œåƒ ChatGPT ä¸€æ ·æ›´ä¼šå¬æŒ‡ä»¤â€çš„æ¨¡å‹ã€‚</p>
<p>å®ƒçš„æ•°æ®ç±»ä¼¼äºï¼š</p>
<div id="fig-" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/lec15-alpaca-example.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Alpaca æ•°æ®ç¤ºä¾‹ï¼šç»™å®šæŒ‡ä»¤ï¼Œç”Ÿæˆå¯¹åº”å›ç­”
</figcaption>
</figure>
</div>
<p>ä¸‹é¢æ˜¯Alpacaçš„Prompt Template</p>
<div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb1-1"><a href="#cb1-1"></a>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a>### Instruction:</span>
<span id="cb1-4"><a href="#cb1-4"></a>{instruction}</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a>### Input:</span>
<span id="cb1-7"><a href="#cb1-7"></a>{input}</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a>### Response:</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å­¦ä¼šäº†â€œçœ‹åˆ° instruction + input åï¼Œåº”è¯¥ç”Ÿæˆä»€ä¹ˆæ ·çš„ responseâ€ã€‚</p>
<p>Alpaca çš„æ•°æ®ç”ŸæˆåŸºæœ¬æ²¿ç€ <strong>Self-Instruct</strong> çš„æ€è·¯èµ°ï¼š</p>
<ul>
<li><strong>èµ·ç‚¹ï¼š175 æ¡äººå·¥å†™çš„ seed instruction-output pairs</strong>ï¼ˆæ¥è‡ª Self-Instruct çš„ seed setï¼‰<br>
</li>
<li>ç”¨ <strong>text-davinci-003</strong>ï¼ˆå½“æ—¶éå¸¸å¼ºçš„ teacherï¼‰ï¼š
<ol type="1">
<li><strong>ç”Ÿæˆæ›´å¤šæŒ‡ä»¤</strong>ï¼ˆç”¨ seed åš in-context ç¤ºä¾‹ï¼Œè®© teacher æ‰©å†™/å˜æ¢å‡ºæ–° instructionï¼‰</li>
<li>å†è®© teacher <strong>ä¸ºè¿™äº›æŒ‡ä»¤ç”Ÿæˆå›ç­”</strong>ï¼Œå¾—åˆ°â€œinstruction-following demonstrationsâ€<br>
æœ€ç»ˆå½¢æˆå¤§çº¦ <strong>52K</strong> æ¡æ•°æ®ã€‚</li>
</ol></li>
</ul>
<p>æ‰€ä»¥ Alpaca çš„æœ¬è´¨æ˜¯ï¼š<strong>ç”¨å¼ºæ¨¡å‹å½“â€œæ•°æ®å·¥å‚â€ï¼Œä½æˆæœ¬é€ å‡ºå¤§æ‰¹ instructionâ†’response çš„ SFT æ ·æœ¬</strong>ã€‚</p>
<div id="fig-alpaca-self-instruct" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alpaca-self-instruct-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/lec15-self-instruct.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alpaca-self-instruct-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Alpaca æ•°æ®ç”Ÿæˆæµç¨‹ç¤ºæ„ï¼šç”¨å¼ºæ¨¡å‹ï¼ˆtext-davinci-003ï¼‰åŸºäºå°‘é‡äººå·¥ç¤ºèŒƒï¼Œè‡ªåŠ¨ç”Ÿæˆå¤§è§„æ¨¡çš„æŒ‡ä»¤-å›ç­”å¯¹ï¼Œç”¨äºå¾®è°ƒåŸºç¡€æ¨¡å‹ï¼ˆLLaMA-7Bï¼‰ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—é™ä½äº†é«˜è´¨é‡ SFT æ•°æ®çš„è·å–æˆæœ¬ã€‚Image source <a href="https://github.com/yizhongw/self-instruct">Self-Instruct: Aligning LM with Self Generated Instructions</a>
</figcaption>
</figure>
</div>
</section>
<section id="openassistant" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="openassistant"><span class="header-section-number">1.1.3</span> OpenAssistant</h3>
<p><strong>OpenAssistant Conversations (OASST1)</strong><span class="citation" data-cites="OpenAssistantConversationsDemocratizing2023kopf">(<a href="#ref-OpenAssistantConversationsDemocratizing2023kopf" role="doc-biblioref">KÃ¶pf et al. 2023</a>)</span> æ˜¯ LAION ç»„ç»‡çš„å…¨çƒä¼—åŒ…é¡¹ç›®äº§å‡ºçš„ä¸€ä¸ª <strong>â€œåŠ©æ‰‹é£æ ¼ï¼ˆassistant-styleï¼‰å¯¹è¯è¯­æ–™â€</strong>ï¼Œç›®æ ‡æ˜¯æŠŠå¯¹é½ï¼ˆSFT / RLHFï¼‰ç ”ç©¶â€œæ°‘ä¸»åŒ–â€ï¼šæŠŠåŸæœ¬ç»å¸¸è¢«å¤§å‚ç§æœ‰åŒ–çš„é«˜è´¨é‡åå¥½/å¯¹è¯æ•°æ®å¼€æºå‡ºæ¥ã€‚å®ƒåŒ…å« <strong>161,443 æ¡æ¶ˆæ¯ã€35 ç§è¯­è¨€ã€è¶…è¿‡ 10,000 æ£µå®Œæ•´æ ‡æ³¨çš„å¯¹è¯æ ‘</strong>ï¼Œå¹¶é™„å¸¦å¤§é‡è´¨é‡è¯„åˆ†ã€‚</p>
<p>ç®€è¦æ¥è¯´ï¼Œæ•´ä¸ªæ•°æ®é›†ç”±ä¸€ç³»åˆ—å¯¹è¯æ ‘ï¼ˆConversation Tree, CTï¼‰ç»„æˆã€‚æ¯ä¸€æ£µæ ‘çš„æ ¹èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªåˆå§‹æç¤ºï¼ˆpromptï¼‰ï¼Œç”±â€œprompterâ€è§’è‰²ç»™å‡ºï¼›åœ¨å¯¹è¯ä¸­åªåŒºåˆ†ä¸¤ç§è§’è‰²ï¼š<strong>prompterï¼ˆæé—®æ–¹ï¼‰</strong>å’Œ assistantï¼ˆå›ç­”æ–¹ï¼‰ï¼Œè€Œâ€œuserâ€è¿™ä¸ªè¯ä»…ç”¨æ¥æŒ‡å‚ä¸æ•°æ®æ ‡æ³¨æˆ–è´¡çŒ®å†…å®¹çš„äººç±»ï¼Œä»¥é¿å…è§’è‰²æ¦‚å¿µæ··æ·†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸¤ç§è§’è‰²åœ¨åŸåˆ™ä¸Šæ—¢å¯ä»¥ç”±äººç±»å®Œæˆï¼Œä¹Ÿå¯ä»¥ç”±æ¨¡å‹ç”Ÿæˆã€‚</p>
<p>åœ¨å¯¹è¯æ ‘ä¸­ï¼š - æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€æ¡ä¹¦é¢æ¶ˆæ¯ï¼Œå¹¶æ˜ç¡®æ ‡æ³¨å…¶è§’è‰²ï¼ˆprompter æˆ– assistantï¼‰ã€‚ - æ¯ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªå­èŠ‚ç‚¹ï¼Œä¸”å­èŠ‚ç‚¹çš„è§’è‰²ä¸€å®šä¸çˆ¶èŠ‚ç‚¹ç›¸åï¼Œè¡¨ç¤ºåŒä¸€è½®å¯¹è¯ä¸‹çš„ä¸åŒå¯èƒ½å›å¤ã€‚ - ä»æ ¹èŠ‚ç‚¹åˆ°æ ‘ä¸­ä»»æ„èŠ‚ç‚¹çš„ä¸€æ¡è·¯å¾„ç§°ä¸ºä¸€ä¸ª threadï¼Œå®ƒå¯¹åº”ä¸€æ®µåˆæ³•çš„å®Œæ•´å¯¹è¯ï¼Œä½“ç°æé—®æ–¹ä¸åŠ©æ‰‹è½®æµå‘è¨€çš„è¿‡ç¨‹ã€‚ - æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šé™„å¸¦é¢å¤–æ ‡æ³¨ä¿¡æ¯ï¼Œä¾‹å¦‚äººå·¥æ ‡ç­¾ã€å…ƒæ•°æ®ï¼ˆé‡‡é›†æ—¶é—´ã€è¯­è¨€ç­‰ï¼‰ã€‚ - assistant èŠ‚ç‚¹è¿˜åŒ…å«æ’åºä¿¡æ¯ï¼ˆrankï¼‰ï¼Œç”¨äºè¡¨ç¤ºåœ¨åŒä¸€çˆ¶ prompt ä¸‹ï¼Œå¤šæ¡å€™é€‰å›å¤ä¹‹é—´çš„äººç±»åå¥½é¡ºåºï¼Œè¿™æ˜¯åç»­åå¥½å­¦ä¹ å’Œå¥–åŠ±å»ºæ¨¡çš„é‡è¦ä¿¡å·ã€‚</p>
<p>æ•´ä½“ä¸Šï¼Œè¿™ç§å¯¹è¯æ ‘ç»“æ„ä¸ä»…èƒ½è¡¨ç¤ºå¤šè½®å¯¹è¯ï¼Œè¿˜èƒ½è‡ªç„¶åœ°æ”¯æŒä¸€é—®å¤šç­” + äººç±»åå¥½æ’åºï¼Œéå¸¸é€‚åˆç”¨äºæŒ‡ä»¤å¾®è°ƒã€å¥–åŠ±æ¨¡å‹è®­ç»ƒä»¥åŠå¯¹é½ç ”ç©¶ã€‚</p>
<p>ä¸‹å›¾æ˜¯OpenAssistantæ•°æ®é›†çš„ä¸€ä¸ªå¯¹è¯æ ‘ç¤ºä¾‹ï¼š</p>
<div id="fig-openassistant-conversation-tree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-openassistant-conversation-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/OpenAssistatn-example.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-openassistant-conversation-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: OpenAssistant æ•°æ®é›†ä¸­çš„ä¸€ä¸ªå¯¹è¯æ ‘ç¤ºä¾‹ï¼Œå±•ç¤ºäº†ä»åˆå§‹æç¤ºï¼ˆpromptï¼‰åˆ°å¤šè½®äº¤äº’çš„å®Œæ•´å¯¹è¯ç»“æ„ã€‚æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€æ¡æ¶ˆæ¯ï¼Œå¹¶æ ‡æ³¨äº†è§’è‰²ï¼ˆprompter æˆ– assistantï¼‰åŠå…¶å¯¹åº”çš„å›å¤é€‰é¡¹å’Œåå¥½æ’åºä¿¡æ¯ã€‚
</figcaption>
</figure>
</div>
</section>
<section id="self-annotated-dataset" class="level3" data-number="1.1.4">
<h3 data-number="1.1.4" class="anchored" data-anchor-id="self-annotated-dataset"><span class="header-section-number">1.1.4</span> Self-Annotated Dataset</h3>
<p>åœ¨è¯¾å ‚ä¸Šï¼Œè¿˜ä¸€èµ·Labeläº†å‡ ä¸ªPromptsï¼Œ ä½†æ˜¯ä»è¿™äº›Promptsçš„ä¾‹å­ä¸­ï¼Œæ˜æ˜¾å¯ä»¥çœ‹å‡ºæœ‰å‡ ä¸ªé—®é¢˜ï¼š</p>
<ul>
<li>è´¨é‡æ–¹å·®æå¤§ï¼ˆhigh varianceï¼‰: åŒä¸€ä¸ª promptï¼Œæœ‰äººè®¤çœŸå†™é•¿æ–‡ã€æœ‰äººä¸€å¥è¯ã€æœ‰äººç›´æ¥å¥— ChatGPT æ¨¡æ¿ã€‚SFT ä¼šæŠŠè¿™ç§é£æ ¼å·®å¼‚å½“æˆâ€œéƒ½å¯¹â€çš„ç¤ºèŒƒå­¦è¿›å»ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºé£æ ¼ä¸ç¨³å®šã€‚</li>
<li>â€œå†™é•¿ã€å†™å¥½â€å¾ˆéš¾ â†’ æ•°æ®ä¼šåçŸ­æˆ–åæ¨¡æ¿: å¤§å¤šæ•°äººå†™ä¸å‡ºæŒç»­é«˜è´¨é‡é•¿å›ç­”ï¼›è¦ä¹ˆå¾ˆçŸ­ï¼Œè¦ä¹ˆç”¨å¥—è¯å¡«å……ã€‚æ¨¡å‹å­¦åˆ°çš„å¾€å¾€æ˜¯â€œæ¨¡æ¿åŒ–ç»“æ„â€ï¼Œä¸ä¸€å®šæ˜¯æ›´æœ‰ç”¨çš„å†…å®¹ã€‚</li>
<li>å®¹æ˜“äº§ç”Ÿâ€œé£æ ¼&gt;æ­£ç¡®æ€§â€çš„åç½®ï¼ˆlength/list bias: äººç±»å†™ä½œå¤©ç„¶å€¾å‘äºåˆ—ç‚¹ã€å†™å¾—æ›´é•¿æ˜¾å¾—æ›´â€œåƒç­”æ¡ˆâ€ã€‚æ¨¡å‹å­¦åˆ°çš„å¯èƒ½æ˜¯â€œå¤šå†™ã€åˆ—ç‚¹ã€å®¢æ°”â€è¿™ç§ç±»å‹ç­¾åï¼Œè€Œä¸æ˜¯â€œç®€æ´ä¸”å‡†ç¡®â€ã€‚</li>
</ul>
</section>
</section>
<section id="algorithm" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="algorithm"><span class="header-section-number">1.2</span> Algorithm</h2>
<p>åœ¨äº†è§£äº†SFTçš„Datasetä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒæ¨¡å‹äº†ã€‚å…¶å®SFTçš„ç®—æ³•å¾ˆç®€å•ï¼Œä¸Pre-Trainingçš„Objectä¸€æ ·ï¼Œéƒ½æ˜¯<strong>Next-Token-Prediction</strong>ï¼Œå…¶åŸºæœ¬çš„ä»£ç æ¡†æ¶æ˜¯ï¼štoken-level NLLï¼‰</p>
<p><span id="eq-sft-obj"><span class="math display">\[
\underset{\theta}{\max} \log p_{\theta}(y | x)
\tag{1}\]</span></span></p>
<p>ä»ä»£ç æ¥çœ‹ï¼Œå°±æ˜¯ç®€å•çš„å‡ æ­¥ï¼š</p>
<div id="c63566c8" class="cell">
<details open="" class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(train_steps):</span>
<span id="cb2-2"><a href="#cb2-2"></a>    batch <span class="op">=</span> <span class="bu">next</span>(train_dataloader)</span>
<span id="cb2-3"><a href="#cb2-3"></a>    </span>
<span id="cb2-4"><a href="#cb2-4"></a>    input_ids <span class="op">=</span> batch[<span class="st">'input_ids'</span>]</span>
<span id="cb2-5"><a href="#cb2-5"></a>    labels <span class="op">=</span> batch[<span class="st">'labels'</span>]</span>
<span id="cb2-6"><a href="#cb2-6"></a>    response_mask <span class="op">=</span> batch[<span class="st">'response_mask'</span>]</span>
<span id="cb2-7"><a href="#cb2-7"></a>    </span>
<span id="cb2-8"><a href="#cb2-8"></a>    output <span class="op">=</span> model(input_ids) </span>
<span id="cb2-9"><a href="#cb2-9"></a>    </span>
<span id="cb2-10"><a href="#cb2-10"></a>    loss <span class="op">=</span> loss_fn(output, input_ids, response_mask)</span>
<span id="cb2-11"><a href="#cb2-11"></a>    loss.backward()</span>
<span id="cb2-12"><a href="#cb2-12"></a>    </span>
<span id="cb2-13"><a href="#cb2-13"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒåŸºæœ¬ä¸Šä¸Pre-Trainingçš„Loss ç±»ä¼¼ï¼Œåªä¸è¿‡å°±æ˜¯å¤šäº†ä¸€ä¸ªResponse Mask.</p>
<div class="question foldable">
<div class="question-header foldable-header">
<p>Questionï¼šä¸ºä»€ä¹ˆè¦ mask promptï¼Ÿ</p>
</div>
<div class="question-container foldable-content">
<p>å› ä¸ºæˆ‘ä»¬å¸Œæœ›æ¨¡å‹å­¦çš„æ˜¯ï¼šâ€œçœ‹åˆ° prompt åï¼Œåº”è¯¥æ€ä¹ˆç­”â€, è€Œä¸æ˜¯ï¼šâ€œæŠŠ prompt ä¹ŸèƒŒä¸‹æ¥å¤ç°ä¸€éâ€ã€‚ é€šè¿‡maskæ‰ prompt éƒ¨åˆ†çš„ lossï¼Œæˆ‘ä»¬åªè®©æ¨¡å‹åœ¨ response éƒ¨åˆ†å­¦ä¹ é¢„æµ‹ï¼Œ å¹¶ä¸”é¿å…æ¨¡å‹è¿‡æ‹Ÿåˆ prompt å†…å®¹ã€‚</p>
</div>
</div>
<section id="mid-training" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="mid-training"><span class="header-section-number">1.2.1</span> Mid-Training</h3>
<p>æ—¢ç„¶SFTå’ŒPre-Trainingçš„è®­ç»ƒç›®æ ‡ä¸€è‡´ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä¸å¯ä»¥å°†SFTçš„è®­ç»ƒæ··åˆåˆ°Pre-Trainingå½“ä¸­å‘¢ï¼Ÿç­”æ¡ˆæ˜¯å¯ä»¥çš„ï¼Œè¿™ä¹Ÿå°±æ˜¯æ‰€è°“çš„<strong>Mid-Training</strong>/<strong>Two-Phase Training</strong></p>
<p>åœ¨è¿™ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸»è¦åš3ä»¶äº‹ï¼š</p>
<ol type="1">
<li>å…ˆæ­£å¸¸åšé¢„è®­ç»ƒï¼ˆPre-train on web/pretraining dataï¼‰ åœ¨Common Crawl / books / code / papers ç­‰å¤§è§„æ¨¡è¯­æ–™ä¸­è®­ç»ƒï¼Œç›®æ ‡æ˜¯ next-token predictionã€‚</li>
<li>åœ¨é¢„è®­ç»ƒçš„ååŠæ®µï¼ŒæŠŠ instruction-tuning æ•°æ®æ··è¿›å»ï¼ˆMix in instruction-tuning data into pre-trainingï¼‰å…³é”®ç‚¹æ˜¯ï¼š
<ul>
<li>ä¸æ˜¯ç­‰é¢„è®­ç»ƒç»“æŸå†å•ç‹¬ SFT</li>
<li>å½“æ¨¡å‹å·²ç»æœ‰ä¸€å®šèƒ½åŠ›ã€å­¦ä¹ ç‡å¼€å§‹ä¸‹é™ï¼ˆè¿›å…¥ decay / anneal é˜¶æ®µï¼‰æ—¶ï¼Œ ç»§ç»­ç”¨â€œé¢„è®­ç»ƒæ•°æ®â€ä¿æŒé€šç”¨èƒ½åŠ›</li>
<li>åŒæ—¶åŠ å¤§â€œé«˜è´¨é‡/æŒ‡ä»¤/å¯¹è¯/æ¨ç†â€æ•°æ®çš„æ¯”ä¾‹ï¼Œè®©æ¨¡å‹åœ¨è¿˜å¤„åœ¨â€œé¢„è®­ç»ƒä¼˜åŒ–çŠ¶æ€â€æ—¶å°±é€æ¸å­¦ä¼šæŒ‡ä»¤è·Ÿéšçš„åˆ†å¸ƒ</li>
<li>è¿™ä¸€æ­¥æœ¬è´¨ä¸Šï¼šè¿˜æ˜¯ next-token lossï¼Œåªæ˜¯æ•°æ®åˆ†å¸ƒå˜äº†ã€‚</li>
</ul></li>
<li>æœ€åå†åšä¸€ä¸ªå¾ˆçŸ­çš„çœŸæ­£ instruction tuningï¼šç”±äºç¬¬äºŒæ­¥å·²ç»æŠŠâ€œæŒ‡ä»¤åˆ†å¸ƒâ€æ·±åº¦èè¿›æ¨¡å‹äº†ï¼Œæœ€åçš„çº¯ SFT å¾€å¾€å¯ä»¥æ›´çŸ­ã€æ›´åƒâ€œæ ¡å‡†/æ”¶å°¾â€ã€‚</li>
</ol>
<p>é€šè¿‡è¿™ä¸ªåšæ³•çš„å¥½å¤„å°±æ˜¯ï¼š<u>è®©æ¨¡å‹èƒ½åœ¨ä¸ä¸¥é‡ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰çš„æƒ…å†µä¸‹ï¼ŒæŠŠ instruction tuning æ‰©å¤§è§„æ¨¡.</u></p>
<p>æˆ‘ä»¬æ¥å¯¹æ¯”ä¸€ä¸‹ä¼ ç»Ÿ SFT å’Œ Mid-Training çš„åŒºåˆ«ï¼š</p>
<ul>
<li><strong>ä¼ ç»Ÿåšæ³•ï¼šå…ˆé¢„è®­ç»ƒå®Œï¼Œå† SFT</strong> ï¼šSFT æ•°æ®é‡è™½ç„¶å°ï¼Œä½†æ¢¯åº¦ä¿¡å·å¾ˆé›†ä¸­ã€é£æ ¼å¼ºï¼Œä¼šæŠŠæ¨¡å‹â€œæ‹‰â€åˆ°å¾ˆçª„çš„åˆ†å¸ƒä¸Šã€‚<br>
å¦‚æœä½  SFT è¿‡æ‹Ÿåˆï¼ˆå­¦ä¹ ç‡å¤§/æ­¥æ•°å¤š/æ•°æ®åˆ†å¸ƒå¤ªåï¼‰ï¼Œå°±å®¹æ˜“ï¼š
<ul>
<li>é€šç”¨èƒ½åŠ›ä¸‹é™ï¼ˆé—å¿˜é¢„è®­ç»ƒé‡Œå­¦åˆ°çš„å¹¿æ³›çŸ¥è¯†/è¯­è¨€èƒ½åŠ›ï¼‰</li>
<li>è¿‡æ‹ŸåˆæŸç§é£æ ¼ï¼ˆæ›´å•°å—¦ã€æ›´çˆ±åˆ—ç‚¹ã€æ›´çˆ±æ¨¡æ¿åŒ–ï¼‰</li>
</ul></li>
<li><strong>Mid-Trainingï¼šé¢„è®­ç»ƒåæœŸé€æ­¥åŠ æŒ‡ä»¤æ•°æ®</strong> ï¼šå› ä¸ºé¢„è®­ç»ƒæ•°æ®è¿˜åœ¨ã€å­¦ä¹ ç‡ä¹Ÿåœ¨ decayï¼Œæ¨¡å‹è¢«â€œæ¸©å’Œåœ°â€å¼•å¯¼åˆ°æŒ‡ä»¤åˆ†å¸ƒï¼Œ
<ul>
<li><strong>ä¸ä¼šä¸€ä¸‹å­è¢« SFT çš„å¼ºåˆ†å¸ƒå†²åˆ·</strong>ã€‚<br>
</li>
<li>åŒæ—¶å¯ä»¥æŠŠ instruction æ•°æ®è§„æ¨¡åšå¤§ï¼ˆç”šè‡³åˆ°â€œåƒé¢„è®­ç»ƒä¸€æ ·å¤§â€ï¼‰ï¼Œè€Œä¸ç”¨æ‹…å¿ƒå½»åº•æŠŠæ¨¡å‹è®­åã€‚</li>
</ul></li>
</ul>
<p>é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œ<strong>ä¿®æ”¹ä¸åŒé˜¶æ®µçš„æ•°æ®æ¯”ä¾‹</strong>å³å¯ï¼Œæ¯”å¦‚ï¼š</p>
<ul>
<li>è®­ç»ƒè¿›åº¦å‰ 70%ï¼šå‡ ä¹å…¨æ˜¯é¢„è®­ç»ƒæ•°æ®</li>
<li>å 30%ï¼ˆå­¦ä¹ ç‡å¼€å§‹è¡°å‡ï¼‰ï¼šé€æ­¥æé«˜ instruction/é«˜è´¨é‡æ•°æ®å æ¯”ï¼šä¾‹å¦‚ä» 0% â†’ 10% â†’ 30% â†’ 50%</li>
<li>è®­ç»ƒæœ«å°¾ï¼šå†åšå°‘é‡çº¯ SFTï¼ˆæ›´åƒâ€œå¯¹é½æ”¶å°¾â€ï¼‰</li>
</ul>
<div id="fig-mid-training-data-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mid-training-data-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/mid-training-data-dist.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mid-training-data-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: è¿™å¼ å›¾è¯´æ˜å¾ˆå¤šæ¨¡å‹ä¼šæŠŠâ€œæŒ‡ä»¤å¾®è°ƒæ•°æ®â€æå‰æ··è¿›é¢„è®­ç»ƒçš„åæœŸï¼ˆdecay/mid-trainingï¼‰ï¼Œè®©æ•°æ®é…æ–¹ä»â€œçº¯ç½‘é¡µé¢„è®­ç»ƒâ€ï¼ˆå·¦å›¾ï¼‰é€æ­¥å˜æˆâ€œé¢„è®­ç»ƒè¯­æ–™ + å„ç±»SFT/é«˜è´¨é‡æŒ‡ä»¤æ•°æ®çš„æ··åˆâ€ï¼ˆå³å›¾ï¼‰ï¼Œä»è€Œæ›´è§„æ¨¡åŒ–åœ°è·å¾—æŒ‡ä»¤è·Ÿéšèƒ½åŠ›å¹¶å‡å°‘ç¾éš¾æ€§é—å¿˜ã€‚
</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="rlhf" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> RLHF</h1>
<p>åœ¨å‰åŠæ®µï¼Œæˆ‘ä»¬å­¦ä¹ äº†SFTï¼Œå›é¡¾ä¸€ä¸‹SFTï¼Œå°±æ˜¯ä½ æœ‰ï¼ˆprompt, ideal responseï¼‰ç¤ºèŒƒæ•°æ®ï¼Œæœ¬è´¨æ˜¯åœ¨åšï¼Œæœ€å¤§åŒ–Next-Token-Predictionçš„ç›®æ ‡ <a href="#eq-sft-obj" class="quarto-xref">Equation&nbsp;1</a>ã€‚</p>
<p>åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œè¿™å«ä¹Ÿå«åšåš<strong>Imitation Learning</strong>ã€‚</p>
<div class="tip foldable is-open">
<div class="tip-header foldable-header">
<p>TIP: What is Imitation Learning?</p>
</div>
<div class="tip-container foldable-content">
<p>Imitation Learnings æ˜¯é€šè¿‡å­¦ä¹ ä¸“å®¶ç¤ºèŒƒæ•°æ®ï¼ˆstate/action æˆ– prompt/responseï¼‰ï¼Œç›´æ¥æ‹Ÿåˆâ€œåº”è¯¥æ€ä¹ˆåšâ€ï¼Œè€Œä¸æ˜¯é€šè¿‡è¯•é”™æ¥ä¼˜åŒ–å¥–åŠ±ã€‚ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬æœ‰ä¸“å®¶ç¤ºèŒƒæ•°æ® <span class="math inline">\(\mathcal{D} = \{(s_1, a_1), (s_2, a_2), \ldots (s_n, a_n)\}\)</span>ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–ï¼š <span class="math display">\[
\underset{\theta}{\max} \sum_{(s, a) \in \mathcal{D}} \log \pi_{\theta}(a | s)
\]</span></p>
</div>
</div>
<p>æˆ‘ä»¬ä¹Ÿæåˆ°äº†è¿™ç§æ–¹æ³•å­˜åœ¨æ˜æ˜¾çš„å‡ ä¸ªé—®é¢˜ï¼Œå…¶ä¸­åŒ…æ‹¬Datasetçš„éš¾ä»¥æ”¶é›†ï¼Œåç½®ä¼šè¢«æ”¾å¤§ï¼ˆstyle/length/list biasï¼‰ç­‰ã€‚å› æ­¤æˆ‘ä»¬å°±ä»SFTï¼ˆImitation Learningï¼‰èµ°å‘äº†Reinforcement Learningï¼ˆOptimizationï¼‰ã€‚ å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æŠŠLMå½“ä½œä¸€ä¸ªPolicy <span class="math inline">\(\pi_{\theta}( y| x)\)</span>, ç›®æ ‡æ˜¯æœ€å¤§åŒ–ï¼š</p>
<p><span id="eq-rlhf-obj"><span class="math display">\[
\underset{\theta}{\max} \mathbb{E}_{y \sim \pi_{\theta}( \cdot | x)}[r(x, y)]
\tag{2}\]</span></span></p>
<p>é€šè¿‡æ”¹å˜æˆ‘ä»¬çš„è®­ç»ƒç›®æ ‡ï¼Œæˆ‘ä»¬ä¸å†éœ€è¦æ¯ä¸ª prompt çš„æ ‡å‡†ç­”æ¡ˆï¼Œè€Œæ˜¯æ”¶é›†ï¼š</p>
<ul>
<li>ç»™åŒä¸€ä¸ª prompt <span class="math inline">\(x\)</span>ï¼Œæ¨¡å‹ç”Ÿæˆå¤šä¸ªå›ç­” <span class="math inline">\(y_1, y_2\)</span>ï¼ˆrolloutsï¼‰</li>
<li>æ ‡æ³¨è€…åªåšåˆ¤æ–­ï¼šå“ªä¸ªæ›´å¥½(pairwise preference), <span class="math inline">\(y^+ \succ y^-\)</span></li>
</ul>
<p>é€šè¿‡è¿™ç§è®­ç»ƒç›®æ ‡çš„æ”¹å˜ï¼Œæˆ‘ä»¬å¯ä»¥èŠ‚çœè®¸å¤šçš„è´¹ç”¨ã€‚</p>
<p>å¹¶ä¸”ï¼Œè¿™ç§æ–¹æ³•ä¹Ÿæ›´ç¬¦åˆäººç±»çš„è®¤çŸ¥ä¹ æƒ¯ï¼Œ<strong>G-V gap (Generation-Validation gap)</strong> å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼š</p>
<div id="fig-gv-gap" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gv-gap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/lec15-gv-gap.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gv-gap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: å›¾é‡Œæ¯ä¸ª annotator çš„åå¥½æ¡å½¢å›¾æ˜¾ç¤ºï¼šæœ‰äººæ˜æ˜¾æ›´åå‘ <strong>Instruct Davinci summaries</strong>ï¼Œè€Œæ€»ä½“åå¥½æ¥è¿‘ 50/50ï¼Œä¸”ä¸€è‡´æ€§ <span class="math inline">\(\alpha\)</span> å¾ˆä½ï¼Œè¯´æ˜åå¥½å·®å¼‚/è‡ªæˆ‘ä¸ä¸€è‡´å¾ˆæ˜æ˜¾ã€‚
</figcaption>
</figure>
</div>
<p>ç”¨ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼š <strong>â€œç”Ÿæˆâ€ä¸€ä¸ªé«˜è´¨é‡ç­”æ¡ˆå¾ˆéš¾ä¸”ä¸ç¨³å®šï¼Œä½†â€œéªŒè¯/æ¯”è¾ƒâ€å“ªä¸ªæ›´å¥½ç›¸å¯¹å®¹æ˜“</strong>ï¼Œå› æ­¤ RLHF é€šè¿‡åå¥½æ¯”è¾ƒæ¥ä¼˜åŒ–æ¨¡å‹æ›´ç¬¦åˆäººç±»çœŸæ­£çš„åå¥½ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å…·ä½“çœ‹çœ‹RLHFæ˜¯ä¸ªä»€ä¹ˆä¸œè¥¿ï¼Œä¸SFTç±»ä¼¼ï¼Œæˆ‘ä»¬ä¸»è¦è¿˜æ˜¯é€šè¿‡ä¸¤ä¸ªæ–¹é¢ï¼š<strong>æ•°æ®</strong>å’Œ<strong>ç®—æ³•</strong>ï¼Œå¹¶ä¸”åœ¨æœ€åçœ‹çœ‹RLHFå­˜åœ¨ä»€ä¹ˆç¼ºç‚¹</p>
<section id="rlhf-data" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="rlhf-data"><span class="header-section-number">2.1</span> RLHF Data</h2>
<p>è¯¾ä¸Šæåˆ° InstructGPT çš„æ ‡æ³¨å‡†åˆ™å¾ˆç»å…¸ï¼š<strong>helpfulã€truthfulã€harmless</strong>ã€‚<br>
å®é™…æ ‡æ³¨ç•Œé¢é€šå¸¸å°±æ˜¯ï¼š</p>
<ul>
<li>A vs B å“ªä¸ªæ›´å¥½ï¼Ÿï¼ˆæˆ– 4 é€‰ 1 / ties ç­‰ï¼‰</li>
<li>æœ‰æ—¶è¿˜ä¼šåˆ†åˆ«æ‰“åˆ†ï¼šäº‹å®æ€§ã€éµå¾ªæŒ‡ä»¤ã€å®‰å…¨æ€§ã€å†™ä½œè´¨é‡ç­‰</li>
</ul>
<p>ä¸è¿‡éœ€è¦æ³¨æ„çš„æ˜¯ï¼š<strong>è¿™ä¸æ˜¯â€œå¯¹é”™é¢˜â€</strong>ï¼Œå¾ˆå¤šä»»åŠ¡æ˜¯å¼€æ”¾å¼åå¥½ã€‚</p>
<p>æœ‰äº†è¿™äº›æ•°æ®ä¹‹åï¼Œæˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªReward Model <span class="math inline">\(r_{\phi}(x, y)\)</span>. æ¯ä¸ªå›ç­”éƒ½æœ‰ä¸€ä¸ªéšè—åˆ†æ•°ï¼Œæ ‡æ³¨è€…æ›´å¸¸é€‰åˆ†é«˜çš„ã€‚<br>
ç”¨ä¸€ä¸ª logistic/softmax å½¢å¼æ‹Ÿåˆï¼š</p>
<p><span id="eq-reward-model-preference"><span class="math display">\[
P(y^+ \succ y^- \mid x) = \sigma\big(r_\phi(x,y^+) - r_\phi(x,y^-)\big)
\tag{3}\]</span></span></p>
<p>äºæ˜¯ä½ çš„ RLHF æ•°æ®å°±å˜æˆ reward model çš„ç›‘ç£æ•°æ®:</p>
<p><span id="eq-reward-model-obj"><span class="math display">\[
\underset{\phi}{\max} \sum_{(x, y^+, y^-) \in D} \log \sigma\big(r_\phi(x,y^+) - r_\phi(x,y^-)\big)
\tag{4}\]</span></span></p>
<p>è®­ç»ƒå®Œæˆåï¼Œå°±æœ‰äº†ä¸€ä¸ª reward modelï¼Œå¯ä»¥ç»™ä»»æ„ (x, y) å¯¹æ‰“åˆ†ï¼š <span class="math inline">\(r_{\phi}(x, y)\)</span>ã€‚</p>
<p>å½“ç„¶ï¼Œè¿™ä¸ªæµç¨‹çœ‹ä¼¼ç®€å•ï¼Œå®é™…ä¸Šè¿˜æ˜¯æœ‰å¾ˆå¤šè€ƒé‡çš„ï¼š</p>
<ul>
<li><strong>æ•°æ®è´¨é‡</strong>ï¼šæ ‡æ³¨è€…åŸ¹è®­ã€å®¡æ ¸ã€åˆ†å¸ƒè¦†ç›–ã€åè§æ§åˆ¶ç­‰</li>
<li><strong>æ•°æ®å¤šæ ·æ€§</strong>ï¼šprompt ç±»å‹ã€å›ç­”é£æ ¼ã€éš¾åº¦ç­‰</li>
<li><strong>æ¨¡å‹æ¶æ„</strong>ï¼šreward model é€šå¸¸æ˜¯ä¸€ä¸ªå°å‹ LMï¼Œæˆ–è€…åœ¨ LM ä¸ŠåŠ ä¸ªå¤´</li>
</ul>
</section>
<section id="rlhf-algorithms" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="rlhf-algorithms"><span class="header-section-number">2.2</span> RLHF Algorithms</h2>
<p>æœ‰äº†Pair-Wise çš„Datasetå’ŒReward Modelä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒçš„æˆ‘ä»¬çš„æ¨¡å‹äº†ã€‚åœ¨InstructGPT<span class="citation" data-cites="TrainingLanguageModels2022ouyang">(<a href="#ref-TrainingLanguageModels2022ouyang" role="doc-biblioref">Ouyang et al. 2022</a>)</span> ä¸­ï¼Œä¸»è¦ç”¨çš„æ˜¯PPOçš„ç®—æ³•ã€‚ æ¥ä¸‹æ¥çœ‹çœ‹PPOçš„å…·ä½“å†…å®¹ã€‚</p>
</section>
<section id="ppo" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="ppo"><span class="header-section-number">2.3</span> PPO</h2>
<p>å›é¡¾ä¸€ä¸‹ï¼Œçœ‹ä¸€ä¸‹æˆ‘ä»¬ç°åœ¨æ‰‹å¤´ä¸Šæœ‰äº›ä»€ä¹ˆä¸œè¥¿ï¼š</p>
<ul>
<li>ä¸€ä¸ªåˆå§‹åŒ–çš„ç­–ç•¥æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ <strong>SFT æ¨¡å‹</strong>ï¼‰<span class="math inline">\(\pi_{\text{ref}}(y|x)\)</span>ï¼ˆä½œä¸ºå‚è€ƒç­–ç•¥/åŸºçº¿ï¼‰</li>
<li>ä¸€ä¸ªå¥–åŠ±å‡½æ•°/å¥–åŠ±æ¨¡å‹ <span class="math inline">\(r_{\phi}(x,y)\)</span>ï¼ˆç”±åå¥½æ•°æ®è®­ç»ƒå‡ºæ¥ï¼‰</li>
<li>è¦è®­ç»ƒçš„ç­–ç•¥ <span class="math inline">\(\pi_\theta(y|x)\)</span>, (ç”±LLMåˆå§‹åŒ–)</li>
</ul>
<p>RLHF-PPO çš„æ ¸å¿ƒç›®æ ‡å°±æ˜¯ï¼š</p>
<p><span id="eq-rlhf-ppo-obj"><span class="math display">\[
\underset{\theta}{\max}  \mathcal{J}(\theta) = \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\big[r_\phi(x,y)\big] \ -\ \beta \, \mathrm{KL}\big(\pi_\theta(\cdot|x)\ \|\ \pi_{\text{ref}}(\cdot|x)\big)
\tag{5}\]</span></span></p>
<p>é€šè¿‡è¿™ä¸ªç›®æ ‡å‡½æ•°ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹ï¼š <strong>å›ç­”æ›´â€œé«˜å¥–åŠ±â€ï¼Œä½†åˆ«åç¦» SFT å¤ªè¿œ</strong>ï¼ˆKL çº¦æŸé˜²æ­¢è·‘é£ã€å­¦ä¼šä½œå¼Šæˆ–å˜å¾—æ€ªå¼‚/ä¸å®‰å…¨ï¼‰ã€‚</p>
<section id="reinforce" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="reinforce"><span class="header-section-number">2.3.1</span> REINFORCE</h3>
<p>åœ¨Neural Networkä¸­ï¼Œæˆ‘ä»¬ä¼˜åŒ–ç›®æ ‡é€šå¸¸ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è®¡ç®—ä¸Šé¢ç›®æ ‡çš„æ¢¯åº¦ã€‚å¯¹äºDeep RLä¹Ÿä¸ä¾‹å¤–ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡ºè¿™ä¸ªObject Function (<a href="#eq-rlhf-ppo-obj" class="quarto-xref">Equation&nbsp;5</a>) çš„æ¢¯åº¦:</p>
<p><span id="eq-reinforce"><span class="math display">\[
\nabla_\theta \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\big[r_\phi(x,y)\big] = \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\left[r_\phi(x,y) \, \nabla_\theta \log \pi_\theta(y|x)\right]
\tag{6}\]</span></span></p>
<p>é€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºæ¢¯åº¦ï¼Œç„¶åç”¨SGDæ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè¿™ä¹Ÿå°±æ˜¯<strong>REINFORCE</strong>ç®—æ³•ã€‚ åœ¨å®é™…æ“ä½œä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡Samplingçš„æ–¹å¼æ¥ä¼°è®¡ä¸Šé¢çš„æœŸæœ›ï¼š</p>
<p><span id="eq-reinforce-sampling"><span class="math display">\[
\nabla_\theta \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\big[r_\phi(x,y)\big] \approx \frac{1}{N} \sum_{i=1}^N r_\phi(x,y_i) \, \nabla_\theta \log \pi_\theta(y_i|x), \quad y_i \sim \pi_\theta(\cdot|x)
\tag{7}\]</span></span></p>
<p>ä½†æ˜¯REINFORCEæœ‰ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š</p>
<ol type="1">
<li><strong>High variance</strong>ï¼šå¥–åŠ±ä¿¡å·å¾€å¾€å¾ˆç¨€ç–ä¸”å™ªå£°å¤§ï¼Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡æ–¹å·®å¾ˆé«˜ï¼Œè®­ç»ƒä¸ç¨³å®šã€‚</li>
<li><strong>å•æ­¥æ›´æ–°</strong>ï¼šREINFORCE æ¯æ¬¡æ›´æ–°éƒ½åŸºäºå½“å‰ç­–ç•¥é‡‡æ ·çš„æ•°æ®ï¼Œä¸èƒ½å¤šæ­¥åˆ©ç”¨æ—§æ•°æ®ï¼Œæ•ˆç‡ä½ã€‚</li>
</ol>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”é€æ­¥å¼•å‡ºPPOç®—æ³•ã€‚</p>
</section>
<section id="variance-reduction-with-advantage-function" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="variance-reduction-with-advantage-function"><span class="header-section-number">2.3.2</span> Variance Reduction with Advantage Function</h3>
<p>æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹ä¸ºä»€ä¹ˆä¼šæœ‰High Varianceçš„é—®é¢˜ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æŠŠå›ç­” <span class="math inline">\(y\)</span> çœ‹æˆä¸€ä¸ªåºåˆ—çš„åŠ¨ä½œ <span class="math inline">\((a_1, a_2, \ldots, a_T)\)</span>ï¼Œæ¯ä¸ªåŠ¨ä½œå¯¹åº”ç”Ÿæˆä¸€ä¸ª tokenã€‚ é‚£ä¹ˆæ ¹æ®é“¾å¼æ³•åˆ™ï¼Œå›ç­”çš„æ¦‚ç‡å¯ä»¥å†™æˆï¼š <span id="eq-policy-chain-rule"><span class="math display">\[
\pi_\theta(y|x) = \prod_{t=1}^T \pi_\theta(a_t | s_t)
\tag{8}\]</span></span></p>
<p>å…¶ä¸­ <span class="math inline">\(s_t\)</span> æ˜¯ç”Ÿæˆç¬¬ <span class="math inline">\(t\)</span> ä¸ª token æ—¶çš„çŠ¶æ€ï¼ˆåŒ…æ‹¬ prompt å’Œå‰é¢ç”Ÿæˆçš„ tokensï¼‰ã€‚ æ ¹æ® REINFORCE çš„æ¢¯åº¦å…¬å¼ <a href="#eq-reinforce" class="quarto-xref">Equation&nbsp;6</a>ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å±•å¼€æˆå¯¹æ¯ä¸ªæ—¶é—´æ­¥çš„è´¡çŒ®æ±‚å’Œï¼š <span id="eq-reinforce-sequence"><span class="math display">\[
\nabla_\theta \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\big[r_\phi(x,y)\big] = \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\left[r_\phi(x,y) \sum_{t=1}^T \nabla_\theta \log \pi_\theta(a_t | s_t)\right]
\tag{9}\]</span></span></p>
<p>è¿™é‡Œçš„å…³é”®é—®é¢˜æ˜¯ï¼š<strong>å¥–åŠ± <span class="math inline">\(r_\phi(x,y)\)</span> æ˜¯å¯¹æ•´ä¸ªåºåˆ— <span class="math inline">\(y\)</span> çš„è¯„ä»·</strong>ï¼Œä½†æˆ‘ä»¬æŠŠå®ƒç›´æ¥ç”¨åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦ä¸Šï¼Œå¯¼è‡´æ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦ä¼°è®¡éƒ½åŒ…å«äº†æ•´ä¸ªåºåˆ—çš„å™ªå£°ï¼Œæ–¹å·®å¾ˆå¤§ã€‚</p>
<p>ä¸ºäº†é™ä½æ¢¯åº¦ä¼°è®¡çš„æ–¹å·®ï¼Œæˆ‘ä»¬å¼•å…¥<strong>ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantage Functionï¼‰</strong> <span class="math inline">\(A_t\)</span>ï¼Œå®ƒè¡¡é‡åœ¨çŠ¶æ€ <span class="math inline">\(s_t\)</span> ä¸‹é‡‡å–åŠ¨ä½œ <span class="math inline">\(a_t\)</span> ç›¸å¯¹äºå¹³å‡æ°´å¹³çš„å¥½åï¼š</p>
<p><span id="eq-advantage-function"><span class="math display">\[
A_t = Q(s_t, a_t) - V(s_t)
\tag{10}\]</span></span></p>
<p>å…¶ä¸­ <span class="math inline">\(Q(s_t, a_t)\)</span> æ˜¯åœ¨çŠ¶æ€ <span class="math inline">\(s_t\)</span> ä¸‹é‡‡å–åŠ¨ä½œ <span class="math inline">\(a_t\)</span> åçš„é¢„æœŸå›æŠ¥ï¼Œ<span class="math inline">\(V(s_t)\)</span> æ˜¯çŠ¶æ€ <span class="math inline">\(s_t\)</span> çš„å¹³å‡å›æŠ¥ã€‚ é€šè¿‡ä½¿ç”¨ä¼˜åŠ¿å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å…¬å¼æ”¹å†™ä¸ºï¼š <span id="eq-reinforce-advantage"><span class="math display">\[
\nabla_\theta \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\big[r_\phi(x,y)\big] = \mathbb{E}_{y\sim \pi_\theta(\cdot|x)}\left[\sum_{t=1}^T A_t \, \nabla_\theta \log \pi_\theta(a_t | s_t)\right]
\tag{11}\]</span></span></p>
<p>è¿™æ ·ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦åªå—åˆ°è¯¥æ—¶é—´æ­¥ä¼˜åŠ¿ <span class="math inline">\(A_t\)</span> çš„å½±å“ï¼Œå‡å°‘äº†æ•´ä¸ªåºåˆ—å¥–åŠ±å¸¦æ¥çš„å™ªå£°ï¼Œä»è€Œé™ä½äº†æ–¹å·®ã€‚</p>
</section>
<section id="off-policy-updates" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="off-policy-updates"><span class="header-section-number">2.3.3</span> Off-Policy Updates</h3>
<p>REINFORCE çš„å¦ä¸€ä¸ªé—®é¢˜æ˜¯å®ƒæ˜¯<strong>on-policy</strong>çš„ï¼šæ¯æ¬¡æ›´æ–°éƒ½éœ€è¦ç”¨å½“å‰ç­–ç•¥é‡‡æ ·æ–°æ•°æ®ï¼Œä¸èƒ½å¤šæ¬¡åˆ©ç”¨æ—§æ•°æ®ï¼Œæ•ˆç‡ä½ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨<strong>ç¦»çº¿æ•°æ®é‡ç”¨ï¼ˆoff-policy updatesï¼‰</strong>çš„æ€æƒ³ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ä¿å­˜ä¹‹å‰é‡‡æ ·çš„æ•°æ®ï¼ˆprompts å’Œç”Ÿæˆçš„å›ç­”ï¼‰ï¼Œå¹¶åœ¨å¤šæ¬¡è¿­ä»£ä¸­é‡å¤ä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡Œæ›´æ–°ã€‚</p>
<p>ä½†æ˜¯ç›´æ¥ä½¿ç”¨æ—§æ•°æ®ä¼šå¼•å…¥åå·®ï¼Œå› ä¸ºè¿™äº›æ•°æ®æ˜¯æ ¹æ®æ—§ç­–ç•¥ <span class="math inline">\(\pi_{\theta_{\text{old}}}\)</span> é‡‡æ ·çš„ï¼Œè€Œæˆ‘ä»¬ç°åœ¨è¦æ›´æ–°çš„æ˜¯æ–°ç­–ç•¥ <span class="math inline">\(\pi_\theta\)</span>ã€‚ ä¸ºäº†çº æ­£è¿™ç§åå·®ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<strong>é‡è¦æ€§é‡‡æ ·ï¼ˆimportance samplingï¼‰</strong>ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªå›ç­”åœ¨æ–°æ—§ç­–ç•¥ä¸‹çš„æ¦‚ç‡æ¯”æ¥è°ƒæ•´æ¢¯åº¦ä¼°è®¡ï¼š</p>
<p><span id="eq-importance-sampling"><span class="math display">\[
\rho(y) = \frac{\pi_\theta(y|x)}{\pi_{\theta_{\text{old}}}(y|x)}
\tag{12}\]</span></span></p>
<p>ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å…¬å¼æ”¹å†™ä¸ºï¼š <span id="eq-off-policy-gradient"><span class="math display">\[
\nabla_\theta \mathbb{E}_{y\sim \pi_{\theta_{\text{old}}}(\cdot|x)}\big[r_\phi(x,y)\big] = \mathbb{E}_{y\sim \pi_{\theta_{\text{old}}}(\cdot|x)}\left[\rho(y) \sum_{t=1}^T A_t \, \nabla_\theta \log \pi_\theta(a_t | s_t)\right]
\tag{13}\]</span></span></p>
<p>è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¤šæ¬¡åˆ©ç”¨æ—§æ•°æ®è¿›è¡Œæ›´æ–°ï¼Œæé«˜æ•°æ®æ•ˆç‡ã€‚</p>
</section>
<section id="proximal-policy-optimization-ppo" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="proximal-policy-optimization-ppo"><span class="header-section-number">2.3.4</span> Proximal Policy Optimization (PPO)</h3>
<p>ç»“åˆä¸Šé¢çš„ä¸¤ä¸ªæ”¹è¿›ï¼Œæˆ‘ä»¬å°±å¼•å‡ºäº†<strong>PPOï¼ˆProximal Policy Optimizationï¼‰</strong>ç®—æ³•ã€‚PPO é€šè¿‡é™åˆ¶æ–°æ—§ç­–ç•¥çš„å˜åŒ–å¹…åº¦ï¼Œè¿›ä¸€æ­¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼ŒPPO ä½¿ç”¨ä¸€ä¸ª<strong>è£å‰ªç›®æ ‡ï¼ˆclipped objectiveï¼‰</strong>ï¼Œé˜²æ­¢ç­–ç•¥æ›´æ–°è¿‡å¤§ï¼š</p>
<p><span id="eq-ppo-clip"><span class="math display">\[
L^{\text{clip}}(\theta) = \mathbb{E}_{y\sim \pi_{\theta_{\text{old}}}(\cdot|x)}\left[\min\left(\rho(y) A, \text{clip}(\rho(y), 1-\epsilon, 1+\epsilon) A\right)\right]
\tag{14}\]</span></span> å…¶ä¸­ <span class="math inline">\(\epsilon\)</span> æ˜¯ä¸€ä¸ªå°çš„è¶…å‚æ•°ï¼Œæ§åˆ¶è£å‰ªèŒƒå›´(é€šå¸¸æ˜¯0.1åˆ°0.3)ã€‚ é€šè¿‡è¿™ä¸ªè£å‰ªç›®æ ‡ï¼ŒPPO ä¿è¯äº†æ–°ç­–ç•¥ä¸ä¼šåç¦»æ—§ç­–ç•¥å¤ªè¿œï¼Œä»è€Œé¿å…äº†è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚</p>
<p>æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹PPOçš„æ•´ä½“è®­ç»ƒæµç¨‹ã€‚</p>
<ol type="1">
<li>Rolloutï¼ˆé‡‡æ ·å›ç­”ï¼‰:å¯¹ä¸€æ‰¹ prompts <span class="math inline">\(x\)</span>ï¼Œç”¨å½“å‰ç­–ç•¥ <span class="math inline">\(\pi_{\theta_{\text{old}}}\)</span> ç”Ÿæˆå›ç­” <span class="math inline">\(y\)</span>ã€‚åŒæ—¶ä¿å­˜æ¯ä¸ªç”Ÿæˆ token çš„ï¼š
<ul>
<li>logprobï¼š<span class="math inline">\(\log \pi_{\theta_{\text{old}}}(a_t|s_t)\)</span></li>
</ul></li>
<li>ç®—å¥–åŠ±ï¼ˆrewardï¼‰:ç”¨å¥–åŠ±æ¨¡å‹ <span class="math inline">\(r_{\phi}(x,y)\)</span> ç»™æ•´æ®µå›ç­”ä¸€ä¸ªæ ‡é‡åˆ†æ•°ã€‚å†åŠ ä¸Š KL æƒ©ç½šï¼Œå¾—åˆ°æœ€ç»ˆå¥–åŠ±ä¿¡å·:
<ul>
<li><p>KL æƒ©ç½šé€šå¸¸æœ‰ä¸¤ç§åšæ³•ï¼š</p>
<ul>
<li>æ˜¾å¼ KL penaltyï¼šæŠŠ <span class="math inline">\(-\beta \, \mathrm{KL}(\pi_\theta(\cdot|x) \| \pi_{\text{ref}}(\cdot|x))\)</span> åŠ è¿› reward</li>
<li>æˆ–åœ¨ loss é‡Œå•ç‹¬åŠ  KL é¡¹ï¼ˆç±»ä¼¼ InstructGPTï¼‰</li>
</ul></li>
<li><p>å¾ˆå¤šå®ç°æŠŠ token-level çš„ KL å˜æˆä¸€ä¸ª shaping reward:</p>
<p><span class="math display">\[
r_t^{\text{KL}} = -\beta\left(\log \pi_\theta(a_t|s_t)-\log \pi_{\text{ref}}(a_t|s_t)\right)
\]</span></p>
<p>ç„¶åæŠŠæœ€ç»ˆå¥–åŠ±åˆ†é…åˆ°åºåˆ—æœ«ç«¯æˆ–åšä¸€äº›åˆ†æ‘Šã€‚</p></li>
</ul></li>
<li>ä¼°è®¡ Value + Advantage</li>
</ol>
<p>è®­ç»ƒä¸€ä¸ª value head <span class="math inline">\(V_\psi(s_t)\)</span> é¢„æµ‹â€œä»å½“å‰å‰ç¼€å¾€åèƒ½æ‹¿åˆ°çš„å›æŠ¥â€ã€‚<br>
ç”¨ï¼ˆGAEï¼‰ç­‰æ–¹æ³•å¾—åˆ° <span class="math inline">\(A_t\)</span></p>
<p><span id="eq-gae"><span class="math display">\[
\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t) = \sum_{l\ge 0}(\gamma\lambda)^l \delta_{t+l}
\tag{15}\]</span></span></p>
<p>4ï¼šPPO updateï¼ˆå¤š epochã€å°æ­¥æ›´æ–°ï¼‰</p>
<p>å¯¹åŒä¸€æ‰¹ rollout æ•°æ®ï¼Œåš K ä¸ª epoch çš„ minibatch æ›´æ–°ï¼š</p>
<ul>
<li><p>policy lossï¼šâˆ’Lclip-L^{clip}âˆ’Lclip</p></li>
<li><p>value lossï¼šâˆ¥VÏˆâˆ’Râˆ¥2|V_- R|^2âˆ¥VÏˆâ€‹âˆ’Râˆ¥2</p></li>
<li><p>entropy bonusï¼šé¼“åŠ±æ¢ç´¢ (+Î±H)(+H)(+Î±H)</p></li>
<li><p>ï¼ˆå¯é€‰ï¼‰KL æ§åˆ¶é¡¹</p></li>
</ul>
<p>æ€»ä½“ lossï¼ˆå¸¸è§å½¢å¼ï¼‰ï¼š</p>
<p>L=Lpolicy+cvLvalueâˆ’ceH+cklKLL = L_{} + c_v L_{} - c_e H + c_{kl}L=Lpolicyâ€‹+cvâ€‹Lvalueâ€‹âˆ’ceâ€‹H+cklâ€‹KL</p>
<p>PPO å·¥ç¨‹ä¸Šå¤æ‚ï¼Œä¸»è¦å› ä¸ºï¼š</p>
<ol type="1">
<li><p><strong>on-policy</strong>ï¼šæ¯è½®éƒ½è¦é‡‡æ ·æ–°æ•°æ®ï¼ˆrollouts æˆæœ¬é«˜ï¼‰</p></li>
<li><p><strong>éœ€è¦ value function</strong>ï¼šè¦è®­ value headï¼Œå®¹æ˜“ä¸ç¨³</p></li>
<li><p><strong>éœ€è¦ careful çš„ KL æ§åˆ¶</strong>ï¼šä¸ç„¶è¦ä¹ˆè·‘é£ã€è¦ä¹ˆå­¦ä¸åŠ¨</p></li>
<li><p><strong>sequence credit assignment</strong>ï¼šå¥–åŠ±å¸¸æ˜¯åºåˆ—çº§ï¼Œæ€ä¹ˆåˆ†åˆ° token ä¸Šå¾ˆæ•æ„Ÿ</p></li>
<li><p><strong>é•¿åº¦åç½®/å¥–åŠ± hacking</strong>ï¼šreward model å¯èƒ½åå¥½é•¿å›ç­” â†’ ç­–ç•¥å­¦ä¼šâ€œå†™é•¿éª—åˆ†â€</p></li>
</ol>
<div class="sourceCode" id="cb3" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># PPO RLHF: one training iteration (one "outer step")</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="co"># Assumes:</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co">#   policy: trainable LM Ï€Î¸</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co">#   ref_policy: frozen LM Ï€ref (often SFT checkpoint)</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co">#   reward_model: rÏ†(x, y) -&gt; scalar reward per sequence</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co">#   value_head: VÏˆ(s_t) -&gt; scalar value per token/state (often a head on top of policy)</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">#</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co"># Notation:</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">#   B = batch size (number of prompts)</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co">#   T = max total tokens (prompt + generated)</span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="co">#   Tp = prompt length (varies per sample)</span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co">#   Tr = response length (varies per sample)</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="co">#</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co"># Key masks:</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="co">#   response_mask[b,t] = 1 if token t is a generated response token (NOT prompt), else 0</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co">#   valid_mask[b,t] = 1 if token t exists (not padding), else 0</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="co">#</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="co"># IMPORTANT alignment:</span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co">#   For causal LM, token-level logprob at position t corresponds to predicting token_ids[t]</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="co">#   from prefix token_ids[:t]. Commonly computed with a 1-step shift.</span></span>
<span id="cb3-21"><a href="#cb3-21"></a></span>
<span id="cb3-22"><a href="#cb3-22"></a><span class="kw">def</span> ppo_train_step(prompts):</span>
<span id="cb3-23"><a href="#cb3-23"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>    <span class="co"># 1) Rollout: sample responses from current policy (old policy snapshot)</span></span>
<span id="cb3-25"><a href="#cb3-25"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-26"><a href="#cb3-26"></a>    <span class="cf">with</span> no_grad():</span>
<span id="cb3-27"><a href="#cb3-27"></a>        policy.<span class="bu">eval</span>()</span>
<span id="cb3-28"><a href="#cb3-28"></a></span>
<span id="cb3-29"><a href="#cb3-29"></a>        <span class="co"># Generate tokens (can be via vLLM or your sampler)</span></span>
<span id="cb3-30"><a href="#cb3-30"></a>        <span class="co"># returns:</span></span>
<span id="cb3-31"><a href="#cb3-31"></a>        <span class="co">#   token_ids: (B, T) padded</span></span>
<span id="cb3-32"><a href="#cb3-32"></a>        <span class="co">#   response_mask: (B, T) 1 for response tokens</span></span>
<span id="cb3-33"><a href="#cb3-33"></a>        <span class="co">#   valid_mask: (B, T) 1 for non-pad tokens</span></span>
<span id="cb3-34"><a href="#cb3-34"></a>        token_ids, response_mask, valid_mask <span class="op">=</span> generate(policy, prompts)</span>
<span id="cb3-35"><a href="#cb3-35"></a></span>
<span id="cb3-36"><a href="#cb3-36"></a>        <span class="co"># (Optional) store prompt lengths, response lengths, etc.</span></span>
<span id="cb3-37"><a href="#cb3-37"></a>        <span class="co"># prompt_mask = valid_mask &amp; (~response_mask)</span></span>
<span id="cb3-38"><a href="#cb3-38"></a></span>
<span id="cb3-39"><a href="#cb3-39"></a>    <span class="co"># Freeze a copy of current params as "old" logically.</span></span>
<span id="cb3-40"><a href="#cb3-40"></a>    <span class="co"># In practice, we keep old_logp computed here as constants.</span></span>
<span id="cb3-41"><a href="#cb3-41"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-42"><a href="#cb3-42"></a>    <span class="co"># 2) Compute old_logp and ref_logp for the generated response tokens</span></span>
<span id="cb3-43"><a href="#cb3-43"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-44"><a href="#cb3-44"></a>    <span class="cf">with</span> no_grad():</span>
<span id="cb3-45"><a href="#cb3-45"></a>        <span class="co"># old policy logprobs on the sampled trajectory</span></span>
<span id="cb3-46"><a href="#cb3-46"></a>        <span class="co"># logp_old: (B, T) where positions not scored can be 0</span></span>
<span id="cb3-47"><a href="#cb3-47"></a>        logp_old <span class="op">=</span> token_logprobs(policy, token_ids)     <span class="co"># aligned to token_ids</span></span>
<span id="cb3-48"><a href="#cb3-48"></a>        logp_ref <span class="op">=</span> token_logprobs(ref_policy, token_ids) <span class="co"># aligned to token_ids</span></span>
<span id="cb3-49"><a href="#cb3-49"></a></span>
<span id="cb3-50"><a href="#cb3-50"></a>        <span class="co"># Only optimize on response tokens (typical RLHF)</span></span>
<span id="cb3-51"><a href="#cb3-51"></a>        <span class="co"># Keep only response positions; everything else masked out.</span></span>
<span id="cb3-52"><a href="#cb3-52"></a>        logp_old <span class="op">=</span> logp_old <span class="op">*</span> response_mask</span>
<span id="cb3-53"><a href="#cb3-53"></a>        logp_ref <span class="op">=</span> logp_ref <span class="op">*</span> response_mask</span>
<span id="cb3-54"><a href="#cb3-54"></a></span>
<span id="cb3-55"><a href="#cb3-55"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-56"><a href="#cb3-56"></a>    <span class="co"># 3) Reward + KL shaping</span></span>
<span id="cb3-57"><a href="#cb3-57"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-58"><a href="#cb3-58"></a>    <span class="cf">with</span> no_grad():</span>
<span id="cb3-59"><a href="#cb3-59"></a>        <span class="co"># Sequence-level reward from reward model (scalar per sample)</span></span>
<span id="cb3-60"><a href="#cb3-60"></a>        <span class="co"># r_seq: (B,)</span></span>
<span id="cb3-61"><a href="#cb3-61"></a>        r_seq <span class="op">=</span> reward_model(prompts, token_ids)  <span class="co"># evaluates (x, y)</span></span>
<span id="cb3-62"><a href="#cb3-62"></a></span>
<span id="cb3-63"><a href="#cb3-63"></a>        <span class="co"># Token-level KL term (per token):</span></span>
<span id="cb3-64"><a href="#cb3-64"></a>        <span class="co">#   kl_t = logÏ€Î¸(a_t|s_t) - logÏ€ref(a_t|s_t)</span></span>
<span id="cb3-65"><a href="#cb3-65"></a>        <span class="co"># For shaping, we usually use old policy logp here because rollout came from old policy.</span></span>
<span id="cb3-66"><a href="#cb3-66"></a>        <span class="co"># kl_tok: (B, T)</span></span>
<span id="cb3-67"><a href="#cb3-67"></a>        kl_tok <span class="op">=</span> (logp_old <span class="op">-</span> logp_ref)  <span class="co"># already masked to response tokens</span></span>
<span id="cb3-68"><a href="#cb3-68"></a></span>
<span id="cb3-69"><a href="#cb3-69"></a>        <span class="co"># KL penalty as "negative reward" per token</span></span>
<span id="cb3-70"><a href="#cb3-70"></a>        <span class="co"># r_kl_tok: (B, T)</span></span>
<span id="cb3-71"><a href="#cb3-71"></a>        r_kl_tok <span class="op">=</span> <span class="op">-</span>beta <span class="op">*</span> kl_tok</span>
<span id="cb3-72"><a href="#cb3-72"></a></span>
<span id="cb3-73"><a href="#cb3-73"></a>        <span class="co"># Combine rewards into a token-level reward signal.</span></span>
<span id="cb3-74"><a href="#cb3-74"></a>        <span class="co"># Common simple choice: put the sequence reward at the final response token,</span></span>
<span id="cb3-75"><a href="#cb3-75"></a>        <span class="co"># plus KL penalty at each response token.</span></span>
<span id="cb3-76"><a href="#cb3-76"></a>        <span class="co"># r_tok: (B, T)</span></span>
<span id="cb3-77"><a href="#cb3-77"></a>        r_tok <span class="op">=</span> zeros_like(kl_tok)                <span class="co"># (B, T)</span></span>
<span id="cb3-78"><a href="#cb3-78"></a>        last_resp_index <span class="op">=</span> last_index(response_mask)  <span class="co"># (B,) gives t_end per sample</span></span>
<span id="cb3-79"><a href="#cb3-79"></a>        r_tok[<span class="bu">range</span>(B), last_resp_index] <span class="op">+=</span> r_seq  <span class="co"># terminal reward</span></span>
<span id="cb3-80"><a href="#cb3-80"></a>        r_tok <span class="op">+=</span> r_kl_tok                          <span class="co"># dense KL shaping</span></span>
<span id="cb3-81"><a href="#cb3-81"></a></span>
<span id="cb3-82"><a href="#cb3-82"></a>        <span class="co"># Ensure padding doesn't contribute</span></span>
<span id="cb3-83"><a href="#cb3-83"></a>        r_tok <span class="op">=</span> r_tok <span class="op">*</span> valid_mask</span>
<span id="cb3-84"><a href="#cb3-84"></a></span>
<span id="cb3-85"><a href="#cb3-85"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-86"><a href="#cb3-86"></a>    <span class="co"># 4) GAE: compute advantages A_t and returns R_t for response tokens</span></span>
<span id="cb3-87"><a href="#cb3-87"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-88"><a href="#cb3-88"></a>    <span class="cf">with</span> no_grad():</span>
<span id="cb3-89"><a href="#cb3-89"></a>        <span class="co"># Value predictions for each token/state</span></span>
<span id="cb3-90"><a href="#cb3-90"></a>        <span class="co"># v: (B, T)</span></span>
<span id="cb3-91"><a href="#cb3-91"></a>        v <span class="op">=</span> value_head(policy, token_ids)  <span class="co"># or separate critic network</span></span>
<span id="cb3-92"><a href="#cb3-92"></a>        v <span class="op">=</span> v <span class="op">*</span> valid_mask</span>
<span id="cb3-93"><a href="#cb3-93"></a></span>
<span id="cb3-94"><a href="#cb3-94"></a>        <span class="co"># Compute next-state values v_next (shifted)</span></span>
<span id="cb3-95"><a href="#cb3-95"></a>        v_next <span class="op">=</span> shift_left(v)            <span class="co"># v_next[:, t] = v[:, t+1], last = 0</span></span>
<span id="cb3-96"><a href="#cb3-96"></a>        v_next <span class="op">=</span> v_next <span class="op">*</span> valid_mask</span>
<span id="cb3-97"><a href="#cb3-97"></a></span>
<span id="cb3-98"><a href="#cb3-98"></a>        <span class="co"># TD residuals Î´_t = r_t + Î³ v_{t+1} - v_t</span></span>
<span id="cb3-99"><a href="#cb3-99"></a>        <span class="co"># delta: (B, T)</span></span>
<span id="cb3-100"><a href="#cb3-100"></a>        delta <span class="op">=</span> r_tok <span class="op">+</span> gamma <span class="op">*</span> v_next <span class="op">-</span> v</span>
<span id="cb3-101"><a href="#cb3-101"></a>        delta <span class="op">=</span> delta <span class="op">*</span> response_mask     <span class="co"># only response tokens matter</span></span>
<span id="cb3-102"><a href="#cb3-102"></a></span>
<span id="cb3-103"><a href="#cb3-103"></a>        <span class="co"># GAE recursion backwards over time for each sample</span></span>
<span id="cb3-104"><a href="#cb3-104"></a>        <span class="co"># adv: (B, T)</span></span>
<span id="cb3-105"><a href="#cb3-105"></a>        adv <span class="op">=</span> zeros_like(delta)</span>
<span id="cb3-106"><a href="#cb3-106"></a>        gae <span class="op">=</span> zeros(B)</span>
<span id="cb3-107"><a href="#cb3-107"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(T)):</span>
<span id="cb3-108"><a href="#cb3-108"></a>            mask_t <span class="op">=</span> response_mask[:, t]  <span class="co"># (B,)</span></span>
<span id="cb3-109"><a href="#cb3-109"></a>            <span class="co"># if mask_t=0, reset gae to 0 so prompt/pad doesn't leak</span></span>
<span id="cb3-110"><a href="#cb3-110"></a>            gae <span class="op">=</span> delta[:, t] <span class="op">+</span> gamma <span class="op">*</span> lam <span class="op">*</span> gae</span>
<span id="cb3-111"><a href="#cb3-111"></a>            gae <span class="op">=</span> gae <span class="op">*</span> mask_t</span>
<span id="cb3-112"><a href="#cb3-112"></a>            adv[:, t] <span class="op">=</span> gae</span>
<span id="cb3-113"><a href="#cb3-113"></a></span>
<span id="cb3-114"><a href="#cb3-114"></a>        <span class="co"># Returns (target for value): R_t = A_t + V_t</span></span>
<span id="cb3-115"><a href="#cb3-115"></a>        ret <span class="op">=</span> adv <span class="op">+</span> v</span>
<span id="cb3-116"><a href="#cb3-116"></a>        ret <span class="op">=</span> ret <span class="op">*</span> response_mask</span>
<span id="cb3-117"><a href="#cb3-117"></a></span>
<span id="cb3-118"><a href="#cb3-118"></a>        <span class="co"># Normalize advantages over all response tokens in the batch (stabilizes PPO)</span></span>
<span id="cb3-119"><a href="#cb3-119"></a>        adv <span class="op">=</span> masked_normalize(adv, response_mask)  <span class="co"># zero-mean, unit-std over masked positions</span></span>
<span id="cb3-120"><a href="#cb3-120"></a></span>
<span id="cb3-121"><a href="#cb3-121"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-122"><a href="#cb3-122"></a>    <span class="co"># 5) PPO clipped loss (policy + value + entropy)</span></span>
<span id="cb3-123"><a href="#cb3-123"></a>    <span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-124"><a href="#cb3-124"></a>    policy.train()</span>
<span id="cb3-125"><a href="#cb3-125"></a></span>
<span id="cb3-126"><a href="#cb3-126"></a>    <span class="co"># Recompute current policy logprobs for the same token_ids (now Î¸ is trainable)</span></span>
<span id="cb3-127"><a href="#cb3-127"></a>    <span class="co"># logp_new: (B, T)</span></span>
<span id="cb3-128"><a href="#cb3-128"></a>    logp_new <span class="op">=</span> token_logprobs(policy, token_ids)</span>
<span id="cb3-129"><a href="#cb3-129"></a>    logp_new <span class="op">=</span> logp_new <span class="op">*</span> response_mask</span>
<span id="cb3-130"><a href="#cb3-130"></a></span>
<span id="cb3-131"><a href="#cb3-131"></a>    <span class="co"># Probability ratio Ï_t = exp(logp_new - logp_old)</span></span>
<span id="cb3-132"><a href="#cb3-132"></a>    <span class="co"># ratio: (B, T)</span></span>
<span id="cb3-133"><a href="#cb3-133"></a>    ratio <span class="op">=</span> exp(logp_new <span class="op">-</span> logp_old) <span class="op">*</span> response_mask</span>
<span id="cb3-134"><a href="#cb3-134"></a></span>
<span id="cb3-135"><a href="#cb3-135"></a>    <span class="co"># Clipped surrogate objective</span></span>
<span id="cb3-136"><a href="#cb3-136"></a>    <span class="co"># unclipped = ratio * adv</span></span>
<span id="cb3-137"><a href="#cb3-137"></a>    <span class="co"># clipped   = clip(ratio, 1-eps, 1+eps) * adv</span></span>
<span id="cb3-138"><a href="#cb3-138"></a>    unclipped <span class="op">=</span> ratio <span class="op">*</span> adv</span>
<span id="cb3-139"><a href="#cb3-139"></a>    clipped <span class="op">=</span> clip(ratio, <span class="dv">1</span> <span class="op">-</span> eps, <span class="dv">1</span> <span class="op">+</span> eps) <span class="op">*</span> adv</span>
<span id="cb3-140"><a href="#cb3-140"></a></span>
<span id="cb3-141"><a href="#cb3-141"></a>    <span class="co"># Policy loss: negative because we maximize objective</span></span>
<span id="cb3-142"><a href="#cb3-142"></a>    <span class="co"># Take masked mean over response tokens</span></span>
<span id="cb3-143"><a href="#cb3-143"></a>    policy_loss <span class="op">=</span> <span class="op">-</span>masked_mean(<span class="bu">min</span>(unclipped, clipped), response_mask)</span>
<span id="cb3-144"><a href="#cb3-144"></a></span>
<span id="cb3-145"><a href="#cb3-145"></a>    <span class="co"># Value loss: regress to ret (returns)</span></span>
<span id="cb3-146"><a href="#cb3-146"></a>    v_pred <span class="op">=</span> value_head(policy, token_ids) <span class="op">*</span> response_mask</span>
<span id="cb3-147"><a href="#cb3-147"></a>    value_loss <span class="op">=</span> masked_mean((v_pred <span class="op">-</span> ret) <span class="op">**</span> <span class="dv">2</span>, response_mask)</span>
<span id="cb3-148"><a href="#cb3-148"></a></span>
<span id="cb3-149"><a href="#cb3-149"></a>    <span class="co"># Entropy bonus (encourage exploration) on response tokens</span></span>
<span id="cb3-150"><a href="#cb3-150"></a>    <span class="co"># entropy_tok: (B, T)</span></span>
<span id="cb3-151"><a href="#cb3-151"></a>    entropy_tok <span class="op">=</span> token_entropy(policy, token_ids) <span class="op">*</span> response_mask</span>
<span id="cb3-152"><a href="#cb3-152"></a>    entropy_bonus <span class="op">=</span> masked_mean(entropy_tok, response_mask)</span>
<span id="cb3-153"><a href="#cb3-153"></a></span>
<span id="cb3-154"><a href="#cb3-154"></a>    <span class="co"># (Optional) explicit KL term vs ref using current logp_new</span></span>
<span id="cb3-155"><a href="#cb3-155"></a>    <span class="co"># Helps keep policy close even if clip isn't enough</span></span>
<span id="cb3-156"><a href="#cb3-156"></a>    kl_new <span class="op">=</span> (logp_new <span class="op">-</span> logp_ref) <span class="op">*</span> response_mask</span>
<span id="cb3-157"><a href="#cb3-157"></a>    kl_mean <span class="op">=</span> masked_mean(kl_new, response_mask)</span>
<span id="cb3-158"><a href="#cb3-158"></a></span>
<span id="cb3-159"><a href="#cb3-159"></a>    total_loss <span class="op">=</span> policy_loss <span class="op">+</span> c_v <span class="op">*</span> value_loss <span class="op">-</span> c_ent <span class="op">*</span> entropy_bonus <span class="op">+</span> c_kl <span class="op">*</span> kl_mean</span>
<span id="cb3-160"><a href="#cb3-160"></a></span>
<span id="cb3-161"><a href="#cb3-161"></a>    optimizer.zero_grad()</span>
<span id="cb3-162"><a href="#cb3-162"></a>    total_loss.backward()</span>
<span id="cb3-163"><a href="#cb3-163"></a>    clip_grad_norm_(policy.parameters(), max_grad_norm)</span>
<span id="cb3-164"><a href="#cb3-164"></a>    optimizer.step()</span>
<span id="cb3-165"><a href="#cb3-165"></a></span>
<span id="cb3-166"><a href="#cb3-166"></a>    <span class="co"># Return logs</span></span>
<span id="cb3-167"><a href="#cb3-167"></a>    <span class="cf">return</span> {</span>
<span id="cb3-168"><a href="#cb3-168"></a>        <span class="st">"loss_total"</span>: total_loss,</span>
<span id="cb3-169"><a href="#cb3-169"></a>        <span class="st">"loss_policy"</span>: policy_loss,</span>
<span id="cb3-170"><a href="#cb3-170"></a>        <span class="st">"loss_value"</span>: value_loss,</span>
<span id="cb3-171"><a href="#cb3-171"></a>        <span class="st">"entropy"</span>: entropy_bonus,</span>
<span id="cb3-172"><a href="#cb3-172"></a>        <span class="st">"kl"</span>: kl_mean,</span>
<span id="cb3-173"><a href="#cb3-173"></a>        <span class="st">"reward_seq_mean"</span>: mean(r_seq),</span>
<span id="cb3-174"><a href="#cb3-174"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="dpo" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="dpo"><span class="header-section-number">2.4</span> DPO</h2>
<p>æ˜¾ç„¶ï¼ŒPPOçš„ç®—æ³•ï¼Œå­˜åœ¨çš„ä¸»è¦ä¸€ä¸ªç¼ºé™·å°±æ˜¯æ‰€éœ€çš„å†…å­˜è¿‡å¤šï¼š æˆ‘ä»¬éœ€è¦ä¿å­˜:</p>
<ul>
<li>Policy: å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹</li>
<li>Reference Policy: å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹</li>
<li>Value Modelï¼š å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹</li>
<li>Reward Modelï¼š å’ŒLMå·®ä¸å¤šå¤§çš„æ¨¡å‹</li>
</ul>
<p>å¹¶ä¸”ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿˜éœ€è¦ä¿å­˜å¤§é‡çš„ä¸­é—´æ¿€æ´»ï¼ˆactivationsï¼‰ç”¨äºåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ã€‚</p>
<p>è¿™å¯¹äºåŠ¨è¾„å‡ ä¸ªBçš„LMæ¨¡å‹æ¥è¯´ï¼Œæ¶ˆè€—æ˜¯å·¨å¤§çš„ï¼Œå› æ­¤ï¼Œæå‡ºäº†DPOçš„ç®—æ³•ã€‚ DPOï¼ˆ<strong>Direct Preference Optimization</strong>ï¼‰<span class="citation" data-cites="DirectPreferenceOptimization2024rafailov">(<a href="#ref-DirectPreferenceOptimization2024rafailov" role="doc-biblioref">Rafailov et al. 2024</a>)</span> å¯ä»¥æŠŠâ€œRLHF + PPOâ€é‚£å¥— <strong>é‡‡æ ·â†’è®­ç»ƒrewardâ†’RLæ›´æ–°</strong>ï¼Œç®€åŒ–æˆä¸€ä¸ª<strong>çº¯ç›‘ç£å¼</strong>çš„åå¥½å­¦ä¹ ï¼šç›´æ¥ç”¨ <span class="math inline">\((x,y+,y^-)\)</span> æ›´æ–°ç­–ç•¥æ¨¡å‹ã€‚ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼š <u>è®©æ¨¡å‹å¯¹ preferred å›ç­”çš„æ¦‚ç‡æ¯” rejected æ›´å¤§ï¼ŒåŒæ—¶ç”¨å‚è€ƒæ¨¡å‹ Ï€ref_{}Ï€refâ€‹ çº¦æŸåˆ«åå¤ªè¿œ</u>ã€‚</p>
<div id="fig-" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/dpo-vs-ppo.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig--caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: å›¾ä¸­å±•ç¤ºäº† DPO å’Œ PPO çš„å¯¹æ¯”ï¼ŒDPO ç›´æ¥ç”¨åå¥½æ•°æ®ï¼ˆchosen vs rejectedï¼‰æ¥è®­ç»ƒç­–ç•¥ <span class="math inline">\(\pi_\theta\)</span>, å¯¹â€œäººç±»æ›´å–œæ¬¢çš„å›ç­”â€ç»™æ›´é«˜æ¦‚ç‡ï¼Œå¯¹â€œä¸å–œæ¬¢çš„å›ç­”â€ç»™æ›´ä½æ¦‚ç‡.
</figcaption>
</figure>
</div>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å…·ä½“çœ‹çœ‹DPOç®—æ³•ï¼š å‡è®¾ policy ä¸æ˜¯ç¥ç»ç½‘ç»œï¼Œè€Œæ˜¯<strong>ä»»æ„åˆ†å¸ƒ</strong>ï¼ˆnonparametricï¼‰ã€‚ åœ¨è¿™ä¸ªå‡è®¾ä¸‹ï¼Œè¿™ä¸ªä¼˜åŒ–é—®é¢˜æœ‰è§£æè§£ï¼š</p>
<p>Ï€r(yâˆ£x)=1Z(x)&nbsp;Ï€ref(yâˆ£x)&nbsp;expâ¡â€‰â£(1Î²r(x,y))<em>r(y|x)=&nbsp;</em>{}(y|x)&nbsp;!(r(x,y))Ï€râ€‹(yâˆ£x)=Z(x)1â€‹&nbsp;Ï€refâ€‹(yâˆ£x)&nbsp;exp(Î²1â€‹r(x,y))</p>
<p>è¿™å…¶å®å°±æ˜¯ä¸€ä¸ª <strong>Boltzmann / energy-based reweighting</strong>ï¼š</p>
<ul>
<li><p>å‚è€ƒåˆ†å¸ƒ <span class="math inline">\(\pi_{\text{ref}}\)</span> æä¾›â€œå…ˆéªŒâ€</p></li>
<li><p>reward è¶Šé«˜ï¼Œexpâ¡(r/Î²)(r/)exp(r/Î²) è¶ŠæŠŠæ¦‚ç‡å¾€ä¸Šæ¨</p></li>
<li><p>Z(x)Z(x)Z(x) æ˜¯å½’ä¸€åŒ–å¸¸æ•°ï¼ˆpartition functionï¼‰</p></li>
</ul>
</section>
<section id="åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°"><span class="header-section-number">2.5</span> åè§£â€å¾—åˆ° implied rewardï¼šreward â‰ˆ log-ratioï¼ˆå·®ä¸€ä¸ªå¸¸æ•°ï¼‰</h2>
<p>æŠŠä¸Šå¼å– log å¹¶æ•´ç†ï¼Œå¾—åˆ°å›¾é‡Œæœ€åä¸€è¡Œï¼š</p>
<p>r(x,y)=Î²logâ¡Ï€r(yâˆ£x)Ï€ref(yâˆ£x)+Î²logâ¡Z(x)r(x,y)= + Z(x)r(x,y)=Î²logÏ€refâ€‹(yâˆ£x)Ï€râ€‹(yâˆ£x)â€‹+Î²logZ(x)</p>
<p>å…³é”®ç‚¹ï¼š</p>
<ul>
<li><p>Î²logâ¡Z(x)Z(x)Î²logZ(x) <strong>åªä¾èµ– xï¼Œä¸ä¾èµ– y</strong> â†’ åœ¨â€œæ¯”è¾ƒ y+y^+y+ vs yâˆ’y^-yâˆ’â€æ—¶ä¼šç›¸æ¶ˆ</p></li>
<li><p>æ‰€ä»¥åœ¨åå¥½å­¦ä¹ é‡Œï¼Œä½ å¯ä»¥æŠŠ reward çš„å·®å†™æˆï¼š</p></li>
</ul>
<p>r(x,y+)âˆ’r(x,yâˆ’)=Î²(logâ¡Ï€(y+âˆ£x)Ï€ref(y+âˆ£x)âˆ’logâ¡Ï€(yâˆ’âˆ£x)Ï€ref(yâˆ’âˆ£x))r(x,y<sup>+)-r(x,y</sup>-) =( - )r(x,y+)âˆ’r(x,yâˆ’)=Î²(logÏ€refâ€‹(y+âˆ£x)Ï€(y+âˆ£x)â€‹âˆ’logÏ€refâ€‹(yâˆ’âˆ£x)Ï€(yâˆ’âˆ£x)â€‹)</p>
<p>è¿™ä¸€æ­¥å°±æ˜¯ DPO çš„æ ¸å¿ƒï¼š<strong>ä¸æ˜¾å¼è®­ç»ƒ reward modelï¼Œè€Œæ˜¯ç”¨ policy çš„ logprobï¼ˆç›¸å¯¹ ref çš„å·®ï¼‰æ¥â€œéšå¼è¡¨ç¤º rewardâ€ã€‚</strong></p>
<p>r(x,y+)âˆ’r(x,yâˆ’)=Î²[logÏ€refâ€‹(y+âˆ£x)Ï€(y+âˆ£x)â€‹âˆ’logÏ€refâ€‹(yâˆ’âˆ£x)Ï€(yâˆ’âˆ£x)â€‹]</p>
<p>æŠŠä¸Šé¢å·®å€¼å†™å¾—æ›´ç´§å‡‘ä¸€ç‚¹ï¼š</p>
<p>Î”Î¸(x)=(logâ¡Ï€Î¸(y+âˆ£x)âˆ’logâ¡Ï€Î¸(yâˆ’âˆ£x))âˆ’(logâ¡Ï€ref(y+âˆ£x)âˆ’logâ¡Ï€ref(yâˆ’âˆ£x))<em>(x) =(</em>(y<sup>+|x)-<em>(y^-|x)) -(</em>{}(y</sup>+|x)-_{}(y^-|x))Î”Î¸â€‹(x)=(logÏ€Î¸â€‹(y+âˆ£x)âˆ’logÏ€Î¸â€‹(yâˆ’âˆ£x))âˆ’(logÏ€refâ€‹(y+âˆ£x)âˆ’logÏ€refâ€‹(yâˆ’âˆ£x))</p>
<p>äºæ˜¯</p>
<p><span id="eq-dpo-reward-delta"><span class="math display">\[
r(x,y^+) - r(x,y^-) = \beta \, \Delta_\theta(x)
\tag{16}\]</span></span></p>
<p>ä»£å›åå¥½ä¼¼ç„¶ï¼š</p>
<p>LDPO(Î¸)=âˆ’E(x,y+,yâˆ’)[logâ¡Ïƒ(Î²â€‰Î”Î¸(x))]<em>{}() = -</em>{(x,y<sup>+,y</sup>-)}LDPOâ€‹(Î¸)=âˆ’E(x,y+,yâˆ’)â€‹[logÏƒ(Î²Î”Î¸â€‹(x))]</p>
<p>è¿™å°±æ˜¯ DPOã€‚</p>
<p><strong>ç›´è§‰è§£é‡Š</strong>ï¼š</p>
<ul>
<li><p>å¦‚æœä½ çš„æ–°ç­–ç•¥ Ï€Î¸<em>â€‹ ç›¸æ¯” ref <strong>æ›´åå‘ chosen</strong>ï¼ˆÎ”Î¸</em>â€‹ å¤§ï¼‰ï¼Œloss å°</p></li>
<li><p>å¦‚æœåè€Œæ›´åå‘ rejectedï¼ˆÎ”Î¸&lt;0_&lt;0Î”Î¸â€‹&lt;0ï¼‰ï¼Œloss å¤§ï¼Œä¼šè¢«æ¢¯åº¦æ¨å›å»</p></li>
</ul>
<p>åœ¨ LLM é‡Œ logâ¡Ï€Î¸(yâˆ£x)_(y|x)logÏ€Î¸â€‹(yâˆ£x) é€šå¸¸æ˜¯ <strong>response tokens çš„ logprob ä¹‹å’Œ</strong>ï¼š</p>
<p>logâ¡Ï€Î¸(yâˆ£x)=âˆ‘tâˆˆresponselogâ¡Ï€Î¸(ytâˆ£x,y&lt;t)<em>(y|x)=</em>{t } <em>(y_t x, y</em>{&lt;t})logÏ€Î¸â€‹(yâˆ£x)=tâˆˆresponseâˆ‘â€‹logÏ€Î¸â€‹(ytâ€‹âˆ£x,y&lt;tâ€‹)</p>
<p>æ‰€ä»¥ DPO è®­ç»ƒä¸€æ¬¡ step å°±æ˜¯ï¼š</p>
<ol type="1">
<li><p>å¯¹ batch ä¸­æ¯ä¸ªæ ·æœ¬ï¼Œåˆ†åˆ«ç®—ï¼š</p>
<ul>
<li><p><code>logp_pos = sum_logp(policy, x, y_pos)</code></p></li>
<li><p><code>logp_neg = sum_logp(policy, x, y_neg)</code></p></li>
<li><p><code>logp_ref_pos = sum_logp(ref, x, y_pos)</code>ï¼ˆno gradï¼‰</p></li>
<li><p><code>logp_ref_neg = sum_logp(ref, x, y_neg)</code>ï¼ˆno gradï¼‰</p></li>
</ul></li>
<li><p><code>delta = (logp_pos - logp_neg) - (logp_ref_pos - logp_ref_neg)</code></p></li>
<li><p><code>loss = -log_sigmoid(beta * delta).mean()</code></p></li>
</ol>
<div class="sourceCode" id="cb4" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="kw">def</span> dpo_train_step(</span>
<span id="cb4-5"><a href="#cb4-5"></a>    policy,                 <span class="co"># trainable LM Ï€Î¸</span></span>
<span id="cb4-6"><a href="#cb4-6"></a>    ref_policy,             <span class="co"># frozen LM Ï€ref (e.g., SFT checkpoint)</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>    optimizer,</span>
<span id="cb4-8"><a href="#cb4-8"></a>    batch_pos_input_ids,    <span class="co"># (B, T) prompt+chosen padded</span></span>
<span id="cb4-9"><a href="#cb4-9"></a>    batch_pos_attn_mask,    <span class="co"># (B, T) bool/int</span></span>
<span id="cb4-10"><a href="#cb4-10"></a>    batch_pos_resp_mask,    <span class="co"># (B, T) bool: 1 only on response tokens</span></span>
<span id="cb4-11"><a href="#cb4-11"></a>    batch_neg_input_ids,    <span class="co"># (B, T) prompt+rejected padded</span></span>
<span id="cb4-12"><a href="#cb4-12"></a>    batch_neg_attn_mask,    <span class="co"># (B, T)</span></span>
<span id="cb4-13"><a href="#cb4-13"></a>    batch_neg_resp_mask,    <span class="co"># (B, T)</span></span>
<span id="cb4-14"><a href="#cb4-14"></a>    beta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb4-15"><a href="#cb4-15"></a>    max_grad_norm: <span class="bu">float</span> <span class="op">|</span> <span class="va">None</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb4-16"><a href="#cb4-16"></a>):</span>
<span id="cb4-17"><a href="#cb4-17"></a>    <span class="co">"""</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="co">    DPO core update step (ONLY training part).</span></span>
<span id="cb4-19"><a href="#cb4-19"></a><span class="co">    Assumes inputs are already tokenized + padded and include response masks.</span></span>
<span id="cb4-20"><a href="#cb4-20"></a></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co">    DPO:</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span class="co">      delta = (logÏ€Î¸(y+|x)-logÏ€Î¸(y-|x)) - (logÏ€ref(y+|x)-logÏ€ref(y-|x))</span></span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="co">      loss  = -E[ log Ïƒ(beta * delta) ]</span></span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="co">    """</span></span>
<span id="cb4-25"><a href="#cb4-25"></a></span>
<span id="cb4-26"><a href="#cb4-26"></a>    <span class="kw">def</span> seq_logprob(model, input_ids, attn_mask, resp_mask):</span>
<span id="cb4-27"><a href="#cb4-27"></a>        <span class="co"># logits: (B, T, V)</span></span>
<span id="cb4-28"><a href="#cb4-28"></a>        logits <span class="op">=</span> model(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attn_mask).logits</span>
<span id="cb4-29"><a href="#cb4-29"></a></span>
<span id="cb4-30"><a href="#cb4-30"></a>        <span class="co"># causal shift: logits[:, t] predicts input_ids[:, t+1]</span></span>
<span id="cb4-31"><a href="#cb4-31"></a>        logits <span class="op">=</span> logits[:, :<span class="op">-</span><span class="dv">1</span>, :]          <span class="co"># (B, T-1, V)</span></span>
<span id="cb4-32"><a href="#cb4-32"></a>        labels <span class="op">=</span> input_ids[:, <span class="dv">1</span>:]           <span class="co"># (B, T-1)</span></span>
<span id="cb4-33"><a href="#cb4-33"></a></span>
<span id="cb4-34"><a href="#cb4-34"></a>        logp <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-35"><a href="#cb4-35"></a>        tok_logp <span class="op">=</span> logp.gather(<span class="op">-</span><span class="dv">1</span>, labels.unsqueeze(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B, T-1)</span></span>
<span id="cb4-36"><a href="#cb4-36"></a></span>
<span id="cb4-37"><a href="#cb4-37"></a>        <span class="co"># align masks with shift</span></span>
<span id="cb4-38"><a href="#cb4-38"></a>        mask <span class="op">=</span> (resp_mask[:, <span class="dv">1</span>:] <span class="op">&amp;</span> attn_mask[:, <span class="dv">1</span>:]).to(tok_logp.dtype)  <span class="co"># (B, T-1)</span></span>
<span id="cb4-39"><a href="#cb4-39"></a></span>
<span id="cb4-40"><a href="#cb4-40"></a>        <span class="cf">return</span> (tok_logp <span class="op">*</span> mask).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># (B,)</span></span>
<span id="cb4-41"><a href="#cb4-41"></a></span>
<span id="cb4-42"><a href="#cb4-42"></a>    <span class="co"># ----- policy logprobs -----</span></span>
<span id="cb4-43"><a href="#cb4-43"></a>    logp_pos <span class="op">=</span> seq_logprob(policy, batch_pos_input_ids, batch_pos_attn_mask, batch_pos_resp_mask)</span>
<span id="cb4-44"><a href="#cb4-44"></a>    logp_neg <span class="op">=</span> seq_logprob(policy, batch_neg_input_ids, batch_neg_attn_mask, batch_neg_resp_mask)</span>
<span id="cb4-45"><a href="#cb4-45"></a></span>
<span id="cb4-46"><a href="#cb4-46"></a>    <span class="co"># ----- reference logprobs (no grad) -----</span></span>
<span id="cb4-47"><a href="#cb4-47"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb4-48"><a href="#cb4-48"></a>        logp_ref_pos <span class="op">=</span> seq_logprob(ref_policy, batch_pos_input_ids, batch_pos_attn_mask, batch_pos_resp_mask)</span>
<span id="cb4-49"><a href="#cb4-49"></a>        logp_ref_neg <span class="op">=</span> seq_logprob(ref_policy, batch_neg_input_ids, batch_neg_attn_mask, batch_neg_resp_mask)</span>
<span id="cb4-50"><a href="#cb4-50"></a></span>
<span id="cb4-51"><a href="#cb4-51"></a>    <span class="co"># ----- DPO loss -----</span></span>
<span id="cb4-52"><a href="#cb4-52"></a>    delta <span class="op">=</span> (logp_pos <span class="op">-</span> logp_neg) <span class="op">-</span> (logp_ref_pos <span class="op">-</span> logp_ref_neg)  <span class="co"># (B,)</span></span>
<span id="cb4-53"><a href="#cb4-53"></a>    loss <span class="op">=</span> <span class="op">-</span>F.logsigmoid(beta <span class="op">*</span> delta).mean()</span>
<span id="cb4-54"><a href="#cb4-54"></a></span>
<span id="cb4-55"><a href="#cb4-55"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-56"><a href="#cb4-56"></a>    loss.backward()</span>
<span id="cb4-57"><a href="#cb4-57"></a></span>
<span id="cb4-58"><a href="#cb4-58"></a>    <span class="cf">if</span> max_grad_norm <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-59"><a href="#cb4-59"></a>        torch.nn.utils.clip_grad_norm_(policy.parameters(), max_grad_norm)</span>
<span id="cb4-60"><a href="#cb4-60"></a></span>
<span id="cb4-61"><a href="#cb4-61"></a>    optimizer.step()</span>
<span id="cb4-62"><a href="#cb4-62"></a></span>
<span id="cb4-63"><a href="#cb4-63"></a>    <span class="cf">return</span> {</span>
<span id="cb4-64"><a href="#cb4-64"></a>        <span class="st">"loss"</span>: <span class="bu">float</span>(loss.detach().cpu()),</span>
<span id="cb4-65"><a href="#cb4-65"></a>        <span class="st">"delta_mean"</span>: <span class="bu">float</span>(delta.detach().mean().cpu()),</span>
<span id="cb4-66"><a href="#cb4-66"></a>        <span class="st">"pref_acc"</span>: <span class="bu">float</span>((delta.detach() <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">float</span>().mean().cpu()),</span>
<span id="cb4-67"><a href="#cb4-67"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="others" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="others"><span class="header-section-number">2.6</span> Others</h2>
<p>åœ¨DPOæå‡ºä¹‹åï¼Œåç»­ä¹Ÿæœ‰è®¸å¤šç®—æ³•å¯¹å…¶æå‡ºäº†æ”¹è¿›ï¼Œåœ¨è¿™é‡Œä»‹ç»ä¸¤ç§ ### SimPO <strong>DPO çš„â€œå‚è€ƒæ¨¡å‹é¡¹ï¼ˆrefï¼‰â€å¯ä»¥ä¸è¦</strong> â†’ å¾—åˆ° <strong>SimPO (no ref)</strong> DPO/åå¥½å­¦ä¹ å¾ˆå®¹æ˜“å‡ºç°ï¼š<strong>é•¿å›ç­”æ›´å®¹æ˜“èµ¢</strong><br>
å› ä¸º sequence logprob æ˜¯ token logprob çš„â€œå’Œâ€ï¼Œé•¿åº¦ä¸åŒä¼šå¯¼è‡´æ¯”è¾ƒä¸å…¬å¹³ã€‚</p>
<p>æ‰€ä»¥æŠŠ</p>
<p>logâ¡Ï€Î¸(yâˆ£x)=âˆ‘tâˆˆylogâ¡pÎ¸(ytâˆ£â‹…)<em>(y|x)=</em>{ty}p_(y_t|)logÏ€Î¸â€‹(yâˆ£x)=tâˆˆyâˆ‘â€‹logpÎ¸â€‹(ytâ€‹âˆ£â‹…)</p>
<p>æ”¹æˆ<strong>å¹³å‡æ¯ token çš„ logprob</strong>ï¼š</p>
<p>1âˆ£yâˆ£logâ¡Ï€Î¸(yâˆ£x)_(y|x)âˆ£yâˆ£1â€‹logÏ€Î¸â€‹(yâˆ£x)</p>
<p>å›¾é‡Œè“æ¡†å°±æ˜¯è¿™ä¸ªï¼šÎ²/âˆ£ywâˆ£â‹…logâ¡Ï€Î¸(ywâˆ£x)/|y_w|<em>(y_w|x)Î²/âˆ£ywâ€‹âˆ£â‹…logÏ€Î¸â€‹(ywâ€‹âˆ£x) å’Œ Î²/âˆ£ylâˆ£â‹…logâ¡Ï€Î¸(ylâˆ£x)/|y_l|</em>(y_l|x)Î²/âˆ£ylâ€‹âˆ£â‹…logÏ€Î¸â€‹(ylâ€‹âˆ£x)ã€‚</p>
<p>imPO çš„ logit é‡Œå‡äº†ä¸€ä¸ª Î³ï¼š</p>
<p>Î”SimPO=Î²âˆ£ywâˆ£logâ¡Ï€Î¸(ywâˆ£x)âˆ’Î²âˆ£ylâˆ£logâ¡Ï€Î¸(ylâˆ£x)âˆ’Î³<em>{} = </em>(y_w|x) - _(y_l|x) -â€‹=âˆ£ywâ€‹âˆ£Î²â€‹logÏ€Î¸â€‹(ywâ€‹âˆ£x)âˆ’âˆ£ylâ€‹âˆ£Î²â€‹logÏ€Î¸â€‹(ylâ€‹âˆ£x)âˆ’Î³</p>
<p>ç›´è§‰ï¼šä½ ä¸æ˜¯åªè¦ ywy_wywâ€‹ æ¯” yly_lylâ€‹ å¥½ä¸€ç‚¹ç‚¹å°±è¡Œï¼Œè€Œæ˜¯å¸Œæœ›å®ƒ<strong>è‡³å°‘å¥½è¿‡ä¸€ä¸ªå¹…åº¦</strong>ï¼ˆmarginï¼‰ã€‚<br>
Î³è¶Šå¤§ï¼Œè®­ç»ƒè¶Šâ€œä¸¥æ ¼â€ã€‚</p>
<div class="sourceCode" id="cb5" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="kw">def</span> simpo_step(</span>
<span id="cb5-5"><a href="#cb5-5"></a>    policy, optimizer,</span>
<span id="cb5-6"><a href="#cb5-6"></a>    pos_input_ids, pos_attn, pos_rmask,</span>
<span id="cb5-7"><a href="#cb5-7"></a>    neg_input_ids, neg_attn, neg_rmask,</span>
<span id="cb5-8"><a href="#cb5-8"></a>    beta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb5-9"><a href="#cb5-9"></a>    gamma: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>,</span>
<span id="cb5-10"><a href="#cb5-10"></a>):</span>
<span id="cb5-11"><a href="#cb5-11"></a>    <span class="kw">def</span> seq_logprob_and_len(model, input_ids, attn_mask, resp_mask):</span>
<span id="cb5-12"><a href="#cb5-12"></a>        logits <span class="op">=</span> model(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attn_mask).logits</span>
<span id="cb5-13"><a href="#cb5-13"></a>        logits <span class="op">=</span> logits[:, :<span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb5-14"><a href="#cb5-14"></a>        labels <span class="op">=</span> input_ids[:, <span class="dv">1</span>:]</span>
<span id="cb5-15"><a href="#cb5-15"></a></span>
<span id="cb5-16"><a href="#cb5-16"></a>        logp <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-17"><a href="#cb5-17"></a>        tok_logp <span class="op">=</span> logp.gather(<span class="op">-</span><span class="dv">1</span>, labels.unsqueeze(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-18"><a href="#cb5-18"></a></span>
<span id="cb5-19"><a href="#cb5-19"></a>        mask <span class="op">=</span> (resp_mask[:, <span class="dv">1</span>:] <span class="op">&amp;</span> attn_mask[:, <span class="dv">1</span>:]).to(tok_logp.dtype)</span>
<span id="cb5-20"><a href="#cb5-20"></a>        seq_lp <span class="op">=</span> (tok_logp <span class="op">*</span> mask).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)            <span class="co"># (B,)</span></span>
<span id="cb5-21"><a href="#cb5-21"></a>        resp_len <span class="op">=</span> mask.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>).clamp_min(<span class="fl">1.0</span>)        <span class="co"># (B,)</span></span>
<span id="cb5-22"><a href="#cb5-22"></a>        <span class="cf">return</span> seq_lp, resp_len</span>
<span id="cb5-23"><a href="#cb5-23"></a></span>
<span id="cb5-24"><a href="#cb5-24"></a>    lp_pos, len_pos <span class="op">=</span> seq_logprob_and_len(policy, pos_input_ids, pos_attn, pos_rmask)</span>
<span id="cb5-25"><a href="#cb5-25"></a>    lp_neg, len_neg <span class="op">=</span> seq_logprob_and_len(policy, neg_input_ids, neg_attn, neg_rmask)</span>
<span id="cb5-26"><a href="#cb5-26"></a></span>
<span id="cb5-27"><a href="#cb5-27"></a>    <span class="co"># SimPO logit (no ref) + length normalization + margin gamma</span></span>
<span id="cb5-28"><a href="#cb5-28"></a>    delta <span class="op">=</span> (beta <span class="op">*</span> (lp_pos <span class="op">/</span> len_pos) <span class="op">-</span> beta <span class="op">*</span> (lp_neg <span class="op">/</span> len_neg) <span class="op">-</span> gamma)</span>
<span id="cb5-29"><a href="#cb5-29"></a></span>
<span id="cb5-30"><a href="#cb5-30"></a>    loss <span class="op">=</span> <span class="op">-</span>F.logsigmoid(delta).mean()</span>
<span id="cb5-31"><a href="#cb5-31"></a></span>
<span id="cb5-32"><a href="#cb5-32"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-33"><a href="#cb5-33"></a>    loss.backward()</span>
<span id="cb5-34"><a href="#cb5-34"></a>    optimizer.step()</span>
<span id="cb5-35"><a href="#cb5-35"></a></span>
<span id="cb5-36"><a href="#cb5-36"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="length-normalized-dpo" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="length-normalized-dpo"><span class="header-section-number">2.6.1</span> Length Normalized DPO</h3>
<div class="sourceCode" id="cb6" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="im">import</span> torch</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="kw">def</span> dpo_len_norm_step(</span>
<span id="cb6-5"><a href="#cb6-5"></a>    policy, ref_policy, optimizer,</span>
<span id="cb6-6"><a href="#cb6-6"></a>    pos_input_ids, pos_attn, pos_rmask,</span>
<span id="cb6-7"><a href="#cb6-7"></a>    neg_input_ids, neg_attn, neg_rmask,</span>
<span id="cb6-8"><a href="#cb6-8"></a>    beta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb6-9"><a href="#cb6-9"></a>):</span>
<span id="cb6-10"><a href="#cb6-10"></a>    <span class="kw">def</span> seq_logprob_and_len(model, input_ids, attn_mask, resp_mask):</span>
<span id="cb6-11"><a href="#cb6-11"></a>        logits <span class="op">=</span> model(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attn_mask).logits</span>
<span id="cb6-12"><a href="#cb6-12"></a>        logits <span class="op">=</span> logits[:, :<span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb6-13"><a href="#cb6-13"></a>        labels <span class="op">=</span> input_ids[:, <span class="dv">1</span>:]</span>
<span id="cb6-14"><a href="#cb6-14"></a></span>
<span id="cb6-15"><a href="#cb6-15"></a>        logp <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-16"><a href="#cb6-16"></a>        tok_logp <span class="op">=</span> logp.gather(<span class="op">-</span><span class="dv">1</span>, labels.unsqueeze(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb6-17"><a href="#cb6-17"></a></span>
<span id="cb6-18"><a href="#cb6-18"></a>        mask <span class="op">=</span> (resp_mask[:, <span class="dv">1</span>:] <span class="op">&amp;</span> attn_mask[:, <span class="dv">1</span>:]).to(tok_logp.dtype)</span>
<span id="cb6-19"><a href="#cb6-19"></a>        seq_lp <span class="op">=</span> (tok_logp <span class="op">*</span> mask).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)            <span class="co"># (B,)</span></span>
<span id="cb6-20"><a href="#cb6-20"></a>        resp_len <span class="op">=</span> mask.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>).clamp_min(<span class="fl">1.0</span>)        <span class="co"># (B,)</span></span>
<span id="cb6-21"><a href="#cb6-21"></a>        <span class="cf">return</span> seq_lp, resp_len</span>
<span id="cb6-22"><a href="#cb6-22"></a></span>
<span id="cb6-23"><a href="#cb6-23"></a>    <span class="co"># policy</span></span>
<span id="cb6-24"><a href="#cb6-24"></a>    lp_pos, len_pos <span class="op">=</span> seq_logprob_and_len(policy, pos_input_ids, pos_attn, pos_rmask)</span>
<span id="cb6-25"><a href="#cb6-25"></a>    lp_neg, len_neg <span class="op">=</span> seq_logprob_and_len(policy, neg_input_ids, neg_attn, neg_rmask)</span>
<span id="cb6-26"><a href="#cb6-26"></a></span>
<span id="cb6-27"><a href="#cb6-27"></a>    <span class="co"># ref (no grad)</span></span>
<span id="cb6-28"><a href="#cb6-28"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-29"><a href="#cb6-29"></a>        lp_ref_pos, len_ref_pos <span class="op">=</span> seq_logprob_and_len(ref_policy, pos_input_ids, pos_attn, pos_rmask)</span>
<span id="cb6-30"><a href="#cb6-30"></a>        lp_ref_neg, len_ref_neg <span class="op">=</span> seq_logprob_and_len(ref_policy, neg_input_ids, neg_attn, neg_rmask)</span>
<span id="cb6-31"><a href="#cb6-31"></a></span>
<span id="cb6-32"><a href="#cb6-32"></a>    <span class="co"># length-normalized log-ratio</span></span>
<span id="cb6-33"><a href="#cb6-33"></a>    pos_term <span class="op">=</span> (lp_pos <span class="op">/</span> len_pos) <span class="op">-</span> (lp_ref_pos <span class="op">/</span> len_ref_pos)</span>
<span id="cb6-34"><a href="#cb6-34"></a>    neg_term <span class="op">=</span> (lp_neg <span class="op">/</span> len_neg) <span class="op">-</span> (lp_ref_neg <span class="op">/</span> len_ref_neg)</span>
<span id="cb6-35"><a href="#cb6-35"></a>    delta <span class="op">=</span> beta <span class="op">*</span> (pos_term <span class="op">-</span> neg_term)</span>
<span id="cb6-36"><a href="#cb6-36"></a></span>
<span id="cb6-37"><a href="#cb6-37"></a>    loss <span class="op">=</span> <span class="op">-</span>F.logsigmoid(delta).mean()</span>
<span id="cb6-38"><a href="#cb6-38"></a></span>
<span id="cb6-39"><a href="#cb6-39"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-40"><a href="#cb6-40"></a>    loss.backward()</span>
<span id="cb6-41"><a href="#cb6-41"></a>    optimizer.step()</span>
<span id="cb6-42"><a href="#cb6-42"></a></span>
<span id="cb6-43"><a href="#cb6-43"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="ppo-vs.-dpo" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="ppo-vs.-dpo"><span class="header-section-number">2.7</span> PPO vs.&nbsp;DPO</h2>
<ul>
<li><p><strong>PPO çš„ä¼˜åŠ¿æ¥è‡ªâ€œæ›´çµæ´»çš„ä¼˜åŒ–ä¿¡å·â€</strong><br>
PPO æ˜¾å¼åš on-policy rollout + advantageï¼ˆGAEï¼‰+ clip + KL çº¦æŸï¼Œèƒ½æ›´ç›´æ¥åœ°æŠŠâ€œå¥–åŠ±æ¨¡å‹/åå¥½ä¿¡å·â€è½¬æˆæ¢¯åº¦æ›´æ–°ï¼›<br>
DPO/SimPO æ›´åƒâ€œæŠŠ RL å˜æˆç›‘ç£å­¦ä¹ â€ï¼Œç®€å•ã€ç¨³å®šã€ä¾¿å®œï¼Œä½†<strong>è¡¨è¾¾èƒ½åŠ›/å¯æ§æ€§æœ‰æ—¶ä¸å¦‚ PPO</strong>ï¼ˆå°¤å…¶å½“ä½ éœ€è¦æ›´ç»†çš„æ§åˆ¶æˆ– reward å¾ˆå¤æ‚æ—¶ï¼‰ã€‚</p></li>
<li><p><strong>å³ä¾§ TÃ¼lu 3 çš„è¡¨ï¼šåŒä¸€ä¸ª benchmark ä¸Šï¼Œç»“è®ºä¹Ÿä¼šè·Ÿç€è¶…å‚å’Œå˜ä½“è·‘</strong><br>
ä½ ä¼šçœ‹åˆ° SimPOã€DPOã€PPOã€DPO-normï¼ˆé•¿åº¦å½’ä¸€åŒ–ï¼‰åˆ†æ•°å·®å¼‚ä¸å¤§ï¼Œè€Œä¸”å¯¹ <strong>Î²ã€Î³ã€å­¦ä¹ ç‡ã€batch sizeã€epoch</strong> å¾ˆæ•æ„Ÿã€‚<br>
â‡’ è¿™é¡µæƒ³è®©ä½ è®°ä½ï¼š<strong>åœ¨ RLHF é‡Œï¼Œå·¥ç¨‹ç»†èŠ‚ï¼ˆæ•°æ® + è¶…å‚ + è®­ç»ƒrecipeï¼‰å¾€å¾€æ¯”â€œç®—æ³•åå­—â€æ›´å†³å®šç»“æœã€‚</strong></p></li>
</ul>
<p>DPO/SimPO æŠŠ RLHF ç®€åŒ–æˆâ€œå¥½å®ç°çš„ç›‘ç£å­¦ä¹ â€ï¼Œä½† PPO ä»å¯èƒ½åœ¨æŸäº›æ•°æ®/å¥–åŠ±/è¶…å‚ç»„åˆä¸‹æ›´å¼ºï¼›å› æ­¤ RLHF çš„å®éªŒç»“è®ºå¿…é¡»è¿åŒ setup ä¸€èµ·çœ‹ã€‚</p>
</section>
</section>
<section id="things-to-watch-out-for-in-rlhf" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Things to watch out for in RLHF</h1>
<p>æ¥ä¸‹æ¥æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹RLHFä¸­å¸¸è§çš„ä¸¤ä¸ªå‘ï¼š</p>
<ul>
<li>å¯¹å¥–åŠ±è¿‡åº¦ä¼˜åŒ–ï¼ˆreward overoptimization / reward hackingï¼‰</li>
<li>mode collapse / entropy</li>
</ul>
<section id="over-optimization" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="over-optimization"><span class="header-section-number">3.1</span> Over-optimization</h2>
<ul>
<li><p>æ¨ªè½´æ˜¯ <strong>KL distance</strong>ï¼ˆRL åçš„ç­–ç•¥è·Ÿåˆå§‹/å‚è€ƒç­–ç•¥å·®å¤šè¿œï¼‰ã€‚</p></li>
<li><p>çºµè½´æ˜¯ <strong>RM score</strong>ï¼ˆreward model ç»™çš„åˆ†ï¼‰ã€‚</p></li>
<li><p>æ›²çº¿å…ˆå‡åâ€œå˜åâ€ï¼šä¸€å¼€å§‹å¾€ RM å–œæ¬¢çš„æ–¹å‘èµ°ï¼Œåˆ†æ•°ä¸Šå‡ï¼›ä½†å½“ KL è¶Šæ¥è¶Šå¤§æ—¶ï¼Œæ¨¡å‹ä¼šå­¦åˆ° <strong>å¥–åŠ±æ¨¡å‹çš„æ¼æ´/æ·å¾„</strong>ï¼Œå¯¼è‡´ï¼š</p>
<ul>
<li><p>RM åˆ†æ•°å¯èƒ½è¿˜å¾ˆé«˜ï¼Œ<strong>ä½†çœŸå®è´¨é‡ï¼ˆäººç±»åå¥½/äº‹å®æ€§/æœ‰ç”¨æ€§ï¼‰å¼€å§‹ä¸‹é™</strong>ï¼›</p></li>
<li><p>è¿™å°±æ˜¯å…¸å‹çš„ <strong>â€œå¯¹ä»£ç†ç›®æ ‡ï¼ˆproxy rewardï¼‰è¿‡æ‹Ÿåˆâ€</strong>ã€‚</p></li>
</ul></li>
</ul>
<p>ä¸€å¥è¯ï¼š<strong>ä½ ä¼˜åŒ–çš„æ˜¯ RMï¼Œä¸æ˜¯äººç±»çœŸå®åå¥½ï¼›èµ°å¤ªè¿œä¼šå¼€å§‹â€œåˆ·åˆ†â€ã€‚</strong></p>
</section>
<section id="model-collapse" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="model-collapse"><span class="header-section-number">3.2</span> Model Collapse</h2>
<p>RLHF ä¼šæŠŠæ¨¡å‹ä»â€œæŒ‰æ¦‚ç‡æ‹Ÿåˆæ•°æ®â€çš„è¯­è¨€æ¨¡å‹ï¼Œæ¨æˆâ€œä¸ºæ‹¿é«˜å¥–åŠ±è€Œè¾“å‡ºâ€çš„ç­–ç•¥æ¨¡å‹ï¼Œä»è€Œé™ä½è¾“å‡ºåˆ†å¸ƒçš„ç†µã€å‹ç¼©å¤šæ ·æ€§ï¼Œå¹¶è®©æ¨¡å‹çš„ç½®ä¿¡åº¦ä¸å†å¯ä¿¡ï¼ˆcalibration å˜å·®ï¼‰ã€‚</p>
<p>This is the updated content.</p>
</section>
</section>
<section id="summary" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Summary</h1>
<p>è¿™èŠ‚è¯¾æŠŠâ€œåè®­ç»ƒï¼ˆpost-trainingï¼‰â€çš„ä¸»çº¿ä¸²èµ·æ¥äº†ï¼šå…ˆç”¨ <strong>SFT</strong> æŠŠæ¨¡å‹ä»â€œä¼šç»­å†™â€æ‹‰åˆ°â€œä¼šæŒ‰æŒ‡ä»¤å›ç­”â€ï¼Œå†ç”¨ <strong>RLHFï¼ˆPPO/DPO/SimPO ç­‰ï¼‰</strong> å»å¯¹é½äººç±»åå¥½ä¸å®‰å…¨è§„èŒƒï¼Œå¹¶è®¨è®ºäº†ä¸€ä¸ªå¾ˆå…³é”®çš„ç°å®ï¼šRLHF çš„ç›®æ ‡å‡½æ•°æœ¬è´¨æ˜¯â€œå¥–åŠ±æœ€å¤§åŒ–ï¼ˆå¸¦ KL çº¦æŸï¼‰â€ï¼Œè¿™ä¼šè®©æ¨¡å‹ä»æ¦‚ç‡å»ºæ¨¡å™¨å˜æˆç­–ç•¥ä¼˜åŒ–å™¨ï¼Œå› æ­¤ä¼šå¸¦æ¥éœ€è¦è­¦æƒ•çš„å‰¯ä½œç”¨â€”â€”<strong>è¿‡ä¼˜åŒ– rewardï¼ˆreward hacking/overfittingï¼‰</strong>ã€<strong>æ¨¡å¼åç¼©/ç†µåç¼©ï¼ˆå¤šæ ·æ€§ä¸‹é™ï¼‰</strong>ï¼Œä»¥åŠæ›´éšè”½ä½†å¾ˆé‡è¦çš„ <strong>calibration å˜å·®</strong>ï¼ˆæ¨¡å‹ç»™å‡ºçš„æ¦‚ç‡/ç½®ä¿¡åº¦ä¸å†å¯é ï¼‰ã€‚æˆ‘å­¦åˆ°çš„æ ¸å¿ƒæ˜¯ï¼šå¯¹é½ä¸æ˜¯â€œå†è®­ç»ƒä¸€æ¬¡â€è¿™ä¹ˆç®€å•ï¼Œè€Œæ˜¯<strong>æ•°æ®ã€ç›®æ ‡ã€æ­£åˆ™ã€è¯„ä¼°</strong>å…±åŒå†³å®šè¡Œä¸ºï¼›å°¤å…¶å½“ reward æœ‰å™ªå£°æˆ–åå·®æ—¶ï¼Œâ€œç»§ç»­æŠŠ reward æ‹‰é«˜â€åè€Œä¼šä¼¤å®³çœŸå®è´¨é‡ä¸æ³›åŒ–ï¼Œæ‰€ä»¥å¿…é¡»ç”¨ KLã€æ—©åœã€ç¦»çº¿è¯„ä¼°ä¸å¤šç»´æŒ‡æ ‡ï¼ˆhelpfulness/safety/verbosity/calibration/entropyï¼‰å»çº¦æŸä¸ç›‘æ§ã€‚</p>
<p>éœ€è¦æ³¨æ„çš„ç‚¹ï¼šç¬¬ä¸€ï¼ŒSFT æ•°æ®å¾ˆè´µä¸”å­˜åœ¨ <strong>G-V gap</strong>ï¼ˆäººå¹¶ä¸æ€»èƒ½å†™å‡ºè‡ªå·±çœŸæ­£åå¥½çš„ç­”æ¡ˆï¼‰ï¼Œæ‰€ä»¥åå¥½æ•°æ®ä¸å¥–åŠ±å­¦ä¹ ä¸å¯é¿å…ï¼›ç¬¬äºŒï¼ŒRLHF çš„è®­ç»ƒä¿¡å·ï¼ˆpairwise/æ ‡é‡ rewardï¼‰æ›´å®¹æ˜“è·å–ï¼Œä½†ä¹Ÿæ›´å®¹æ˜“è¢«æ¨¡å‹â€œé’»ç©ºå­â€ï¼Œå‡ºç° reward ä¸Šå‡ä½†äººè¯„/æ³›åŒ–ä¸‹é™ï¼›ç¬¬ä¸‰ï¼ŒRLHF å¾€å¾€ä¼šé™ä½ç†µå¹¶ç ´åæ ¡å‡†ï¼Œè¿™ä¼šå½±å“ç½®ä¿¡é—¨æ§ã€å·¥å…·è°ƒç”¨ä¸é£é™©æ§åˆ¶ç­‰ä¸‹æ¸¸ç³»ç»Ÿè®¾è®¡ï¼Œå› æ­¤åœ¨å·¥ç¨‹ä¸Šè¦æŠŠâ€œæ¨¡å‹æ¦‚ç‡â€å½“ä½œç­–ç•¥åˆ†æ•°è€Œéå¯é ç½®ä¿¡åº¦ï¼Œå¹¶ä¸“é—¨åšæ ¡å‡†/æ¸©åº¦/ç†µçº¦æŸä¸è¯„ä¼°ã€‚</p>
<p>ä¸‹ä¸€æ­¥æ˜¯ <strong>RLVRï¼ˆReinforcement Learning with Verifiable Rewardsï¼‰</strong>ï¼ŒåŸå› å¾ˆç›´æ¥ï¼šRLHF çš„éš¾ç‚¹åœ¨äºâ€œäººç±»åå¥½â€ä¸â€œå¥–åŠ±æ¨¡å‹â€éƒ½å¸¦å™ªå£°ï¼Œæ ‡æ³¨è´µã€å°ºåº¦éš¾ã€å®¹æ˜“è¿‡æ‹Ÿåˆå¥–åŠ±ï¼›è€Œ RLVR æŠŠè®­ç»ƒä¿¡å·æ¢æˆ<strong>å¯éªŒè¯ã€ä½å™ªå£°ã€å¯ç¨‹åºåŒ–åˆ¤å®š</strong>çš„ rewardï¼ˆä¾‹å¦‚æ•°å­¦/ä»£ç /çº¦æŸæ»¡è¶³/å•å…ƒæµ‹è¯•/æ ¼å¼ä¸å¯æ‰§è¡Œæ£€æŸ¥ï¼‰ï¼Œè®©ä¼˜åŒ–ç›®æ ‡æ›´æ¥è¿‘â€œå®¢è§‚æ­£ç¡®æ€§â€ï¼Œæ˜¾è‘—é™ä½ reward hacking çš„ç©ºé—´ï¼ŒåŒæ—¶æˆæœ¬æ›´ä½ã€å¯æ‰©å±•æ€§æ›´å¼ºã€‚æ¢å¥è¯è¯´ï¼ŒRLVR è¯•å›¾æŠŠå¯¹é½é‡Œæœ€ä¸ç¨³å®šçš„ä¸€ç¯ï¼ˆä¸»è§‚åå¥½ä¸ä»£ç† rewardï¼‰æ›¿æ¢æˆæ›´ç¡¬çš„ç›‘ç£ä¿¡å·ï¼Œä»è€Œåœ¨è§„æ¨¡åŒ–è®­ç»ƒæ—¶æ›´ç¨³ã€æ›´å¯æ§ï¼Œä¹Ÿæ›´é€‚åˆæŠŠâ€œæ¨ç†èƒ½åŠ›â€å¾€ä¸Šæ‹‰ã€‚</p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-OpenAssistantConversationsDemocratizing2023kopf" class="csl-entry" role="listitem">
KÃ¶pf, Andreas, Yannic Kilcher, Dimitri von RÃ¼tte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, et al. 2023. <span>â€œ<span>OpenAssistant Conversations</span> â€“ <span>Democratizing Large Language Model Alignment</span>.â€</span> October 31, 2023. <a href="https://doi.org/10.48550/arXiv.2304.07327">https://doi.org/10.48550/arXiv.2304.07327</a>.
</div>
<div id="ref-FlanCollectionDesigning2023longpre" class="csl-entry" role="listitem">
Longpre, Shayne, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, et al. 2023. <span>â€œThe <span>Flan Collection</span>: <span>Designing Data</span> and <span>Methods</span> for <span>Effective Instruction Tuning</span>.â€</span> February 14, 2023. <a href="https://doi.org/10.48550/arXiv.2301.13688">https://doi.org/10.48550/arXiv.2301.13688</a>.
</div>
<div id="ref-TrainingLanguageModels2022ouyang" class="csl-entry" role="listitem">
Ouyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. 2022. <span>â€œTraining Language Models to Follow Instructions with Human Feedback.â€</span> March 4, 2022. <a href="https://doi.org/10.48550/arXiv.2203.02155">https://doi.org/10.48550/arXiv.2203.02155</a>.
</div>
<div id="ref-DirectPreferenceOptimization2024rafailov" class="csl-entry" role="listitem">
Rafailov, Rafael, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2024. <span>â€œDirect <span>Preference Optimization</span>: <span>Your Language Model</span> Is <span>Secretly</span> a <span>Reward Model</span>.â€</span> July 29, 2024. <a href="https://doi.org/10.48550/arXiv.2305.18290">https://doi.org/10.48550/arXiv.2305.18290</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yyzhang2025\.github\.io\/LearningNotes");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark_dimmed">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "YYZhang2025/YYZhang2025.github.io";
    script.dataset.repoId = "R_kgDOQlDTcQ";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOQlDTcc4C2MRz";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../posts/CS336/Lecture13&amp;14/lec13.html" class="pagination-link" aria-label="Lecture 13&amp;14: Data Collection &amp; Processing">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Lecture 13&amp;14: Data Collection &amp; Processing</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../posts/CS336/Lecture16&amp;17/lec16.html" class="pagination-link" aria-label="Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)">
        <span class="nav-page-text">Lecture 16 &amp; 17: LLM Alignment SFT &amp; RLVR(GRPO)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Â© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with â¤ï¸ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize,
          commentDelimiter: el.dataset.commentDelimiter,
          lineNumber: el.dataset.lineNumber.toLowerCase() === "true",
          lineNumberPunc: el.dataset.lineNumberPunc,
          noEnd: el.dataset.noEnd.toLowerCase() === "true",
          titlePrefix: el.dataset.captionPrefix
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




<script src="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>