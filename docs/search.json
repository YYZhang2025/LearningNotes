[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About This Website",
    "section": "",
    "text": "åœ¨2026å¹´æ˜¥èŠ‚æœŸé—´ï¼Œæ— èŠè‡³æï¼Œäºæ˜¯å°†ä¹‹å‰çš„èµ„æ–™é‡æ–°æ•´ç†äº†ä¸€ä¸‹ï¼Œç»„æˆäº†è¿™ä¸ªç½‘ç«™ã€‚ä¸ä¹‹å‰çš„ç½‘ç«™ä¸ä¸€æ ·ï¼Œè¿™ä¸ªç½‘ç«™ä¸»è¦æ˜¯ç”¨æ¥è®°å½•ä¸åŒè¯¾ç¨‹ï¼Œé˜…è¯»ç¬”è®°ï¼Œä»¥åŠè¿˜åœ¨è¿›è¡Œçš„100 Paper with Code ç³»åˆ—çš„ã€‚ä¹‹æ‰€ä»¥æŠŠè¿™ä¸ªç½‘ç«™å‘½åä¸ºâ€œLearning Notesâ€ï¼Œæ˜¯å› ä¸ºæˆ‘è§‰å¾—è¿™ä¸ªåå­—æ¯”è¾ƒè´´åˆ‡ï¼Œæ¯•ç«Ÿè¿™ä¸ªç½‘ç«™çš„ä¸»è¦å†…å®¹å°±æ˜¯ä¸€äº›å­¦ä¹ ç¬”è®°ã€‚å¸Œæœ›è¿™ä¸ªç½‘ç«™èƒ½å¤Ÿå¸®åŠ©åˆ°ä¸€äº›æ­£åœ¨å­¦ä¹ ç›¸å…³è¯¾ç¨‹æˆ–è€…å¯¹ç›¸å…³é¢†åŸŸæ„Ÿå…´è¶£çš„äººã€‚\n\n\néšç€2023å¹´ChatGPTçš„çˆ†å‘ï¼Œéšä¹‹è€Œæ¥çš„æ˜¯å„ç§å„æ ·çš„AIå·¥å…·ï¼Œç½‘ç»œä¸Šä¹Ÿå……æ–¥ç€å„ç§AIç”Ÿæˆçš„å†…å®¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¹Ÿæœ‰å¥½å¤šå°ä¼™ä¼´ç§ä¿¡æˆ‘è¯´ï¼Œä¸ºä»€ä¹ˆè¿˜è¦å†™è¿™ç§å­¦ä¹ çš„ç¬”è®°ï¼Ÿç°åœ¨AIè¿™ä¹ˆå‘è¾¾ï¼Œç›´æ¥AIæ€»ç»“ï¼Œç”Ÿæˆä¸å°±å¥½äº†å—ï¼Ÿ çš„ç¡®ï¼Œä»ChatGPTï¼Œ åˆ°ç°åœ¨ï¼ˆ2026å¹´åˆï¼‰å¤§ç«çš„OpenClawï¼Œè¿™äº›AIå·¥å…·çš„ç¡®å¯ä»¥å¸®åŠ©æˆ‘ä»¬å®Œæˆå¾ˆå¤šä»»åŠ¡ï¼Œä½†æ˜¯ä½¿ç”¨ä¸‹æ¥ï¼Œç»™æˆ‘å¸¦æ¥çš„æ˜¯ä¸€ç§ç©ºè™šæ„Ÿï¼Œå°±å¥½åƒåƒäº†å¿«é¤ä¸€æ ·ï¼Œè™½ç„¶å¾ˆæ–¹ä¾¿ï¼Œä½†æ˜¯åƒå®Œä¹‹åå°±æ²¡æœ‰ä»€ä¹ˆæ»¡è¶³æ„Ÿäº†ã€‚å†…å®¹çˆ†ç‚¸å¼çš„å¢é•¿ï¼Œæ¯å¤©è¢«å„ç§ä¿¡æ¯åŒ…å›´ï¼Œä¸æ–­ç”¨AIå¡«è¡¥ç©ºç™½ï¼Œä½†å´å¾ˆéš¾çœŸæ­£æ¶ˆåŒ–å’Œç†è§£è¿™äº›ä¿¡æ¯ã€‚åŒ…æ‹¬ç°åœ¨çš„Vibe Codingï¼Œå¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…æ­å»ºï¼Œéƒ¨ç½²ä¸€ä¸ªå¯è¿è¡Œçš„ç½‘ç«™ï¼Œç„¶åå‘¢ï¼Ÿæˆ‘ä»¬éœ€è¦çš„ä¸æ˜¯ä¸€ä¸ªå¯è¿è¡Œçš„ç½‘ç«™ï¼Œè€Œæ˜¯ä¸€ä¸ªæœ‰ä»·å€¼ï¼Œæœ‰å†…å®¹çš„ç½‘ç«™ã€‚å°±å¥½åƒç°åœ¨çš„AIå·¥å…·ï¼Œå¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆä¸€ç¯‡æ–‡ç« ï¼Œä½†æ˜¯æˆ‘ä»¬éœ€è¦çš„ä¸æ˜¯ä¸€ç¯‡æ–‡ç« ï¼Œè€Œæ˜¯ä¸€ç¯‡æœ‰æ·±åº¦ï¼Œæœ‰è§è§£çš„æ–‡ç« ã€‚æ‰€ä»¥æˆ‘è§‰å¾—ï¼Œåœ¨è¿™ä¸ªAIæ—¶ä»£ï¼Œå†™å­¦ä¹ ç¬”è®°ä¾ç„¶æ˜¯éå¸¸æœ‰å¿…è¦çš„ã€‚é€šè¿‡å†™å­¦ä¹ ç¬”è®°ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°æ¶ˆåŒ–å’Œç†è§£è¿™äº›ä¿¡æ¯ï¼ŒçœŸæ­£æŒæ¡è¿™äº›çŸ¥è¯†ï¼Œè€Œä¸æ˜¯è¢«è¿™äº›ä¿¡æ¯æ‰€æ·¹æ²¡ã€‚æˆ‘å°è¯•è¿‡ç”¨Claudeæ¥æ”¶é›†æ€»ç»“æˆ‘æƒ³è¦çš„å†…å®¹ï¼Œå¾ˆå‰å®³ï¼Œä¸€ä¸‹å­åˆ›å»ºå‡ºæ¥20å¤šä¸ªMarkdownæ–‡ä»¶ï¼Œå†…å®¹ä¹Ÿæ˜¯å¯åœˆå¯ç‚¹ï¼Œæœ‰è®¸å¤šæˆ‘æ²¡æœ‰äº†è§£è¿‡çš„è§’åº¦ï¼Œä½†æ˜¯æˆ‘ä¸èƒ½ç«‹é©¬å¸æ”¶é‡Œé¢çš„å†…å®¹ï¼Œå°±å¥½åƒå›«å›µåæ£, è¿‡ç›®å°±å¿˜ï¼Œ åè€Œæ˜¯è‡ªå·±å†™çš„ç¬”è®°ï¼Œè™½ç„¶å¯èƒ½ä¸å¤Ÿå®Œç¾ï¼Œä½†æ˜¯åœ¨å†™çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘éœ€è¦ä¸æ–­åœ°æ€è€ƒï¼Œä¸æ–­åœ°ç†è§£ï¼Œè¿™æ ·æ‰èƒ½çœŸæ­£æŒæ¡è¿™äº›çŸ¥è¯†ã€‚æ‰€ä»¥æˆ‘è§‰å¾—ï¼Œåœ¨è¿™ä¸ªAIæ—¶ä»£ï¼Œå†™å­¦ä¹ ç¬”è®°ä¾ç„¶æ˜¯éå¸¸æœ‰å¿…è¦çš„ã€‚çŸ¥å…¶ç„¶è¿˜è¦çŸ¥å…¶æ‰€ä»¥ç„¶ï¼Œåªæœ‰çœŸæ­£ç†è§£äº†è¿™äº›çŸ¥è¯†ï¼Œæ‰èƒ½æ›´å¥½åœ°åº”ç”¨è¿™äº›çŸ¥è¯†ï¼Œè€Œä¸æ˜¯è¢«è¿™äº›çŸ¥è¯†æ‰€æŸç¼šã€‚\nç¬¬äºŒåŸå› å°±æ˜¯ï¼Œåœ¨æœ¬ç§‘æœŸé—´ï¼Œæœ‰å¹¸æ‹œè¯»è¿‡CSè‡ªå­¦æŒ‡å—ã€‚æˆ‘ç®—æ˜¯å®ƒçš„å¿ å®ç²‰ä¸äº†ï¼Œä»å®ƒåœ¨å‡ ç™¾ä¸ªâ­ï¸çš„é˜¶æ®µï¼Œåˆ°ç°åœ¨å·²ç»æœ‰7ä¸‡å¤šä¸ªâ­ï¸ï¼Œæˆ‘éƒ½ä¸€ç›´åœ¨å…³æ³¨å®ƒçš„æ›´æ–°ã€‚å®ƒçš„å†…å®¹éå¸¸ä¸°å¯Œï¼Œæ¶µç›–äº†è®¡ç®—æœºç§‘å­¦çš„å„ä¸ªé¢†åŸŸï¼Œä»åŸºç¡€çš„ç¼–ç¨‹ï¼Œåˆ°ç®—æ³•ï¼Œå†åˆ°äººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ ç­‰ç­‰ã€‚ä»é‚£æ—¶èµ·ï¼Œæˆ‘å°±è¢«å®ƒçš„ä½œè€…ï¼Œä»¥åŠé‡Œé¢æ¶µç›–çš„æ‰€æœ‰è¯¾ç¨‹çš„å¤§å­¦ï¼Œæ•™æˆçš„Open Sourceç²¾ç¥æ‰€æ·±æ·±å¸å¼•äº†ã€‚ä¹Ÿæ­£æ˜¯å› ä¸ºè¿™ä¸ªç½‘ç«™ï¼Œæˆ‘æ‰æœ‰äº†å†™å­¦ä¹ ç¬”è®°çš„æƒ³æ³•ï¼Œå¸Œæœ›èƒ½å¤ŸæŠŠæˆ‘åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç§¯ç´¯çš„ä¸€äº›çŸ¥è¯†å’Œç»éªŒåˆ†äº«ç»™æ›´å¤šçš„äººï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°å­¦ä¹ å’Œæˆé•¿ã€‚\n\n\n\nè¿™ä¸ªç½‘ç«™ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼š\n\nè¯¾ç¨‹ç¬”è®°ï¼šä¸€äº›ä¹‹å‰å­¦è¿‡çš„ç»å…¸è¯¾ç¨‹çš„ç¬”è®°ä»¥åŠæ€»ç»“ï¼Œæ¯”å¦‚æœ€è¿‘å¤§ç«çš„CS336ç­‰ã€‚\né˜…è¯»ç¬”è®°ï¼šè®°å½•ç»å…¸çš„ä¹¦ç±ï¼Œä»¥åŠé‡Œé¢Exerciseçš„è§£ç­”ï¼Œæ¯”å¦‚Bishopçš„ã€ŠDeep Learning Foundations and Concaptsã€‹ã€‚\n100 Paper with Codeç³»åˆ—: è®°å½•ä¸€äº›ç»å…¸çš„è®ºæ–‡ï¼Œä»¥åŠç»“åˆä»£ç å®ç°ï¼Œå¯¹å…¶ä¸­çš„ä¸€äº›é‡è¦å†…å®¹è¿›è¡Œæ€»ç»“å’Œåˆ†äº«ï¼Œæ¯”å¦‚ Transformer, DINO, CLIPç­‰ç­‰ã€‚\n\n\n\n\n\n\n  \n\n  \n\n    \n\n      \n      \n        \n          \n        \n      \n\n      \n\n        \n        \n          CS336: LLM from Scratch Lecture Notes and Assignments\n        \n\n        \n        \n          \n            CS336æ˜¯å…³äºä»é›¶å¼€å§‹æ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆè¯¾ç¨‹ï¼Œæ¶µç›–äº†ä»Transformeræ¶æ„çš„åŸºç¡€çŸ¥è¯†ï¼Œåˆ°MoEæ¨¡å‹ï¼ŒGPUåŠ é€Ÿï¼ŒParallelismè®­ç»ƒï¼Œæ¨¡å‹çš„è¯„ä¼°ï¼Œæ•°æ®çš„æ”¶é›†å’Œå¤„ç†ï¼Œä»¥åŠLLMçš„å¯¹é½ç®—æ³•ç­‰æœ€æ–°çš„è¿›å±•ã€‚è¿™ä¸ªé¡µé¢åŒ…å«äº†CS336è¯¾ç¨‹çš„æ‰€æœ‰å­¦ä¹ ç¬”è®°å’Œä½œä¸šè§£ç­”ã€‚\n          \n        \n\n      \n\n    \n\n  \n\n\nNo matching items\n\n\n\n\n\n\n\n  \n\n  \n\n    \n\n      \n      \n        \n          \n        \n      \n\n      \n\n        \n        \n          Deep Learning Foundation and Concepts(DLFaC) Learning Notes\n        \n\n        \n        \n          \n            This page contains all the learning notes for the Deep Learning Foundation and Concepts (DLFaC) course. I hope you can find something useful here. HAPPY LEARNINGğŸ˜ğŸ˜!!!\n          \n        \n\n      \n\n    \n\n  \n\n\nNo matching items\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\nCategories\n\n\n\n\n\n\n\n\n01: Attention is All You Need (Transformer)\n\n\nTransformer æ˜¯ä¸€ç§åŸºäº è‡ªæ³¨æ„åŠ›æœºåˆ¶ çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œèƒ½å¤Ÿå¹¶è¡Œå¤„ç†åºåˆ—ï¼Œåœ¨è¯­è¨€ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼›å¹¶ä¸”ä½œä¸º GPTã€BERT ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ ¸å¿ƒåŸºç¡€ï¼Œæ¨åŠ¨äº†å½“ä»Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•ã€‚åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ Transformer çš„åŸºæœ¬åŸç†ï¼Œä»¥åŠå…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬ Word Embeddingã€Position Embeddingã€Attentionã€Normalization Layer å’Œ Feed Forward Layerã€‚å¹¶é€šè¿‡åœ¨ Ted Talks æ•°æ®é›†ä¸Šçš„å®éªŒï¼Œå±•ç¤º Transformer åœ¨å®é™…ä»»åŠ¡ä¸­çš„åº”ç”¨æ•ˆæœã€‚\n\n\nNLP, Architecture, Transformer, â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸\n\n\n\n\n\n\n02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)\n\n\nVision Transformer (ViT) é€šè¿‡å°†å›¾åƒåˆ‡åˆ†ä¸º Patch å¹¶ç›´æ¥åº”ç”¨æ ‡å‡† Transformer æ¶æ„ï¼Œå®ç°äº†å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æœ¬æ–‡ä»‹ç»äº† ViT çš„æ ¸å¿ƒç»„ä»¶ï¼ŒåŒ…æ‹¬ Patch Embeddingã€Position Embeddingã€[CLS] Token ä»¥åŠ Transformer ç¼–ç å™¨å—ï¼Œæ¢è®¨äº† ViT ç›¸è¾ƒäºä¼ ç»Ÿ CNN çš„å½’çº³åç½®å·®å¼‚(Inductive Bias)ï¼Œå¹¶å±•ç¤ºäº† ViT åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„ä¼˜å¼‚è¡¨ç°ã€‚\n\n\nComputer Vision, Transformer\n\n\n\n\n\n\n03: Training data-efficient image transformers & distillation through attention (DeiT)\n\n\nTraining data-efficient image transformers & distillation through attentionï¼ˆDeiTï¼‰æå‡ºäº†ä¸€ç§é€šè¿‡çŸ¥è¯†è’¸é¦ï¼ˆdistillation token ä¸ attention-based distillationï¼‰æ˜¾è‘—æå‡ Vision Transformer æ•°æ®æ•ˆç‡çš„æ–¹æ³•ï¼Œä½¿ ViT èƒ½åœ¨ä¸­å°è§„æ¨¡æ•°æ®é›†ä¸Šé«˜æ•ˆè®­ç»ƒå¹¶è¾¾åˆ°ä¸ CNN å¯æ¯”çš„æ€§èƒ½ã€‚\n\n\nComputer Vision, Transformer, Knowledge Distillation\n\n\n\n\n\n\n04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)\n\n\nSwin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚\n\n\nComputer Vision, Attention, Transformer\n\n\n\n\n\n\n05: ViViT: A Video Vision Transformer(ViViT)\n\n\nViViT: A Video Vision Transformeræå‡ºå°† Vision Transformer ç³»ç»Ÿæ€§æ‰©å±•åˆ°è§†é¢‘å»ºæ¨¡ï¼Œé€šè¿‡æ—¶ç©ºåˆ†è§£ä¸é«˜æ•ˆæ³¨æ„åŠ›è®¾è®¡ç›´æ¥å¯¹è§†é¢‘åºåˆ—è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨è§†é¢‘åˆ†ç±»ç­‰ä»»åŠ¡ä¸Šå–å¾—å¼ºæ€§èƒ½ä¸è‰¯å¥½å¯æ‰©å±•æ€§ã€‚\n\n\nComputer Vision, Transformer\n\n\n\n\n\n\n06: Learning Transferable Visual Models From Natural Language Supervision (CLIP)\n\n\nä¸€ç§é€šè¿‡å¯¹é½å›¾åƒä¸è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œåœ¨æµ·é‡å›¾æ–‡å¯¹ä¸Šè®­ç»ƒç»Ÿä¸€è¡¨ç¤ºï¼Œä»è€Œè·å¾—å¼ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›çš„è§†è§‰æ¨¡å‹ã€‚\n\n\nMulti Modality, Representation Learning\n\n\n\n\n\n\n07: Emerging Properties in Self-Supervised Vision Transformers (DINO)\n\n\nä¸€ç§æ— éœ€æ ‡ç­¾çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æ•™å¸ˆâ€“å­¦ç”Ÿè‡ªè’¸é¦è®­ç»ƒ Vision Transformerï¼Œè‡ªå‘æ¶Œç°å‡ºè¯­ä¹‰ä¸€è‡´çš„å…¨å±€è¡¨ç¤ºä¸æ¸…æ™°çš„æ³¨æ„åŠ›åˆ†å‰²èƒ½åŠ›ã€‚\n\n\nSelf Supervised Learning, Representation Learning\n\n\n\n\n\n\n08: Auto-Encoding Variational Bayes (VAE)\n\n\nVAEï¼ˆå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼‰æ˜¯ä¸€ç±»ç»“åˆæ¦‚ç‡å›¾æ¨¡å‹ä¸ç¥ç»ç½‘ç»œçš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡å¼•å…¥å¯å‚æ•°åŒ–çš„è¿‘ä¼¼åéªŒ \\(q_\\phi(z|x)\\) æ¥æ‘Šé”€æ¨æ–­æˆæœ¬ï¼Œå¹¶ç”¨æœ€å¤§åŒ– ELBO çš„æ–¹å¼åŒæ—¶å­¦ä¹ æ•°æ®çš„æ½œåœ¨è¡¨ç¤ºä¸ç”Ÿæˆè¿‡ç¨‹ï¼šå…¶ä¸­é‡å»ºé¡¹ç¡®ä¿æ¨¡å‹èƒ½ä»æ½œå˜é‡è¿˜åŸæ•°æ®ï¼ŒKL é¡¹åˆ™å°†æ½œç©ºé—´çº¦æŸä¸ºæ¥è¿‘å…ˆéªŒçš„è¿ç»­ç»“æ„ã€‚å€ŸåŠ©é‡å‚æ•°åŒ–æŠ€å·§ï¼ŒVAE èƒ½åœ¨ç«¯åˆ°ç«¯è®­ç»ƒä¸­é«˜æ•ˆåœ°å­¦ä¹ ä¸€ä¸ªå¹³æ»‘ã€å¯é‡‡æ ·çš„æ½œç©ºé—´ï¼Œä»è€Œå®ç°è¡¨ç¤ºå­¦ä¹ ã€æ’å€¼ã€ç”Ÿæˆç­‰åŠŸèƒ½ï¼Œæ˜¯ç°ä»£æ·±åº¦ç”Ÿæˆæ¨¡å‹çš„é‡è¦åŸºç¡€ã€‚\n\n\nSelf Supervised Learning, Generative Model, Representation Learning\n\n\n\n\n\n\n09: Masked Autoencoders Are Scalable Vision Learners(MAE)\n\n\nä¸€ç§é€šè¿‡éšæœºé®æŒ¡å¤§æ¯”ä¾‹å›¾åƒ patch å¹¶é‡å»ºç¼ºå¤±å†…å®¹è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿ Vision Transformer èƒ½ä»¥æ›´é«˜æ•ˆç‡å’Œæ›´å¥½å¯æ‰©å±•æ€§å­¦ä¹ é€šç”¨è§†è§‰è¡¨ç¤ºã€‚\n\n\nSelf Supervised Learning, Representation Learning, AutoEncoder\n\n\n\n\n\n\n10: Conditional Image Generation with PixelCNN Decoders (Pixel Gated CNN)\n\n\nä¸€ç§åŸºäºåƒç´ çº§è‡ªå›å½’å»ºæ¨¡çš„æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é—¨æ§å·ç§¯ï¼ˆGated CNNï¼‰åœ¨ç»™å®šæ¡ä»¶ï¼ˆå¦‚ç±»åˆ«æˆ–ä¸Šä¸‹æ–‡ï¼‰ä¸‹é€åƒç´ ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚\n\n\nGenerative Model\n\n\n\n\n\n\n11: Neural Discrete Representation Learning (VQ_VAE)\n\n\nä¸€ç§é€šè¿‡ç¦»æ•£åŒ–æ½œåœ¨è¡¨ç¤ºå¹¶ä½¿ç”¨ç æœ¬è¿›è¡Œé‡æ„çš„ç”Ÿæˆæ¨¡å‹ï¼Œå°†è¿ç»­è¡¨ç¤ºè½¬ä¸ºç¦»æ•£ç¬¦å·ï¼Œä»è€Œå­¦ä¹ é«˜è´¨é‡ã€å¯ç»„åˆçš„è§†è§‰è¡¨ç¤ºå¹¶æ”¯æŒé«˜æ•ˆç”Ÿæˆã€‚\n\n\nRepresentation Learning, Self Supervised Learning\n\n\n\n\n\n\n15: High-Resolution Image Synthesis with Latent Diffusion Models (Latent Diffusion Model)\n\n\nä¸€ç§åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£å»ºæ¨¡çš„ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ã€é«˜è´¨é‡çš„å›¾åƒç”Ÿæˆã€‚\n\n\nGenerative Model\n\n\n\n\n\n\n16: Scalable Diffusion Models with Transformers (DiT)\n\n\nä¸€ç§å°† Transformer æ¶æ„å¼•å…¥æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡åºåˆ—åŒ–å»ºæ¨¡ä¸è§„æ¨¡åŒ–è®­ç»ƒï¼Œåœ¨å¤§æ¨¡å‹ä¸å¤§æ•°æ®è®¾ç½®ä¸‹å®ç°æ›´å¼ºçš„ç”Ÿæˆè´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚\n\n\nGenerative Model, Diffusion Model\n\n\n\n\n\n\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)\n\n\nFlashAttention æ˜¯ä¸€IO-awareçš„exact Attention å®ç°ï¼šå®ƒæŠŠ QKáµ€ å’Œ softmax çš„è®¡ç®—æŒ‰å—ï¼ˆtilingï¼‰æ¬è¿›ç‰‡ä¸Š SRAM/å…±äº«å†…å­˜ï¼Œç”¨åœ¨çº¿ softmaxï¼ˆç»´æŠ¤ running max ä¸ sum çš„ log-sum-exp å½’ä¸€åŒ–ï¼‰åœ¨ä¸ä¿å­˜å®Œæ•´æ³¨æ„åŠ›çŸ©é˜µçš„æƒ…å†µä¸‹å®Œæˆè®¡ç®—ï¼Œå¹¶ä¸”é€šè¿‡Recomputingçš„æŠ€æœ¯ï¼Œä»è€Œæ˜¾è‘—å‡å°‘ HBM è¯»å†™ã€é™ä½æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿã€‚\n\n\nTransformer\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\næœ€åï¼Œå¸Œæœ›è¿™ä¸ªç½‘ç«™èƒ½å¤Ÿå¸®åŠ©åˆ°ä¸€äº›æ­£åœ¨å­¦ä¹ ç›¸å…³è¯¾ç¨‹æˆ–è€…å¯¹ç›¸å…³é¢†åŸŸæ„Ÿå…´è¶£çš„äººã€‚å¦‚æœä½ æƒ³è¦æ›´å…¨é¢çš„äº†è§£æŸä¸€æ–¹é¢çš„çŸ¥è¯†ï¼Œæˆ‘æ¨èå¯ä»¥å»é˜…è¯»æˆ‘ä»¬çš„Blogï¼Œé‡Œé¢æœ‰å¾ˆå¤šå…³äºä¸åŒé¢†åŸŸçš„å†…å®¹ã€‚\n\nå½“ç„¶ï¼Œç”±äºä¸ªäººç²¾åŠ›æœ‰é™ï¼Œç½‘ç«™å†…å®¹éš¾å…æœ‰æ‰€ä¸è¶³ä¹‹å¤„ï¼Œå¦‚æœä½ æœ‰ä»»ä½•å»ºè®®æˆ–è€…æƒ³è¦åˆ†äº«çš„å†…å®¹ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ã€‚è°¢è°¢ï¼\n\n\n\nè¿™ä¸ªç½‘ç«™çš„Logoæ˜¯æˆ‘å®¶çš„çŒ«ï¼Œå«åšèŠ±èŠ±ã€‚å¸Œæœ›å¤§å®¶åœ¨AIçš„æ—¶ä»£ï¼Œèƒ½å¤ŸåƒèŠ±èŠ±ä¸€æ ·ï¼Œä¿æŒå¥½å¥‡å¿ƒå’Œæ¢ç´¢ç²¾ç¥ï¼Œä¸æ–­åœ°å­¦ä¹ å’Œæˆé•¿ã€‚ä¹Ÿå¸Œæœ›è¿™ä¸ªç½‘ç«™èƒ½å¤Ÿæˆä¸ºä¸€ä¸ªæœ‰ä»·å€¼ï¼Œæœ‰å†…å®¹çš„ç½‘ç«™ï¼Œå¸®åŠ©æ›´å¤šçš„äººå­¦ä¹ å’Œæˆé•¿ã€‚ä¹Ÿå¸Œæœ›è¿™åªå¯çˆ±çš„çŒ«å’ªèƒ½å¤Ÿç»™å¤§å®¶å¸¦æ¥ä¸€äº›å¿«ä¹å’Œæ¸©æš–ã€‚",
    "crumbs": [
      "About website"
    ]
  },
  {
    "objectID": "index.html#ä¸ºä»€ä¹ˆåœ¨aiæ—¶ä»£è¿˜è¦å†™å­¦ä¹ ç¬”è®°",
    "href": "index.html#ä¸ºä»€ä¹ˆåœ¨aiæ—¶ä»£è¿˜è¦å†™å­¦ä¹ ç¬”è®°",
    "title": "About This Website",
    "section": "",
    "text": "éšç€2023å¹´ChatGPTçš„çˆ†å‘ï¼Œéšä¹‹è€Œæ¥çš„æ˜¯å„ç§å„æ ·çš„AIå·¥å…·ï¼Œç½‘ç»œä¸Šä¹Ÿå……æ–¥ç€å„ç§AIç”Ÿæˆçš„å†…å®¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¹Ÿæœ‰å¥½å¤šå°ä¼™ä¼´ç§ä¿¡æˆ‘è¯´ï¼Œä¸ºä»€ä¹ˆè¿˜è¦å†™è¿™ç§å­¦ä¹ çš„ç¬”è®°ï¼Ÿç°åœ¨AIè¿™ä¹ˆå‘è¾¾ï¼Œç›´æ¥AIæ€»ç»“ï¼Œç”Ÿæˆä¸å°±å¥½äº†å—ï¼Ÿ çš„ç¡®ï¼Œä»ChatGPTï¼Œ åˆ°ç°åœ¨ï¼ˆ2026å¹´åˆï¼‰å¤§ç«çš„OpenClawï¼Œè¿™äº›AIå·¥å…·çš„ç¡®å¯ä»¥å¸®åŠ©æˆ‘ä»¬å®Œæˆå¾ˆå¤šä»»åŠ¡ï¼Œä½†æ˜¯ä½¿ç”¨ä¸‹æ¥ï¼Œç»™æˆ‘å¸¦æ¥çš„æ˜¯ä¸€ç§ç©ºè™šæ„Ÿï¼Œå°±å¥½åƒåƒäº†å¿«é¤ä¸€æ ·ï¼Œè™½ç„¶å¾ˆæ–¹ä¾¿ï¼Œä½†æ˜¯åƒå®Œä¹‹åå°±æ²¡æœ‰ä»€ä¹ˆæ»¡è¶³æ„Ÿäº†ã€‚å†…å®¹çˆ†ç‚¸å¼çš„å¢é•¿ï¼Œæ¯å¤©è¢«å„ç§ä¿¡æ¯åŒ…å›´ï¼Œä¸æ–­ç”¨AIå¡«è¡¥ç©ºç™½ï¼Œä½†å´å¾ˆéš¾çœŸæ­£æ¶ˆåŒ–å’Œç†è§£è¿™äº›ä¿¡æ¯ã€‚åŒ…æ‹¬ç°åœ¨çš„Vibe Codingï¼Œå¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…æ­å»ºï¼Œéƒ¨ç½²ä¸€ä¸ªå¯è¿è¡Œçš„ç½‘ç«™ï¼Œç„¶åå‘¢ï¼Ÿæˆ‘ä»¬éœ€è¦çš„ä¸æ˜¯ä¸€ä¸ªå¯è¿è¡Œçš„ç½‘ç«™ï¼Œè€Œæ˜¯ä¸€ä¸ªæœ‰ä»·å€¼ï¼Œæœ‰å†…å®¹çš„ç½‘ç«™ã€‚å°±å¥½åƒç°åœ¨çš„AIå·¥å…·ï¼Œå¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆä¸€ç¯‡æ–‡ç« ï¼Œä½†æ˜¯æˆ‘ä»¬éœ€è¦çš„ä¸æ˜¯ä¸€ç¯‡æ–‡ç« ï¼Œè€Œæ˜¯ä¸€ç¯‡æœ‰æ·±åº¦ï¼Œæœ‰è§è§£çš„æ–‡ç« ã€‚æ‰€ä»¥æˆ‘è§‰å¾—ï¼Œåœ¨è¿™ä¸ªAIæ—¶ä»£ï¼Œå†™å­¦ä¹ ç¬”è®°ä¾ç„¶æ˜¯éå¸¸æœ‰å¿…è¦çš„ã€‚é€šè¿‡å†™å­¦ä¹ ç¬”è®°ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°æ¶ˆåŒ–å’Œç†è§£è¿™äº›ä¿¡æ¯ï¼ŒçœŸæ­£æŒæ¡è¿™äº›çŸ¥è¯†ï¼Œè€Œä¸æ˜¯è¢«è¿™äº›ä¿¡æ¯æ‰€æ·¹æ²¡ã€‚æˆ‘å°è¯•è¿‡ç”¨Claudeæ¥æ”¶é›†æ€»ç»“æˆ‘æƒ³è¦çš„å†…å®¹ï¼Œå¾ˆå‰å®³ï¼Œä¸€ä¸‹å­åˆ›å»ºå‡ºæ¥20å¤šä¸ªMarkdownæ–‡ä»¶ï¼Œå†…å®¹ä¹Ÿæ˜¯å¯åœˆå¯ç‚¹ï¼Œæœ‰è®¸å¤šæˆ‘æ²¡æœ‰äº†è§£è¿‡çš„è§’åº¦ï¼Œä½†æ˜¯æˆ‘ä¸èƒ½ç«‹é©¬å¸æ”¶é‡Œé¢çš„å†…å®¹ï¼Œå°±å¥½åƒå›«å›µåæ£, è¿‡ç›®å°±å¿˜ï¼Œ åè€Œæ˜¯è‡ªå·±å†™çš„ç¬”è®°ï¼Œè™½ç„¶å¯èƒ½ä¸å¤Ÿå®Œç¾ï¼Œä½†æ˜¯åœ¨å†™çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘éœ€è¦ä¸æ–­åœ°æ€è€ƒï¼Œä¸æ–­åœ°ç†è§£ï¼Œè¿™æ ·æ‰èƒ½çœŸæ­£æŒæ¡è¿™äº›çŸ¥è¯†ã€‚æ‰€ä»¥æˆ‘è§‰å¾—ï¼Œåœ¨è¿™ä¸ªAIæ—¶ä»£ï¼Œå†™å­¦ä¹ ç¬”è®°ä¾ç„¶æ˜¯éå¸¸æœ‰å¿…è¦çš„ã€‚çŸ¥å…¶ç„¶è¿˜è¦çŸ¥å…¶æ‰€ä»¥ç„¶ï¼Œåªæœ‰çœŸæ­£ç†è§£äº†è¿™äº›çŸ¥è¯†ï¼Œæ‰èƒ½æ›´å¥½åœ°åº”ç”¨è¿™äº›çŸ¥è¯†ï¼Œè€Œä¸æ˜¯è¢«è¿™äº›çŸ¥è¯†æ‰€æŸç¼šã€‚\nç¬¬äºŒåŸå› å°±æ˜¯ï¼Œåœ¨æœ¬ç§‘æœŸé—´ï¼Œæœ‰å¹¸æ‹œè¯»è¿‡CSè‡ªå­¦æŒ‡å—ã€‚æˆ‘ç®—æ˜¯å®ƒçš„å¿ å®ç²‰ä¸äº†ï¼Œä»å®ƒåœ¨å‡ ç™¾ä¸ªâ­ï¸çš„é˜¶æ®µï¼Œåˆ°ç°åœ¨å·²ç»æœ‰7ä¸‡å¤šä¸ªâ­ï¸ï¼Œæˆ‘éƒ½ä¸€ç›´åœ¨å…³æ³¨å®ƒçš„æ›´æ–°ã€‚å®ƒçš„å†…å®¹éå¸¸ä¸°å¯Œï¼Œæ¶µç›–äº†è®¡ç®—æœºç§‘å­¦çš„å„ä¸ªé¢†åŸŸï¼Œä»åŸºç¡€çš„ç¼–ç¨‹ï¼Œåˆ°ç®—æ³•ï¼Œå†åˆ°äººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ ç­‰ç­‰ã€‚ä»é‚£æ—¶èµ·ï¼Œæˆ‘å°±è¢«å®ƒçš„ä½œè€…ï¼Œä»¥åŠé‡Œé¢æ¶µç›–çš„æ‰€æœ‰è¯¾ç¨‹çš„å¤§å­¦ï¼Œæ•™æˆçš„Open Sourceç²¾ç¥æ‰€æ·±æ·±å¸å¼•äº†ã€‚ä¹Ÿæ­£æ˜¯å› ä¸ºè¿™ä¸ªç½‘ç«™ï¼Œæˆ‘æ‰æœ‰äº†å†™å­¦ä¹ ç¬”è®°çš„æƒ³æ³•ï¼Œå¸Œæœ›èƒ½å¤ŸæŠŠæˆ‘åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç§¯ç´¯çš„ä¸€äº›çŸ¥è¯†å’Œç»éªŒåˆ†äº«ç»™æ›´å¤šçš„äººï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°å­¦ä¹ å’Œæˆé•¿ã€‚",
    "crumbs": [
      "About website"
    ]
  },
  {
    "objectID": "index.html#ç½‘ç«™å†…å®¹",
    "href": "index.html#ç½‘ç«™å†…å®¹",
    "title": "About This Website",
    "section": "",
    "text": "è¿™ä¸ªç½‘ç«™ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼š\n\nè¯¾ç¨‹ç¬”è®°ï¼šä¸€äº›ä¹‹å‰å­¦è¿‡çš„ç»å…¸è¯¾ç¨‹çš„ç¬”è®°ä»¥åŠæ€»ç»“ï¼Œæ¯”å¦‚æœ€è¿‘å¤§ç«çš„CS336ç­‰ã€‚\né˜…è¯»ç¬”è®°ï¼šè®°å½•ç»å…¸çš„ä¹¦ç±ï¼Œä»¥åŠé‡Œé¢Exerciseçš„è§£ç­”ï¼Œæ¯”å¦‚Bishopçš„ã€ŠDeep Learning Foundations and Concaptsã€‹ã€‚\n100 Paper with Codeç³»åˆ—: è®°å½•ä¸€äº›ç»å…¸çš„è®ºæ–‡ï¼Œä»¥åŠç»“åˆä»£ç å®ç°ï¼Œå¯¹å…¶ä¸­çš„ä¸€äº›é‡è¦å†…å®¹è¿›è¡Œæ€»ç»“å’Œåˆ†äº«ï¼Œæ¯”å¦‚ Transformer, DINO, CLIPç­‰ç­‰ã€‚\n\n\n\n\n\n\n  \n\n  \n\n    \n\n      \n      \n        \n          \n        \n      \n\n      \n\n        \n        \n          CS336: LLM from Scratch Lecture Notes and Assignments\n        \n\n        \n        \n          \n            CS336æ˜¯å…³äºä»é›¶å¼€å§‹æ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆè¯¾ç¨‹ï¼Œæ¶µç›–äº†ä»Transformeræ¶æ„çš„åŸºç¡€çŸ¥è¯†ï¼Œåˆ°MoEæ¨¡å‹ï¼ŒGPUåŠ é€Ÿï¼ŒParallelismè®­ç»ƒï¼Œæ¨¡å‹çš„è¯„ä¼°ï¼Œæ•°æ®çš„æ”¶é›†å’Œå¤„ç†ï¼Œä»¥åŠLLMçš„å¯¹é½ç®—æ³•ç­‰æœ€æ–°çš„è¿›å±•ã€‚è¿™ä¸ªé¡µé¢åŒ…å«äº†CS336è¯¾ç¨‹çš„æ‰€æœ‰å­¦ä¹ ç¬”è®°å’Œä½œä¸šè§£ç­”ã€‚\n          \n        \n\n      \n\n    \n\n  \n\n\nNo matching items\n\n\n\n\n\n\n\n  \n\n  \n\n    \n\n      \n      \n        \n          \n        \n      \n\n      \n\n        \n        \n          Deep Learning Foundation and Concepts(DLFaC) Learning Notes\n        \n\n        \n        \n          \n            This page contains all the learning notes for the Deep Learning Foundation and Concepts (DLFaC) course. I hope you can find something useful here. HAPPY LEARNINGğŸ˜ğŸ˜!!!\n          \n        \n\n      \n\n    \n\n  \n\n\nNo matching items\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\nCategories\n\n\n\n\n\n\n\n\n01: Attention is All You Need (Transformer)\n\n\nTransformer æ˜¯ä¸€ç§åŸºäº è‡ªæ³¨æ„åŠ›æœºåˆ¶ çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œèƒ½å¤Ÿå¹¶è¡Œå¤„ç†åºåˆ—ï¼Œåœ¨è¯­è¨€ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼›å¹¶ä¸”ä½œä¸º GPTã€BERT ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ ¸å¿ƒåŸºç¡€ï¼Œæ¨åŠ¨äº†å½“ä»Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•ã€‚åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ Transformer çš„åŸºæœ¬åŸç†ï¼Œä»¥åŠå…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬ Word Embeddingã€Position Embeddingã€Attentionã€Normalization Layer å’Œ Feed Forward Layerã€‚å¹¶é€šè¿‡åœ¨ Ted Talks æ•°æ®é›†ä¸Šçš„å®éªŒï¼Œå±•ç¤º Transformer åœ¨å®é™…ä»»åŠ¡ä¸­çš„åº”ç”¨æ•ˆæœã€‚\n\n\nNLP, Architecture, Transformer, â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸\n\n\n\n\n\n\n02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)\n\n\nVision Transformer (ViT) é€šè¿‡å°†å›¾åƒåˆ‡åˆ†ä¸º Patch å¹¶ç›´æ¥åº”ç”¨æ ‡å‡† Transformer æ¶æ„ï¼Œå®ç°äº†å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æœ¬æ–‡ä»‹ç»äº† ViT çš„æ ¸å¿ƒç»„ä»¶ï¼ŒåŒ…æ‹¬ Patch Embeddingã€Position Embeddingã€[CLS] Token ä»¥åŠ Transformer ç¼–ç å™¨å—ï¼Œæ¢è®¨äº† ViT ç›¸è¾ƒäºä¼ ç»Ÿ CNN çš„å½’çº³åç½®å·®å¼‚(Inductive Bias)ï¼Œå¹¶å±•ç¤ºäº† ViT åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„ä¼˜å¼‚è¡¨ç°ã€‚\n\n\nComputer Vision, Transformer\n\n\n\n\n\n\n03: Training data-efficient image transformers & distillation through attention (DeiT)\n\n\nTraining data-efficient image transformers & distillation through attentionï¼ˆDeiTï¼‰æå‡ºäº†ä¸€ç§é€šè¿‡çŸ¥è¯†è’¸é¦ï¼ˆdistillation token ä¸ attention-based distillationï¼‰æ˜¾è‘—æå‡ Vision Transformer æ•°æ®æ•ˆç‡çš„æ–¹æ³•ï¼Œä½¿ ViT èƒ½åœ¨ä¸­å°è§„æ¨¡æ•°æ®é›†ä¸Šé«˜æ•ˆè®­ç»ƒå¹¶è¾¾åˆ°ä¸ CNN å¯æ¯”çš„æ€§èƒ½ã€‚\n\n\nComputer Vision, Transformer, Knowledge Distillation\n\n\n\n\n\n\n04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)\n\n\nSwin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚\n\n\nComputer Vision, Attention, Transformer\n\n\n\n\n\n\n05: ViViT: A Video Vision Transformer(ViViT)\n\n\nViViT: A Video Vision Transformeræå‡ºå°† Vision Transformer ç³»ç»Ÿæ€§æ‰©å±•åˆ°è§†é¢‘å»ºæ¨¡ï¼Œé€šè¿‡æ—¶ç©ºåˆ†è§£ä¸é«˜æ•ˆæ³¨æ„åŠ›è®¾è®¡ç›´æ¥å¯¹è§†é¢‘åºåˆ—è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨è§†é¢‘åˆ†ç±»ç­‰ä»»åŠ¡ä¸Šå–å¾—å¼ºæ€§èƒ½ä¸è‰¯å¥½å¯æ‰©å±•æ€§ã€‚\n\n\nComputer Vision, Transformer\n\n\n\n\n\n\n06: Learning Transferable Visual Models From Natural Language Supervision (CLIP)\n\n\nä¸€ç§é€šè¿‡å¯¹é½å›¾åƒä¸è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œåœ¨æµ·é‡å›¾æ–‡å¯¹ä¸Šè®­ç»ƒç»Ÿä¸€è¡¨ç¤ºï¼Œä»è€Œè·å¾—å¼ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›çš„è§†è§‰æ¨¡å‹ã€‚\n\n\nMulti Modality, Representation Learning\n\n\n\n\n\n\n07: Emerging Properties in Self-Supervised Vision Transformers (DINO)\n\n\nä¸€ç§æ— éœ€æ ‡ç­¾çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æ•™å¸ˆâ€“å­¦ç”Ÿè‡ªè’¸é¦è®­ç»ƒ Vision Transformerï¼Œè‡ªå‘æ¶Œç°å‡ºè¯­ä¹‰ä¸€è‡´çš„å…¨å±€è¡¨ç¤ºä¸æ¸…æ™°çš„æ³¨æ„åŠ›åˆ†å‰²èƒ½åŠ›ã€‚\n\n\nSelf Supervised Learning, Representation Learning\n\n\n\n\n\n\n08: Auto-Encoding Variational Bayes (VAE)\n\n\nVAEï¼ˆå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼‰æ˜¯ä¸€ç±»ç»“åˆæ¦‚ç‡å›¾æ¨¡å‹ä¸ç¥ç»ç½‘ç»œçš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡å¼•å…¥å¯å‚æ•°åŒ–çš„è¿‘ä¼¼åéªŒ \\(q_\\phi(z|x)\\) æ¥æ‘Šé”€æ¨æ–­æˆæœ¬ï¼Œå¹¶ç”¨æœ€å¤§åŒ– ELBO çš„æ–¹å¼åŒæ—¶å­¦ä¹ æ•°æ®çš„æ½œåœ¨è¡¨ç¤ºä¸ç”Ÿæˆè¿‡ç¨‹ï¼šå…¶ä¸­é‡å»ºé¡¹ç¡®ä¿æ¨¡å‹èƒ½ä»æ½œå˜é‡è¿˜åŸæ•°æ®ï¼ŒKL é¡¹åˆ™å°†æ½œç©ºé—´çº¦æŸä¸ºæ¥è¿‘å…ˆéªŒçš„è¿ç»­ç»“æ„ã€‚å€ŸåŠ©é‡å‚æ•°åŒ–æŠ€å·§ï¼ŒVAE èƒ½åœ¨ç«¯åˆ°ç«¯è®­ç»ƒä¸­é«˜æ•ˆåœ°å­¦ä¹ ä¸€ä¸ªå¹³æ»‘ã€å¯é‡‡æ ·çš„æ½œç©ºé—´ï¼Œä»è€Œå®ç°è¡¨ç¤ºå­¦ä¹ ã€æ’å€¼ã€ç”Ÿæˆç­‰åŠŸèƒ½ï¼Œæ˜¯ç°ä»£æ·±åº¦ç”Ÿæˆæ¨¡å‹çš„é‡è¦åŸºç¡€ã€‚\n\n\nSelf Supervised Learning, Generative Model, Representation Learning\n\n\n\n\n\n\n09: Masked Autoencoders Are Scalable Vision Learners(MAE)\n\n\nä¸€ç§é€šè¿‡éšæœºé®æŒ¡å¤§æ¯”ä¾‹å›¾åƒ patch å¹¶é‡å»ºç¼ºå¤±å†…å®¹è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿ Vision Transformer èƒ½ä»¥æ›´é«˜æ•ˆç‡å’Œæ›´å¥½å¯æ‰©å±•æ€§å­¦ä¹ é€šç”¨è§†è§‰è¡¨ç¤ºã€‚\n\n\nSelf Supervised Learning, Representation Learning, AutoEncoder\n\n\n\n\n\n\n10: Conditional Image Generation with PixelCNN Decoders (Pixel Gated CNN)\n\n\nä¸€ç§åŸºäºåƒç´ çº§è‡ªå›å½’å»ºæ¨¡çš„æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é—¨æ§å·ç§¯ï¼ˆGated CNNï¼‰åœ¨ç»™å®šæ¡ä»¶ï¼ˆå¦‚ç±»åˆ«æˆ–ä¸Šä¸‹æ–‡ï¼‰ä¸‹é€åƒç´ ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚\n\n\nGenerative Model\n\n\n\n\n\n\n11: Neural Discrete Representation Learning (VQ_VAE)\n\n\nä¸€ç§é€šè¿‡ç¦»æ•£åŒ–æ½œåœ¨è¡¨ç¤ºå¹¶ä½¿ç”¨ç æœ¬è¿›è¡Œé‡æ„çš„ç”Ÿæˆæ¨¡å‹ï¼Œå°†è¿ç»­è¡¨ç¤ºè½¬ä¸ºç¦»æ•£ç¬¦å·ï¼Œä»è€Œå­¦ä¹ é«˜è´¨é‡ã€å¯ç»„åˆçš„è§†è§‰è¡¨ç¤ºå¹¶æ”¯æŒé«˜æ•ˆç”Ÿæˆã€‚\n\n\nRepresentation Learning, Self Supervised Learning\n\n\n\n\n\n\n15: High-Resolution Image Synthesis with Latent Diffusion Models (Latent Diffusion Model)\n\n\nä¸€ç§åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£å»ºæ¨¡çš„ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ã€é«˜è´¨é‡çš„å›¾åƒç”Ÿæˆã€‚\n\n\nGenerative Model\n\n\n\n\n\n\n16: Scalable Diffusion Models with Transformers (DiT)\n\n\nä¸€ç§å°† Transformer æ¶æ„å¼•å…¥æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡åºåˆ—åŒ–å»ºæ¨¡ä¸è§„æ¨¡åŒ–è®­ç»ƒï¼Œåœ¨å¤§æ¨¡å‹ä¸å¤§æ•°æ®è®¾ç½®ä¸‹å®ç°æ›´å¼ºçš„ç”Ÿæˆè´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚\n\n\nGenerative Model, Diffusion Model\n\n\n\n\n\n\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)\n\n\nFlashAttention æ˜¯ä¸€IO-awareçš„exact Attention å®ç°ï¼šå®ƒæŠŠ QKáµ€ å’Œ softmax çš„è®¡ç®—æŒ‰å—ï¼ˆtilingï¼‰æ¬è¿›ç‰‡ä¸Š SRAM/å…±äº«å†…å­˜ï¼Œç”¨åœ¨çº¿ softmaxï¼ˆç»´æŠ¤ running max ä¸ sum çš„ log-sum-exp å½’ä¸€åŒ–ï¼‰åœ¨ä¸ä¿å­˜å®Œæ•´æ³¨æ„åŠ›çŸ©é˜µçš„æƒ…å†µä¸‹å®Œæˆè®¡ç®—ï¼Œå¹¶ä¸”é€šè¿‡Recomputingçš„æŠ€æœ¯ï¼Œä»è€Œæ˜¾è‘—å‡å°‘ HBM è¯»å†™ã€é™ä½æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿã€‚\n\n\nTransformer\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "About website"
    ]
  },
  {
    "objectID": "index.html#æœ€å",
    "href": "index.html#æœ€å",
    "title": "About This Website",
    "section": "",
    "text": "æœ€åï¼Œå¸Œæœ›è¿™ä¸ªç½‘ç«™èƒ½å¤Ÿå¸®åŠ©åˆ°ä¸€äº›æ­£åœ¨å­¦ä¹ ç›¸å…³è¯¾ç¨‹æˆ–è€…å¯¹ç›¸å…³é¢†åŸŸæ„Ÿå…´è¶£çš„äººã€‚å¦‚æœä½ æƒ³è¦æ›´å…¨é¢çš„äº†è§£æŸä¸€æ–¹é¢çš„çŸ¥è¯†ï¼Œæˆ‘æ¨èå¯ä»¥å»é˜…è¯»æˆ‘ä»¬çš„Blogï¼Œé‡Œé¢æœ‰å¾ˆå¤šå…³äºä¸åŒé¢†åŸŸçš„å†…å®¹ã€‚\n\nå½“ç„¶ï¼Œç”±äºä¸ªäººç²¾åŠ›æœ‰é™ï¼Œç½‘ç«™å†…å®¹éš¾å…æœ‰æ‰€ä¸è¶³ä¹‹å¤„ï¼Œå¦‚æœä½ æœ‰ä»»ä½•å»ºè®®æˆ–è€…æƒ³è¦åˆ†äº«çš„å†…å®¹ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ã€‚è°¢è°¢ï¼",
    "crumbs": [
      "About website"
    ]
  },
  {
    "objectID": "index.html#å…³äºlogo",
    "href": "index.html#å…³äºlogo",
    "title": "About This Website",
    "section": "",
    "text": "è¿™ä¸ªç½‘ç«™çš„Logoæ˜¯æˆ‘å®¶çš„çŒ«ï¼Œå«åšèŠ±èŠ±ã€‚å¸Œæœ›å¤§å®¶åœ¨AIçš„æ—¶ä»£ï¼Œèƒ½å¤ŸåƒèŠ±èŠ±ä¸€æ ·ï¼Œä¿æŒå¥½å¥‡å¿ƒå’Œæ¢ç´¢ç²¾ç¥ï¼Œä¸æ–­åœ°å­¦ä¹ å’Œæˆé•¿ã€‚ä¹Ÿå¸Œæœ›è¿™ä¸ªç½‘ç«™èƒ½å¤Ÿæˆä¸ºä¸€ä¸ªæœ‰ä»·å€¼ï¼Œæœ‰å†…å®¹çš„ç½‘ç«™ï¼Œå¸®åŠ©æ›´å¤šçš„äººå­¦ä¹ å’Œæˆé•¿ã€‚ä¹Ÿå¸Œæœ›è¿™åªå¯çˆ±çš„çŒ«å’ªèƒ½å¤Ÿç»™å¤§å®¶å¸¦æ¥ä¸€äº›å¿«ä¹å’Œæ¸©æš–ã€‚",
    "crumbs": [
      "About website"
    ]
  },
  {
    "objectID": "posts/CS336/Ass04/ass04.html",
    "href": "posts/CS336/Ass04/ass04.html",
    "title": "Assignment 04: Data Collection & Processing",
    "section": "",
    "text": "Some text here.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html",
    "href": "posts/CS336/Ass05/ass05.html",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "",
    "text": "TL;DR: å¿«é€Ÿç‰ˆ\n\n\nåªéœ€å°†è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ŒWe are ready to GOï¼ï¼ï¼\nä¸‹è½½ä»£ç \ngit clone https://github.com/YYZhang2025/Stanford-CS336.git\ncd Stanford-CS336/assignment5-alignment\nå®‰è£…ä¾èµ–ï¼Œä¸‹è½½æ•°æ®é›†å’Œæ¨¡å‹\npip install uv \nuv sync --no-install-package flash-attn\nuv sync\nsource .venv/bin/activate\n\nhf download YuYangZhang/Reasoning-Dataset  --repo-type dataset --local-dir data\n\npython download_model.py \\\n  --repo-id Qwen/Qwen2.5-Math-1.5B \\\n  --save-dir models/Qwen2.5-Math-1.5B \\\n  --method snapshot --no-symlinks --verify\n\n\næˆ‘ä»¬å…ˆæ¥ä¸‹è½½æ¨¡å‹æƒé‡ï¼Œåªéœ€ä¸€ä¸ªå‘½ä»¤ï¼š\npython download_model.py \\\n  --repo-id Qwen/Qwen2.5-Math-1.5B \\\n  --save-dir models/Qwen2.5-Math-1.5B \\\n  --method snapshot --no-symlinks --verify\né€šè¿‡ä¸Šé¢çš„å‘½ä»¤ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠQwen2.5-Math-1.5Bæ¨¡å‹ä¸‹è½½åˆ°models/Qwen2.5-Math-1.5Bç›®å½•ä¸‹ã€‚\n\nåœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬å°†ä¼šç”¨åˆ°Math Datasetï¼Œä¸è¿‡Assignmentä¸­ï¼Œç”±äºç‰ˆæƒé—®é¢˜ï¼Œå¹¶æ²¡æœ‰æä¾›å®Œæ•´çš„æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è‡ªè¡Œä¸‹è½½æ•°æ®é›†ï¼Œåœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬ä¸»è¦ä¼šç”¨åˆ°ä»¥ä¸‹ä¸¤ä¸ªæ•°æ®é›†ï¼š\n\nGSM8K Datasetï¼šä¸€ä¸ªåŒ…å«8,500å¤šä¸ªé«˜ä¸­æ°´å¹³æ•°å­¦é—®é¢˜çš„æ•°æ®é›†ï¼Œä¸“æ³¨äºé€æ­¥æ¨ç†å’Œè§£å†³æ–¹æ¡ˆç”Ÿæˆã€‚ï¼ˆè¿™ä¸ªæ•°æ®é›†åœ¨Assignmentä¸­å·²ç»æä¾› data/gsm8kï¼‰\nMATH Dataset: è¿™ä¸ªæ•°æ®é›†åŒ…å«12,500å¤šä¸ªé«˜ä¸­å’Œå¤§å­¦æ°´å¹³çš„æ•°å­¦é—®é¢˜ï¼Œæ¶µç›–å¤šä¸ªä¸»é¢˜å’Œéš¾åº¦çº§åˆ« Linkã€‚\n\næˆ‘ä»¬ç°åœ¨ä¸‹è½½MATH:\nhf download nlile/hendrycks-MATH-benchmark \\\n  --repo-type dataset \\\n  --local-dir ./data/hendrycks-MATH-benchmark\n\nmv ./data/hendrycks-MATH-benchmark  ./data/math\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥é¢„å¤„ç†ä¸€ä¸‹è¿™äº›æ•°æ®é›†ï¼Œå› ä¸ºä¸åŒçš„æ•°æ®é›†æ ¼å¼ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦æŠŠä»–ä»¬å¤„ç†æˆç»Ÿä¸€çš„æ ¼å¼ï¼Œ ä»¥ä¾¿æˆ‘ä»¬åç»­çš„è®­ç»ƒã€‚å…ˆæ¥çœ‹GSM8Kæ•°æ®é›†çš„æ ¼å¼ï¼š\n{\n  \"question\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\", \n  \"answer\": \"Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.\\nNatalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.\\n#### 72\"}\næ¯ä¸ªæ ·æœ¬åŒ…å« question å’Œ answer ä¸¤ä¸ªå­—æ®µï¼Œæˆ‘ä»¬éœ€è¦æŠŠä»–ä»¬å¤„ç†æˆ prompt å’Œ cot çš„æ ¼å¼ï¼Œå¹¶ä¸”æå–å‡ºé‡Œé¢çš„ç­”æ¡ˆï¼š\n\n\nassignment5-alignment/cs336_alignment/dataset_utils/gsm8k.py\n\ndef extract_gsm8k_answer(answer: str) -&gt; str:\n    ANS_RE = re.compile(r\"####\\s*([\\-0-9\\.\\,]+)\")\n    match = ANS_RE.search(answer)\n    if match:\n        return match.group(1).strip().replace(\",\", \"\")\n    return \"[invalid]\"\n\n\ndef process_row(row: Dict[str, Any]):\n    problem = row[\"question\"]\n    cot = row[\"answer\"]\n    clean_cot = re.sub(r\"\\s*\\n####\\s*-?\\d+(?:\\.\\d+)?\\s*$\", \"\", cot)\n    answer = extract_gsm8k_answer(row[\"answer\"])\n\n    clean_cot = wrap_cot_with_answer(clean_cot, answer)\n\n    return problem, str(clean_cot), str(answer).lower() if answer is not None else None\n\nåœ¨é¢„å¤„ç†ä¹‹åï¼Œæˆ‘ä»¬ä¼šæŠŠæ•°æ®é›†å¤„ç†æˆä¸‹é¢çš„æ ¼å¼ï¼š\n{\n  \"question\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\", \n  \"cot\": \"Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.\\nNatalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.\\n&lt;/think&gt; &lt;answer&gt;72&lt;/answer&gt;\", \n  \"answer\": \"72\"\n}\nç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦å¯¹MATHæ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼ŒMATHæ•°æ®é›†çš„æ ¼å¼å¦‚ä¸‹ï¼š\n{\n  \"problem\": \"How many vertical asymptotes does the graph of $y=\\\\frac{2}{x^2+x-6}$ have?\", \n  \"solution\": \"The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $\\\\boxed{2}$ vertical asymptotes.\", \n  \"answer\": \"2\"\n}\n\n\nassignment5-alignment/cs336_alignment/dataset_utils/math.py\n\ndef process_row(row: Dict[str, Any]):\n    problem = row[\"problem\"]\n    cot = row[\"solution\"]\n\n    if row[\"answer\"] is None:\n        answer = extract_final_answer_from_text(cot)\n    else:\n        answer = row[\"answer\"]\n        cot = wrap_cot_with_answer(cot, answer)\n\n    return problem, str(cot), str(answer).lower() if answer is not None else None\n\nåœ¨å¤„ç†ä¹‹åï¼Œæˆ‘ä»¬ä¼šæŠŠMATHæ•°æ®é›†å¤„ç†æˆä¸‹é¢çš„æ ¼å¼ï¼š\n{\n  \"question\": \"How many vertical asymptotes does the graph of $y=\\\\frac{2}{x^2+x-6}$ have?\", \n  \"cot\": \"The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $\\\\boxed{2}$ vertical asymptotes.\\n&lt;/think&gt; &lt;answer&gt;2&lt;/answer&gt;\", \n  \"answer\": \"2\"\n}\nå…·ä½“çš„ç»†èŠ‚ï¼Œçœ‹assignment5-alignment/cs336_alignment/dataset_utils æ–‡ä»¶å¤¹ä¸‹çš„ä»£ç ã€‚ä»¥åŠ assignment5-alignment/preprocess.py è¿™ä¸ªè„šæœ¬ã€‚åœ¨è¿™é‡Œå°±ä¸èµ˜è¿°äº†ã€‚å¤„ç†å®Œä¹‹åï¼Œæˆ‘ä»¬ä¼šæœ‰ï¼š\ndata/\nâ”œâ”€â”€ alpaca_eval/\nâ”œâ”€â”€ gsm8k/\nâ”œâ”€â”€ math/\nâ”œâ”€â”€ mmlu/\nâ”œâ”€â”€ pre-processed/\nâ”‚   â”œâ”€â”€ gsm8k/\nâ”‚   â”‚   â”œâ”€â”€ test.jsonl\nâ”‚   â”‚   â””â”€â”€ train.jsonl\nâ”‚   â””â”€â”€ math/\nâ”‚       â”œâ”€â”€ test.jsonl\nâ”‚       â””â”€â”€ train.jsonl\nå½“ç„¶ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥é€‰æ‹©ç›´æ¥ä½¿ç”¨æˆ‘å·²ç»å¤„ç†å¥½çš„æ•°æ®é›†ï¼Œ ç›´æ¥ä»è¿™é‡Œä¸‹è½½å³å¯ã€‚æˆ–è€…ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤ï¼š\nhf download YuYangZhang/Reasoning-Dataset  --repo-type dataset --local-dir data",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#vllm",
    "href": "posts/CS336/Ass05/ass05.html#vllm",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "2.1 vLLM",
    "text": "2.1 vLLM\nåœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨vLLM æ¥è¿›è¡Œæ¨¡å‹çš„æ¨ç†ï¼Œ ä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ›´å¿«çš„è¿›è¡Œè¯„ä¼°å’Œè®­ç»ƒã€‚ ä»¥ä¸‹å‡ ä¸ªæ–¹æ³•ï¼š\n\n\nassignment5-alignment/cs336_alignment/vllm_utils.py\n\ndef init_vllm(model_id: str, device: str, seed: int, gpu_memory_utilization: float = 0.85):\n    vllm_set_random_seed(seed)\n    world_size_patch = patch(\"torch.distributed.get_world_size\", return_value=1)\n    profiling_patch = patch(\n        \"vllm.worker.worker.Worker._assert_memory_footprint_increased_during_profiling\", return_value=None\n    )\n    with world_size_patch, profiling_patch:\n        return LLM(\n            model=model_id,\n            device=device,\n            dtype=torch.bfloat16,\n            enable_prefix_caching=True,\n            gpu_memory_utilization=gpu_memory_utilization,\n        )\n\ndef load_policy_into_vllm_instance(policy: PreTrainedModel, llm: LLM):\n    state_dict = policy.state_dict()\n    llm_model = llm.llm_engine.model_executor.driver_worker.model_runner.model\n    llm_model.load_weights(state_dict.items())\n  \ndef generate_responses(vllm: LLM, prompts: list[str], sampling_params) -&gt; list[str]:\n    outputs = vllm.generate(\n        prompts,\n        sampling_params=sampling_params,\n    )\n    responses = [output.outputs[0].text for output in outputs]\n    return responses\n\nå½“æˆ‘ä»¬éœ€è¦ä½¿ç”¨vLLMè¿›è¡Œæ¨ç†æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦å…ˆåˆå§‹åŒ–vLLMå®ä¾‹ï¼Œ ä¹‹åæŠŠæ¨¡å‹æƒé‡loadè¿›å»ï¼Œ æœ€åè°ƒç”¨generate_responseså‡½æ•°å³å¯å®Œæˆæ¨ç†ï¼š\nvllm = init_vllm(\n    model_id=MODEL_NAME,\n    device=str(get_device(rank=1)),\n    seed=42,\n    gpu_memory_utilization=0.85,\n)\nsampling_params = SamplingParams(\n    max_tokens=1024, temperature=1, top_p=1, stop=[\"&lt;/answer&gt;\"], include_stop_str_in_output=True\n)\nload_policy_into_vllm_instance(policy, vllm)\nresponses = generate_responses(\n    vllm,\n    prompts,\n    sampling_params=sampling_params,\n)\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å…ˆæ¥è¯„ä¼°ä¸€ä¸‹Qwen2.5-Math-1.5Båœ¨MATHå’ŒGSM8Kæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œ å…·ä½“çš„è¯„ä¼°ä»£ç åœ¨ assignment5-alignment/eval.py ä»¥åŠ assignment5-alignment/cs336_alignment/eval.pyï¼Œ è¿è¡Œä¸‹é¢çš„å‘½ä»¤å³å¯ï¼š\npython eval.py  \næ¥çœ‹ä¸€ä¸‹è¯„ä¼°ç»“æœï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset_path\ntotal\nanswer_correct\nformat_correct\nreward_1\nformatted_but_answer_wrong\nanswer_accuracy\n\n\n\n\nmath/train.jsonl\n12000\n359\n2038\n359\n1679\n0.029\n\n\nmath/test.jsonl\n500\n13\n77\n13\n64\n0.026\n\n\ngsm8k/train.jsonl\n7473\n232\n1433\n232\n1201\n0.031\n\n\ngsm8k/test.jsonl\n1319\n41\n258\n41\n217\n0.031\n\n\n\n\n\nTableÂ 1: Qwen2.5-Math-1.5B Zero-Shot Evaluation Results on MATH and GSM8K Datasets\n\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼Œåœ¨Zero-Shotçš„æƒ…å†µä¸‹ï¼ŒQwen2.5-Math-1.5Båœ¨MATHå’ŒGSM8Kæ•°æ®é›†ä¸Šçš„è¡¨ç°éƒ½éå¸¸å·®ï¼Œåªæœ‰å¤§çº¦2.6%åˆ°3.1%çš„å‡†ç¡®ç‡ã€‚è¿™ä¹Ÿç¬¦åˆé¢„æœŸï¼Œå› ä¸ºQwen2.5-Math-1.5Bè™½ç„¶æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è¯­è¨€æ¨¡å‹ï¼Œä½†åœ¨æ²¡æœ‰ç»è¿‡ä¸“é—¨å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œå…¶åœ¨å¤æ‚æ•°å­¦é—®é¢˜ä¸Šçš„è¡¨ç°ä»ç„¶æœ‰é™ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#tokenize-prompt-and-output",
    "href": "posts/CS336/Ass05/ass05.html#tokenize-prompt-and-output",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.1 Tokenize Prompt and Output",
    "text": "3.1 Tokenize Prompt and Output\né¦–å…ˆæˆ‘ä»¬è¦å®šä¹‰çš„ç¬¬ä¸€ä¸ªå‡½æ•°å°±æ˜¯ tokenize_prompt_and_output(), å®ƒçš„ä½œç”¨ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯æ¥æ”¶ä¸€ç³»åˆ—çš„promptsï¼Œå’Œ Responseï¼Œå¹¶ä¸”tokenizeä»–ä»¬ï¼Œå¹¶ä¸”è¿”å›ä»–ä»¬çš„idsã€‚ä¸è¿‡ï¼Œéœ€è¦æ³¨æ„çš„ä¸€ç‚¹ï¼Œä¹Ÿæ˜¯å¾ˆé‡è¦çš„ä¸€ç‚¹å°±æ˜¯ï¼Œæˆ‘ä»¬è¦åŒæ—¶è¿”å›Response Maskã€‚ æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹è¿™ä¸ªResponse Maskçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼š\n\nå‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ª \\(q\\) å’Œ \\(o\\), æˆ‘ä»¬å°†å®ƒå¹¶åœ¨ä¸€èµ·ï¼Œå¾—åˆ°äº†æˆ‘ä»¬çš„å‡½æ•° \\([q, o ]\\), æˆ‘ä»¬å°†æ•´æ®µä¼ å…¥Modelï¼Œåœ¨æ²¡æœ‰Response Maskçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹å°±æ˜¯å¯¹æ‰€æœ‰çš„tokenè®¡ç®—lossï¼Œè¿™æ ·æ¨¡å‹å°±ä¼šè¢«è¿«å»é¢„æµ‹ï¼š\n\nprompt é‡Œçš„ä¸‹ä¸€ä¸ª tokenï¼ˆæœ¬è´¨æ˜¯åœ¨â€œå¤è¿°/é‡å»º promptâ€ï¼‰\noutput é‡Œçš„ tokenï¼ˆè¿™æ‰æ˜¯æˆ‘ä»¬çœŸæ­£å…³å¿ƒçš„ï¼‰\n\nä½†æ˜¯åœ¨SFTè®­ç»ƒçš„é˜¶æ®µï¼Œ prompt æ˜¯è¾“å…¥æ¡ä»¶ï¼Œæˆ‘ä»¬å¹¶ä¸å¸Œæœ›ä¼˜åŒ–æ¨¡å‹å»â€œèƒŒ prompt çš„åˆ†å¸ƒâ€ï¼Œåªå¸Œæœ›å®ƒåœ¨ç»™å®š prompt åç”Ÿæˆæ­£ç¡®è¾“å‡ºã€‚æ‰€ä»¥ç”¨ response_mask æŠŠ loss é™å®šåœ¨ output token ä¸Šï¼š è®­ç»ƒä¿¡å·åªæ¥è‡ªå›ç­”éƒ¨åˆ†ã€‚å½“ç„¶ï¼Œé™¤æ­¤ä¹‹å¤–ï¼ŒResponse Maskè¿˜å¯¹åº”ç€pad tokens ä¸¾ä¸ªç›´è§‚çš„ä¾‹å­ï¼š\nå‡è®¾è¾“å…¥æ˜¯ï¼š\n\nq: â€œ2+2=?â€\no: â€œ4â€\n\næ‹¼æ¥å token åºåˆ—æ˜¯ï¼š[q_tokens][o_tokens][pad...]\nresponse_mask ä¼šåƒè¿™æ ·ï¼š\n\nq_tokens â†’ False False False â€¦\no_tokens â†’ True True â€¦\npad â†’ False False â€¦\n\nTokens:        [ 2 , + , 2 , = , ? , 4 , &lt;pad&gt; , &lt;pad&gt; ]\nResponse_mask: [ F , F , F , F , F , T ,   F   ,   F   ] \nç»“æœï¼šloss åªåœ¨ â€œ4â€ çš„ token ä¸Šç®—ï¼Œprompt éƒ¨åˆ†å®Œå…¨ä¸å‚ä¸ã€‚\næˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç æ˜¯æ€ä¹ˆå®ç°çš„ï¼š\né¦–å…ˆç¬¬ä¸€æ­¥è‡ªç„¶æ˜¯Tokenize Promptså’ŒResponseï¼š\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\nprompt_tokens = tokenizer(\n    prompt_strs,\n    add_special_tokens=False,\n    padding=False,\n    truncation=False,\n    return_attention_mask=False,\n)\n\noutput_tokens = tokenizer(\n    output_strs,\n    add_special_tokens=False,\n    padding=False,\n    truncation=False,\n    return_attention_mask=False,\n)\n\næ³¨æ„! åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¹¶ä¸ä¼šè¿”å›Tensor è¿”å›çš„æ˜¯Listï¼Œ å¹¶ä¸”Listé‡Œé¢æ¯ä¸ªå…ƒç´ çš„é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ï¼Œ\næ¥ä¸‹æ¥ï¼Œ æˆ‘ä»¬æŠŠè¿™ä¸¤ä¸ªListä¸­çš„å†…å®¹ concat åœ¨ä¸€èµ·ï¼Œå¾—åˆ° [q, o]ï¼Œ å¹¶ä¸”è®¡ç®—å‡ºæˆ‘ä»¬çš„Response Mask\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\ninput_ids = []\nresponse_mask = []\n\nfor p_ids, o_ids in zip(prompt_tokens[\"input_ids\"], output_tokens[\"input_ids\"]):\n    combined_ids = p_ids + o_ids\n    input_ids.append(combined_ids)\n\n    mask = ([False] * len(p_ids)) + ([True] * len(o_ids))\n    response_mask.append(mask)\n\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œinput_ids å’Œ response_mask é‡Œé¢çš„å†…å®¹é•¿åº¦ä¸ä¸€æ ·é•¿ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦å°†å®ƒPad åˆ°åŒæ ·çš„é•¿åº¦ï¼Œè¿™æ ·æ‰å¯ä»¥ä¼ å…¥æ¨¡å‹ï¼š\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\nMAX_LEN = max(len(ids) for ids in input_ids)\n# 151643 for Qwen/Qwen2.5-Math-1.5B\npad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n\ndef pad_to(x, value):\n    return x + [value] * (MAX_LEN - len(x))\n\nfull = torch.tensor([pad_to(x, pad_id) for x in input_ids], dtype=torch.long)\nresponse_mask = torch.tensor([pad_to(x, False) for x in response_mask], dtype=torch.bool)\n\næ¥ä¸‹æ¥å°±æ„å»ºæˆ‘ä»¬çš„inputå’Œlabelsï¼Œ Labelsä¸­è®°å½•çš„æ˜¯inputsä¸­çš„ä¸‹ä¸€ä¸ªï¼š\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\ninput_ids = full[:, :-1].contiguous()\nlabels = full[:, 1:].contiguous()\nresponse_mask = response_mask[:, 1:].contiguous()\n\n\nreturn {\n        \"input_ids\": input_ids,\n        \"labels\": labels,\n        \"response_mask\": response_mask,\n    }\n\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ Response Maskä¸­æ˜¯Labelsä¸­çš„maskï¼Œè€Œä¸æ˜¯inputs_idsä¸­çš„maskã€‚\n\n\nTL;DR: Tokenization & Prompts\n\n\nåœ¨è¿™é‡Œå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦åšä¸¤ä»¶äº‹æƒ…ï¼š\n\nTokenize Prompt å’Œ Outputï¼Œè¿™é‡Œçš„Promptæ˜¯æˆ‘ä»¬æ·»åŠ äº†Templateä¹‹å\nConcat Tokenized Promptï¼Œ Outputä¸€èµ·ï¼Œå¹¶ä¸”ç”ŸæˆResponse Mask\nPaddingåˆ°ç›¸åŒçš„é•¿åº¦\nå°†Concatä¹‹åçš„å†…å®¹ç§»ä¸€ä½ï¼Œå¾—åˆ°inputså’Œlabels",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#per-token-entropy",
    "href": "posts/CS336/Ass05/ass05.html#per-token-entropy",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.2 Per Token Entropy",
    "text": "3.2 Per Token Entropy\nå¯¹äºæ¯ä¸€ä¸ªä½ç½®\\(t\\), æ¨¡å‹ä¼šç»™å‡ºä¸€ä¸‹ä¸ªtokençš„åˆ†å¸ƒï¼Œä¹Ÿå°±æ˜¯ \\(p_{t}(x) = \\text{softmax}(\\text{logits}_{t})\\), Entropyå®šä¹‰ä¸ºï¼š\n\\[\nH(p) = - \\sum_{x \\in \\mathcal{X}} p(x) \\log p(x)\n\\tag{2}\\]\n\nEntropy é«˜ï¼š åˆ†å¸ƒæ›´â€œå¹³â€ï¼Œæ¨¡å‹ä¸é‚£ä¹ˆç¡®å®šï¼ˆæ¢ç´¢æ›´å¼ºï¼‰ï¼ˆå¯¹äºCategory Distributionï¼Œ\\(p(x) = \\frac{1}{| x| }\\) æœ‰æœ€é«˜çš„Entropy\nEntropy ä½ï¼šåˆ†å¸ƒæ›´â€œå°–â€ï¼Œæ¨¡å‹æ›´ç¡®å®šï¼ˆå¯èƒ½å˜å¾—è¿‡åº¦è‡ªä¿¡ã€æ¨¡å¼åç¼©ï¼ˆmodel collapseï¼‰\n\nåœ¨ RL é‡Œå¦‚æœä½ çœ‹åˆ° entropy å¾ˆå¿«æ‰åˆ°å¾ˆä½ï¼Œå¸¸è§å«ä¹‰æ˜¯ï¼š\n\nç­–ç•¥å˜å¾—å¤ªç¡®å®šï¼ˆexploration å˜å·®ï¼‰\nè®­ç»ƒå¯èƒ½å¼€å§‹â€œé’» reward æ¼æ´â€æˆ–è¾“å‡ºå•ä¸€æ¨¡æ¿\nå­¦ä¹ å¯èƒ½ä¸ç¨³å®šï¼ˆå°¤å…¶å’Œ KL/clip é…åˆä¸å½“æ—¶ï¼‰\n\nè®¡ç®—entropyä¹Ÿå¾ˆç®€å•çš„ï¼Œ\n\\[\n\\begin{split}\n\\ell &= \\text{logits} \\\\\n\\log p &= \\log\\text{softmax}(\\ell) \\\\\np &= \\exp(\\log p) \\\\\nH(p) &= - \\sum_{x \\in \\mathcal{X}} p(x) \\log p(x)\n\\end{split}\n\\tag{3}\\]\nç”¨ä¸Šé¢çš„å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå‡½æ•° compute_entropy æ¥è®¡ç®—entropyï¼š\ndef compute_entropy(logits: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the entropy of the probability distribution defined by the logits.\n    \"\"\"\n    log_probs = F.log_softmax(logits, dim=-1)\n    probs = torch.exp(log_probs)\n    entropy = -torch.sum(probs * log_probs, dim=-1)\n\n    return entropy",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#getting-log-probs-from-model",
    "href": "posts/CS336/Ass05/ass05.html#getting-log-probs-from-model",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.3 Getting Log Probs from Model",
    "text": "3.3 Getting Log Probs from Model\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å®šä¹‰å¦ä¸€ä¸ªHelper Function get_response_log_probs å®ƒçš„ä½œç”¨æ˜¯ï¼šæŠŠâ€œæ¨¡å‹å¯¹æ¯ä¸ªä½ç½®çœŸå® token çš„æ¡ä»¶æ¦‚ç‡â€ç®—å‡ºæ¥ï¼ˆä»¥ log å½¢å¼ï¼‰ï¼Œå¹¶æŒ‰ token ç²’åº¦è¿”å› å¯èƒ½ç°åœ¨ç†è§£è¿™ä¸ªæœ‰ç‚¹å›°éš¾ï¼Œåœ¨ä¹‹åSFT å’Œ RL çš„ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¼šå…·ä½“è®²è§£ä¸€ä¸‹çš„ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸‹è¿™ä¸ªå‡½æ•° æˆ‘ä»¬çŸ¥é“ï¼ŒSFT çš„Loss EquationÂ 1 ä¸­éœ€è¦ç”¨åˆ° \\(\\log p_\\theta(R_t \\mid P, R_{&lt;t})\\)ï¼Œ ä¹Ÿå°±æ˜¯æ¨¡å‹åœ¨ä½ç½®\\(t\\)ä¸Šï¼Œ å¯¹çœŸå®token \\(R_t\\)çš„log probã€‚ å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—è¿™ä¸ªå€¼ï¼š\ndef get_response_log_probs(\n    model, input_ids: torch.Tensor, labels: torch.Tensor, return_token_entropy: bool = False\n) -&gt; dict[str, torch.Tensor]:\nå¯¹äºæ¨¡å‹è¾“å‡º \\(f_{\\theta}(x)\\), å…¶è¾“å‡ºçš„æ˜¯Logitsï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰normalizedçš„distributionï¼Œæˆ‘ä»¬ç¬¬ä¸€æ­¥è‡ªç„¶æ˜¯åˆ©ç”¨softmaxæ¥å°†å…¶å˜ä¸ºåˆ†å¸ƒï¼Œ ä¹‹åæˆ‘ä»¬å†æ ¹æ®æˆ‘ä»¬éœ€è¦çš„labelï¼Œä½œä¸ºç´¢å¼•ï¼Œæ¥æå–å‡ºæˆ‘ä»¬éœ€è¦çš„log-probs\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\ndef get_response_log_probs(\n    model, \n    input_ids: torch.Tensor, # ï¼ˆB, Tï¼‰\n    labels: torch.Tensor, # ï¼ˆB, Tï¼‰\n    return_token_entropy: bool = False\n) -&gt; dict[str, torch.Tensor]:\n    logits = model(input_ids=input_ids).logits # (B, T, V)\n\n    logp = F.log_softmax(logits, dim=-1)\n    log_probs = logp.gather(-1, labels.unsqueeze(-1)).squeeze(-1) \n\n    res = {\n        \"log_probs\": log_probs,\n    }\n    if return_token_entropy:\n        entropy = compute_entropy(logits)\n        res[\"token_entropy\"] = entropy\n    return res\n\nè¿™ä¸ªå‡½æ•°æœ€å…³é”®çš„éƒ¨åˆ†å°±æ˜¯ç¬¬10è¡Œï¼Œ é€šè¿‡ gather å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®labelsï¼Œæ¥æå–å‡ºæˆ‘ä»¬éœ€è¦çš„log_probsã€‚logpçš„shapeæ˜¯(B, T, V)ï¼Œ å…¶ä¸­Bæ˜¯Batch Sizeï¼Œ Tæ˜¯Sequence Lengthï¼Œ Væ˜¯Vocabulary Sizeï¼Œè€Œlabelsçš„shapeæ˜¯(B, T)ï¼Œ å› æ­¤é€šè¿‡ gather å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¯ä¸ªä½ç½®ä¸Šï¼ŒçœŸå®tokençš„log_probsï¼Œ æœ€ç»ˆå¾—åˆ°çš„log_probs shapeæ˜¯ (B, T)ï¼Œ ä¹Ÿå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç»“æœã€‚\n\n\nWARNING: About Response Mask\n\n\næˆ‘ä»¬åœ¨è¿™ä¸€æ­¥ï¼Œå¹¶æ²¡ç”¨ç”¨åˆ°Response Maskï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¿”å›æ‰€æœ‰ä½ç½®çš„Log Probsï¼Œ åŒ…æ‹¬Promptéƒ¨åˆ†å’ŒPadéƒ¨åˆ†ã€‚æˆ‘ä»¬éœ€è¦åœ¨ä¹‹åçš„Lossè®¡ç®—ä¸­ masked_normalizeï¼Œä½¿ç”¨Response Maskæ¥Maskæ‰Promptå’ŒPadéƒ¨åˆ†ã€‚\n\n\nå› æ­¤ï¼Œåœ¨SFT ä¸­ï¼ŒLog Probs æˆ‘ä»¬é€šè¿‡ log_probs.sum(dim=-1) å¯ä»¥è®¡ç®—å‡ºLossï¼Œå½“ç„¶ï¼Œåœ¨åšè¿™ä¸ªè®¡ç®—ä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜éœ€è¦Maskæ‰Promptsï¼Œæˆ‘ä»¬æ¥ä¸‹å»æ¥å®ç°å®ƒï¼š",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#masked-normalize",
    "href": "posts/CS336/Ass05/ass05.html#masked-normalize",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.4 Masked Normalize",
    "text": "3.4 Masked Normalize\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å®ç° masked_normalize å‡½æ•°ï¼Œ è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯ï¼šæ ¹æ®Maskï¼Œå¯¹Tensorè¿›è¡ŒMaskï¼Œå¹¶ä¸”è¿›è¡ŒNormalize\n\n\nassignment5-alignment/cs336_alignment/algs/utils.py\n\ndef masked_normalize(\n    tensor: torch.Tensor, # (B, T)\n    mask: torch.Tensor,  # (B, T)\n    normalize_constant: float = 1.0, \n    dim: int | None = None\n) -&gt; torch.Tensor:\n    assert tensor.shape == mask.shape, \"Tensor and mask must have the same shape\"\n\n    masked_f = mask.type_as(tensor)\n    masked_tensor = tensor * masked_f\n    masked_sum = torch.sum(masked_tensor, dim=dim) if dim is not None else torch.sum(masked_tensor)\n\n    return masked_sum / normalize_constant\n\nè¿™ä¸ªå‡½æ•°å¾ˆç®€å•ï¼Œé¦–å…ˆæˆ‘ä»¬ä¼šæ ¹æ®Maskæ¥Maskæ‰Tensorä¸­ä¸éœ€è¦çš„éƒ¨åˆ†ï¼Œ ä¹‹åæˆ‘ä»¬ä¼šå¯¹å‰©ä¸‹çš„éƒ¨åˆ†è¿›è¡ŒSumï¼Œ æœ€åæˆ‘ä»¬ä¼šæ ¹æ®normalize_constantæ¥è¿›è¡ŒNormalizeã€‚ ä¼ å…¥masked_normalizeçš„tensorï¼Œä¸€èˆ¬æ˜¯Log Probsï¼Œ è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è®¡ç®—å‡ºMasked Log Probsçš„å’Œ, ä¹Ÿå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„Lossã€‚å…¶ä¸­æˆ‘è®¤ä¸ºä¸€ä¸ªå¾ˆå·§å¦™çš„è®¾è®¡æ˜¯ normalize_constant å’Œ dim å‚æ•°ï¼Œ é€šè¿‡è¿™ä¸¤ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥çµæ´»çš„æ§åˆ¶æˆ‘ä»¬æƒ³è¦çš„Normalizeæ–¹å¼ï¼Œ ä»¥åŠæƒ³è¦Sumçš„ç»´åº¦ï¼Œ æ¯”å¦‚ï¼š\n\nå¦‚æœæˆ‘ä»¬æƒ³è¦è®¡ç®—Batchä¸­æ‰€æœ‰Tokençš„Lossï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥ dim=Noneï¼Œ å¹¶ä¸” normalize_constant = mask.sum()ï¼Œ è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°Batchä¸­æ‰€æœ‰Tokençš„å¹³å‡Lossã€‚ (Token Level Loss)\nå¦‚æœæˆ‘ä»¬æƒ³è¦è®¡ç®—Batchä¸­æ¯ä¸ªSequenceçš„Lossï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥ dim=-1ï¼Œ å¹¶ä¸” normalize_constant = mask.sum(dim = -1)ï¼Œ è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°Batchä¸­æ¯ä¸ªSequenceçš„Lossã€‚ (Sequence Level Loss)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#sft-micro-batch-training-step",
    "href": "posts/CS336/Ass05/ass05.html#sft-micro-batch-training-step",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.5 SFT Micro-batch Training Step",
    "text": "3.5 SFT Micro-batch Training Step\næœ‰äº†è¿™äº›Helper Functionsï¼Œæˆ‘ä»¬å¯ä»¥æ¥å®ç°SFTçš„è®­ç»ƒ, ç”±äºQwen2.5-Math-1.5Bçš„æ¨¡å‹æ¯”è¾ƒå¤§ï¼Œ æˆ‘ä»¬ä¸èƒ½å®Œå…¨å®ç°Batch Sizeè¾ƒå¤§çš„ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡Gradient Accumulationçš„æŠ€æœ¯ï¼Œæ¥ä½¿å¾—è®­ç»ƒå˜å¾—å¯èƒ½ï¼Œæˆ‘ä»¬å…ˆæ¥å®šä¹‰ä¸€å°æ­¥ï¼š\n\n\nassignment5-alignment/cs336_alignment/algs/sft.py\n\ndef sft_microbatch_train_step(\n    policy_log_probs: torch.Tensor,\n    response_mask: torch.Tensor,\n    gradient_accumulation_steps: int,\n    normalize_constant: float = 1.0,\n) -&gt; tuple[torch.Tensor, dict[str, torch.Tensor]]:\n\nå…¶å®å¾ˆç®€å•ï¼Œè¿™ä¸ªå‡½æ•°å°±åšä¸¤ä»¶äº‹æƒ…ï¼š\n\nè®¡ç®—Loss\nBackward è®¡ç®—Gradient\n\n\\[\n\\mathcal{L}_{\\text{SFT}}^{\\text{batch-sum}}\n=\n-\\sum_{i=1}^{B}\\sum_{t=1}^{T}\nm^{(i)}_t\\;\n\\log p_\\theta\\!\\big(y^{(i)}_t \\mid x^{(i)}_{&lt;t}\\big)\n\\tag{4}\\]\nå…¶ä¸­ \\(m_{t}^{(i)}\\) è¡¨ç¤ºçš„æ˜¯Maskå€¼\n\n\nassignment5-alignment/cs336_alignment/algs/sft.py\n\nloss_unscaled = masked_normalize(\n    policy_log_probs,\n    response_mask,\n    normalize_constant=normalize_constant,\n    dim=-1,\n) # æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ dim=-1ï¼Œ è€Œä¸” normalize_constant = 1.0ï¼Œ ä¹Ÿå°±æ˜¯Sequence Level Loss\n\nloss_unscaled = -loss_unscaled.mean()\nloss_scaled = loss_unscaled / gradient_accumulation_steps \nloss_scaled.backward()\n\nmetadata = {\n    \"loss_unscaled\": loss_unscaled.detach(),\n}\nreturn loss_scaled.detach(), metadata\n\nGradient Accumulationçš„å®ç°ä¹Ÿå¾ˆç®€å•ï¼Œ æˆ‘ä»¬åªéœ€è¦åœ¨è®¡ç®—Lossä¹‹åï¼Œ é™¤ä»¥ gradient_accumulation_steps å³å¯ã€‚ è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨ä¹‹åçš„SFT Trainerä¸­ï¼Œ å®ç°Gradient Accumulationçš„åŠŸèƒ½äº†ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#sft-trainer",
    "href": "posts/CS336/Ass05/ass05.html#sft-trainer",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.6 SFT Trainer",
    "text": "3.6 SFT Trainer\næœ‰äº†è¿™äº›Helper Functionsï¼Œæˆ‘ä»¬å°±å¯ä»¥å®šä¹‰æˆ‘ä»¬çš„SFT Traineräº†ã€‚ç›¸å½“çš„ç›´è§‚\nclass SFTTrainer:\n    def __init__(\n        self,\n        model: PreTrainedModel,\n        train_config: SFTTrainingConfig,\n        device: torch.device,\n        dataset_dir_base: str = \"./data/pre-processed\",\n    ): \n        ...\n    \n    def train_step(\n        self,\n    ) -&gt; tuple[float, float]: \n        ... \n        \n    def train(self, vllm=None):\n        ...\nåœ¨è¿™é‡Œå°±ä¸è¿‡å¤šçš„èµ˜è¿°äº†ï¼Œæœ‰éœ€è¦çš„åŒå­¦è¯·è‡ªè¡ŒæŸ¥çœ‹ä»£ç  assignment5-alignment/cs336_alignment/algs/sft.py ä»¥åŠå®ƒçš„è®­ç»ƒä»£ç  assignment5-alignment/train_sft.py",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#sft-experiment",
    "href": "posts/CS336/Ass05/ass05.html#sft-experiment",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "3.7 SFT Experiment",
    "text": "3.7 SFT Experiment\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹SFT çš„è®­ç»ƒç»“æœï¼š\n\n\n\n\n\n\n\n\n\n\n\n(a) Accuracy\n\n\n\n\n\n\n\n\n\n\n\n(b) Format Reward\n\n\n\n\n\n\n\nFigureÂ 1: Result of SFT on Qwen2.5-Math-1.5B\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼Œç»è¿‡SFTè®­ç»ƒä¹‹åï¼Œæ¨¡å‹åœ¨MATH, GSM8Kæ•°æ®é›†ä¸Šçš„è¡¨ç°éƒ½æœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œå°¤å…¶æ˜¯åœ¨Format Rewardä¸Šï¼Œæå‡éå¸¸æ˜æ˜¾ï¼Œè¿™ä¹Ÿç¬¦åˆæˆ‘ä»¬ä¹‹å‰æåˆ°çš„SFTçš„ä½œç”¨ï¼Œ è®©æ¨¡å‹å˜å¾—æ›´åƒåŠ©ç†ï¼Œæ›´ä¼šæŒ‰æŒ‡ä»¤åšäº‹ã€‚å¹¶ä¸”Accuracyä¹Ÿæœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œ è¿™ä¹Ÿè¯´æ˜SFTåœ¨æå‡æ¨¡å‹èƒ½åŠ›æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#ei-experiment",
    "href": "posts/CS336/Ass05/ass05.html#ei-experiment",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "4.1 EI Experiment",
    "text": "4.1 EI Experiment\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹EI çš„è®­ç»ƒç»“æœï¼š\n\n\n\n\n\n\n\n\n\n\n\n(a) GSM8K Accuracy\n\n\n\n\n\n\n\n\n\n\n\n(b) Format Reward\n\n\n\n\n\n\n\nFigureÂ 2: Result of EI on Qwen2.5-Math-1.5B on MATH and GSM8K Datasets\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼Œç»è¿‡EIè®­ç»ƒä¹‹åï¼Œæ¨¡å‹åœ¨MATH, GSM8Kæ•°æ®é›†ä¸Šçš„è¡¨ç°éƒ½æœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œå°¤å…¶æ˜¯åœ¨Accuracyä¸Šï¼Œæå‡éå¸¸æ˜æ˜¾ï¼Œè¿™ä¹Ÿç¬¦åˆæˆ‘ä»¬ä¹‹å‰æåˆ°çš„EIçš„ä½œç”¨ï¼Œé€šè¿‡é‡‡æ ·æ›´å¤šçš„Prompt-Response Pairsï¼Œæ¥æå‡æ¨¡å‹çš„èƒ½åŠ›ã€‚å¹¶ä¸”Format Rewardä¹Ÿæœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œ è¿™ä¹Ÿè¯´æ˜EIåœ¨æå‡æ¨¡å‹èƒ½åŠ›æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#grpo-experiment",
    "href": "posts/CS336/Ass05/ass05.html#grpo-experiment",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "5.1 GRPO Experiment",
    "text": "5.1 GRPO Experiment\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹GRPO çš„è®­ç»ƒç»“æœï¼š\n\n\n\n\n\n\n\n\n\n\n\n(a) GRPO Accuracy\n\n\n\n\n\n\n\n\n\n\n\n(b) GSM8K Token Entropy\n\n\n\n\n\n\n\nFigureÂ 3: Result of GRPO on Qwen2.5-Math-1.5B on GSM8K Dataset",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Ass05/ass05.html#other-experiments",
    "href": "posts/CS336/Ass05/ass05.html#other-experiments",
    "title": "Assignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO",
    "section": "5.2 Other Experiments",
    "text": "5.2 Other Experiments\nåœ¨Assignmentä¸­ï¼Œ æˆ‘è¿˜å®ç°äº†ä¸€äº›å…¶ä»–çš„å®éªŒï¼Œ æ¯”å¦‚ä¸åŒçš„Reward Functionï¼Œ ä¸åŒçš„Loss Typeï¼Œ ä»¥åŠä¸åŒçš„Group Sizeã€‚ç”±äºæ—¶é—´çš„å…³ç³»ï¼Œæˆ‘å¹¶æ²¡æœ‰åšè¿™äº›å®éªŒï¼Œä¸è¿‡åœ¨ä»£ç ä¸­ï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„å®ç°è¿™äº›å®éªŒã€‚\n\n5.2.1 Learning Rate Tuning\né¦–å…ˆç¬¬ä¸€ä¸ªå®éªŒå°±æ˜¯å­¦ä¹ ç‡çš„è°ƒèŠ‚ï¼Œ ç”±äºGRPOçš„è®­ç»ƒæ¯”è¾ƒä¸ç¨³å®šï¼Œ å› æ­¤å­¦ä¹ ç‡çš„é€‰æ‹©éå¸¸é‡è¦ã€‚ æˆ‘å°è¯•äº†ä¸åŒçš„å­¦ä¹ ç‡ï¼Œ å‘ç°0.0001æ˜¯ä¸€ä¸ªæ¯”è¾ƒåˆé€‚çš„é€‰æ‹©ï¼Œ è¿‡é«˜çš„å­¦ä¹ ç‡ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œ è¿‡ä½çš„å­¦ä¹ ç‡ä¼šå¯¼è‡´è®­ç»ƒæ”¶æ•›æ…¢ã€‚\n\n\n5.2.2 Effect of Baseline\nBaselineçš„ä½œç”¨æ˜¯å‡å°‘è®­ç»ƒçš„æ–¹å·®ï¼Œ å› æ­¤æˆ‘å°è¯•äº†ä¸åŒçš„Baselineï¼Œ å‘ç°ä½¿ç”¨Baselineå¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œ å¹¶ä¸”å¯ä»¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n\n5.2.3 Length Normalization\nåœ¨è®¡ç®—Log Probsçš„æ—¶å€™ï¼Œæ ¹æ®ä¸åŒçš„Length Normalizationæ–¹å¼ï¼Œ ä¹Ÿä¼šå¯¹è®­ç»ƒäº§ç”Ÿå½±å“ã€‚ æˆ‘å°è¯•äº†ä¸åŒçš„Normalizationæ–¹å¼ï¼Œ å‘ç°ä½¿ç”¨Token Level Normalizationå¯ä»¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n\n5.2.4 Normalization with group std\nåœ¨è®¡ç®—Advantageçš„æ—¶å€™ï¼Œ æˆ‘å°è¯•äº†æ˜¯å¦ä½¿ç”¨Group Stdæ¥è¿›è¡ŒNormalizationï¼Œ\n\n\n5.2.5 Off-Policy vs.Â On-Policy\nè¦æƒ³æŠŠGRPO è®­ç»ƒå¥½ï¼Œ è¿˜æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„ç‚¹å°±æ˜¯Off-Policy å’Œ On-Policyçš„é€‰æ‹©ã€‚ åœ¨GRPOä¸­ï¼Œ æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯On-Policyçš„æ–¹å¼ï¼Œ ä¹Ÿå°±æ˜¯ä½¿ç”¨Old Policyæ¥é‡‡æ ·æ•°æ®ï¼Œ ç„¶åä½¿ç”¨New Policyæ¥è¿›è¡Œä¼˜åŒ–ã€‚ è¿™ç§æ–¹å¼å¯ä»¥æå‡è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œ å¹¶ä¸”å¯ä»¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚è¦æƒ³æŠŠå®ƒæ”¹æˆOff-Policyä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œ ä½†æ˜¯éœ€è¦æ³¨æ„ä¸€äº›ç»†èŠ‚ï¼Œ æ¯”å¦‚Importance Samplingç­‰ã€‚\n\n\n5.2.6 Off Policy Clipping\n\n\n5.2.7 Different Prompts\nå½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°è¯•ä¸åŒçš„Promptsï¼Œ ä»¥ä¾¿æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚ ä¸åŒçš„Promptä¼šå¯¹æ¨¡å‹çš„æ€§èƒ½äº§ç”Ÿå½±å“ï¼Œ å› æ­¤é€‰æ‹©åˆé€‚çš„Promptä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚å½“Promptsæ”¹å˜æ—¶ï¼Œå¯¹åº”çš„Reward Functionä¹Ÿéœ€è¦ç›¸åº”çš„è°ƒæ•´ï¼Œ ä»¥ä¾¿æ›´å¥½çš„é€‚åº”æ–°çš„Promptã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 05: SFT & GRPO"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html",
    "href": "posts/CS336/Lecture15/lec15.html",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "",
    "text": "åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è®­ç»ƒï¼ˆPre-Trainingï¼‰è·å¾—äº†ä¸€ä¸ªå¯ä»¥è‡ªåŠ¨è¡¥å…¨çš„LLMã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªæ˜¾ç„¶å’Œæˆ‘ä»¬ç°åœ¨ä½¿ç”¨çš„ChatGPTï¼ŒGeminiæœ‰å¾ˆå¤§çš„åŒºåˆ«ï¼Œå¦‚ä½•ä»è¿™ä¸ªGPTå˜æˆChatGPTï¼Œå°†æ˜¯æˆ‘ä»¬æ¥ä¸‹å»è¦å­¦ä¹ çš„å†…å®¹ã€‚ä¹Ÿå°±æ˜¯æ‰€è°“çš„Post-Trainingï¼Œé€šè¿‡Post-Trainingï¼Œæ¨¡å‹å¯ä»¥è¾“å‡ºåˆ¶å®šçš„å†…å®¹ï¼Œå¹¶ä¸”å˜å¾—æ›´åŠ å®‰å…¨ã€‚åœ¨è¿™èŠ‚Lectureä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šå­¦ä¹ ï¼š",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#dataset",
    "href": "posts/CS336/Lecture15/lec15.html#dataset",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "1.1 Dataset",
    "text": "1.1 Dataset\nSFTï¼ˆç›‘ç£å¾®è°ƒï¼‰é˜¶æ®µç”¨çš„æ•°æ®é‡é€šå¸¸ è¿œå°äºé¢„è®­ç»ƒï¼Œä½†å®ƒå¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“å´æå¤§ï¼Œæ‰€ä»¥ï¼š\n\næ•°æ®é‡Œçš„â€œç»†èŠ‚â€ä¼šè¢«æ¨¡å‹å¼ºçƒˆæ”¾å¤§ï¼šé£æ ¼ã€é•¿åº¦ã€æ ¼å¼ã€å£å»ã€æ˜¯å¦çˆ±åˆ—ç‚¹ã€æ˜¯å¦çˆ±åŠ å¼•ç”¨ã€æ˜¯å¦çˆ± emojiâ€¦â€¦éƒ½ä¼šè¢«å­¦æˆâ€œé»˜è®¤è¡Œä¸ºâ€ã€‚\nSFT æ›´æ“…é•¿æ•™ä¼šæ¨¡å‹è¾“å‡ºçš„â€œç±»å‹ç­¾åâ€ï¼ˆtype signatureï¼‰ï¼šåƒä¸åƒèŠå¤©ã€æ˜¯ä¸æ˜¯æœ‰ç»“æ„ã€æœ‰æ²¡æœ‰ç¤¼è²Œã€ä¼šä¸ä¼šæ‹’ç»ã€‚\nä½† SFT ä¸ä¸€å®šå¯é åœ°æ•™ä¼šâ€œæ–°çŸ¥è¯†â€ï¼Œç”šè‡³ä¼šå¼•å…¥æ·å¾„è¡Œä¸ºï¼ˆæ¯”å¦‚ä¸ºäº†ç¬¦åˆâ€œä¸“å®¶ç­”æ¡ˆçš„å½¢å¼â€ï¼Œå»ç¼–é€ å¼•ç”¨/äº‹å®ï¼‰ã€‚\n\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹å‡ ä¸ªSFTæ•°æ®çš„ä¾‹å­ï¼š\n\n1.1.1 FLAN\nFLAN(Longpre et al. 2023) æ•°æ®æ˜¯æŠŠå¾ˆå¤š NLP ä»»åŠ¡ç”¨â€œè‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¨¡æ¿â€è¡¨è¾¾å‡ºæ¥ï¼Œç„¶åæŠŠæ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šåš instruction tuningï¼ˆæŒ‡ä»¤å¾®è°ƒï¼‰ï¼Œä»è€Œæå‡é›¶æ ·æœ¬æ³›åŒ– FLAN ç³»åˆ—çš„å…³é”®ä¸æ˜¯åŸå§‹ä»»åŠ¡ï¼Œè€Œæ˜¯ï¼š - æŠŠæ¯ä¸ªä»»åŠ¡å†™æˆè‹¥å¹²ç§ è‡ªç„¶è¯­è¨€æ¨¡æ¿ï¼ˆinstruction + input + outputï¼‰ - æ¨¡å‹è®­ç»ƒæ—¶çœ‹åˆ°çš„æ˜¯â€œåƒèŠå¤©æŒ‡ä»¤ä¸€æ ·çš„æ–‡æœ¬â€ï¼Œä½†èƒŒåå¾ˆå¤šæ˜¯åˆ†ç±»/æŠ½å–/QA/ç”Ÿæˆç­‰ä¼ ç»Ÿä»»åŠ¡\nè®ºæ–‡æŠŠå®ƒç§°ä¸º â€œtasks formatted with instructionsâ€ çš„ instruction tuning\n\n\n\n\n\n\nFigureÂ 2: FLAN æ•°æ®ç¤ºä¾‹ï¼šæŠŠåˆ†ç±»ä»»åŠ¡å†™æˆâ€œæŒ‡ä»¤ + è¾“å…¥ + è¾“å‡ºâ€çš„å½¢å¼\n\n\n\n\n\n1.1.2 Alpaca\nAlpaca æ˜¯æ–¯å¦ç¦ CRFM / Tatsu-lab åœ¨ 2023 å¹´æå‡ºçš„ä¸€ä¸ªå¯å¤ç°è·¯çº¿ï¼š\nç”¨ LLaMA-7B åšåŸºåº§ï¼Œæ‹¿ä¸€ä»½ç”±æ›´å¼ºæ¨¡å‹ç”Ÿæˆçš„æŒ‡ä»¤è·Ÿéšæ•°æ®ï¼ˆ52Kï¼‰åš SFTï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªâ€œåƒ ChatGPT ä¸€æ ·æ›´ä¼šå¬æŒ‡ä»¤â€çš„æ¨¡å‹ã€‚\nå®ƒçš„æ•°æ®ç±»ä¼¼äºï¼š\n\n\n\n\n\n\nFigureÂ 3: Alpaca æ•°æ®ç¤ºä¾‹ï¼šç»™å®šæŒ‡ä»¤ï¼Œç”Ÿæˆå¯¹åº”å›ç­”\n\n\n\nä¸‹é¢æ˜¯Alpacaçš„Prompt Template\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\né€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å­¦ä¼šäº†â€œçœ‹åˆ° instruction + input åï¼Œåº”è¯¥ç”Ÿæˆä»€ä¹ˆæ ·çš„ responseâ€ã€‚\nAlpaca çš„æ•°æ®ç”ŸæˆåŸºæœ¬æ²¿ç€ Self-Instruct çš„æ€è·¯èµ°ï¼š\n\nèµ·ç‚¹ï¼š175 æ¡äººå·¥å†™çš„ seed instruction-output pairsï¼ˆæ¥è‡ª Self-Instruct çš„ seed setï¼‰\n\nç”¨ text-davinci-003ï¼ˆå½“æ—¶éå¸¸å¼ºçš„ teacherï¼‰ï¼š\n\nç”Ÿæˆæ›´å¤šæŒ‡ä»¤ï¼ˆç”¨ seed åš in-context ç¤ºä¾‹ï¼Œè®© teacher æ‰©å†™/å˜æ¢å‡ºæ–° instructionï¼‰\nå†è®© teacher ä¸ºè¿™äº›æŒ‡ä»¤ç”Ÿæˆå›ç­”ï¼Œå¾—åˆ°â€œinstruction-following demonstrationsâ€\næœ€ç»ˆå½¢æˆå¤§çº¦ 52K æ¡æ•°æ®ã€‚\n\n\næ‰€ä»¥ Alpaca çš„æœ¬è´¨æ˜¯ï¼šç”¨å¼ºæ¨¡å‹å½“â€œæ•°æ®å·¥å‚â€ï¼Œä½æˆæœ¬é€ å‡ºå¤§æ‰¹ instructionâ†’response çš„ SFT æ ·æœ¬ã€‚\n\n\n\n\n\n\nFigureÂ 4: Alpaca æ•°æ®ç”Ÿæˆæµç¨‹ç¤ºæ„ï¼šç”¨å¼ºæ¨¡å‹ï¼ˆtext-davinci-003ï¼‰åŸºäºå°‘é‡äººå·¥ç¤ºèŒƒï¼Œè‡ªåŠ¨ç”Ÿæˆå¤§è§„æ¨¡çš„æŒ‡ä»¤-å›ç­”å¯¹ï¼Œç”¨äºå¾®è°ƒåŸºç¡€æ¨¡å‹ï¼ˆLLaMA-7Bï¼‰ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—é™ä½äº†é«˜è´¨é‡ SFT æ•°æ®çš„è·å–æˆæœ¬ã€‚Image source Self-Instruct: Aligning LM with Self Generated Instructions\n\n\n\n\n\n1.1.3 OpenAssistant\nOpenAssistant Conversations (OASST1)(KÃ¶pf et al. 2023) æ˜¯ LAION ç»„ç»‡çš„å…¨çƒä¼—åŒ…é¡¹ç›®äº§å‡ºçš„ä¸€ä¸ª â€œåŠ©æ‰‹é£æ ¼ï¼ˆassistant-styleï¼‰å¯¹è¯è¯­æ–™â€ï¼Œç›®æ ‡æ˜¯æŠŠå¯¹é½ï¼ˆSFT / RLHFï¼‰ç ”ç©¶â€œæ°‘ä¸»åŒ–â€ï¼šæŠŠåŸæœ¬ç»å¸¸è¢«å¤§å‚ç§æœ‰åŒ–çš„é«˜è´¨é‡åå¥½/å¯¹è¯æ•°æ®å¼€æºå‡ºæ¥ã€‚å®ƒåŒ…å« 161,443 æ¡æ¶ˆæ¯ã€35 ç§è¯­è¨€ã€è¶…è¿‡ 10,000 æ£µå®Œæ•´æ ‡æ³¨çš„å¯¹è¯æ ‘ï¼Œå¹¶é™„å¸¦å¤§é‡è´¨é‡è¯„åˆ†ã€‚\nç®€è¦æ¥è¯´ï¼Œæ•´ä¸ªæ•°æ®é›†ç”±ä¸€ç³»åˆ—å¯¹è¯æ ‘ï¼ˆConversation Tree, CTï¼‰ç»„æˆã€‚æ¯ä¸€æ£µæ ‘çš„æ ¹èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªåˆå§‹æç¤ºï¼ˆpromptï¼‰ï¼Œç”±â€œprompterâ€è§’è‰²ç»™å‡ºï¼›åœ¨å¯¹è¯ä¸­åªåŒºåˆ†ä¸¤ç§è§’è‰²ï¼šprompterï¼ˆæé—®æ–¹ï¼‰å’Œ assistantï¼ˆå›ç­”æ–¹ï¼‰ï¼Œè€Œâ€œuserâ€è¿™ä¸ªè¯ä»…ç”¨æ¥æŒ‡å‚ä¸æ•°æ®æ ‡æ³¨æˆ–è´¡çŒ®å†…å®¹çš„äººç±»ï¼Œä»¥é¿å…è§’è‰²æ¦‚å¿µæ··æ·†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸¤ç§è§’è‰²åœ¨åŸåˆ™ä¸Šæ—¢å¯ä»¥ç”±äººç±»å®Œæˆï¼Œä¹Ÿå¯ä»¥ç”±æ¨¡å‹ç”Ÿæˆã€‚\nåœ¨å¯¹è¯æ ‘ä¸­ï¼š - æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€æ¡ä¹¦é¢æ¶ˆæ¯ï¼Œå¹¶æ˜ç¡®æ ‡æ³¨å…¶è§’è‰²ï¼ˆprompter æˆ– assistantï¼‰ã€‚ - æ¯ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªå­èŠ‚ç‚¹ï¼Œä¸”å­èŠ‚ç‚¹çš„è§’è‰²ä¸€å®šä¸çˆ¶èŠ‚ç‚¹ç›¸åï¼Œè¡¨ç¤ºåŒä¸€è½®å¯¹è¯ä¸‹çš„ä¸åŒå¯èƒ½å›å¤ã€‚ - ä»æ ¹èŠ‚ç‚¹åˆ°æ ‘ä¸­ä»»æ„èŠ‚ç‚¹çš„ä¸€æ¡è·¯å¾„ç§°ä¸ºä¸€ä¸ª threadï¼Œå®ƒå¯¹åº”ä¸€æ®µåˆæ³•çš„å®Œæ•´å¯¹è¯ï¼Œä½“ç°æé—®æ–¹ä¸åŠ©æ‰‹è½®æµå‘è¨€çš„è¿‡ç¨‹ã€‚ - æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šé™„å¸¦é¢å¤–æ ‡æ³¨ä¿¡æ¯ï¼Œä¾‹å¦‚äººå·¥æ ‡ç­¾ã€å…ƒæ•°æ®ï¼ˆé‡‡é›†æ—¶é—´ã€è¯­è¨€ç­‰ï¼‰ã€‚ - assistant èŠ‚ç‚¹è¿˜åŒ…å«æ’åºä¿¡æ¯ï¼ˆrankï¼‰ï¼Œç”¨äºè¡¨ç¤ºåœ¨åŒä¸€çˆ¶ prompt ä¸‹ï¼Œå¤šæ¡å€™é€‰å›å¤ä¹‹é—´çš„äººç±»åå¥½é¡ºåºï¼Œè¿™æ˜¯åç»­åå¥½å­¦ä¹ å’Œå¥–åŠ±å»ºæ¨¡çš„é‡è¦ä¿¡å·ã€‚\næ•´ä½“ä¸Šï¼Œè¿™ç§å¯¹è¯æ ‘ç»“æ„ä¸ä»…èƒ½è¡¨ç¤ºå¤šè½®å¯¹è¯ï¼Œè¿˜èƒ½è‡ªç„¶åœ°æ”¯æŒä¸€é—®å¤šç­” + äººç±»åå¥½æ’åºï¼Œéå¸¸é€‚åˆç”¨äºæŒ‡ä»¤å¾®è°ƒã€å¥–åŠ±æ¨¡å‹è®­ç»ƒä»¥åŠå¯¹é½ç ”ç©¶ã€‚\nä¸‹å›¾æ˜¯OpenAssistantæ•°æ®é›†çš„ä¸€ä¸ªå¯¹è¯æ ‘ç¤ºä¾‹ï¼š\n\n\n\n\n\n\nFigureÂ 5: OpenAssistant æ•°æ®é›†ä¸­çš„ä¸€ä¸ªå¯¹è¯æ ‘ç¤ºä¾‹ï¼Œå±•ç¤ºäº†ä»åˆå§‹æç¤ºï¼ˆpromptï¼‰åˆ°å¤šè½®äº¤äº’çš„å®Œæ•´å¯¹è¯ç»“æ„ã€‚æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€æ¡æ¶ˆæ¯ï¼Œå¹¶æ ‡æ³¨äº†è§’è‰²ï¼ˆprompter æˆ– assistantï¼‰åŠå…¶å¯¹åº”çš„å›å¤é€‰é¡¹å’Œåå¥½æ’åºä¿¡æ¯ã€‚\n\n\n\n\n\n1.1.4 Self-Annotated Dataset\nåœ¨è¯¾å ‚ä¸Šï¼Œè¿˜ä¸€èµ·Labeläº†å‡ ä¸ªPromptsï¼Œ ä½†æ˜¯ä»è¿™äº›Promptsçš„ä¾‹å­ä¸­ï¼Œæ˜æ˜¾å¯ä»¥çœ‹å‡ºæœ‰å‡ ä¸ªé—®é¢˜ï¼š\n\nè´¨é‡æ–¹å·®æå¤§ï¼ˆhigh varianceï¼‰: åŒä¸€ä¸ª promptï¼Œæœ‰äººè®¤çœŸå†™é•¿æ–‡ã€æœ‰äººä¸€å¥è¯ã€æœ‰äººç›´æ¥å¥— ChatGPT æ¨¡æ¿ã€‚SFT ä¼šæŠŠè¿™ç§é£æ ¼å·®å¼‚å½“æˆâ€œéƒ½å¯¹â€çš„ç¤ºèŒƒå­¦è¿›å»ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºé£æ ¼ä¸ç¨³å®šã€‚\nâ€œå†™é•¿ã€å†™å¥½â€å¾ˆéš¾ â†’ æ•°æ®ä¼šåçŸ­æˆ–åæ¨¡æ¿: å¤§å¤šæ•°äººå†™ä¸å‡ºæŒç»­é«˜è´¨é‡é•¿å›ç­”ï¼›è¦ä¹ˆå¾ˆçŸ­ï¼Œè¦ä¹ˆç”¨å¥—è¯å¡«å……ã€‚æ¨¡å‹å­¦åˆ°çš„å¾€å¾€æ˜¯â€œæ¨¡æ¿åŒ–ç»“æ„â€ï¼Œä¸ä¸€å®šæ˜¯æ›´æœ‰ç”¨çš„å†…å®¹ã€‚\nå®¹æ˜“äº§ç”Ÿâ€œé£æ ¼&gt;æ­£ç¡®æ€§â€çš„åç½®ï¼ˆlength/list bias: äººç±»å†™ä½œå¤©ç„¶å€¾å‘äºåˆ—ç‚¹ã€å†™å¾—æ›´é•¿æ˜¾å¾—æ›´â€œåƒç­”æ¡ˆâ€ã€‚æ¨¡å‹å­¦åˆ°çš„å¯èƒ½æ˜¯â€œå¤šå†™ã€åˆ—ç‚¹ã€å®¢æ°”â€è¿™ç§ç±»å‹ç­¾åï¼Œè€Œä¸æ˜¯â€œç®€æ´ä¸”å‡†ç¡®â€ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#algorithm",
    "href": "posts/CS336/Lecture15/lec15.html#algorithm",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "1.2 Algorithm",
    "text": "1.2 Algorithm\nåœ¨äº†è§£äº†SFTçš„Datasetä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒæ¨¡å‹äº†ã€‚å…¶å®SFTçš„ç®—æ³•å¾ˆç®€å•ï¼Œä¸Pre-Trainingçš„Objectä¸€æ ·ï¼Œéƒ½æ˜¯Next-Token-Predictionï¼Œå…¶åŸºæœ¬çš„ä»£ç æ¡†æ¶æ˜¯ï¼štoken-level NLLï¼‰\n\\[\n\\underset{\\theta}{\\max} \\log p_{\\theta}(y | x)\n\\tag{1}\\]\nä»ä»£ç æ¥çœ‹ï¼Œå°±æ˜¯ç®€å•çš„å‡ æ­¥ï¼š\n\n\nShow the code\nfor step in range(train_steps):\n    batch = next(train_dataloader)\n    \n    input_ids = batch['input_ids']\n    labels = batch['labels']\n    response_mask = batch['response_mask']\n    \n    output = model(input_ids) \n    \n    loss = loss_fn(output, input_ids, response_mask)\n    loss.backward()\n    \n    optimizer.step()\n\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒåŸºæœ¬ä¸Šä¸Pre-Trainingçš„Loss ç±»ä¼¼ï¼Œåªä¸è¿‡å°±æ˜¯å¤šäº†ä¸€ä¸ªResponse Mask.\n\n\nQuestionï¼šä¸ºä»€ä¹ˆè¦ mask promptï¼Ÿ\n\n\nå› ä¸ºæˆ‘ä»¬å¸Œæœ›æ¨¡å‹å­¦çš„æ˜¯ï¼šâ€œçœ‹åˆ° prompt åï¼Œåº”è¯¥æ€ä¹ˆç­”â€, è€Œä¸æ˜¯ï¼šâ€œæŠŠ prompt ä¹ŸèƒŒä¸‹æ¥å¤ç°ä¸€éâ€ã€‚ é€šè¿‡maskæ‰ prompt éƒ¨åˆ†çš„ lossï¼Œæˆ‘ä»¬åªè®©æ¨¡å‹åœ¨ response éƒ¨åˆ†å­¦ä¹ é¢„æµ‹ï¼Œ å¹¶ä¸”é¿å…æ¨¡å‹è¿‡æ‹Ÿåˆ prompt å†…å®¹ã€‚\n\n\n\n1.2.1 Mid-Training\næ—¢ç„¶SFTå’ŒPre-Trainingçš„è®­ç»ƒç›®æ ‡ä¸€è‡´ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä¸å¯ä»¥å°†SFTçš„è®­ç»ƒæ··åˆåˆ°Pre-Trainingå½“ä¸­å‘¢ï¼Ÿç­”æ¡ˆæ˜¯å¯ä»¥çš„ï¼Œè¿™ä¹Ÿå°±æ˜¯æ‰€è°“çš„Mid-Training/Two-Phase Training\nåœ¨è¿™ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸»è¦åš3ä»¶äº‹ï¼š\n\nå…ˆæ­£å¸¸åšé¢„è®­ç»ƒï¼ˆPre-train on web/pretraining dataï¼‰ åœ¨Common Crawl / books / code / papers ç­‰å¤§è§„æ¨¡è¯­æ–™ä¸­è®­ç»ƒï¼Œç›®æ ‡æ˜¯ next-token predictionã€‚\nåœ¨é¢„è®­ç»ƒçš„ååŠæ®µï¼ŒæŠŠ instruction-tuning æ•°æ®æ··è¿›å»ï¼ˆMix in instruction-tuning data into pre-trainingï¼‰å…³é”®ç‚¹æ˜¯ï¼š\n\nä¸æ˜¯ç­‰é¢„è®­ç»ƒç»“æŸå†å•ç‹¬ SFT\nå½“æ¨¡å‹å·²ç»æœ‰ä¸€å®šèƒ½åŠ›ã€å­¦ä¹ ç‡å¼€å§‹ä¸‹é™ï¼ˆè¿›å…¥ decay / anneal é˜¶æ®µï¼‰æ—¶ï¼Œ ç»§ç»­ç”¨â€œé¢„è®­ç»ƒæ•°æ®â€ä¿æŒé€šç”¨èƒ½åŠ›\nåŒæ—¶åŠ å¤§â€œé«˜è´¨é‡/æŒ‡ä»¤/å¯¹è¯/æ¨ç†â€æ•°æ®çš„æ¯”ä¾‹ï¼Œè®©æ¨¡å‹åœ¨è¿˜å¤„åœ¨â€œé¢„è®­ç»ƒä¼˜åŒ–çŠ¶æ€â€æ—¶å°±é€æ¸å­¦ä¼šæŒ‡ä»¤è·Ÿéšçš„åˆ†å¸ƒ\nè¿™ä¸€æ­¥æœ¬è´¨ä¸Šï¼šè¿˜æ˜¯ next-token lossï¼Œåªæ˜¯æ•°æ®åˆ†å¸ƒå˜äº†ã€‚\n\næœ€åå†åšä¸€ä¸ªå¾ˆçŸ­çš„çœŸæ­£ instruction tuningï¼šç”±äºç¬¬äºŒæ­¥å·²ç»æŠŠâ€œæŒ‡ä»¤åˆ†å¸ƒâ€æ·±åº¦èè¿›æ¨¡å‹äº†ï¼Œæœ€åçš„çº¯ SFT å¾€å¾€å¯ä»¥æ›´çŸ­ã€æ›´åƒâ€œæ ¡å‡†/æ”¶å°¾â€ã€‚\n\né€šè¿‡è¿™ä¸ªåšæ³•çš„å¥½å¤„å°±æ˜¯ï¼šè®©æ¨¡å‹èƒ½åœ¨ä¸ä¸¥é‡ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰çš„æƒ…å†µä¸‹ï¼ŒæŠŠ instruction tuning æ‰©å¤§è§„æ¨¡.\næˆ‘ä»¬æ¥å¯¹æ¯”ä¸€ä¸‹ä¼ ç»Ÿ SFT å’Œ Mid-Training çš„åŒºåˆ«ï¼š\n\nä¼ ç»Ÿåšæ³•ï¼šå…ˆé¢„è®­ç»ƒå®Œï¼Œå† SFT ï¼šSFT æ•°æ®é‡è™½ç„¶å°ï¼Œä½†æ¢¯åº¦ä¿¡å·å¾ˆé›†ä¸­ã€é£æ ¼å¼ºï¼Œä¼šæŠŠæ¨¡å‹â€œæ‹‰â€åˆ°å¾ˆçª„çš„åˆ†å¸ƒä¸Šã€‚\nå¦‚æœä½  SFT è¿‡æ‹Ÿåˆï¼ˆå­¦ä¹ ç‡å¤§/æ­¥æ•°å¤š/æ•°æ®åˆ†å¸ƒå¤ªåï¼‰ï¼Œå°±å®¹æ˜“ï¼š\n\né€šç”¨èƒ½åŠ›ä¸‹é™ï¼ˆé—å¿˜é¢„è®­ç»ƒé‡Œå­¦åˆ°çš„å¹¿æ³›çŸ¥è¯†/è¯­è¨€èƒ½åŠ›ï¼‰\nè¿‡æ‹ŸåˆæŸç§é£æ ¼ï¼ˆæ›´å•°å—¦ã€æ›´çˆ±åˆ—ç‚¹ã€æ›´çˆ±æ¨¡æ¿åŒ–ï¼‰\n\nMid-Trainingï¼šé¢„è®­ç»ƒåæœŸé€æ­¥åŠ æŒ‡ä»¤æ•°æ® ï¼šå› ä¸ºé¢„è®­ç»ƒæ•°æ®è¿˜åœ¨ã€å­¦ä¹ ç‡ä¹Ÿåœ¨ decayï¼Œæ¨¡å‹è¢«â€œæ¸©å’Œåœ°â€å¼•å¯¼åˆ°æŒ‡ä»¤åˆ†å¸ƒï¼Œ\n\nä¸ä¼šä¸€ä¸‹å­è¢« SFT çš„å¼ºåˆ†å¸ƒå†²åˆ·ã€‚\n\nåŒæ—¶å¯ä»¥æŠŠ instruction æ•°æ®è§„æ¨¡åšå¤§ï¼ˆç”šè‡³åˆ°â€œåƒé¢„è®­ç»ƒä¸€æ ·å¤§â€ï¼‰ï¼Œè€Œä¸ç”¨æ‹…å¿ƒå½»åº•æŠŠæ¨¡å‹è®­åã€‚\n\n\né€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œä¿®æ”¹ä¸åŒé˜¶æ®µçš„æ•°æ®æ¯”ä¾‹å³å¯ï¼Œæ¯”å¦‚ï¼š\n\nè®­ç»ƒè¿›åº¦å‰ 70%ï¼šå‡ ä¹å…¨æ˜¯é¢„è®­ç»ƒæ•°æ®\nå 30%ï¼ˆå­¦ä¹ ç‡å¼€å§‹è¡°å‡ï¼‰ï¼šé€æ­¥æé«˜ instruction/é«˜è´¨é‡æ•°æ®å æ¯”ï¼šä¾‹å¦‚ä» 0% â†’ 10% â†’ 30% â†’ 50%\nè®­ç»ƒæœ«å°¾ï¼šå†åšå°‘é‡çº¯ SFTï¼ˆæ›´åƒâ€œå¯¹é½æ”¶å°¾â€ï¼‰\n\n\n\n\n\n\n\nFigureÂ 6: è¿™å¼ å›¾è¯´æ˜å¾ˆå¤šæ¨¡å‹ä¼šæŠŠâ€œæŒ‡ä»¤å¾®è°ƒæ•°æ®â€æå‰æ··è¿›é¢„è®­ç»ƒçš„åæœŸï¼ˆdecay/mid-trainingï¼‰ï¼Œè®©æ•°æ®é…æ–¹ä»â€œçº¯ç½‘é¡µé¢„è®­ç»ƒâ€ï¼ˆå·¦å›¾ï¼‰é€æ­¥å˜æˆâ€œé¢„è®­ç»ƒè¯­æ–™ + å„ç±»SFT/é«˜è´¨é‡æŒ‡ä»¤æ•°æ®çš„æ··åˆâ€ï¼ˆå³å›¾ï¼‰ï¼Œä»è€Œæ›´è§„æ¨¡åŒ–åœ°è·å¾—æŒ‡ä»¤è·Ÿéšèƒ½åŠ›å¹¶å‡å°‘ç¾éš¾æ€§é—å¿˜ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#rlhf-data",
    "href": "posts/CS336/Lecture15/lec15.html#rlhf-data",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.1 RLHF Data",
    "text": "2.1 RLHF Data\nè¯¾ä¸Šæåˆ° InstructGPT çš„æ ‡æ³¨å‡†åˆ™å¾ˆç»å…¸ï¼šhelpfulã€truthfulã€harmlessã€‚\nå®é™…æ ‡æ³¨ç•Œé¢é€šå¸¸å°±æ˜¯ï¼š\n\nA vs B å“ªä¸ªæ›´å¥½ï¼Ÿï¼ˆæˆ– 4 é€‰ 1 / ties ç­‰ï¼‰\næœ‰æ—¶è¿˜ä¼šåˆ†åˆ«æ‰“åˆ†ï¼šäº‹å®æ€§ã€éµå¾ªæŒ‡ä»¤ã€å®‰å…¨æ€§ã€å†™ä½œè´¨é‡ç­‰\n\nä¸è¿‡éœ€è¦æ³¨æ„çš„æ˜¯ï¼šè¿™ä¸æ˜¯â€œå¯¹é”™é¢˜â€ï¼Œå¾ˆå¤šä»»åŠ¡æ˜¯å¼€æ”¾å¼åå¥½ã€‚\næœ‰äº†è¿™äº›æ•°æ®ä¹‹åï¼Œæˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªReward Model \\(r_{\\phi}(x, y)\\). æ¯ä¸ªå›ç­”éƒ½æœ‰ä¸€ä¸ªéšè—åˆ†æ•°ï¼Œæ ‡æ³¨è€…æ›´å¸¸é€‰åˆ†é«˜çš„ã€‚\nç”¨ä¸€ä¸ª logistic/softmax å½¢å¼æ‹Ÿåˆï¼š\n\\[\nP(y^+ \\succ y^- \\mid x) = \\sigma\\big(r_\\phi(x,y^+) - r_\\phi(x,y^-)\\big)\n\\tag{3}\\]\näºæ˜¯ä½ çš„ RLHF æ•°æ®å°±å˜æˆ reward model çš„ç›‘ç£æ•°æ®:\n\\[\n\\underset{\\phi}{\\max} \\sum_{(x, y^+, y^-) \\in D} \\log \\sigma\\big(r_\\phi(x,y^+) - r_\\phi(x,y^-)\\big)\n\\tag{4}\\]\nè®­ç»ƒå®Œæˆåï¼Œå°±æœ‰äº†ä¸€ä¸ª reward modelï¼Œå¯ä»¥ç»™ä»»æ„ (x, y) å¯¹æ‰“åˆ†ï¼š \\(r_{\\phi}(x, y)\\)ã€‚\nå½“ç„¶ï¼Œè¿™ä¸ªæµç¨‹çœ‹ä¼¼ç®€å•ï¼Œå®é™…ä¸Šè¿˜æ˜¯æœ‰å¾ˆå¤šè€ƒé‡çš„ï¼š\n\næ•°æ®è´¨é‡ï¼šæ ‡æ³¨è€…åŸ¹è®­ã€å®¡æ ¸ã€åˆ†å¸ƒè¦†ç›–ã€åè§æ§åˆ¶ç­‰\næ•°æ®å¤šæ ·æ€§ï¼šprompt ç±»å‹ã€å›ç­”é£æ ¼ã€éš¾åº¦ç­‰\næ¨¡å‹æ¶æ„ï¼šreward model é€šå¸¸æ˜¯ä¸€ä¸ªå°å‹ LMï¼Œæˆ–è€…åœ¨ LM ä¸ŠåŠ ä¸ªå¤´",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#rlhf-algorithms",
    "href": "posts/CS336/Lecture15/lec15.html#rlhf-algorithms",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.2 RLHF Algorithms",
    "text": "2.2 RLHF Algorithms\næœ‰äº†Pair-Wise çš„Datasetå’ŒReward Modelä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒçš„æˆ‘ä»¬çš„æ¨¡å‹äº†ã€‚åœ¨InstructGPT(Ouyang et al. 2022) ä¸­ï¼Œä¸»è¦ç”¨çš„æ˜¯PPOçš„ç®—æ³•ã€‚ æ¥ä¸‹æ¥çœ‹çœ‹PPOçš„å…·ä½“å†…å®¹ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#ppo",
    "href": "posts/CS336/Lecture15/lec15.html#ppo",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.3 PPO",
    "text": "2.3 PPO\nå›é¡¾ä¸€ä¸‹ï¼Œçœ‹ä¸€ä¸‹æˆ‘ä»¬ç°åœ¨æ‰‹å¤´ä¸Šæœ‰äº›ä»€ä¹ˆä¸œè¥¿ï¼š\n\nä¸€ä¸ªåˆå§‹åŒ–çš„ç­–ç•¥æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ SFT æ¨¡å‹ï¼‰\\(\\pi_{\\text{ref}}(y|x)\\)ï¼ˆä½œä¸ºå‚è€ƒç­–ç•¥/åŸºçº¿ï¼‰\nä¸€ä¸ªå¥–åŠ±å‡½æ•°/å¥–åŠ±æ¨¡å‹ \\(r_{\\phi}(x,y)\\)ï¼ˆç”±åå¥½æ•°æ®è®­ç»ƒå‡ºæ¥ï¼‰\nè¦è®­ç»ƒçš„ç­–ç•¥ \\(\\pi_\\theta(y|x)\\), (ç”±LLMåˆå§‹åŒ–)\n\nRLHF-PPO çš„æ ¸å¿ƒç›®æ ‡å°±æ˜¯ï¼š\n\\[\n\\underset{\\theta}{\\max}  \\mathcal{J}(\\theta) = \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\big[r_\\phi(x,y)\\big] \\ -\\ \\beta \\, \\mathrm{KL}\\big(\\pi_\\theta(\\cdot|x)\\ \\|\\ \\pi_{\\text{ref}}(\\cdot|x)\\big)\n\\tag{5}\\]\né€šè¿‡è¿™ä¸ªç›®æ ‡å‡½æ•°ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹ï¼š å›ç­”æ›´â€œé«˜å¥–åŠ±â€ï¼Œä½†åˆ«åç¦» SFT å¤ªè¿œï¼ˆKL çº¦æŸé˜²æ­¢è·‘é£ã€å­¦ä¼šä½œå¼Šæˆ–å˜å¾—æ€ªå¼‚/ä¸å®‰å…¨ï¼‰ã€‚\n\n2.3.1 REINFORCE\nåœ¨Neural Networkä¸­ï¼Œæˆ‘ä»¬ä¼˜åŒ–ç›®æ ‡é€šå¸¸ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è®¡ç®—ä¸Šé¢ç›®æ ‡çš„æ¢¯åº¦ã€‚å¯¹äºDeep RLä¹Ÿä¸ä¾‹å¤–ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡ºè¿™ä¸ªObject Function (EquationÂ 5) çš„æ¢¯åº¦:\n\\[\n\\nabla_\\theta \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\big[r_\\phi(x,y)\\big] = \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\left[r_\\phi(x,y) \\, \\nabla_\\theta \\log \\pi_\\theta(y|x)\\right]\n\\tag{6}\\]\né€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºæ¢¯åº¦ï¼Œç„¶åç”¨SGDæ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè¿™ä¹Ÿå°±æ˜¯REINFORCEç®—æ³•ã€‚ åœ¨å®é™…æ“ä½œä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡Samplingçš„æ–¹å¼æ¥ä¼°è®¡ä¸Šé¢çš„æœŸæœ›ï¼š\n\\[\n\\nabla_\\theta \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\big[r_\\phi(x,y)\\big] \\approx \\frac{1}{N} \\sum_{i=1}^N r_\\phi(x,y_i) \\, \\nabla_\\theta \\log \\pi_\\theta(y_i|x), \\quad y_i \\sim \\pi_\\theta(\\cdot|x)\n\\tag{7}\\]\nä½†æ˜¯REINFORCEæœ‰ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š\n\nHigh varianceï¼šå¥–åŠ±ä¿¡å·å¾€å¾€å¾ˆç¨€ç–ä¸”å™ªå£°å¤§ï¼Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡æ–¹å·®å¾ˆé«˜ï¼Œè®­ç»ƒä¸ç¨³å®šã€‚\nå•æ­¥æ›´æ–°ï¼šREINFORCE æ¯æ¬¡æ›´æ–°éƒ½åŸºäºå½“å‰ç­–ç•¥é‡‡æ ·çš„æ•°æ®ï¼Œä¸èƒ½å¤šæ­¥åˆ©ç”¨æ—§æ•°æ®ï¼Œæ•ˆç‡ä½ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”é€æ­¥å¼•å‡ºPPOç®—æ³•ã€‚\n\n\n2.3.2 Variance Reduction with Advantage Function\næˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹ä¸ºä»€ä¹ˆä¼šæœ‰High Varianceçš„é—®é¢˜ã€‚\nå‡è®¾æˆ‘ä»¬æŠŠå›ç­” \\(y\\) çœ‹æˆä¸€ä¸ªåºåˆ—çš„åŠ¨ä½œ \\((a_1, a_2, \\ldots, a_T)\\)ï¼Œæ¯ä¸ªåŠ¨ä½œå¯¹åº”ç”Ÿæˆä¸€ä¸ª tokenã€‚ é‚£ä¹ˆæ ¹æ®é“¾å¼æ³•åˆ™ï¼Œå›ç­”çš„æ¦‚ç‡å¯ä»¥å†™æˆï¼š \\[\n\\pi_\\theta(y|x) = \\prod_{t=1}^T \\pi_\\theta(a_t | s_t)\n\\tag{8}\\]\nå…¶ä¸­ \\(s_t\\) æ˜¯ç”Ÿæˆç¬¬ \\(t\\) ä¸ª token æ—¶çš„çŠ¶æ€ï¼ˆåŒ…æ‹¬ prompt å’Œå‰é¢ç”Ÿæˆçš„ tokensï¼‰ã€‚ æ ¹æ® REINFORCE çš„æ¢¯åº¦å…¬å¼ EquationÂ 6ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å±•å¼€æˆå¯¹æ¯ä¸ªæ—¶é—´æ­¥çš„è´¡çŒ®æ±‚å’Œï¼š \\[\n\\nabla_\\theta \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\big[r_\\phi(x,y)\\big] = \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\left[r_\\phi(x,y) \\sum_{t=1}^T \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t)\\right]\n\\tag{9}\\]\nè¿™é‡Œçš„å…³é”®é—®é¢˜æ˜¯ï¼šå¥–åŠ± \\(r_\\phi(x,y)\\) æ˜¯å¯¹æ•´ä¸ªåºåˆ— \\(y\\) çš„è¯„ä»·ï¼Œä½†æˆ‘ä»¬æŠŠå®ƒç›´æ¥ç”¨åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦ä¸Šï¼Œå¯¼è‡´æ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦ä¼°è®¡éƒ½åŒ…å«äº†æ•´ä¸ªåºåˆ—çš„å™ªå£°ï¼Œæ–¹å·®å¾ˆå¤§ã€‚\nä¸ºäº†é™ä½æ¢¯åº¦ä¼°è®¡çš„æ–¹å·®ï¼Œæˆ‘ä»¬å¼•å…¥ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantage Functionï¼‰ \\(A_t\\)ï¼Œå®ƒè¡¡é‡åœ¨çŠ¶æ€ \\(s_t\\) ä¸‹é‡‡å–åŠ¨ä½œ \\(a_t\\) ç›¸å¯¹äºå¹³å‡æ°´å¹³çš„å¥½åï¼š\n\\[\nA_t = Q(s_t, a_t) - V(s_t)\n\\tag{10}\\]\nå…¶ä¸­ \\(Q(s_t, a_t)\\) æ˜¯åœ¨çŠ¶æ€ \\(s_t\\) ä¸‹é‡‡å–åŠ¨ä½œ \\(a_t\\) åçš„é¢„æœŸå›æŠ¥ï¼Œ\\(V(s_t)\\) æ˜¯çŠ¶æ€ \\(s_t\\) çš„å¹³å‡å›æŠ¥ã€‚ é€šè¿‡ä½¿ç”¨ä¼˜åŠ¿å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å…¬å¼æ”¹å†™ä¸ºï¼š \\[\n\\nabla_\\theta \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\big[r_\\phi(x,y)\\big] = \\mathbb{E}_{y\\sim \\pi_\\theta(\\cdot|x)}\\left[\\sum_{t=1}^T A_t \\, \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t)\\right]\n\\tag{11}\\]\nè¿™æ ·ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦åªå—åˆ°è¯¥æ—¶é—´æ­¥ä¼˜åŠ¿ \\(A_t\\) çš„å½±å“ï¼Œå‡å°‘äº†æ•´ä¸ªåºåˆ—å¥–åŠ±å¸¦æ¥çš„å™ªå£°ï¼Œä»è€Œé™ä½äº†æ–¹å·®ã€‚\n\n\n2.3.3 Off-Policy Updates\nREINFORCE çš„å¦ä¸€ä¸ªé—®é¢˜æ˜¯å®ƒæ˜¯on-policyçš„ï¼šæ¯æ¬¡æ›´æ–°éƒ½éœ€è¦ç”¨å½“å‰ç­–ç•¥é‡‡æ ·æ–°æ•°æ®ï¼Œä¸èƒ½å¤šæ¬¡åˆ©ç”¨æ—§æ•°æ®ï¼Œæ•ˆç‡ä½ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨ç¦»çº¿æ•°æ®é‡ç”¨ï¼ˆoff-policy updatesï¼‰çš„æ€æƒ³ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ä¿å­˜ä¹‹å‰é‡‡æ ·çš„æ•°æ®ï¼ˆprompts å’Œç”Ÿæˆçš„å›ç­”ï¼‰ï¼Œå¹¶åœ¨å¤šæ¬¡è¿­ä»£ä¸­é‡å¤ä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡Œæ›´æ–°ã€‚\nä½†æ˜¯ç›´æ¥ä½¿ç”¨æ—§æ•°æ®ä¼šå¼•å…¥åå·®ï¼Œå› ä¸ºè¿™äº›æ•°æ®æ˜¯æ ¹æ®æ—§ç­–ç•¥ \\(\\pi_{\\theta_{\\text{old}}}\\) é‡‡æ ·çš„ï¼Œè€Œæˆ‘ä»¬ç°åœ¨è¦æ›´æ–°çš„æ˜¯æ–°ç­–ç•¥ \\(\\pi_\\theta\\)ã€‚ ä¸ºäº†çº æ­£è¿™ç§åå·®ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‡è¦æ€§é‡‡æ ·ï¼ˆimportance samplingï¼‰ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªå›ç­”åœ¨æ–°æ—§ç­–ç•¥ä¸‹çš„æ¦‚ç‡æ¯”æ¥è°ƒæ•´æ¢¯åº¦ä¼°è®¡ï¼š\n\\[\n\\rho(y) = \\frac{\\pi_\\theta(y|x)}{\\pi_{\\theta_{\\text{old}}}(y|x)}\n\\tag{12}\\]\nç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ¢¯åº¦å…¬å¼æ”¹å†™ä¸ºï¼š \\[\n\\nabla_\\theta \\mathbb{E}_{y\\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)}\\big[r_\\phi(x,y)\\big] = \\mathbb{E}_{y\\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)}\\left[\\rho(y) \\sum_{t=1}^T A_t \\, \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t)\\right]\n\\tag{13}\\]\nè¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¤šæ¬¡åˆ©ç”¨æ—§æ•°æ®è¿›è¡Œæ›´æ–°ï¼Œæé«˜æ•°æ®æ•ˆç‡ã€‚\n\n\n2.3.4 Proximal Policy Optimization (PPO)\nç»“åˆä¸Šé¢çš„ä¸¤ä¸ªæ”¹è¿›ï¼Œæˆ‘ä»¬å°±å¼•å‡ºäº†PPOï¼ˆProximal Policy Optimizationï¼‰ç®—æ³•ã€‚PPO é€šè¿‡é™åˆ¶æ–°æ—§ç­–ç•¥çš„å˜åŒ–å¹…åº¦ï¼Œè¿›ä¸€æ­¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼ŒPPO ä½¿ç”¨ä¸€ä¸ªè£å‰ªç›®æ ‡ï¼ˆclipped objectiveï¼‰ï¼Œé˜²æ­¢ç­–ç•¥æ›´æ–°è¿‡å¤§ï¼š\n\\[\nL^{\\text{clip}}(\\theta) = \\mathbb{E}_{y\\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)}\\left[\\min\\left(\\rho(y) A, \\text{clip}(\\rho(y), 1-\\epsilon, 1+\\epsilon) A\\right)\\right]\n\\tag{14}\\] å…¶ä¸­ \\(\\epsilon\\) æ˜¯ä¸€ä¸ªå°çš„è¶…å‚æ•°ï¼Œæ§åˆ¶è£å‰ªèŒƒå›´(é€šå¸¸æ˜¯0.1åˆ°0.3)ã€‚ é€šè¿‡è¿™ä¸ªè£å‰ªç›®æ ‡ï¼ŒPPO ä¿è¯äº†æ–°ç­–ç•¥ä¸ä¼šåç¦»æ—§ç­–ç•¥å¤ªè¿œï¼Œä»è€Œé¿å…äº†è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚\næˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹PPOçš„æ•´ä½“è®­ç»ƒæµç¨‹ã€‚\n\nRolloutï¼ˆé‡‡æ ·å›ç­”ï¼‰:å¯¹ä¸€æ‰¹ prompts \\(x\\)ï¼Œç”¨å½“å‰ç­–ç•¥ \\(\\pi_{\\theta_{\\text{old}}}\\) ç”Ÿæˆå›ç­” \\(y\\)ã€‚åŒæ—¶ä¿å­˜æ¯ä¸ªç”Ÿæˆ token çš„ï¼š\n\nlogprobï¼š\\(\\log \\pi_{\\theta_{\\text{old}}}(a_t|s_t)\\)\n\nç®—å¥–åŠ±ï¼ˆrewardï¼‰:ç”¨å¥–åŠ±æ¨¡å‹ \\(r_{\\phi}(x,y)\\) ç»™æ•´æ®µå›ç­”ä¸€ä¸ªæ ‡é‡åˆ†æ•°ã€‚å†åŠ ä¸Š KL æƒ©ç½šï¼Œå¾—åˆ°æœ€ç»ˆå¥–åŠ±ä¿¡å·:\n\nKL æƒ©ç½šé€šå¸¸æœ‰ä¸¤ç§åšæ³•ï¼š\n\næ˜¾å¼ KL penaltyï¼šæŠŠ \\(-\\beta \\, \\mathrm{KL}(\\pi_\\theta(\\cdot|x) \\| \\pi_{\\text{ref}}(\\cdot|x))\\) åŠ è¿› reward\næˆ–åœ¨ loss é‡Œå•ç‹¬åŠ  KL é¡¹ï¼ˆç±»ä¼¼ InstructGPTï¼‰\n\nå¾ˆå¤šå®ç°æŠŠ token-level çš„ KL å˜æˆä¸€ä¸ª shaping reward:\n\\[\nr_t^{\\text{KL}} = -\\beta\\left(\\log \\pi_\\theta(a_t|s_t)-\\log \\pi_{\\text{ref}}(a_t|s_t)\\right)\n\\]\nç„¶åæŠŠæœ€ç»ˆå¥–åŠ±åˆ†é…åˆ°åºåˆ—æœ«ç«¯æˆ–åšä¸€äº›åˆ†æ‘Šã€‚\n\nä¼°è®¡ Value + Advantage\n\nè®­ç»ƒä¸€ä¸ª value head \\(V_\\psi(s_t)\\) é¢„æµ‹â€œä»å½“å‰å‰ç¼€å¾€åèƒ½æ‹¿åˆ°çš„å›æŠ¥â€ã€‚\nç”¨ï¼ˆGAEï¼‰ç­‰æ–¹æ³•å¾—åˆ° \\(A_t\\)\n\\[\n\\delta_t = r_t + \\gamma V(s_{t+1}) - V(s_t) = \\sum_{l\\ge 0}(\\gamma\\lambda)^l \\delta_{t+l}\n\\tag{15}\\]\n4ï¼šPPO updateï¼ˆå¤š epochã€å°æ­¥æ›´æ–°ï¼‰\nå¯¹åŒä¸€æ‰¹ rollout æ•°æ®ï¼Œåš K ä¸ª epoch çš„ minibatch æ›´æ–°ï¼š\n\npolicy lossï¼šâˆ’Lclip-L^{clip}âˆ’Lclip\nvalue lossï¼šâˆ¥VÏˆâˆ’Râˆ¥2|V_- R|^2âˆ¥VÏˆâ€‹âˆ’Râˆ¥2\nentropy bonusï¼šé¼“åŠ±æ¢ç´¢ (+Î±H)(+H)(+Î±H)\nï¼ˆå¯é€‰ï¼‰KL æ§åˆ¶é¡¹\n\næ€»ä½“ lossï¼ˆå¸¸è§å½¢å¼ï¼‰ï¼š\nL=Lpolicy+cvLvalueâˆ’ceH+cklKLL = L_{} + c_v L_{} - c_e H + c_{kl}L=Lpolicyâ€‹+cvâ€‹Lvalueâ€‹âˆ’ceâ€‹H+cklâ€‹KL\nPPO å·¥ç¨‹ä¸Šå¤æ‚ï¼Œä¸»è¦å› ä¸ºï¼š\n\non-policyï¼šæ¯è½®éƒ½è¦é‡‡æ ·æ–°æ•°æ®ï¼ˆrollouts æˆæœ¬é«˜ï¼‰\néœ€è¦ value functionï¼šè¦è®­ value headï¼Œå®¹æ˜“ä¸ç¨³\néœ€è¦ careful çš„ KL æ§åˆ¶ï¼šä¸ç„¶è¦ä¹ˆè·‘é£ã€è¦ä¹ˆå­¦ä¸åŠ¨\nsequence credit assignmentï¼šå¥–åŠ±å¸¸æ˜¯åºåˆ—çº§ï¼Œæ€ä¹ˆåˆ†åˆ° token ä¸Šå¾ˆæ•æ„Ÿ\né•¿åº¦åç½®/å¥–åŠ± hackingï¼šreward model å¯èƒ½åå¥½é•¿å›ç­” â†’ ç­–ç•¥å­¦ä¼šâ€œå†™é•¿éª—åˆ†â€\n\n# PPO RLHF: one training iteration (one \"outer step\")\n# Assumes:\n#   policy: trainable LM Ï€Î¸\n#   ref_policy: frozen LM Ï€ref (often SFT checkpoint)\n#   reward_model: rÏ†(x, y) -&gt; scalar reward per sequence\n#   value_head: VÏˆ(s_t) -&gt; scalar value per token/state (often a head on top of policy)\n#\n# Notation:\n#   B = batch size (number of prompts)\n#   T = max total tokens (prompt + generated)\n#   Tp = prompt length (varies per sample)\n#   Tr = response length (varies per sample)\n#\n# Key masks:\n#   response_mask[b,t] = 1 if token t is a generated response token (NOT prompt), else 0\n#   valid_mask[b,t] = 1 if token t exists (not padding), else 0\n#\n# IMPORTANT alignment:\n#   For causal LM, token-level logprob at position t corresponds to predicting token_ids[t]\n#   from prefix token_ids[:t]. Commonly computed with a 1-step shift.\n\ndef ppo_train_step(prompts):\n    # ------------------------------------------------------------\n    # 1) Rollout: sample responses from current policy (old policy snapshot)\n    # ------------------------------------------------------------\n    with no_grad():\n        policy.eval()\n\n        # Generate tokens (can be via vLLM or your sampler)\n        # returns:\n        #   token_ids: (B, T) padded\n        #   response_mask: (B, T) 1 for response tokens\n        #   valid_mask: (B, T) 1 for non-pad tokens\n        token_ids, response_mask, valid_mask = generate(policy, prompts)\n\n        # (Optional) store prompt lengths, response lengths, etc.\n        # prompt_mask = valid_mask & (~response_mask)\n\n    # Freeze a copy of current params as \"old\" logically.\n    # In practice, we keep old_logp computed here as constants.\n    # ------------------------------------------------------------\n    # 2) Compute old_logp and ref_logp for the generated response tokens\n    # ------------------------------------------------------------\n    with no_grad():\n        # old policy logprobs on the sampled trajectory\n        # logp_old: (B, T) where positions not scored can be 0\n        logp_old = token_logprobs(policy, token_ids)     # aligned to token_ids\n        logp_ref = token_logprobs(ref_policy, token_ids) # aligned to token_ids\n\n        # Only optimize on response tokens (typical RLHF)\n        # Keep only response positions; everything else masked out.\n        logp_old = logp_old * response_mask\n        logp_ref = logp_ref * response_mask\n\n    # ------------------------------------------------------------\n    # 3) Reward + KL shaping\n    # ------------------------------------------------------------\n    with no_grad():\n        # Sequence-level reward from reward model (scalar per sample)\n        # r_seq: (B,)\n        r_seq = reward_model(prompts, token_ids)  # evaluates (x, y)\n\n        # Token-level KL term (per token):\n        #   kl_t = logÏ€Î¸(a_t|s_t) - logÏ€ref(a_t|s_t)\n        # For shaping, we usually use old policy logp here because rollout came from old policy.\n        # kl_tok: (B, T)\n        kl_tok = (logp_old - logp_ref)  # already masked to response tokens\n\n        # KL penalty as \"negative reward\" per token\n        # r_kl_tok: (B, T)\n        r_kl_tok = -beta * kl_tok\n\n        # Combine rewards into a token-level reward signal.\n        # Common simple choice: put the sequence reward at the final response token,\n        # plus KL penalty at each response token.\n        # r_tok: (B, T)\n        r_tok = zeros_like(kl_tok)                # (B, T)\n        last_resp_index = last_index(response_mask)  # (B,) gives t_end per sample\n        r_tok[range(B), last_resp_index] += r_seq  # terminal reward\n        r_tok += r_kl_tok                          # dense KL shaping\n\n        # Ensure padding doesn't contribute\n        r_tok = r_tok * valid_mask\n\n    # ------------------------------------------------------------\n    # 4) GAE: compute advantages A_t and returns R_t for response tokens\n    # ------------------------------------------------------------\n    with no_grad():\n        # Value predictions for each token/state\n        # v: (B, T)\n        v = value_head(policy, token_ids)  # or separate critic network\n        v = v * valid_mask\n\n        # Compute next-state values v_next (shifted)\n        v_next = shift_left(v)            # v_next[:, t] = v[:, t+1], last = 0\n        v_next = v_next * valid_mask\n\n        # TD residuals Î´_t = r_t + Î³ v_{t+1} - v_t\n        # delta: (B, T)\n        delta = r_tok + gamma * v_next - v\n        delta = delta * response_mask     # only response tokens matter\n\n        # GAE recursion backwards over time for each sample\n        # adv: (B, T)\n        adv = zeros_like(delta)\n        gae = zeros(B)\n        for t in reversed(range(T)):\n            mask_t = response_mask[:, t]  # (B,)\n            # if mask_t=0, reset gae to 0 so prompt/pad doesn't leak\n            gae = delta[:, t] + gamma * lam * gae\n            gae = gae * mask_t\n            adv[:, t] = gae\n\n        # Returns (target for value): R_t = A_t + V_t\n        ret = adv + v\n        ret = ret * response_mask\n\n        # Normalize advantages over all response tokens in the batch (stabilizes PPO)\n        adv = masked_normalize(adv, response_mask)  # zero-mean, unit-std over masked positions\n\n    # ------------------------------------------------------------\n    # 5) PPO clipped loss (policy + value + entropy)\n    # ------------------------------------------------------------\n    policy.train()\n\n    # Recompute current policy logprobs for the same token_ids (now Î¸ is trainable)\n    # logp_new: (B, T)\n    logp_new = token_logprobs(policy, token_ids)\n    logp_new = logp_new * response_mask\n\n    # Probability ratio Ï_t = exp(logp_new - logp_old)\n    # ratio: (B, T)\n    ratio = exp(logp_new - logp_old) * response_mask\n\n    # Clipped surrogate objective\n    # unclipped = ratio * adv\n    # clipped   = clip(ratio, 1-eps, 1+eps) * adv\n    unclipped = ratio * adv\n    clipped = clip(ratio, 1 - eps, 1 + eps) * adv\n\n    # Policy loss: negative because we maximize objective\n    # Take masked mean over response tokens\n    policy_loss = -masked_mean(min(unclipped, clipped), response_mask)\n\n    # Value loss: regress to ret (returns)\n    v_pred = value_head(policy, token_ids) * response_mask\n    value_loss = masked_mean((v_pred - ret) ** 2, response_mask)\n\n    # Entropy bonus (encourage exploration) on response tokens\n    # entropy_tok: (B, T)\n    entropy_tok = token_entropy(policy, token_ids) * response_mask\n    entropy_bonus = masked_mean(entropy_tok, response_mask)\n\n    # (Optional) explicit KL term vs ref using current logp_new\n    # Helps keep policy close even if clip isn't enough\n    kl_new = (logp_new - logp_ref) * response_mask\n    kl_mean = masked_mean(kl_new, response_mask)\n\n    total_loss = policy_loss + c_v * value_loss - c_ent * entropy_bonus + c_kl * kl_mean\n\n    optimizer.zero_grad()\n    total_loss.backward()\n    clip_grad_norm_(policy.parameters(), max_grad_norm)\n    optimizer.step()\n\n    # Return logs\n    return {\n        \"loss_total\": total_loss,\n        \"loss_policy\": policy_loss,\n        \"loss_value\": value_loss,\n        \"entropy\": entropy_bonus,\n        \"kl\": kl_mean,\n        \"reward_seq_mean\": mean(r_seq),\n    }",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#dpo",
    "href": "posts/CS336/Lecture15/lec15.html#dpo",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.4 DPO",
    "text": "2.4 DPO\næ˜¾ç„¶ï¼ŒPPOçš„ç®—æ³•ï¼Œå­˜åœ¨çš„ä¸»è¦ä¸€ä¸ªç¼ºé™·å°±æ˜¯æ‰€éœ€çš„å†…å­˜è¿‡å¤šï¼š æˆ‘ä»¬éœ€è¦ä¿å­˜:\n\nPolicy: å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹\nReference Policy: å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹\nValue Modelï¼š å’ŒLMä¸€æ ·å¤§çš„æ¨¡å‹\nReward Modelï¼š å’ŒLMå·®ä¸å¤šå¤§çš„æ¨¡å‹\n\nå¹¶ä¸”ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿˜éœ€è¦ä¿å­˜å¤§é‡çš„ä¸­é—´æ¿€æ´»ï¼ˆactivationsï¼‰ç”¨äºåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ã€‚\nè¿™å¯¹äºåŠ¨è¾„å‡ ä¸ªBçš„LMæ¨¡å‹æ¥è¯´ï¼Œæ¶ˆè€—æ˜¯å·¨å¤§çš„ï¼Œå› æ­¤ï¼Œæå‡ºäº†DPOçš„ç®—æ³•ã€‚ DPOï¼ˆDirect Preference Optimizationï¼‰(Rafailov et al. 2024) å¯ä»¥æŠŠâ€œRLHF + PPOâ€é‚£å¥— é‡‡æ ·â†’è®­ç»ƒrewardâ†’RLæ›´æ–°ï¼Œç®€åŒ–æˆä¸€ä¸ªçº¯ç›‘ç£å¼çš„åå¥½å­¦ä¹ ï¼šç›´æ¥ç”¨ \\((x,y+,y^-)\\) æ›´æ–°ç­–ç•¥æ¨¡å‹ã€‚ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼š è®©æ¨¡å‹å¯¹ preferred å›ç­”çš„æ¦‚ç‡æ¯” rejected æ›´å¤§ï¼ŒåŒæ—¶ç”¨å‚è€ƒæ¨¡å‹ Ï€ref_{}Ï€refâ€‹ çº¦æŸåˆ«åå¤ªè¿œã€‚\n\n\n\n\n\n\nFigureÂ 8: å›¾ä¸­å±•ç¤ºäº† DPO å’Œ PPO çš„å¯¹æ¯”ï¼ŒDPO ç›´æ¥ç”¨åå¥½æ•°æ®ï¼ˆchosen vs rejectedï¼‰æ¥è®­ç»ƒç­–ç•¥ \\(\\pi_\\theta\\), å¯¹â€œäººç±»æ›´å–œæ¬¢çš„å›ç­”â€ç»™æ›´é«˜æ¦‚ç‡ï¼Œå¯¹â€œä¸å–œæ¬¢çš„å›ç­”â€ç»™æ›´ä½æ¦‚ç‡.\n\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å…·ä½“çœ‹çœ‹DPOç®—æ³•ï¼š å‡è®¾ policy ä¸æ˜¯ç¥ç»ç½‘ç»œï¼Œè€Œæ˜¯ä»»æ„åˆ†å¸ƒï¼ˆnonparametricï¼‰ã€‚ åœ¨è¿™ä¸ªå‡è®¾ä¸‹ï¼Œè¿™ä¸ªä¼˜åŒ–é—®é¢˜æœ‰è§£æè§£ï¼š\nÏ€r(yâˆ£x)=1Z(x)Â Ï€ref(yâˆ£x)Â expâ¡â€‰â£(1Î²r(x,y))r(y|x)=Â {}(y|x)Â !(r(x,y))Ï€râ€‹(yâˆ£x)=Z(x)1â€‹Â Ï€refâ€‹(yâˆ£x)Â exp(Î²1â€‹r(x,y))\nè¿™å…¶å®å°±æ˜¯ä¸€ä¸ª Boltzmann / energy-based reweightingï¼š\n\nå‚è€ƒåˆ†å¸ƒ \\(\\pi_{\\text{ref}}\\) æä¾›â€œå…ˆéªŒâ€\nreward è¶Šé«˜ï¼Œexpâ¡(r/Î²)(r/)exp(r/Î²) è¶ŠæŠŠæ¦‚ç‡å¾€ä¸Šæ¨\nZ(x)Z(x)Z(x) æ˜¯å½’ä¸€åŒ–å¸¸æ•°ï¼ˆpartition functionï¼‰",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°",
    "href": "posts/CS336/Lecture15/lec15.html#åè§£å¾—åˆ°-implied-rewardreward-log-ratioå·®ä¸€ä¸ªå¸¸æ•°",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.5 åè§£â€å¾—åˆ° implied rewardï¼šreward â‰ˆ log-ratioï¼ˆå·®ä¸€ä¸ªå¸¸æ•°ï¼‰",
    "text": "2.5 åè§£â€å¾—åˆ° implied rewardï¼šreward â‰ˆ log-ratioï¼ˆå·®ä¸€ä¸ªå¸¸æ•°ï¼‰\næŠŠä¸Šå¼å– log å¹¶æ•´ç†ï¼Œå¾—åˆ°å›¾é‡Œæœ€åä¸€è¡Œï¼š\nr(x,y)=Î²logâ¡Ï€r(yâˆ£x)Ï€ref(yâˆ£x)+Î²logâ¡Z(x)r(x,y)= + Z(x)r(x,y)=Î²logÏ€refâ€‹(yâˆ£x)Ï€râ€‹(yâˆ£x)â€‹+Î²logZ(x)\nå…³é”®ç‚¹ï¼š\n\nÎ²logâ¡Z(x)Z(x)Î²logZ(x) åªä¾èµ– xï¼Œä¸ä¾èµ– y â†’ åœ¨â€œæ¯”è¾ƒ y+y^+y+ vs yâˆ’y^-yâˆ’â€æ—¶ä¼šç›¸æ¶ˆ\næ‰€ä»¥åœ¨åå¥½å­¦ä¹ é‡Œï¼Œä½ å¯ä»¥æŠŠ reward çš„å·®å†™æˆï¼š\n\nr(x,y+)âˆ’r(x,yâˆ’)=Î²(logâ¡Ï€(y+âˆ£x)Ï€ref(y+âˆ£x)âˆ’logâ¡Ï€(yâˆ’âˆ£x)Ï€ref(yâˆ’âˆ£x))r(x,y+)-r(x,y-) =( - )r(x,y+)âˆ’r(x,yâˆ’)=Î²(logÏ€refâ€‹(y+âˆ£x)Ï€(y+âˆ£x)â€‹âˆ’logÏ€refâ€‹(yâˆ’âˆ£x)Ï€(yâˆ’âˆ£x)â€‹)\nè¿™ä¸€æ­¥å°±æ˜¯ DPO çš„æ ¸å¿ƒï¼šä¸æ˜¾å¼è®­ç»ƒ reward modelï¼Œè€Œæ˜¯ç”¨ policy çš„ logprobï¼ˆç›¸å¯¹ ref çš„å·®ï¼‰æ¥â€œéšå¼è¡¨ç¤º rewardâ€ã€‚\nr(x,y+)âˆ’r(x,yâˆ’)=Î²[logÏ€refâ€‹(y+âˆ£x)Ï€(y+âˆ£x)â€‹âˆ’logÏ€refâ€‹(yâˆ’âˆ£x)Ï€(yâˆ’âˆ£x)â€‹]\næŠŠä¸Šé¢å·®å€¼å†™å¾—æ›´ç´§å‡‘ä¸€ç‚¹ï¼š\nÎ”Î¸(x)=(logâ¡Ï€Î¸(y+âˆ£x)âˆ’logâ¡Ï€Î¸(yâˆ’âˆ£x))âˆ’(logâ¡Ï€ref(y+âˆ£x)âˆ’logâ¡Ï€ref(yâˆ’âˆ£x))(x) =((y+|x)-(y^-|x)) -({}(y+|x)-_{}(y^-|x))Î”Î¸â€‹(x)=(logÏ€Î¸â€‹(y+âˆ£x)âˆ’logÏ€Î¸â€‹(yâˆ’âˆ£x))âˆ’(logÏ€refâ€‹(y+âˆ£x)âˆ’logÏ€refâ€‹(yâˆ’âˆ£x))\näºæ˜¯\n\\[\nr(x,y^+) - r(x,y^-) = \\beta \\, \\Delta_\\theta(x)\n\\tag{16}\\]\nä»£å›åå¥½ä¼¼ç„¶ï¼š\nLDPO(Î¸)=âˆ’E(x,y+,yâˆ’)[logâ¡Ïƒ(Î²â€‰Î”Î¸(x))]{}() = -{(x,y+,y-)}LDPOâ€‹(Î¸)=âˆ’E(x,y+,yâˆ’)â€‹[logÏƒ(Î²Î”Î¸â€‹(x))]\nè¿™å°±æ˜¯ DPOã€‚\nç›´è§‰è§£é‡Šï¼š\n\nå¦‚æœä½ çš„æ–°ç­–ç•¥ Ï€Î¸â€‹ ç›¸æ¯” ref æ›´åå‘ chosenï¼ˆÎ”Î¸â€‹ å¤§ï¼‰ï¼Œloss å°\nå¦‚æœåè€Œæ›´åå‘ rejectedï¼ˆÎ”Î¸&lt;0_&lt;0Î”Î¸â€‹&lt;0ï¼‰ï¼Œloss å¤§ï¼Œä¼šè¢«æ¢¯åº¦æ¨å›å»\n\nåœ¨ LLM é‡Œ logâ¡Ï€Î¸(yâˆ£x)_(y|x)logÏ€Î¸â€‹(yâˆ£x) é€šå¸¸æ˜¯ response tokens çš„ logprob ä¹‹å’Œï¼š\nlogâ¡Ï€Î¸(yâˆ£x)=âˆ‘tâˆˆresponselogâ¡Ï€Î¸(ytâˆ£x,y&lt;t)(y|x)={t } (y_t x, y{&lt;t})logÏ€Î¸â€‹(yâˆ£x)=tâˆˆresponseâˆ‘â€‹logÏ€Î¸â€‹(ytâ€‹âˆ£x,y&lt;tâ€‹)\næ‰€ä»¥ DPO è®­ç»ƒä¸€æ¬¡ step å°±æ˜¯ï¼š\n\nå¯¹ batch ä¸­æ¯ä¸ªæ ·æœ¬ï¼Œåˆ†åˆ«ç®—ï¼š\n\nlogp_pos = sum_logp(policy, x, y_pos)\nlogp_neg = sum_logp(policy, x, y_neg)\nlogp_ref_pos = sum_logp(ref, x, y_pos)ï¼ˆno gradï¼‰\nlogp_ref_neg = sum_logp(ref, x, y_neg)ï¼ˆno gradï¼‰\n\ndelta = (logp_pos - logp_neg) - (logp_ref_pos - logp_ref_neg)\nloss = -log_sigmoid(beta * delta).mean()\n\nimport torch\nimport torch.nn.functional as F\n\ndef dpo_train_step(\n    policy,                 # trainable LM Ï€Î¸\n    ref_policy,             # frozen LM Ï€ref (e.g., SFT checkpoint)\n    optimizer,\n    batch_pos_input_ids,    # (B, T) prompt+chosen padded\n    batch_pos_attn_mask,    # (B, T) bool/int\n    batch_pos_resp_mask,    # (B, T) bool: 1 only on response tokens\n    batch_neg_input_ids,    # (B, T) prompt+rejected padded\n    batch_neg_attn_mask,    # (B, T)\n    batch_neg_resp_mask,    # (B, T)\n    beta: float = 0.1,\n    max_grad_norm: float | None = 1.0,\n):\n    \"\"\"\n    DPO core update step (ONLY training part).\n    Assumes inputs are already tokenized + padded and include response masks.\n\n    DPO:\n      delta = (logÏ€Î¸(y+|x)-logÏ€Î¸(y-|x)) - (logÏ€ref(y+|x)-logÏ€ref(y-|x))\n      loss  = -E[ log Ïƒ(beta * delta) ]\n    \"\"\"\n\n    def seq_logprob(model, input_ids, attn_mask, resp_mask):\n        # logits: (B, T, V)\n        logits = model(input_ids=input_ids, attention_mask=attn_mask).logits\n\n        # causal shift: logits[:, t] predicts input_ids[:, t+1]\n        logits = logits[:, :-1, :]          # (B, T-1, V)\n        labels = input_ids[:, 1:]           # (B, T-1)\n\n        logp = F.log_softmax(logits, dim=-1)\n        tok_logp = logp.gather(-1, labels.unsqueeze(-1)).squeeze(-1)  # (B, T-1)\n\n        # align masks with shift\n        mask = (resp_mask[:, 1:] & attn_mask[:, 1:]).to(tok_logp.dtype)  # (B, T-1)\n\n        return (tok_logp * mask).sum(dim=-1)  # (B,)\n\n    # ----- policy logprobs -----\n    logp_pos = seq_logprob(policy, batch_pos_input_ids, batch_pos_attn_mask, batch_pos_resp_mask)\n    logp_neg = seq_logprob(policy, batch_neg_input_ids, batch_neg_attn_mask, batch_neg_resp_mask)\n\n    # ----- reference logprobs (no grad) -----\n    with torch.no_grad():\n        logp_ref_pos = seq_logprob(ref_policy, batch_pos_input_ids, batch_pos_attn_mask, batch_pos_resp_mask)\n        logp_ref_neg = seq_logprob(ref_policy, batch_neg_input_ids, batch_neg_attn_mask, batch_neg_resp_mask)\n\n    # ----- DPO loss -----\n    delta = (logp_pos - logp_neg) - (logp_ref_pos - logp_ref_neg)  # (B,)\n    loss = -F.logsigmoid(beta * delta).mean()\n\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n\n    if max_grad_norm is not None:\n        torch.nn.utils.clip_grad_norm_(policy.parameters(), max_grad_norm)\n\n    optimizer.step()\n\n    return {\n        \"loss\": float(loss.detach().cpu()),\n        \"delta_mean\": float(delta.detach().mean().cpu()),\n        \"pref_acc\": float((delta.detach() &gt; 0).float().mean().cpu()),\n    }",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#others",
    "href": "posts/CS336/Lecture15/lec15.html#others",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.6 Others",
    "text": "2.6 Others\nåœ¨DPOæå‡ºä¹‹åï¼Œåç»­ä¹Ÿæœ‰è®¸å¤šç®—æ³•å¯¹å…¶æå‡ºäº†æ”¹è¿›ï¼Œåœ¨è¿™é‡Œä»‹ç»ä¸¤ç§ ### SimPO DPO çš„â€œå‚è€ƒæ¨¡å‹é¡¹ï¼ˆrefï¼‰â€å¯ä»¥ä¸è¦ â†’ å¾—åˆ° SimPO (no ref) DPO/åå¥½å­¦ä¹ å¾ˆå®¹æ˜“å‡ºç°ï¼šé•¿å›ç­”æ›´å®¹æ˜“èµ¢\nå› ä¸º sequence logprob æ˜¯ token logprob çš„â€œå’Œâ€ï¼Œé•¿åº¦ä¸åŒä¼šå¯¼è‡´æ¯”è¾ƒä¸å…¬å¹³ã€‚\næ‰€ä»¥æŠŠ\nlogâ¡Ï€Î¸(yâˆ£x)=âˆ‘tâˆˆylogâ¡pÎ¸(ytâˆ£â‹…)(y|x)={ty}p_(y_t|)logÏ€Î¸â€‹(yâˆ£x)=tâˆˆyâˆ‘â€‹logpÎ¸â€‹(ytâ€‹âˆ£â‹…)\næ”¹æˆå¹³å‡æ¯ token çš„ logprobï¼š\n1âˆ£yâˆ£logâ¡Ï€Î¸(yâˆ£x)_(y|x)âˆ£yâˆ£1â€‹logÏ€Î¸â€‹(yâˆ£x)\nå›¾é‡Œè“æ¡†å°±æ˜¯è¿™ä¸ªï¼šÎ²/âˆ£ywâˆ£â‹…logâ¡Ï€Î¸(ywâˆ£x)/|y_w|(y_w|x)Î²/âˆ£ywâ€‹âˆ£â‹…logÏ€Î¸â€‹(ywâ€‹âˆ£x) å’Œ Î²/âˆ£ylâˆ£â‹…logâ¡Ï€Î¸(ylâˆ£x)/|y_l|(y_l|x)Î²/âˆ£ylâ€‹âˆ£â‹…logÏ€Î¸â€‹(ylâ€‹âˆ£x)ã€‚\nimPO çš„ logit é‡Œå‡äº†ä¸€ä¸ª Î³ï¼š\nÎ”SimPO=Î²âˆ£ywâˆ£logâ¡Ï€Î¸(ywâˆ£x)âˆ’Î²âˆ£ylâˆ£logâ¡Ï€Î¸(ylâˆ£x)âˆ’Î³{} = (y_w|x) - _(y_l|x) -â€‹=âˆ£ywâ€‹âˆ£Î²â€‹logÏ€Î¸â€‹(ywâ€‹âˆ£x)âˆ’âˆ£ylâ€‹âˆ£Î²â€‹logÏ€Î¸â€‹(ylâ€‹âˆ£x)âˆ’Î³\nç›´è§‰ï¼šä½ ä¸æ˜¯åªè¦ ywy_wywâ€‹ æ¯” yly_lylâ€‹ å¥½ä¸€ç‚¹ç‚¹å°±è¡Œï¼Œè€Œæ˜¯å¸Œæœ›å®ƒè‡³å°‘å¥½è¿‡ä¸€ä¸ªå¹…åº¦ï¼ˆmarginï¼‰ã€‚\nÎ³è¶Šå¤§ï¼Œè®­ç»ƒè¶Šâ€œä¸¥æ ¼â€ã€‚\nimport torch\nimport torch.nn.functional as F\n\ndef simpo_step(\n    policy, optimizer,\n    pos_input_ids, pos_attn, pos_rmask,\n    neg_input_ids, neg_attn, neg_rmask,\n    beta: float = 0.1,\n    gamma: float = 0.0,\n):\n    def seq_logprob_and_len(model, input_ids, attn_mask, resp_mask):\n        logits = model(input_ids=input_ids, attention_mask=attn_mask).logits\n        logits = logits[:, :-1, :]\n        labels = input_ids[:, 1:]\n\n        logp = F.log_softmax(logits, dim=-1)\n        tok_logp = logp.gather(-1, labels.unsqueeze(-1)).squeeze(-1)\n\n        mask = (resp_mask[:, 1:] & attn_mask[:, 1:]).to(tok_logp.dtype)\n        seq_lp = (tok_logp * mask).sum(dim=-1)            # (B,)\n        resp_len = mask.sum(dim=-1).clamp_min(1.0)        # (B,)\n        return seq_lp, resp_len\n\n    lp_pos, len_pos = seq_logprob_and_len(policy, pos_input_ids, pos_attn, pos_rmask)\n    lp_neg, len_neg = seq_logprob_and_len(policy, neg_input_ids, neg_attn, neg_rmask)\n\n    # SimPO logit (no ref) + length normalization + margin gamma\n    delta = (beta * (lp_pos / len_pos) - beta * (lp_neg / len_neg) - gamma)\n\n    loss = -F.logsigmoid(delta).mean()\n\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\n    return loss\n\n2.6.1 Length Normalized DPO\nimport torch\nimport torch.nn.functional as F\n\ndef dpo_len_norm_step(\n    policy, ref_policy, optimizer,\n    pos_input_ids, pos_attn, pos_rmask,\n    neg_input_ids, neg_attn, neg_rmask,\n    beta: float = 0.1,\n):\n    def seq_logprob_and_len(model, input_ids, attn_mask, resp_mask):\n        logits = model(input_ids=input_ids, attention_mask=attn_mask).logits\n        logits = logits[:, :-1, :]\n        labels = input_ids[:, 1:]\n\n        logp = F.log_softmax(logits, dim=-1)\n        tok_logp = logp.gather(-1, labels.unsqueeze(-1)).squeeze(-1)\n\n        mask = (resp_mask[:, 1:] & attn_mask[:, 1:]).to(tok_logp.dtype)\n        seq_lp = (tok_logp * mask).sum(dim=-1)            # (B,)\n        resp_len = mask.sum(dim=-1).clamp_min(1.0)        # (B,)\n        return seq_lp, resp_len\n\n    # policy\n    lp_pos, len_pos = seq_logprob_and_len(policy, pos_input_ids, pos_attn, pos_rmask)\n    lp_neg, len_neg = seq_logprob_and_len(policy, neg_input_ids, neg_attn, neg_rmask)\n\n    # ref (no grad)\n    with torch.no_grad():\n        lp_ref_pos, len_ref_pos = seq_logprob_and_len(ref_policy, pos_input_ids, pos_attn, pos_rmask)\n        lp_ref_neg, len_ref_neg = seq_logprob_and_len(ref_policy, neg_input_ids, neg_attn, neg_rmask)\n\n    # length-normalized log-ratio\n    pos_term = (lp_pos / len_pos) - (lp_ref_pos / len_ref_pos)\n    neg_term = (lp_neg / len_neg) - (lp_ref_neg / len_ref_neg)\n    delta = beta * (pos_term - neg_term)\n\n    loss = -F.logsigmoid(delta).mean()\n\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\n    return loss",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#ppo-vs.-dpo",
    "href": "posts/CS336/Lecture15/lec15.html#ppo-vs.-dpo",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "2.7 PPO vs.Â DPO",
    "text": "2.7 PPO vs.Â DPO\n\nPPO çš„ä¼˜åŠ¿æ¥è‡ªâ€œæ›´çµæ´»çš„ä¼˜åŒ–ä¿¡å·â€\nPPO æ˜¾å¼åš on-policy rollout + advantageï¼ˆGAEï¼‰+ clip + KL çº¦æŸï¼Œèƒ½æ›´ç›´æ¥åœ°æŠŠâ€œå¥–åŠ±æ¨¡å‹/åå¥½ä¿¡å·â€è½¬æˆæ¢¯åº¦æ›´æ–°ï¼›\nDPO/SimPO æ›´åƒâ€œæŠŠ RL å˜æˆç›‘ç£å­¦ä¹ â€ï¼Œç®€å•ã€ç¨³å®šã€ä¾¿å®œï¼Œä½†è¡¨è¾¾èƒ½åŠ›/å¯æ§æ€§æœ‰æ—¶ä¸å¦‚ PPOï¼ˆå°¤å…¶å½“ä½ éœ€è¦æ›´ç»†çš„æ§åˆ¶æˆ– reward å¾ˆå¤æ‚æ—¶ï¼‰ã€‚\nå³ä¾§ TÃ¼lu 3 çš„è¡¨ï¼šåŒä¸€ä¸ª benchmark ä¸Šï¼Œç»“è®ºä¹Ÿä¼šè·Ÿç€è¶…å‚å’Œå˜ä½“è·‘\nä½ ä¼šçœ‹åˆ° SimPOã€DPOã€PPOã€DPO-normï¼ˆé•¿åº¦å½’ä¸€åŒ–ï¼‰åˆ†æ•°å·®å¼‚ä¸å¤§ï¼Œè€Œä¸”å¯¹ Î²ã€Î³ã€å­¦ä¹ ç‡ã€batch sizeã€epoch å¾ˆæ•æ„Ÿã€‚\nâ‡’ è¿™é¡µæƒ³è®©ä½ è®°ä½ï¼šåœ¨ RLHF é‡Œï¼Œå·¥ç¨‹ç»†èŠ‚ï¼ˆæ•°æ® + è¶…å‚ + è®­ç»ƒrecipeï¼‰å¾€å¾€æ¯”â€œç®—æ³•åå­—â€æ›´å†³å®šç»“æœã€‚\n\nDPO/SimPO æŠŠ RLHF ç®€åŒ–æˆâ€œå¥½å®ç°çš„ç›‘ç£å­¦ä¹ â€ï¼Œä½† PPO ä»å¯èƒ½åœ¨æŸäº›æ•°æ®/å¥–åŠ±/è¶…å‚ç»„åˆä¸‹æ›´å¼ºï¼›å› æ­¤ RLHF çš„å®éªŒç»“è®ºå¿…é¡»è¿åŒ setup ä¸€èµ·çœ‹ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#over-optimization",
    "href": "posts/CS336/Lecture15/lec15.html#over-optimization",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "3.1 Over-optimization",
    "text": "3.1 Over-optimization\n\næ¨ªè½´æ˜¯ KL distanceï¼ˆRL åçš„ç­–ç•¥è·Ÿåˆå§‹/å‚è€ƒç­–ç•¥å·®å¤šè¿œï¼‰ã€‚\nçºµè½´æ˜¯ RM scoreï¼ˆreward model ç»™çš„åˆ†ï¼‰ã€‚\næ›²çº¿å…ˆå‡åâ€œå˜åâ€ï¼šä¸€å¼€å§‹å¾€ RM å–œæ¬¢çš„æ–¹å‘èµ°ï¼Œåˆ†æ•°ä¸Šå‡ï¼›ä½†å½“ KL è¶Šæ¥è¶Šå¤§æ—¶ï¼Œæ¨¡å‹ä¼šå­¦åˆ° å¥–åŠ±æ¨¡å‹çš„æ¼æ´/æ·å¾„ï¼Œå¯¼è‡´ï¼š\n\nRM åˆ†æ•°å¯èƒ½è¿˜å¾ˆé«˜ï¼Œä½†çœŸå®è´¨é‡ï¼ˆäººç±»åå¥½/äº‹å®æ€§/æœ‰ç”¨æ€§ï¼‰å¼€å§‹ä¸‹é™ï¼›\nè¿™å°±æ˜¯å…¸å‹çš„ â€œå¯¹ä»£ç†ç›®æ ‡ï¼ˆproxy rewardï¼‰è¿‡æ‹Ÿåˆâ€ã€‚\n\n\nä¸€å¥è¯ï¼šä½ ä¼˜åŒ–çš„æ˜¯ RMï¼Œä¸æ˜¯äººç±»çœŸå®åå¥½ï¼›èµ°å¤ªè¿œä¼šå¼€å§‹â€œåˆ·åˆ†â€ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture15/lec15.html#model-collapse",
    "href": "posts/CS336/Lecture15/lec15.html#model-collapse",
    "title": "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)",
    "section": "3.2 Model Collapse",
    "text": "3.2 Model Collapse\nRLHF ä¼šæŠŠæ¨¡å‹ä»â€œæŒ‰æ¦‚ç‡æ‹Ÿåˆæ•°æ®â€çš„è¯­è¨€æ¨¡å‹ï¼Œæ¨æˆâ€œä¸ºæ‹¿é«˜å¥–åŠ±è€Œè¾“å‡ºâ€çš„ç­–ç•¥æ¨¡å‹ï¼Œä»è€Œé™ä½è¾“å‡ºåˆ†å¸ƒçš„ç†µã€å‹ç¼©å¤šæ ·æ€§ï¼Œå¹¶è®©æ¨¡å‹çš„ç½®ä¿¡åº¦ä¸å†å¯ä¿¡ï¼ˆcalibration å˜å·®ï¼‰ã€‚\nThis is the updated content.",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 15: LLM Alignment SFT & RLHF(PPO, DPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture01/lec01.html#character-level-tokenization",
    "href": "posts/CS336/Lecture01/lec01.html#character-level-tokenization",
    "title": "Lecture 01: Introduction & Tokenization",
    "section": "2.1 Character-level Tokenization",
    "text": "2.1 Character-level Tokenization\nCharacter-level Tokenizationæ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå•ä¸ªå­—ç¬¦ã€‚ ä¾‹å¦‚ï¼Œå¥å­ â€œHello, world!â€ ä¼šè¢«æ‹†åˆ†ä¸ºä»¥ä¸‹tokensï¼š\n['H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd', '!']\néœ€è¦çŸ¥é“çš„å°±æ˜¯ï¼Œæ¯ä¸ªCharacterå°±æ˜¯ä¸€ä¸ªtokenï¼Œåˆ©ç”¨Pythonï¼Œçš„ord()å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è½¬æ¢ä¸ºå¯¹åº”çš„æ•´æ•°IDï¼š\ntext = \"Hello, world!\"\ntokens = [char for char in text]\ntoken_ids = [ord(char) for char in tokens]\nprint(tokens)\nprint(token_ids)\nè¿™ç§æ–¹å¼å¾ˆç®€å•ï¼Œä¹Ÿå¾ˆç›´è§‚ï¼Œä½†æ˜¯å®ƒæœ‰ä¸€äº›æ˜æ˜¾çš„ç¼ºç‚¹ï¼š\n\nVocabulary Sizeï¼šå¯¹äºæ‰€æœ‰å¯èƒ½çš„å­—ç¬¦ï¼ˆåŒ…æ‹¬å­—æ¯ã€æ•°å­—ã€æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦ï¼‰ï¼ŒVocabulary Sizeä¼šéå¸¸å¤§ï¼Œå¯¼è‡´æ¨¡å‹å‚æ•°é‡å¢åŠ ã€‚ï¼ˆå¤§çº¦æœ‰150K ä¸ªä¸åŒçš„å­—ç¬¦ï¼‰\n150Kä¸ªå­—ç¬¦ä¸­ï¼Œæœ‰å¾ˆå¤šå­—ç¬¦æ˜¯éå¸¸å°‘è§çš„ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥å­¦ä¹ åˆ°è¿™äº›å­—ç¬¦çš„è¡¨ç¤ºã€‚\nè¯­ä¹‰ä¿¡æ¯ç¼ºå¤±ï¼šå•ä¸ªå­—ç¬¦æ— æ³•æ•æ‰åˆ°è¯è¯­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥ç†è§£ä¸Šä¸‹æ–‡ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 01: Introduction & BPE"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture01/lec01.html#word-level-tokenization",
    "href": "posts/CS336/Lecture01/lec01.html#word-level-tokenization",
    "title": "Lecture 01: Introduction & Tokenization",
    "section": "2.2 Word-level Tokenization",
    "text": "2.2 Word-level Tokenization\nä¸Character-level Tokenizationä¸åŒï¼ŒWord-level Tokenizationæ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå•è¯ã€‚ ä¾‹å¦‚ï¼Œå¥å­ â€œHello, world!â€ ä¼šè¢«æ‹†åˆ†ä¸ºä»¥ä¸‹tokensï¼š\n['Hello,', 'world!']\næ¯ä¸ªå•è¯å°±æ˜¯ä¸€ä¸ªtokenï¼ŒåŒæ ·åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªç®€å•çš„Pythonä»£ç å°†å•è¯è½¬æ¢ä¸ºå¯¹åº”çš„æ•´æ•°IDï¼š\nimport regex\n\ntext= \"Hello, world!\"\ntokens = text.split()  # ç®€å•çš„ç©ºæ ¼æ‹†åˆ†\nvocab = {word: idx for idx, word in enumerate(set(tokens))}\ntoken_ids = [vocab[word] for word in tokens]\nprint(tokens)\nprint(token_ids)\né™¤äº†ç®€å•çš„æ ¹æ®ç©ºæ ¼æ‹†åˆ†å•è¯çš„æ–¹æ³•ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æœ‰ç¨å¾®å¤æ‚ä¸€ç‚¹çš„æ–¹æ³•ï¼Œæ¯”å¦‚ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥å¤„ç†æ ‡ç‚¹ç¬¦å·ç­‰ã€‚ä¸¾ä¸ªä¾‹å­ï¼ŒGPT-2çš„tokenizerå°±æ˜¯ä½¿ç”¨äº†ä¸€ç§åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„æ–¹æ³•æ¥è¿›è¡ŒWord-level Tokenizationã€‚\nGPT2_TOKENIZER_REGEX = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\nå½“ç„¶ï¼Œè¿™ç§æ–¹æ³•ä¹Ÿæœ‰æ¯”è¾ƒæ˜æ˜¾çš„ç¼ºç‚¹ï¼š\n\nVocabulary Size ä¾ç„¶å¾ˆå¤§ï¼šå¯¹äºæ‰€æœ‰å¯èƒ½çš„å•è¯ï¼ŒVocabulary Sizeä¼šéå¸¸å¤§ï¼Œå¯¼è‡´æ¨¡å‹å‚æ•°é‡å¢åŠ ã€‚\næœªç™»å½•è¯é—®é¢˜ï¼ˆOut-of-Vocabulary, OOVï¼‰ï¼šå¯¹äºè®­ç»ƒé›†ä¸­æœªå‡ºç°çš„å•è¯ï¼Œæ¨¡å‹æ— æ³•å¤„ç†ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ å°½ç®¡æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›æ–¹æ³•ï¼ˆå¦‚ä½¿ç”¨ç‰¹æ®Šçš„&lt;UNK&gt; tokenï¼‰æ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†ä»ç„¶æ— æ³•å®Œå…¨è§£å†³ã€‚\nVocabulary Size çš„å¤§å°ä¸æ˜¯å›ºå®šçš„ï¼Œéšç€è®­ç»ƒæ•°æ®çš„å¢åŠ ï¼ŒVocabulary Sizeä¼šä¸æ–­å¢åŠ ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥æ‰©å±•ã€‚\nå¾ˆå¤šå•è¯æ˜¯éå¸¸å°‘è§çš„ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥å­¦ä¹ åˆ°è¿™äº›å•è¯çš„è¡¨ç¤ºã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 01: Introduction & BPE"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture01/lec01.html#byte-based-tokenization",
    "href": "posts/CS336/Lecture01/lec01.html#byte-based-tokenization",
    "title": "Lecture 01: Introduction & Tokenization",
    "section": "2.3 Byte-Based Tokenization",
    "text": "2.3 Byte-Based Tokenization\nåœ¨å­¦ä¹ Byte Pair Encoding (BPE)ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆä»‹ç»ä¸€ä¸‹Byte-Based Tokenizationã€‚ Byte-Based Tokenizationæ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå­—èŠ‚å•å…ƒï¼ˆbyte-level tokensï¼‰ã€‚ ä¾‹å¦‚ï¼Œå¥å­ â€œHello, world!â€ ä¼šè¢«æ‹†åˆ†ä¸ºä»¥ä¸‹tokensï¼š\n['H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd', '!']\næ¯ä¸ªå­—èŠ‚å°±æ˜¯ä¸€ä¸ªtokenï¼ŒåŒæ ·åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªç®€å•çš„Pythonä»£ç å°†å­—èŠ‚è½¬æ¢ä¸ºå¯¹åº”çš„æ•´æ•°IDï¼š\ntext = \"Hello, world!\"\ntokens = [char.encode('utf-8') for char in text]\ntoken_ids = [byte[0] for byte in tokens]\nprint(tokens)\nprint(token_ids)\nè¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ï¼š\n\nVocabulary Size å›ºå®šä¸”è¾ƒå°ï¼šç”±äºå­—èŠ‚çš„èŒƒå›´æ˜¯0-255ï¼ŒVocabulary Sizeå›ºå®šä¸º256ï¼Œæ¨¡å‹å‚æ•°é‡è¾ƒå°ã€‚\næ— OOVé—®é¢˜ï¼šç”±äºæ‰€æœ‰æ–‡æœ¬éƒ½å¯ä»¥è¡¨ç¤ºä¸ºå­—èŠ‚åºåˆ—ï¼Œä¸å­˜åœ¨OOVçš„é—®é¢˜ã€‚\né€‚ç”¨äºå¤šè¯­è¨€æ–‡æœ¬ï¼šå­—èŠ‚çº§åˆ«çš„è¡¨ç¤ºå¯ä»¥å¤„ç†å„ç§è¯­è¨€çš„æ–‡æœ¬ã€‚\nç®€å•é«˜æ•ˆï¼šå­—èŠ‚çº§åˆ«çš„è¡¨ç¤ºç®€å•ä¸”é«˜æ•ˆï¼Œé€‚åˆå¤§è§„æ¨¡æ–‡æœ¬å¤„ç†ã€‚\n\nä¸è¿‡ï¼Œè¿™ç§æ–¹æ³•æœ‰ä¸ªæ˜æ˜¾çš„ç¼ºç‚¹å°±æ˜¯Compression Ratioè¾ƒä½ã€‚ ç”±äºå­—èŠ‚çº§åˆ«çš„è¡¨ç¤ºè¿‡äºç»†ç²’åº¦ï¼Œå¯¼è‡´æ–‡æœ¬é•¿åº¦å¢åŠ ï¼Œå½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚å› ä¸ºTransformeræ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦ä¸è¾“å…¥é•¿åº¦çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œè¾“å…¥é•¿åº¦å¢åŠ ä¼šæ˜¾è‘—å¢åŠ è®¡ç®—èµ„æºçš„æ¶ˆè€—ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 01: Introduction & BPE"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture01/lec01.html#byte-pair-encoding-bpe",
    "href": "posts/CS336/Lecture01/lec01.html#byte-pair-encoding-bpe",
    "title": "Lecture 01: Introduction & Tokenization",
    "section": "2.4 Byte Pair Encoding (BPE)",
    "text": "2.4 Byte Pair Encoding (BPE)\nä¸ºäº†å…‹æœCharacter-levelå’ŒWord-level Tokenizationçš„ç¼ºç‚¹ï¼ŒåŒæ—¶æé«˜Byte-Based Tokenizationçš„Compression Ratioï¼Œæˆ‘ä»¬å¼•å…¥äº†Byte Pair Encoding (BPE)ç®—æ³• (Sennrich, Haddow, and Birch 2016) ã€‚ BPEæ˜¯ä¸€ç§åŸºäºé¢‘ç‡çš„å­è¯å•å…ƒï¼ˆsubword unitï¼‰åˆ†è¯æ–¹æ³•ã€‚ å®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡è¿­ä»£åœ°åˆå¹¶æœ€é¢‘ç¹å‡ºç°çš„å­—ç¬¦å¯¹ï¼ˆbyte pairsï¼‰æ¥æ„å»ºä¸€ä¸ªæ›´ç´§å‡‘çš„è¯æ±‡è¡¨ã€‚\n\n\n\nBPEç®—æ³•çš„æ­¥éª¤å¦‚ä¸‹ï¼š\n\nåˆå§‹åŒ–Vocabularyï¼šå°†æ–‡æœ¬ä¸­çš„æ‰€æœ‰å”¯ä¸€å­—ç¬¦ä½œä¸ºåˆå§‹çš„è¯æ±‡è¡¨ï¼ˆvocabularyï¼‰ã€‚\nç»Ÿè®¡é¢‘ç‡ get_statsï¼šè®¡ç®—æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—ç¬¦å¯¹çš„å‡ºç°é¢‘ç‡ã€‚\nåˆå¹¶å­—ç¬¦å¯¹å¹¶ä¸”æ›´æ–°Vocabularyï¼šé€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—ç¬¦å¯¹ï¼Œå°†å…¶åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„tokenï¼Œå¹¶æ›´æ–°æ–‡æœ¬ä¸­çš„æ‰€æœ‰å‡ºç°è¯¥å­—ç¬¦å¯¹çš„åœ°æ–¹ï¼Œå¹¶ä¸”å°†æ–°tokenæ·»åŠ åˆ°è¯æ±‡è¡¨ä¸­ã€‚\né‡å¤æ­¥éª¤2-4ï¼šé‡å¤ä¸Šè¿°æ­¥éª¤ï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„è¯æ±‡è¡¨å¤§å°æˆ–æ»¡è¶³å…¶ä»–åœæ­¢æ¡ä»¶ã€‚\n\n\n\n\n\n\n\n\n\nFigureÂ 4: BPEç®—æ³•çš„ç¤ºæ„å›¾ï¼Œå±•ç¤ºäº†å­—ç¬¦å¯¹çš„åˆå¹¶è¿‡ç¨‹ã€‚\n\n\n\n\n\n\nä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„BPEç®—æ³•çš„Pythonå®ç°ç¤ºä¾‹ï¼š\ndef train_bpe(string: str, num_merges: int):\n    indices = list(map(int, string.encode(\"utf-8\"))) \n    merges: dict[tuple[int, int], int] = {}  \n    vocab: dict[int, bytes] = {x: bytes([x]) for x in range(256)}  \n\n    for i in range(num_merges):\n        counts = defaultdict(int)\n        for index1, index2 in zip(indices, indices[1:]): \n            counts[(index1, index2)] += 1\n        \n        pair = max(counts, key=counts.get)  # @inspect pair\n        index1, index2 = pair\n\n        new_index = 256 + i\n        merges[pair] = new_index\n        vocab[new_index] = vocab[index1] + vocab[index2]\n        indices = merge(indices, pair, new_index)\n\n    return merges, vocab\nä»¥ä¸Šæ˜¯æœ€ç®€å•çš„BPEç®—æ³•çš„å®ç°ï¼Œæ˜¾ç„¶æœ‰å¾ˆå¤šçš„ä¸è¶³ï¼Œæˆ‘ä»¬åœ¨Assignment 01çš„ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œä¼šä¼˜åŒ–è¿™ä¸ªå®ç°ï¼š\n\nä¼˜åŒ– merge å‡½æ•°çš„æ•ˆç‡ã€‚\nåˆ©ç”¨pre-tokenizationæ¥åŠ é€ŸBPEçš„è®­ç»ƒè¿‡ç¨‹ã€‚\n\nç­‰\nå¯¹äºé‚£äº›æƒ³æ·±å…¥ç†è§£BPEç®—æ³•çš„åŒå­¦ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹èµ„æºï¼š \nå…³äºBPEç®—æ³•ï¼Œè¿˜æœ‰å¾ˆå¤šå¯ä»¥ä¼˜åŒ–çš„åœ°æ–¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å¯»æ‰¾æœ€é¢‘ç¹å­—ç¬¦å¯¹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„ï¼ˆå¦‚ä¼˜å…ˆé˜Ÿåˆ—ï¼‰æ¥åŠ é€ŸæŸ¥æ‰¾è¿‡ç¨‹ã€‚\nåœ¨åˆå¹¶å­—ç¬¦å¹¶ä¸”æ›´æ–°æ–‡æœ¬æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ›´é«˜æ•ˆçš„å­—ç¬¦ä¸²å¤„ç†æ–¹æ³•æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ã€‚è¿™äº›ä¼˜åŒ–å¯ä»¥æ˜¾è‘—æé«˜BPEç®—æ³•çš„è®­ç»ƒé€Ÿåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®\n\nè¿™äº›æ–¹æ³•æˆ‘ä»¬å°†åœ¨ Assignment 01ä¸­è¿›è¡Œæ›´åŠ è¯¦ç»†çš„ä»‹ç»ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 01: Introduction & BPE"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture13&14/lec13.html",
    "href": "posts/CS336/Lecture13&14/lec13.html",
    "title": "Lecture 13 & 14: Data",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 13&14: Data Collection & Processing"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html",
    "href": "posts/CS336/Ass01/ass01.html",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "",
    "text": "Assignment 01 è¦æ±‚æˆ‘ä»¬ä»0å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ¶µç›–ï¼š\né€šè¿‡è¿™ä¸€ä¸ªAssignmentï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£åˆ°åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„LMæ¨¡å‹çš„å…¨éƒ¨æµç¨‹ï¼Œåç»­çš„è¯¾ç¨‹ä»¥åŠAssignmentéƒ½ä¼šåŸºäºè¿™ä¸ªæµç¨‹è¿›è¡Œæ‰©å±•å’Œä¼˜åŒ–ã€‚\nåœ¨å®Œæˆè¿™ä¸ªAssignmentä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å­¦ä¹ Lecture 01,02,03 çš„å†…å®¹ï¼Œä¸»è¦åŒ…æ‹¬ï¼š\nå½“ç„¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¯¹Transformeræœ‰ä¸€å®šçš„äº†è§£ï¼Œå¦‚æœä½ ä¸äº†è§£Transformerï¼Œæˆ‘ä¸ªäººæ¨èé˜…è¯»è¿™ç¯‡ 100-PaperwithCodeç³»åˆ—çš„ç¬¬ä¸€ç¯‡ï¼š01 Attention is all you Need.\nå¯¹äºä¸ç†Ÿæ‚‰LMçš„åŒå­¦ä»¬æ¥è¯´ï¼Œè¿™ä¸ªAssignmentå¯èƒ½æœ‰ä¸€å®šçš„éš¾åº¦ï¼Œæ¯•ç«Ÿå…‰ä»»åŠ¡çš„æè¿°å°±50å¤šé¡µã€‚ä¸è¿‡ï¼Œåªè¦æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œè¿˜æ˜¯å¯ä»¥å®Œæˆè¿™ä¸ªAssignmentçš„ã€‚åŠ æ²¹ï¼Œåˆ«æ”¾å¼ƒğŸ˜ƒğŸ˜ƒï¼ï¼\né¢„è®¡éœ€è¦çš„æ—¶é—´10hours.",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#download-start-code-and-dataset",
    "href": "posts/CS336/Ass01/ass01.html#download-start-code-and-dataset",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "1.1 Download Start Code and Dataset",
    "text": "1.1 Download Start Code and Dataset\né¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½Start Codeï¼š\ngit clone https://github.com/stanford-cs336/assignment1-basics\nä¸‹è½½å®Œä»£ç ä¹‹åï¼Œæˆ‘ä»¬å†ä¸‹è½½æ•°æ®é›†ï¼š\nmkdir -p data\ncd data\n\nwget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\nwget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n\nwget https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\ngunzip owt_train.txt.gz\nwget https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\ngunzip owt_valid.txt.gz\n\ncd ..\nä¸Šé¢è¿™ä¸ªä»£ç ä¼šä¸‹è½½ä¸¤ä¸ªæ•°æ®é›†ï¼š\n\nTinyStoriesï¼šä¸€ä¸ªéå¸¸å°çš„æ•…äº‹æ•°æ®é›†(1GB) ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•ä»£ç ã€‚\nOpenWebText (OWT) Sampleï¼šä¸€ä¸ªè¾ƒå¤§çš„æ–‡æœ¬æ•°æ®é›†(4.7GB)ï¼Œé€‚åˆè¿›è¡Œæ›´æ·±å…¥çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚\n\né™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®‰è£… uv:\n\n\nuvæ˜¯ä»€ä¹ˆï¼Ÿ\n\n\nuvæ˜¯ä¸€ä¸ªè½»é‡çº§çš„Pythoné¡¹ç›®ç®¡ç†å’Œè¿è¡Œå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´æ–¹ä¾¿åœ°è¿è¡Œå’Œæµ‹è¯•ä»£ç ã€‚åœ¨è¿™ä¸ªAssignmentä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨uvæ¥è¿è¡Œæµ‹è¯•å’Œç®¡ç†é¡¹ç›®ä¾èµ–ã€‚\n\n\npip install uv\nå®‰è£…å®Œuvä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ä¸€ä¸‹çš„ä»£ç æ¥è¿è¡Œæµ‹è¯•ä»£ç ï¼š\nuv run pytest \nuv run python train.py",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#sec-bpe-recap",
    "href": "posts/CS336/Ass01/ass01.html#sec-bpe-recap",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.1 BPE Algorithm Recap",
    "text": "2.1 BPE Algorithm Recap\nå›é¡¾ä¸€ä¸‹BPEç®—æ³•çš„åŸºæœ¬æ­¥éª¤ï¼š\n\nInitialization: å°†è¾“å…¥æ–‡æœ¬è§†ä¸ºå­—èŠ‚åºåˆ—ï¼Œæ¯ä¸ªå­—èŠ‚ä½œä¸ºä¸€ä¸ªtokenã€‚åˆå§‹åŒ–è¯æ±‡è¡¨åŒ…å«æ‰€æœ‰å¯èƒ½çš„å­—èŠ‚ï¼ˆ0-255ï¼‰ã€‚ä»¥åŠSpecial Tokensï¼Œæ¯”å¦‚ &lt;|endoftext|&gt;\nCount Pairs: ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚\nMerge Pairs: å°†é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹å…¶åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„tokenï¼Œæ›´æ–°æ–‡æœ¬å’Œè¯æ±‡è¡¨:\n\nGet the most frequent pair: æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹ã€‚\nAdd the new pair: å°†è¿™ä¸ªæ–°çš„å­—èŠ‚å¯¹åŠ å…¥è¯æ±‡è¡¨ã€‚\nUpdate the word counter: æ›´æ–°æ–‡æœ¬ä¸­æ‰€æœ‰å‡ºç°è¯¥å­—èŠ‚å¯¹çš„åœ°æ–¹ã€‚\nUpdate Pairs Counts: é‡æ–°ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚\n\nRepeat: é‡å¤æ­¥éª¤2,3ï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„åˆå¹¶æ¬¡æ•°\n\nBPE çš„ä¼ªä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š\n\n\n\\begin{algorithm} \\caption{BPE Training} \\begin{algorithmic} \\Require Corpus text $\\mathcal{D}$ \\Require Number of merges $M$ \\Require Special tokens $\\mathcal{S}$ (e.g., \\texttt{&lt;|endoftext|&gt;}) \\Ensure Vocabulary $V$, merge rules list $\\Pi$ \\State Convert each document $x \\in \\mathcal{D}$ into bytes $b(x)$ \\State Initialize tokenized corpus as sequences of single-byte tokens \\State $V \\gets \\{0,1,\\dots,255\\} \\cup \\mathcal{S}$ \\State $\\Pi \\gets [\\,]$ \\For{$t = 1$ \\textbf{to} $M$} \\State $C \\gets$ empty map from pair $\\to$ count \\For{\\textbf{each} token sequence $s$ in the corpus} \\Comment{Count adjacent byte-token pairs} \\For{\\textbf{each} index $i$ from $1$ to $|s|-1$} \\State $C[(s_i, s_{i+1})] \\gets C[(s_i, s_{i+1})] + 1$ \\EndFor \\EndFor \\State Choose $(a,b)$ with the largest count in $C$ \\Comment{Select the most frequent pair} \\State Define a new token $new$ as the merge of $(a,b)$ \\State $V \\gets V \\cup \\{new\\}$ \\Comment{Create a new merged token and record the merge rule} \\State Append $(a,b)\\rightarrow new$ to $\\Pi$ \\For{\\textbf{each} token sequence $s$ in the corpus} \\Comment{Replace all occurrences of $(a,b)$ in the corpus} \\State Replace adjacent $(a,b)$ with $new$ left-to-right (non-overlapping) \\EndFor \\EndFor \\State \\Return $V, \\Pi$ \\end{algorithmic} \\end{algorithm}\n\n\né¦–å…ˆï¼Œæˆ‘ä»¬æ¥å®ç°ä¸€ä¸‹æœ€ç®€å•çš„BPEç®—æ³•:",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#sec-bpe-v0",
    "href": "posts/CS336/Ass01/ass01.html#sec-bpe-v0",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.2 BPE Version 0",
    "text": "2.2 BPE Version 0\nå‡å¦‚æˆ‘ä»¬è¦Tokenizedä»¥ä¸‹çš„æ–‡æœ¬ï¼š\nstring = \"\"\" \nlow low low low low &lt;|endoftext|&gt;\nlower lower widest widest widest &lt;|endoftext|&gt;\nnewest newest newest newest newest newest \n\"\"\"\nStep1 è¦åšçš„å°±æ˜¯åˆå§‹åŒ–æˆ‘ä»¬çš„è¯æ±‡è¡¨ï¼š\ndef init_vocab(special_tokens: list[str] | None = None) -&gt; dict[int, bytes]:\n    vocab: dict[int, bytes] = {x: bytes([x]) for x in range(256)}  # idx -&gt; byte representation\n    current_index = 256\n\n    if special_tokens:\n        for token in special_tokens:\n            token_bytes = token.encode(\"utf-8\")\n            vocab[current_index] = token_bytes\n            current_index += 1\n\n    return vocab\nåˆå§‹åŒ–æ—¶ï¼Œæˆ‘ä»¬ä¼šå…ˆä¸ºæ‰€æœ‰ byte å€¼ 0â€“255 å»ºç«‹åŸºç¡€è¯è¡¨ï¼ˆæ–‡æœ¬å…ˆç”¨ UTF-8 ç¼–ç æˆå­—èŠ‚åºåˆ—æ¥å¤„ç†ï¼‰ï¼Œå¹¶é¢å¤–åŠ å…¥ special tokensï¼›åœ¨ç¼–ç è¿‡ç¨‹ä¸­è¿™äº› special tokens ä¼šè¢« ä¼˜å…ˆåŒ¹é…å¹¶ä½œä¸ºæ•´ä½“ä¿ç•™ï¼Œä¸å‚ä¸æ™®é€šçš„åˆ‡åˆ†ä¸ BPE åˆå¹¶ã€‚\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥å®ç°Step2: ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚\ndef pair_counts(word_counter: dict[tuple[int, ...], int]) -&gt; dict[tuple[int, int], int]:\n    pairs: dict[tuple[int, int], int] = {}\n\n    for word, count in word_counter.items():\n        for a, b in zip(word, word[1:]):\n            pairs[(a, b)] = pairs.get((a, b), 0) + count\n\n    return pairs\næˆ‘ä»¬å…ˆç»Ÿè®¡æ¯ä¸ªè¯ï¼ˆtoken åºåˆ—ï¼‰å‡ºç°çš„æ¬¡æ•° countï¼Œå†åœ¨éå†è¯¥è¯çš„ç›¸é‚» token å¯¹æ—¶ï¼ŒæŠŠæ¯ä¸ª pair çš„å‡ºç°æ¬¡æ•°ç´¯åŠ  countï¼Œä»è€Œå¾—åˆ°å…¨è¯­æ–™çš„ pair é¢‘æ¬¡ã€‚\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç° Step3.1: æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—èŠ‚å¯¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éµå¾ªçš„è§„åˆ™æ˜¯ï¼š\n\né¢‘ç‡æœ€é«˜çš„pair\nè‹¥å¤šä¸ª pair é¢‘ç‡ç›¸åŒï¼Œæˆ‘ä»¬æŒ‰ pair çš„å­—å…¸åºï¼ˆå…ˆæ¯”å·¦ tokenï¼Œå†æ¯”å³ tokenï¼‰é€‰æ‹©æ›´å¤§çš„é‚£ä¸ªã€‚\n\ndef get_most_frequent_pair(\n    pair_counter: dict[tuple[int, int], int],\n) -&gt; tuple[int, int]:\n    max_freq = max(pair_counter.values())\n    candidates = [pair for pair, freq in pair_counter.items() if freq == max_freq]\n    res = max(candidates)\n\n    return res\nå®ƒ(res)æ˜¯æœ¬è½®è¦ merge çš„ pairï¼ˆå°†å®ƒæ›¿æ¢ä¸ºä¸€ä¸ªæ–° tokenï¼‰\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç°Step3.2: å°†è¿™ä¸ªæ–°çš„å­—èŠ‚å¯¹åŠ å…¥è¯æ±‡è¡¨ï¼š\ndef add_pair_to_vocab(\n    vocab: dict[int, bytes],\n    pair: tuple[int, int],\n) -&gt; int:\n    index1, index2 = pair\n    vocab[len(vocab)] = vocab[index1] + vocab[index2]\n    return len(vocab) - 1\nå°†è¿™ä¸ªæ–°çš„pairåŠ å…¥è¯æ±‡è¡¨åï¼Œæˆ‘ä»¬éœ€è¦å®ç° Step3.3 å’Œ Step3.4: æ›´æ–°æ–‡æœ¬ä¸­æ‰€æœ‰å‡ºç°è¯¥å­—èŠ‚å¯¹çš„åœ°æ–¹ï¼Œä»¥åŠé‡æ–°ç»Ÿè®¡æ–‡æœ¬ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦éå†æ‰€æœ‰çš„wordï¼Œæ¥çœ‹æ˜¯ä¸æ˜¯æœ‰è¿™ä¸ªpairå‡ºç°ï¼Œè‹¥å‡ºç°äº†ï¼Œå°±å°†å…¶åˆå¹¶æˆä¸€ä¸ªæ–°çš„tokenã€‚ åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é‡æ–°ç»Ÿè®¡æ‰€æœ‰çš„pairçš„é¢‘ç‡ã€‚\ndef merge_pair_ids(\n    word_counter: dict[tuple[bytes] | tuple[int], int],\n    pair: tuple[int, int],\n    new_id: int,\n) -&gt; tuple[dict[tuple[int], int], dict[tuple[int, int], int]]:\n    new_word_counter: defaultdict[tuple[int], int] = defaultdict(int)\n    updated_pair_counts: defaultdict[tuple[int, int], int] = defaultdict(int)\n\n    for token, freq in word_counter.items():\n        new_token = []\n        i = 0\n        L = len(token)\n\n        while i &lt; L:\n            if i + 1 &lt; L and (token[i], token[i + 1]) == pair:\n                new_token.append(new_id)\n                i += 2\n            else:\n                new_token.append(token[i])\n                i += 1\n\n        new_word_counter[tuple(new_token)] += freq\n\n        for index1, index2 in zip(new_token[:-1], new_token[1:]):\n            updated_pair_counts[(index1, index2)] += freq\n\n    return dict(new_word_counter), dict(updated_pair_counts)\nè‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†ä¸€è½®ï¼Œé‡å¤ä»¥ä¸Šçš„æ­¥éª¤ï¼Œç›´åˆ°æˆ‘ä»¬è¾¾åˆ°ç›®æ ‡çš„è½®æ•°ï¼Œæ”¾åœ¨ä¸€èµ·ä»£ç å°±æ˜¯ï¼š\ndef train_bpe(\n    string: str = string,\n    vocab_size: int = 263,\n    special_tokens: list[str] = special_tokens,\n    save_path: str | None = None,\n):\n    vocab = init_vocab(special_tokens)\n    num_merges = vocab_size - len(vocab)\n\n    merges: dict[tuple[int, int], int] = {}\n\n    word_counter = pre_tokenize(string, special_tokens, including_special=False)\n\n    pairs_freqs = pair_counts(word_counter)\n\n    for _ in range(num_merges):\n        most_common_pair = get_most_frequent_pair(pairs_freqs)\n        new_index = add_pair_to_vocab(vocab, most_common_pair)\n        merges[most_common_pair] = new_index\n        word_counter, pairs_freqs = merge_pair_ids(word_counter, most_common_pair, new_index)\n    \n    return vocab, merges\nè¿™ä¹Ÿå°±æ˜¯æˆ‘ä»¬æœ€ç®€å•çš„BPEçš„ç®—æ³•ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºBPE Version0, å½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªä»£ç ï¼Œå¹¶ä¸”æŠŠvocab_sizeè®¾ç½®ä¸º263æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹mergesçš„é¡ºåºã€‚\ntrain_bpe(\n    string=string,\n    vocab_size=256 + 1 + 6, # 256 bytes + 1 special token + 6 merges\n    special_tokens=special_tokens,\n)\nMost common pair: (b's', b't') -&gt; 9\nMost common pair: (b'e', b'st') -&gt; 9\nMost common pair: (b'o', b'w') -&gt; 7\nMost common pair: (b'l', b'ow') -&gt; 7\nMost common pair: (b'w', b'est') -&gt; 6\nMost common pair: (b'n', b'e') -&gt; 6\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡è¿™ä¸ªç‰ˆæœ¬çš„BPEç®—æ³•æ˜¯æ­£ç¡®çš„ï¼Œä½†æ˜¯å®ƒçš„æ•ˆç‡éå¸¸ä½ï¼Œå› ä¸ºæ¯æ¬¡æˆ‘ä»¬éƒ½éœ€è¦éå†æ‰€æœ‰çš„pairï¼Œæ¥æ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„pairï¼Œè¿™æ ·çš„æ—¶é—´å¤æ‚åº¦æ˜¯ \\(\\mathcal{O}(N \\cdot P)\\)ï¼Œå…¶ä¸­Næ˜¯åˆå¹¶çš„æ¬¡æ•°ï¼ŒPæ˜¯pairçš„æ•°é‡ã€‚å¦‚æœåªæ˜¯ç”¨è¿™ç§ç®€å•çš„ç®—æ³•ï¼Œæˆ‘ä»¬æ˜¯é€šä¸è¿‡æµ‹è¯•çš„ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦ä¼˜åŒ–è¿™ä¸ªç®—æ³•ï¼Œä¸è¿‡åœ¨ä¼˜åŒ–ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€ä¸‹Pre-Processingçš„æ­¥éª¤ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#pre-processing",
    "href": "posts/CS336/Ass01/ass01.html#pre-processing",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.3 Pre-Processing",
    "text": "2.3 Pre-Processing\nåœ¨å®ç°BPEç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼ˆPre-Processingï¼‰ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ï¼š\n\næ ¹æ®Special Tokensæ¥åˆ†æ–‡æœ¬\næ ¹æ®æ­£åˆ™è¡¨è¾¾æ¥åˆ†æ–‡æœ¬\n\næˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹æ ¹æ®Special Tokensæ¥åˆ†æ–‡æœ¬çš„æƒ…å†µ\n\n2.3.1 Special Tokens Based Splitting\nåœ¨è¿™ä¸€èŠ‚(SectionÂ 2.1) ï¼Œæˆ‘ä»¬å·²ç»äº†è§£è¿‡äº†ï¼Œåœ¨åˆå§‹åŒ–vocab æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦åˆå§‹åŒ–special tokensï¼Œå…¶ä¸­ä¸€ä¸ªå¸¸è§çš„special tokenså°±æ˜¯ &lt;|endoftext|&gt;. è¿™ä¸ªtokenæ„å‘³ç€ä¸€æ®µæ–‡æœ¬çš„ç»“æŸã€‚ç»™å‡ºä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æƒ…å°±æ˜¯æŠŠè¿™ä¸ªæ–‡æœ¬åˆ†æˆè®¸å¤šæ®µï¼Œä»£ç çš„å®ç°å¦‚ä¸‹ï¼š\ndef split_by_special_tokens(text: str, special_tokens: list[str], include_special: bool = False) -&gt; list[str]:\n    if not special_tokens:\n        return [text]\n\n    special_tokens_sorted = sorted(special_tokens, key=len, reverse=True)\n    pattern = \"|\".join(re.escape(t) for t in special_tokens_sorted)\n\n    if include_special:\n        special_chunks = re.split(f\"({pattern})\", text)\n    else:\n        # Split without capturing the special tokens\n        special_chunks = re.split(pattern, text)\n\n    return special_chunks\nè‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº† Special Token-aware çš„åˆ‡åˆ†ï¼š\n\né€šè¿‡æŠŠæ‰€æœ‰ special tokens å…ˆæŒ‰é•¿åº¦é™åºæ’åºï¼Œå¹¶ç”¨æ­£åˆ™æ„é€ åŒ¹é… patternï¼Œæˆ‘ä»¬å¯ä»¥æŠŠåŸå§‹é•¿æ–‡æœ¬æ‹†æˆä¸€ç³»åˆ— æ™®é€šæ–‡æœ¬ç‰‡æ®µï¼ˆä»¥åŠå¯é€‰çš„ special token ç‰‡æ®µï¼‰ã€‚\nå½“ include_special=True æ—¶ï¼Œre.split(f\"({pattern})\", text) ä¼šæŠŠåŒ¹é…åˆ°çš„ special token ä¹Ÿä¿ç•™ä¸‹æ¥ï¼Œä»è€Œåœ¨åç»­ç¼–ç æ—¶æˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬å½“ä½œâ€œåŸå­ tokenâ€ç›´æ¥æ˜ å°„åˆ°å¯¹åº”çš„ idï¼›\nå½“ include_special=False æ—¶ï¼Œspecial token ä¼šä½œä¸ºåˆ†éš”ç¬¦è¢«ä¸¢å¼ƒï¼Œä»…è¿”å›æ™®é€šæ–‡æœ¬ç‰‡æ®µï¼Œé€‚åˆè®­ç»ƒé˜¶æ®µä¸æƒ³è®© special tokens å‚ä¸ pair ç»Ÿè®¡ / merges çš„åœºæ™¯ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯¹æ¯ä¸ªæ™®é€šç‰‡æ®µæ‰§è¡ŒRegular-basedçš„åˆ‡åˆ†äº†ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šæŠŠæ–‡æœ¬åˆ‡æˆæ›´å°çš„ç‰‡æ®µï¼Œæ¯”å¦‚è¯ã€å­è¯ç‰‡æ®µã€æ ‡ç‚¹åˆ†éš”ç‰‡æ®µç­‰ã€‚\n\n\n2.3.2 Regex-based Splitting (Pre-Tokenization)\nPre-Tokenizationï¼ˆé¢„åˆ†è¯ï¼‰ å°±æ˜¯åœ¨çœŸæ­£è®­ç»ƒ BPE åˆå¹¶è§„åˆ™ä¹‹å‰ï¼Œå…ˆå¯¹æ•´ä»½è¯­æ–™åšä¸€æ¬¡ç²—ç²’åº¦çš„åˆ‡åˆ†ï¼ŒæŠŠæ–‡æœ¬åˆ‡æˆä¸€æ®µæ®µâ€œæ›´å¤§çš„ç‰‡æ®µâ€ï¼ˆpre-tokenï¼‰ï¼Œç„¶ååœ¨è¿™äº›ç‰‡æ®µå†…éƒ¨å»ç»Ÿè®¡ç›¸é‚»å­—èŠ‚ï¼ˆbyte pairï¼‰çš„å‡ºç°é¢‘ç‡ã€‚ã€ é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆéœ€è¦Pre-Tokenizationå‘¢ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š\n\nåŸå› ä¸€ï¼šé¿å…â€œæ¯åˆå¹¶ä¸€æ¬¡å°±å…¨è¯­æ–™æ‰«ä¸€éâ€  æˆ‘ä»¬çŸ¥é“ï¼Œmergeä¸€æ¬¡ï¼Œæˆ‘ä»¬å°±è¦é‡æ–°æ‰«æä¸€æ¬¡ï¼Œä»¥è·å¾—æ›´æ–°åçš„æ–°è¯­æ–™ï¼Œå¦‚æœè¿™ä¸ªè¯­æ–™ç‰¹åˆ«å¤§ï¼Œæˆ–è€…æˆ‘ä»¬mergeçš„æ¬¡æ•°ç‰¹åˆ«å¤šï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´æˆ‘ä»¬ç®—æ³•ç‰¹åˆ«çš„æ…¢ã€‚  è¿™ä¸ªæ—¶å€™æˆ‘ä»¬å°±éœ€è¦Pre-Tokenizationï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š\n\nå…ˆæŠŠè¯­æ–™åˆ‡æˆå¾ˆå¤šâ€œpre-tokenâ€ï¼ˆæ¯”å¦‚è¯ã€å­è¯ç‰‡æ®µã€æ ‡ç‚¹åˆ†éš”ç‰‡æ®µç­‰ï¼‰\n\nç»Ÿè®¡æ—¶ä¸å†å¯¹æ•´ä¸ªè¯­æ–™é€å­—ç¬¦/é€å­—èŠ‚æ‰«æï¼Œè€Œæ˜¯åˆ©ç”¨é‡å¤å‡ºç°çš„ pre-token çš„æ¬¡æ•°æ¥åŠ é€Ÿã€‚\n\nä¸¾ä¸ªä¾‹å­ï¼š\n\nâ€˜textâ€™ è¿™ä¸ª pre-token å‡ºç°äº† 10 æ¬¡\nå½“æˆ‘ä»¬è¦ç»Ÿè®¡ â€˜tâ€™ å’Œ â€˜eâ€™ ç›¸é‚»å‡ºç°æ¬¡æ•°\nåªè¦åœ¨ â€˜textâ€™ é‡Œçœ‹åˆ°ä¸€æ¬¡ â€œtâ€+â€œeâ€ ç›¸é‚»ï¼Œå°±å¯ä»¥ä¸€æ¬¡æ€§æŠŠè®¡æ•°åŠ  10 è€Œä¸æ˜¯æŠŠè¯­æ–™é‡Œæ¯ä¸ª â€˜textâ€™ éƒ½é€å­—èŠ‚å†çœ‹ä¸€éã€‚\n\n\nåŸå› äºŒï¼šé¿å…å­¦å‡ºâ€œåªæœ‰æ ‡ç‚¹ä¸åŒâ€çš„é‡å¤ token  æ¯”å¦‚æœ‰ä¸¤ä¸ªè¯ dog! å’Œ dog. å¦‚æœæˆ‘ä»¬é‚£ä¸Pre-tokenizationï¼Œé‚£ä¹ˆè¿™ä¸ªå¾ˆå®¹æ˜“è¢«å½“æˆä¸åŒçš„åºåˆ—ï¼Œä»è€Œå¯¹äºè¿™ä¸ªç±»ä¼¼çš„è¯ï¼Œæœ‰ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„IDsã€‚è€Œ Pre-tokenization é€šå¸¸ä¼šç”¨ä¸€äº›è§„åˆ™ï¼ˆæ¯”å¦‚æŒ‰ç©ºç™½ã€æ ‡ç‚¹è¾¹ç•Œç­‰ï¼‰å…ˆåˆ‡å¼€ï¼Œè®© BPE æ›´å¤šåœ¨â€œè¯å†…éƒ¨â€å­¦ä¹ åˆå¹¶è§„å¾‹ï¼Œè€Œä¸æ˜¯æŠŠè¯å’Œå„ç§æ ‡ç‚¹ç²˜åœ¨ä¸€èµ·ä¹±åˆå¹¶ã€‚\nåœ¨è¿™ä¸ª Assignment é‡Œï¼Œæˆ‘ä»¬é‡‡ç”¨ regex-based pre-tokenizerï¼ˆGPT-2 ä½¿ç”¨çš„é‚£æ¡æ­£åˆ™ï¼‰ï¼Œå…ˆæŠŠåŸå§‹æ–‡æœ¬åˆ‡æˆä¸€ä¸²â€œé¢„åˆ†è¯ç‰‡æ®µâ€ï¼ˆpre-tokensï¼‰ï¼Œå†å¯¹æ¯ä¸ªç‰‡æ®µåš byte-level BPEã€‚\nPAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n\n\nRegex è¯¦è§£\n\n\næˆ‘ä»¬æ¥è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼š å®ƒçš„åˆ†å—è§„åˆ™ï¼ˆä»å·¦åˆ°å³åŒ¹é…ï¼‰ï¼š\n\nè‹±è¯­ç¼©å†™/è¯å°¾ï¼šâ€™s, â€™t, â€™re, â€™ve, â€™ll, â€™m, â€™d ç­‰ï¼ˆç¬¬ä¸€æ®µï¼‰\nå­—æ¯ä¸²ï¼š ?+ â€”â€” ä¸€æ®µå­—æ¯ï¼ˆå…è®¸å‰é¢å¸¦ä¸€ä¸ªå¯é€‰ç©ºæ ¼ï¼ŒæŠŠç©ºæ ¼â€œç²˜â€åˆ°åé¢çš„ token ä¸Šï¼‰\næ•°å­—ä¸²ï¼š ?+ â€”â€” ä¸€æ®µæ•°å­—ï¼ˆåŒæ ·å…è®¸å‰ç½®ç©ºæ ¼ï¼‰\næ ‡ç‚¹/å…¶å®ƒç¬¦å·ä¸²ï¼š ?[^\\s\\p{L}\\p{N}]+ â€”â€” éç©ºç™½ã€éå­—æ¯ã€éæ•°å­—çš„ä¸€ä¸²ç¬¦å·ï¼ˆä¹Ÿå…è®¸å‰ç½®ç©ºæ ¼ï¼‰\nç©ºç™½ï¼š+(?!)ï¼ˆæœ«å°¾ç©ºç™½ï¼‰æˆ– +ï¼ˆä¸€èˆ¬ç©ºç™½ï¼‰\n\n+ï¼šåŒ¹é…ä¸€æ®µç©ºç™½ï¼ˆç©ºæ ¼ã€æ¢è¡Œã€tab ç­‰ï¼‰ã€‚\n(?!)ï¼šè´Ÿå‘å‰ç»ï¼Œç¡®ä¿è¿™æ®µç©ºç™½åé¢æ²¡æœ‰éç©ºç™½å­—ç¬¦ï¼ˆå³è¿™æ˜¯è¡Œå°¾æˆ–æ–‡æœ¬æœ«å°¾çš„ç©ºç™½ï¼‰ã€‚\n\n\nè¿™ç§è®¾è®¡çš„å…³é”®ç‚¹æ˜¯ï¼šå¾ˆå¤š token ä¼šæŠŠå‰å¯¼ç©ºæ ¼åŒ…å«è¿›å»ï¼ˆä¾‹å¦‚ â€ helloâ€ ä¼šè¢«å½“æˆä¸€ä¸ªæ•´ä½“çš„ pre-tokenï¼‰ï¼Œè¿™èƒ½æ›´å¥½åœ°åŒ¹é…è‹±è¯­é‡Œâ€œè¯è¾¹ç•Œ=ç©ºæ ¼â€çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œä¹Ÿæ›´æ¥è¿‘ GPT-2 çš„å®é™… tokenizer è¡Œä¸ºã€‚å¦‚æœä¸ç†è§£ï¼Œä¹Ÿæ²¡æœ‰å…³ç³»ï¼Œç›´æ¥ç”¨è¿™ä¸ªæ­£åˆ™å°±è¡Œã€‚\n\n\næœ‰äº†è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç° Pre-Tokenization äº†ï¼Œä»£ç å¦‚ä¸‹ï¼š\ndef pre_tokenize(string: str, special_tokens: list[str], including_special: bool = False) -&gt; Counter:\n    word_counter = Counter()\n\n    chunks = split_by_special_tokens(string, special_tokens, include_special=including_special)\n\n    for chunk in chunks:\n        if including_special and chunk in special_tokens:\n            word_counter[tuple(string_to_bytes(chunk))] += 1\n        else:\n            for match in re.finditer(PAT, chunk):\n                word = match.group(0)\n                word_encoded = tuple(string_to_bytes(word, return_int=True))\n                word_counter[word_encoded] += 1\n\n    return word_counter\né€šè¿‡ pre-tokenizationï¼Œæˆ‘ä»¬æŠŠåŸå§‹æ–‡æœ¬è½¬æ¢æˆè®¸å¤šâ€œé¢„åˆ†è¯ç‰‡æ®µâ€çš„ byte/id åºåˆ—ï¼Œå¹¶ç”¨ Counter ç»Ÿè®¡æ¯ç§ç‰‡æ®µå‡ºç°çš„æ¬¡æ•°ã€‚åç»­åœ¨ç»Ÿè®¡ pair é¢‘ç‡æ—¶ï¼Œæ¯ä¸ªç‰‡æ®µçš„ç›¸é‚» token å¯¹å‡ºç°æ¬¡æ•°éƒ½ä¼šæŒ‰å…¶ count åŠ æƒç´¯åŠ ï¼Œä»è€Œå¾—åˆ°å…¨è¯­æ–™çš„ pair é¢‘æ¬¡ã€‚\n\n\n2.3.3 Multi-Processing\nä»¥ä¸Šè¿™ä¸¤æ­¥ï¼ˆSpecial Token-aware Splitting å’Œ Regex-based Pre-Tokenizationï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ª Multi-Processing\n\n\nMulti-Processing Review\n\n\nPython çš„MultiProcessing æ˜¯ä¸€ä¸ª- å¤šè¿›ç¨‹ æ›´é€‚åˆ CPU å¯†é›†å‹ä»»åŠ¡ï¼ˆæ¯”å¦‚é¢„åˆ†è¯ã€ç»Ÿè®¡ï¼‰ã€‚ï¼Œæˆ‘ä»¬åªéœ€è¦äº†è§£ä»¥ä¸‹çš„å†…å®¹ï¼š\nfrom multiprocessing import Process, Queue  \nimport queue  \nfrom collections import Counter \n\ndef task(*args):  # å®šä¹‰å®é™…è¦å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡å‡½æ•°\n    # ... do something ...  # è¿™é‡Œå†™ä½ çš„çœŸå®ä»»åŠ¡é€»è¾‘\n    return Counter()  # è¿”å›ä¸€ä¸ª Counterï¼ˆç¤ºä¾‹ï¼‰ï¼Œä¾¿äºä¸»è¿›ç¨‹èšåˆ\n\ndef task_worker(out_queue: Queue, *args):  # workerï¼šæ¥æ”¶è¾“å‡ºé˜Ÿåˆ—å’Œä»»åŠ¡å‚æ•°\n\n    output = task(*args)  # æ‰§è¡Œä»»åŠ¡ï¼Œå¾—åˆ°éƒ¨åˆ†ç»“æœ\n    \n    out_queue.put(output)  # æŠŠç»“æœæ”¾è¿›é˜Ÿåˆ—ï¼Œäº¤ç»™ä¸»è¿›ç¨‹æ±‡æ€»\n\nnum_process = 4  # è¿›ç¨‹æ•°ç¤ºä¾‹ï¼ˆä½ éœ€è¦è‡ªå·±è®¾ç½®ï¼‰\ntask_args_list = [(\"a\",), (\"b\",), (\"c\",), (\"d\",)]  # æ¯ä¸ªè¿›ç¨‹çš„å‚æ•°ç¤ºä¾‹ï¼ˆä½ éœ€è¦æ›¿æ¢æˆçœŸå®å‚æ•°ï¼‰\n\nout_queue: Queue = manager.Queue() # åˆ›å»ºè¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—\nprocesses: list[Process] = []  # ä¿å­˜æ‰€æœ‰è¿›ç¨‹å¯¹è±¡ï¼Œæ–¹ä¾¿åé¢ join\n\nfor args in task_args_list:  # éå†æ¯ä¸ªä»»åŠ¡çš„å‚æ•°\n    p = Process(target=task_worker, args=(out_queue, *args))  # åˆ›å»ºè¿›ç¨‹ï¼Œå¹¶æŠŠé˜Ÿåˆ—+å‚æ•°ä¼ ç»™ worker\n    processes.append(p)  # è®°å½•è¿›ç¨‹å¯¹è±¡\n    p.start()  # å¯åŠ¨è¿›ç¨‹å¼€å§‹æ‰§è¡Œ\n\nall_out = Counter()  # ä¸»è¿›ç¨‹çš„æ€» Counterï¼Œç”¨äºç´¯åŠ æ‰€æœ‰éƒ¨åˆ†ç»“æœ\n\nfor _ in range(len(processes)):  # é¢„æœŸæ¯ä¸ªè¿›ç¨‹éƒ½ä¼š put ä¸€æ¬¡ç»“æœï¼Œæ‰€ä»¥æ”¶ len(processes) æ¬¡\n    try:\n        partial_out = out_queue.get(timeout=10)  # ä»é˜Ÿåˆ—å–ä¸€ä¸ªç»“æœï¼Œæœ€å¤šç­‰å¾… 10 ç§’\n        all_out.update(partial_out)  # æŠŠè¿™ä¸ªè¿›ç¨‹çš„ Counter åˆå¹¶åˆ°æ€» Counter\n    except queue.Empty:  # å¦‚æœè¶…æ—¶æ²¡å–åˆ°ï¼Œå°±è·³è¿‡\n        continue  # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª\n\nfor p in processes:  # éå†æ‰€æœ‰è¿›ç¨‹\n    p.join()  # ç­‰å¾…è¿›ç¨‹ç»“æŸ\n\n\næœ‰äº†è¿™äº›å‰ç½®çŸ¥è¯†ä¹‹åï¼Œå®ç°è¿™ä¸ªPre-Processingçš„æ­¥éª¤å°±å¾ˆå®¹æ˜“äº†ï¼Œä»¥ä¸‹æ˜¯Pre-processçš„ä»£ç \n\n\ncs336_basics/tokenizer/tokenizer.py\n\ndef pre_tokenize_string_worker(*args):\n    input_path, special_tokens, queue, start, end, include_special = args\n\n    # Read the chunk from the file\n    with open(input_path, \"rb\") as f:\n        f.seek(start)\n        chunk = f.read(end - start).decode(\"utf-8\", errors=\"ignore\")\n\n    word_counter = pre_tokenize(chunk, special_tokens, include_special)\n\n    # Put the result in the queue\n    queue.put(word_counter)\n\ndef train_bpe():\n    with open(input_path, \"rb\") as f:\n        chunk_boundaries = find_chunk_boundaries(\n            f, desired_num_chunks=kwargs.get(\"desired_num_chunks\", NUM_PROCESSES), split_special_token=b\"\\n\"\n        )\n    \n    manager = Manager()\n    queue = manager.Queue()\n    processes: list[Process] = []\n    \n    for start, end in zip(chunk_boundaries[:-1], chunk_boundaries[1:]):\n        p = Process(\n            target=pre_tokenize_string_worker,\n            args=(input_path, special_tokens, queue, start, end, False),\n        )\n        processes.append(p)\n        p.start()\n\n    word_counter = Counter() \n    for _ in range(len(processes)):\n        try:\n            partial_counter = queue.get(timeout=10)\n            word_counter.update(partial_counter)\n        except Empty:\n            continue\n    for p in processes:\n        p.join()\n\né€šè¿‡è¿™ä¸ªåˆé›†ï¼Œæˆ‘ä»¬çš„å¾—åˆ°äº† word_counter è¿™ä¸ªå˜é‡. å®ƒè®°å½•äº†æ¯ä¸ª pre-tokenï¼ˆbyte/id åºåˆ—ï¼‰åœ¨æ•´ä¸ªè¯­æ–™ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥åŸºäºè¿™ä¸ª word_counter æ¥ç»Ÿè®¡ pair é¢‘æ¬¡ï¼Œå¹¶è¿›è¡Œ BPE åˆå¹¶äº†.\n\n\nMulti-Processing æ³¨æ„äº‹é¡¹\n\n\néœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œè¿›ç¨‹æ•°ï¼ˆNUM_PROCESSORï¼‰å¹¶ä¸æ˜¯è¶Šå¤šè¶Šå¥½ã€‚åœ¨å®é™…å®ç°ä¸­ï¼Œå½“è¿›ç¨‹æ•°ç»§ç»­å¢å¤§æ—¶ï¼Œæ•´ä½“é€Ÿåº¦åè€Œå¯èƒ½å˜æ…¢ï¼Œä¸»è¦åŸå› æœ‰ä¸‰ç‚¹ï¼š\n\nåˆ›å»ºä¸è°ƒåº¦å¼€é”€ï¼šå¯åŠ¨å¤šä¸ªè¿›ç¨‹æœ¬èº«å°±æœ‰æˆæœ¬ï¼ˆfork/spawnã€åˆå§‹åŒ–ã€è°ƒåº¦ï¼‰ï¼Œä»»åŠ¡è¶Šç»†ç¢ï¼Œè¿™éƒ¨åˆ†å¼€é”€å æ¯”è¶Šé«˜ã€‚\nè·¨è¿›ç¨‹é€šä¿¡æˆæœ¬ï¼šå¤šè¿›ç¨‹ä¹‹é—´éœ€è¦ä¼ é€’æ•°æ®ï¼ˆä¾‹å¦‚æŠŠ chunk åˆ†å‘ç»™ workerã€å†æŠŠç»Ÿè®¡ç»“æœæ±‡æ€»å›æ¥ï¼‰ï¼Œä¼šå¼•å…¥åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼ˆpickleï¼‰ä»¥åŠ IPC çš„é¢å¤–è€—æ—¶ã€‚\nå†…å­˜ä¸ç¼“å­˜å‹åŠ›ï¼šè¿›ç¨‹è¶Šå¤šï¼Œå¾€å¾€ä¼šå¸¦æ¥æ›´é«˜çš„å†…å­˜å ç”¨ä¸ cache/memory bandwidth ç«äº‰ï¼Œåè€Œæ‹–æ…¢ååã€‚\n\nå› æ­¤ï¼Œå¤šè¿›ç¨‹çš„æœ€ä½³æ•°é‡é€šå¸¸å–å†³äºï¼šä»»åŠ¡ç²’åº¦ã€æ•°æ®è§„æ¨¡ã€CPU æ ¸æ•°ã€ä»¥åŠ IPC çš„æ¯”ä¾‹ã€‚åœ¨æœ¬æ¬¡ Assignment çš„è¯­æ–™è§„æ¨¡ä¸å®ç°æ–¹å¼ä¸‹ï¼Œä¸€ä¸ªç»éªŒä¸Šæ›´ç¨³çš„é€‰æ‹©æ˜¯ NUM_PROCESSOR=4ï¼šæ—¢èƒ½è·å¾—æ˜æ˜¾çš„å¹¶è¡ŒåŠ é€Ÿï¼Œåˆèƒ½é¿å…è¿‡å¤šè¿›ç¨‹å¸¦æ¥çš„é¢å¤–å¼€é”€ä¸æ‹¥å¡ã€‚\n\n\n\n\n2.3.4 Others\né™¤äº† word_counterï¼ˆè®°å½•æ¯ä¸ª word/token åºåˆ—å‡ºç°æ¬¡æ•°ï¼‰ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä¼šé¢å¤–æ„å»ºä¸¤ä¸ªè¾…åŠ©ç»“æ„ï¼Œæ¥æ”¯æŒåç»­ æ›´é«˜æ•ˆçš„ pair ç»Ÿè®¡ä¸æ›´æ–°ï¼š\n\n\ncs336_basics/tokenizer/tokenizer.py\n\npairs_counter = Counter()\npair_to_words: dict[tuple[int, int], set[tuple[int, ...]]] = defaultdict(set)\nfor word in word_counter:\n    for i in range(len(word) - 1):\n        pair = (word[i], word[i + 1])\n        pair_to_words[pair].add(word)\n        pairs_counter[pair] += word_counter[word]\n\n\npairs_counter[pair]ï¼šè®°å½•è¯¥ç›¸é‚» pair åœ¨å…¨è¯­æ–™ä¸­çš„æ€»å‡ºç°æ¬¡æ•°ã€‚ å› ä¸ºæ¯ä¸ª word åœ¨è¯­æ–™ä¸­å‡ºç°äº† word_counter[word] æ¬¡ï¼Œæ‰€ä»¥ word å†…éƒ¨æ¯å‡ºç°ä¸€æ¬¡ pairï¼Œå°±ä¸ºå…¨å±€é¢‘æ¬¡è´¡çŒ® word_counter[word]ã€‚\npair_to_words[pair]ï¼šè®°å½•è¯¥ pair å‡ºç°åœ¨å“ªäº› wordï¼ˆtoken åºåˆ—ï¼‰é‡Œ, è¿™ä¸ªæ˜ å°„éå¸¸å…³é”®ï¼šå½“æˆ‘ä»¬é€‰æ‹©æŸä¸ª pair è¿›è¡Œ merge æ—¶ï¼Œåªæœ‰åŒ…å«è¯¥ pair çš„ word ä¼šå‘ç”Ÿå˜åŒ–ã€‚å€ŸåŠ© pair_to_wordsï¼Œæˆ‘ä»¬å¯ä»¥åªéå†è¿™äº›â€œå—å½±å“çš„ wordsâ€ï¼Œå¹¶å¯¹ pairs_counter åšå±€éƒ¨å¢é‡æ›´æ–°ï¼Œè€Œä¸æ˜¯æ¯è½®éƒ½é‡æ–°æ‰«æå…¨éƒ¨ word_counterã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#bpe-version-1-using-heap",
    "href": "posts/CS336/Ass01/ass01.html#bpe-version-1-using-heap",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.4 BPE Version 1: Using Heap",
    "text": "2.4 BPE Version 1: Using Heap\nä¸€ä¸ªå¾ˆæ˜æ˜¾çš„ä¼˜åŒ–ç‚¹æ˜¯ï¼šæ¯ä¸€è½®éƒ½è¦æ‰¾å½“å‰é¢‘ç‡æœ€é«˜çš„ pairã€‚åœ¨ Version 0 (SectionÂ 2.2) é‡Œï¼Œæˆ‘ä»¬æ¯è½®éƒ½é€šè¿‡éå† pairs_counter æ¥å–æœ€å¤§å€¼ï¼Œè¿™ä¸€æ­¥æ˜¯ \\(\\mathcal{O}(n)\\)ï¼ˆ\\(n\\) æ˜¯ pair çš„æ•°é‡ï¼‰ã€‚è€Œè¿™ä¸ªæ“ä½œæ­£å¥½ç¬¦åˆå †ï¼ˆheapï¼‰çš„ä½¿ç”¨åœºæ™¯ï¼šç”¨å †ç»´æŠ¤â€œå½“å‰æœ€å¤§çš„å…ƒç´ â€ï¼Œå°±èƒ½æŠŠâ€œå–æœ€å¤§â€é™åˆ° \\(\\mathcal{O}(\\log n)\\)ï¼ˆä¸¥æ ¼æ¥è¯´æ˜¯ï¼šå–å †é¡¶æ˜¯ \\(\\mathcal{O}(1)\\)ï¼Œä½†å¦‚æœåŒ…å« pop/push æ›´æ–°åˆ™æ˜¯ \\(\\mathcal{O}(\\log n)\\)ï¼‰ã€‚\nå…·ä½“åšæ³•æ˜¯æŠŠæ¯ä¸ª pair ä½œä¸ºå †å…ƒç´ ï¼Œå¹¶æŠŠâ€œæ’åºä¾æ®â€è®¾è®¡æˆï¼š\n\né¢‘æ¬¡è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜\né¢‘æ¬¡ç›¸åŒåˆ™æŒ‰ pair çš„å­—å…¸åºæ›´å¤§è€…ä¼˜å…ˆ\n\nåœ¨ Python çš„ heapq æ˜¯æœ€å°å †ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç”¨è´Ÿå·æŠŠå®ƒå˜æˆâ€œæœ€å¤§å †â€ï¼Œä¾‹å¦‚å­˜æˆï¼š\n\nkey = (-freq, -a, -b)\n\nè¿™æ ·æ¯ä¸€è½®æˆ‘ä»¬éƒ½èƒ½å¿«é€Ÿæ‹¿åˆ°å€™é€‰çš„â€œæœ€å¸¸è§ pairâ€ã€‚\nä¸è¿‡è¦æ³¨æ„ä¸€ç‚¹ï¼šé¢‘æ¬¡åœ¨ merge ä¹‹åä¼šå‘ç”Ÿå˜åŒ–ï¼Œå› æ­¤å †é‡Œæ—§çš„æ¡ç›®å¯èƒ½å˜â€œè¿‡æœŸâ€ã€‚åœ¨ pop å †é¡¶æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥è¯¥ pair çš„å½“å‰é¢‘æ¬¡æ˜¯å¦å’Œå †é‡Œå­˜çš„é¢‘æ¬¡ä¸€è‡´ï¼›å¦‚æœä¸ä¸€è‡´ï¼Œè¯´æ˜å †é¡¶æ˜¯è¿‡æœŸçš„ï¼Œå°±ç»§ç»­ pop ç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„ pairã€‚\n\n\ncs336_basics/tokenizer/merge_fn.py\n\nclass HeapItem:\n    def __init__(self, neg_freq: int, pair_bytes: tuple[bytes, bytes], pair: tuple[int, int]):\n        self.neg_freq = neg_freq\n        self.pair_bytes = pair_bytes\n        self.pair = pair\n\n    def __lt__(self, other: \"HeapItem\") -&gt; bool:\n        if self.neg_freq != other.neg_freq:\n            return self.neg_freq &lt; other.neg_freq\n        return self.pair_bytes &gt; other.pair_bytes  # reverse order for max-heap behavior\n\n\ndef build_pair_heap(pairs_freqs: Counter, vocab: dict[int, bytes]):\n    heap = []\n    for (a, b), f in pairs_freqs.items():\n        if f &gt; 0:\n            item = HeapItem(-f, (vocab[a], vocab[b]), (a, b))\n            heapq.heappush(heap, item)\n    return heap\n\n\ndef pop_most_frequent_pair(heap, pairs_counter: Counter) -&gt; tuple[int, int]:\n    while heap:\n        item = heap[0]  # Peek at the top item\n        neg_f = item.neg_freq\n        pair = item.pair\n        cur_f = pairs_counter.get(pair, 0)\n        if cur_f &lt;= 0 or -neg_f != cur_f:  # frequency changed, which means the pair we store in heap is stale\n            heapq.heappop(heap)\n            continue\n        return pair\n\n    raise ValueError(\"No positive-frequency pairs remain\")",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#bpe-version-2-using-heap-indexing",
    "href": "posts/CS336/Ass01/ass01.html#bpe-version-2-using-heap-indexing",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.5 BPE Version 2: Using Heap + Indexing",
    "text": "2.5 BPE Version 2: Using Heap + Indexing\né™¤äº†ç”¨ Heap åŠ é€Ÿâ€œé€‰å‡ºé¢‘ç‡æœ€é«˜çš„ pairâ€ï¼Œå¦ä¸€ä¸ªæ›´å…³é”®çš„ç“¶é¢ˆåœ¨äº merge æ›´æ–°é˜¶æ®µï¼šåœ¨ Version 0{SectionÂ 2.2} é‡Œï¼Œæˆ‘ä»¬æ¯ä¸€è½®éƒ½ä¼šéå† word_counter é‡Œçš„æ‰€æœ‰ wordï¼Œæ£€æŸ¥è¿™ä¸ª word é‡Œæ˜¯å¦å‡ºç°äº†ç›®æ ‡ pairï¼›è¿™ä¸€æ­¥çš„ä»£ä»·é€šå¸¸éå¸¸é«˜ï¼Œå› ä¸ºç»å¤§å¤šæ•° word æ ¹æœ¬ä¸åŒ…å« å½“å‰è¦ merge çš„ pairï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯æŠŠå®ƒä»¬éƒ½æ‰«äº†ä¸€éã€‚\nå› æ­¤æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªâ€œå€’æ’ç´¢å¼•â€æ¥åš ç©ºé—´æ¢æ—¶é—´ï¼šæå‰ç»´æŠ¤ä¸€ä¸ªæ˜ å°„ pair -&gt; {wordsâ€¦}ï¼Œè®°å½•æ¯ä¸ª pair å‡ºç°åœ¨å“ªäº› word ä¸­ã€‚è¿™æ ·å½“æˆ‘ä»¬å†³å®š merge æŸä¸ª pair æ—¶ï¼Œå°±åªéœ€è¦éå† pair_to_words[pair] é‡Œçš„é‚£ä¸€å°éƒ¨åˆ† wordï¼Œè€Œä¸å¿…å…¨é‡æ‰«ææ‰€æœ‰ wordã€‚\nè¿™ä¹Ÿæ­£æ˜¯æˆ‘ä»¬æ­å»º pair_to_words çš„åŸå› ï¼š\n\næ²¡æœ‰ç´¢å¼•ï¼šæ¯è½® merge éƒ½æ˜¯ å…¨é‡æ‰«ææ‰€æœ‰ wordsï¼ˆæ…¢ï¼Œ\\(\\mathcal{O}(\\#words)\\) çº§åˆ«ï¼‰ã€‚\næœ‰ç´¢å¼•ï¼šæ¯è½®åªå¤„ç† åŒ…å«è¯¥ pair çš„ words å­é›†ï¼ˆå¿«ï¼Œå¤æ‚åº¦å–å†³äºè¯¥ pair çš„è¦†ç›–èŒƒå›´ï¼Œé€šå¸¸è¿œå°äºå…¨é‡ï¼‰ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨ merge ä¹‹åï¼Œæ›´æ–°è¿™ä¸ªç´¢å¼•ï¼šå½“æŸä¸ª pair è¢« merge æˆä¸€ä¸ªæ–° token åï¼Œæ‰€æœ‰åŒ…å«è¯¥ pair çš„ word éƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æŠŠè¿™äº› word ä»æ—§ pair çš„ç´¢å¼•é‡Œç§»é™¤ï¼Œå¹¶æŠŠå®ƒä»¬æ·»åŠ åˆ°æ–° pair çš„ç´¢å¼•é‡Œã€‚å…·ä½“å®ç°å¦‚ä¸‹ï¼š\n\n\ncs336_basics/tokenizer/merge_fn.py\n\ndef merge_pairs_with_heap_index(\n    word_counter: dict[tuple[int, ...], int],\n    pair_counter: Counter,\n    target_pair: tuple[int, int],\n    new_id: int,\n    vocab: dict[int, bytes],\n    pair_heap,\n    pair_to_words: dict[tuple[int, int], set[tuple[int, ...]]],\n) -&gt; tuple[\n    dict[tuple[int, ...], int],\n    Counter,\n    list,\n    dict[tuple[int, int], set[tuple[int, ...]]],\n]:\n    # Start from full counters so unaffected words remain.\n    new_word_counter: Counter = Counter(word_counter)\n    updated_pair_counter: Counter = pair_counter.copy()\n    changed_pairs: set[tuple[int, int]] = set()\n\n    # Get all words that contain the target pair.\n    affected_words = list(pair_to_words.get(target_pair, set()))\n\n    for w in affected_words:\n        freq = word_counter.get(w, 0)\n        if freq &lt;= 0 or len(w) &lt; 2:\n            continue\n\n        # 1. Remove the old word from the corpus counts.\n        new_word_counter[w] -= freq\n        if new_word_counter[w] &lt;= 0:\n            del new_word_counter[w]\n\n        # 2. Subtract ALL old adjacent pairs for this word + remove old word from index.\n        for i in range(len(w) - 1):\n            pair = (w[i], w[i + 1])\n            updated_pair_counter[pair] -= freq\n            changed_pairs.add(pair)\n\n            s = pair_to_words.get(pair)\n            if s is not None:\n                s.discard(w)\n                if not s:\n                    del pair_to_words[pair]\n\n        # 3. Build merged word (greedy left-to-right, same as standard BPE).\n        new_word = get_new_word(w, target_pair, new_id)\n        new_word_counter[new_word] += freq\n\n        # 4. Add ALL new adjacent pairs for merged word + add merged word into index.\n        if len(new_word) &gt;= 2:\n            for i in range(len(new_word) - 1):\n                pair = (new_word[i], new_word[i + 1])\n                updated_pair_counter[pair] += freq\n                changed_pairs.add(pair)\n                pair_to_words.setdefault(pair, set()).add(new_word)\n\n    # 5. Push updated frequencies for changed pairs into heap (skip non-positive).\n    if pair_heap is not None:\n        for p in changed_pairs:\n            f = updated_pair_counter.get(p, 0)\n            if f &gt; 0:\n                heapq.heappush(pair_heap, HeapItem(-f, (vocab[p[0]], vocab[p[1]]), p))\n\n    return dict(new_word_counter), updated_pair_counter, pair_heap, pair_to_words\n\næœ‰äº†è¿™ä¸¤ä¸ªä¼˜åŒ–çš„ç‚¹ï¼ŒBPEçš„è®­ç»ƒé€Ÿåº¦å¯ä»¥å¤§å¤§çš„æå‡ï¼Œ\n\n\nComparison of BPE Versions\n\n\n\n\n\n\n\n\nç‰ˆæœ¬\næ‰¾æœ€é¢‘ç¹ pair\næ›´æ–°è®¡æ•°\nè®­ç»ƒä¸»å¾ªç¯ç“¶é¢ˆ\n\n\n\n\nv0\næ¯è½®æ‰«ä¸€é pairs (\\(\\mathcal{O}(\\#pairs)\\))\næ¯è½®é‡ç®—\nå¾ˆæ…¢\n\n\nheap\npop \\(\\mathcal{O}(\\log \\#pairs)\\)\nä»å¯èƒ½æ‰«å¾ˆå¤š\næ›´å¿«\n\n\nheap + pair_to_words\npop \\(\\mathcal{O}(\\log \\#pairs)\\)\nåªæ›´æ–°å—å½±å“çš„ words/pairs\næ˜æ˜¾æ›´å¿«",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#train-bpe",
    "href": "posts/CS336/Ass01/ass01.html#train-bpe",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.6 Train BPE",
    "text": "2.6 Train BPE\nå°†ä¸Šé¢çš„å®ç°ï¼Œæ›¿æ¢æˆæˆ‘ä»¬æœ€æ–°çš„å®ç°åï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç°BPEçš„ç®—æ³•ï¼š\n\n\ncs336_basics/tokenizer/tokenizer.py\n\ndef train_bpe(\n    input_path: str | os.PathLike,\n    vocab_size: int,\n    special_tokens: list[str] | None = None,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; tuple[dict[int, bytes], list[tuple[bytes, bytes]]]:\n    num_merges = vocab_size - 256 - (len(special_tokens) if special_tokens else 0)\n    vocab: dict[int, bytes] = init_vocab(special_tokens)\n    merges: list[tuple[bytes, bytes]] = []\n\n    # 1. Pre-tokenization\n    # 1.1 Find chunk boundaries\n    with open(input_path, \"rb\") as f:\n        chunk_boundaries = find_chunk_boundaries(\n            f, desired_num_chunks=kwargs.get(\"desired_num_chunks\", NUM_PROCESSES), split_special_token=b\"\\n\"\n        )\n\n    if verbose:\n        print_color(f\"Identified {len(chunk_boundaries) - 1} chunks for pre-tokenization.\")\n\n    # 1.2 Count word frequencies across chunks using multiprocessing\n    manager = Manager()\n    queue = manager.Queue()\n    processes: list[Process] = []\n\n    for start, end in zip(chunk_boundaries[:-1], chunk_boundaries[1:]):\n        p = Process(\n            target=pre_tokenize_string_worker,\n            args=(input_path, special_tokens, queue, start, end, False),\n        )\n        processes.append(p)\n        p.start()\n\n    if verbose:\n        print_color(\"Pre-tokenization processes completed. Aggregating results...\")\n\n    word_counter = Counter()\n    for _ in range(len(processes)):\n        try:\n            partial_counter = queue.get(timeout=10)\n            word_counter.update(partial_counter)\n        except Empty:\n            continue\n    for p in processes:\n        p.join()\n\n    if verbose:\n        print_color(f\"Completed pre-tokenization. Vocabulary size: {len(word_counter)} unique tokens.\")\n\n    pairs_counter = Counter()\n    pair_to_words: dict[tuple[int, int], set[tuple[int, ...]]] = defaultdict(set)\n    for word in word_counter:\n        for i in range(len(word) - 1):\n            pair = (word[i], word[i + 1])\n            pair_to_words[pair].add(word)\n            pairs_counter[pair] += word_counter[word]\n\n    # 2. BPE Core Loop\n    pair_heap = build_pair_heap(pairs_counter, vocab)\n\n    for i in trange(num_merges):\n        most_frequent_pair = pop_most_frequent_pair(pair_heap, pairs_counter)\n        new_id = update_vocab(vocab, most_frequent_pair)\n\n        word_counter, pairs_counter, pair_heap, pair_to_words = merge_pairs_with_heap_index(\n            word_counter, pairs_counter, most_frequent_pair, new_id, vocab, pair_heap, pair_to_words\n        )\n\n        merges.append((vocab[most_frequent_pair[0]], vocab[most_frequent_pair[1]]))\n\n    if kwargs.get(\"save_path\"):\n        save_vocab_and_merges(vocab, merges, kwargs[\"save_path\"])\n        with open(os.path.join(kwargs[\"save_path\"], \"special_tokens.txt\"), \"w\", encoding=\"utf-8\") as f:\n            if special_tokens:\n                for token in special_tokens:\n                    f.write(f\"{token}\\n\")\n\n    return vocab, merges\n\nè¿è¡Œä¸€ä¸‹æµ‹è¯•ä»£ç \n\n\ntests/adapters.py\n\nfrom cs336_basics.tokenizer.tokenizer import train_bpe\n\nreturn train_bpe(\n    input_path=input_path,\n    vocab_size=vocab_size,\n    special_tokens=special_tokens,\n    **kwargs,\n)\n\nuv run pytest tests/test_train_bpe.py\næˆ‘ä»¬çœ‹åˆ°ï¼Œæ‰€æœ‰çš„æµ‹è¯•éƒ½é€šè¿‡äº†ï¼",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#bpe-on-tinystory",
    "href": "posts/CS336/Ass01/ass01.html#bpe-on-tinystory",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.7 BPE on TinyStory",
    "text": "2.7 BPE on TinyStory\nåœ¨TinyStoryä¸Šè®­ç»ƒBPEï¼Œ\nuv run python ./train_bpe.py\nåªéœ€è¦ä¸åˆ°2minsã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#bpe-tokenizer",
    "href": "posts/CS336/Ass01/ass01.html#bpe-tokenizer",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.8 BPE Tokenizer",
    "text": "2.8 BPE Tokenizer\næœ‰äº†vocab merges æˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªBPE Tokenizer\n\n\ncs336_basics/tokenizer/tokenizer.py\n\n\nclass BPETokenizer:\n    def __init__(\n        self,\n        vocab: dict[int, bytes],\n        merges: list[tuple[bytes, bytes]],\n        special_tokens: list[str] | None = None,\n    ):\n        self.vocab = vocab\n        self.merges = merges\n        self.special_tokens = special_tokens if special_tokens else []\n        self.special_tokens_bytes = [t.encode(\"utf-8\") for t in self.special_tokens]\n        self.special_set = set(self.special_tokens_bytes)\n\n        self.vocab_inv = {v: k for k, v in self.vocab.items()}\n\n        rank: dict[tuple[int, int], int] = {}\n        merge_to_new_id: dict[tuple[int, int], int] = {}\n\n        for r, (a_bytes, b_bytes) in enumerate(self.merges):\n            a_id = self.vocab_inv.get(a_bytes)\n            b_id = self.vocab_inv.get(b_bytes)\n            # The merged token should be present in vocab; if not, skip this merge rule.\n            new_id = self.vocab_inv.get(a_bytes + b_bytes)\n            if a_id is None or b_id is None or new_id is None:\n                continue\n            pair = (a_id, b_id)\n            rank[pair] = r\n            merge_to_new_id[pair] = new_id\n\n        self.rank = rank\n        self.merge_to_new_id = merge_to_new_id\n\n        self.eos_token_id = self.vocab_inv.get(b\"&lt;|endoftext|&gt;\", None)\n    def encode(self):\n        pass \n    \n    def encode_iterable(self):\n        pass\n    \n    def decode(self):\n        tokens = b\"\".join(self.vocab.get(i, b\"\\xef\\xbf\\xbd\") for i in ids)\n        return tokens.decode(\"utf-8\", errors=\"replace\")\n    @classmethod\n    def from_files(\n        cls, vocab_filepath: str, merges_filepath: str, special_tokens: list[str] | str | None = None\n    ) -&gt; \"BPETokenizer\":\n        with open(vocab_filepath) as vf:\n            vocab_data = json.load(vf)\n            vocab = {int(i): bytes(v, \"latin1\") for v, i in vocab_data.items()}\n\n        merges = []\n        with open(merges_filepath) as mf:\n            # Skip the first line (header)\n            next(mf)\n            for line in mf:\n                if line.strip() and not line.startswith(\"#\"):\n                    parts = line.strip().split()\n                    if len(parts) == 2:\n                        merges.append((bytes(parts[0], \"latin1\"), bytes(parts[1], \"latin1\")))\n\n        if isinstance(special_tokens, str):\n            with open(special_tokens, encoding=\"utf-8\") as stf:\n                special_tokens_list = [line.strip() for line in stf if line.strip()]\n        elif isinstance(special_tokens, list):\n            special_tokens_list = special_tokens\n        else:\n            special_tokens_list = []\n\n        return cls(vocab, merges, special_tokens_list)\n\nBPE Tokenizer ä¸»è¦å®ç°ä¸‰ä¸ªåŠŸèƒ½ï¼š\n\nencodeï¼šæŠŠå­—ç¬¦ä¸²ç¼–ç æˆ token IDs åˆ—è¡¨\nencode_iterableï¼šæŠŠå­—ç¬¦ä¸²ç¼–ç æˆ token IDs ç”Ÿæˆå™¨\ndecodeï¼šæŠŠ token IDs åˆ—è¡¨è§£ç æˆå­—ç¬¦ä¸²\n\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸»è¦ä»‹ç» encode çš„å®ç°ï¼›ç›¸æ¯”ä¹‹ä¸‹ï¼Œdecode çš„é€»è¾‘æ›´ç›´æ¥ï¼šæŠŠ token ids ä¾æ¬¡æ˜ å°„å›å¯¹åº”çš„ bytesï¼Œæ‹¼æ¥æˆå®Œæ•´çš„å­—èŠ‚åºåˆ—ï¼Œå†ç”¨ UTF-8 è§£ç å¾—åˆ°å­—ç¬¦ä¸²ã€‚éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯ b\"\\xef\\xbf\\xbd\" çš„å¤„ç†â€”â€”å®ƒæ˜¯ Unicode U+FFFDï¼ˆreplacement characterï¼Œâ€œï¿½â€ï¼‰åœ¨ UTF-8 ä¸‹çš„å­—èŠ‚è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨ decode æ—¶ä¼šå¯¹æ¯ä¸ª iï¼ˆtoken idï¼‰æ‰§è¡Œä¸€æ¬¡æŸ¥è¡¨ self.vocab.get(i, ...)ï¼š\n\nå¦‚æœ i èƒ½åœ¨è¯è¡¨ä¸­æ‰¾åˆ°ï¼Œå°±å–å‡ºå¯¹åº”çš„ bytesï¼›\nå¦‚æœæ‰¾ä¸åˆ°ï¼ˆä¾‹å¦‚é‡åˆ°éæ³•/è¶Šç•Œçš„ idï¼Œæˆ–è¯è¡¨ä¸å®Œæ•´ï¼‰ï¼Œå°±ç”¨ bâ€â€ ä½œä¸ºå…œåº•ã€‚ è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼šå³ä½¿è¾“å…¥ ids ä¸­æ··å…¥äº†æœªçŸ¥ tokenï¼Œdecode ä¹Ÿä¸ä¼šå´©æºƒï¼Œè€Œæ˜¯ç”¨â€œï¿½â€æ˜¾å¼æ ‡è®°æ— æ³•è¿˜åŸçš„éƒ¨åˆ†ï¼Œä¿è¯æ•´ä¸ªè§£ç è¿‡ç¨‹å§‹ç»ˆå¯è¿è¡Œã€è¾“å‡ºå§‹ç»ˆæ˜¯ä¸€ä¸ªåˆæ³•å­—ç¬¦ä¸²ã€‚\n\n\n2.8.1 Encode in BPETokenizer\ndef encode(self, text: str) -&gt; list[int]:\n    def merge_one_pretoken(ids: list[int]) -&gt; list[int]:\n        pass \n    \n    # step 1\n    byte_tokens = self._pre_tokenize(text)\n    \n    # step 2\n    token_ids: list[int] = []\n    for btok in byte_tokens:\n        if btok in self.special_set:\n            token_ids.append(self.vocab_inv[btok])\n        else:\n            ids = [self.vocab_inv[bytes([b])] for b in btok]\n            token_ids.extend(merge_one_pretoken(ids))\n\n    return token_ids\nè¿™ä¸ªencodeä¸»è¦åšä¸¤ä¸ªäº‹æƒ…ï¼š\n\nPre-tokenizationï¼šå…ˆç²—ç²’åº¦åˆ‡åˆ†æ–‡æœ¬\nå¯¹æ¯ä¸ª pre-token åš BPE merge\n\nç¬¬ä¸€æ­¥å’Œæˆ‘ä»¬ä¹‹å‰å®ç°çš„ä¸€æ ·ï¼Œå¯¹äºç¬¬äºŒæ­¥ï¼Œä¸»è¦çš„å®ç°æ–¹æ³•åœ¨ merge_one_pretoken ä¸­å®ç°ã€‚ åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡Heapå’ŒDouble Linked List æ¥é«˜æ•ˆå®ç°è¿™ä¸ªEncodeã€‚\né¦–å…ˆï¼Œæˆ‘ä»¬ç”¨æ•°ç»„æ¥æ¨¡æ‹ŸåŒå‘é“¾è¡¨ï¼š\nprev = [-1] * n\nnxt  = [-1] * n\nalive = [True] * n\nåˆå¹¶æ—¶å¹¶ä¸çœŸçš„ del æ‰å…ƒç´ ï¼Œè€Œæ˜¯ï¼š\n\næ ‡è®°è¢«åæ‰çš„èŠ‚ç‚¹ alive[j] = False\nè°ƒæ•´æŒ‡é’ˆ nxt[i] = nxt[j]ã€prev[nxt[j]] = i\n\nè¿™æ ·æ¯æ¬¡åˆå¹¶éƒ½æ˜¯ \\(\\mathcal{O}(1)\\) çš„æ—¶é—´å¤æ‚åº¦ã€‚\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªmin heapï¼Œæ¥è·å–æˆ‘ä»¬æœ€å…ˆè¦å®ç°mergeçš„pairï¼Œä¹Ÿå°±æ˜¯åœ¨è®­ç»ƒé˜¶æ®µï¼Œå‡ºç°é¢‘ç‡æœ€é«˜çš„pairã€‚\nå †é‡Œå­˜ (rank, i)ï¼Œè¡¨ç¤ºå½“å‰ä½ç½® i ä¸å…¶å³é‚»å±… nxt[i] çš„ pair åœ¨ merge è§„åˆ™ä¸­çš„ä¼˜å…ˆçº§ï¼ˆrank è¶Šå°è¶Šå…ˆåˆå¹¶ï¼‰ã€‚ æ¯æ¬¡å–å‡ºæœ€å° rank çš„å€™é€‰ï¼Œåšä¸€æ¬¡åˆå¹¶ï¼Œç„¶ååªéœ€è¦é‡æ–°æ£€æŸ¥å±€éƒ¨çš„ä¸¤ä¸ª pairï¼š\n\n(prev[i], i)\n(i, nxt[i])\n\nheap: list[tuple[int, int]] = []\n\ndef push_if_valid(i: int):\n    cur_r = None\n    j = nxt[i]\n    if j == -1 or not alive[i] or not alive[j]:\n        cur_r = None\n    else:\n        cur_r = self.rank.get((ids[i], ids[j]))\n\n    if cur_r is not None:\n        heapq.heappush(heap, (cur_r, i))\n\nfor i in range(n):\n    push_if_valid(i)\nä¸ä¹‹å‰çš„heapä¸€æ ·ï¼Œheapé‡Œé¢çš„å†…å®¹ä¼š â€œè¿‡æœŸâ€ï¼š å› ä¸ºåˆå¹¶ä¼šæ”¹å˜é‚»æ¥å…³ç³»ï¼Œå †ä¸­æ—§æ¡ç›®ä¼šè¿‡æœŸï¼Œæ‰€ä»¥æ¯æ¬¡ pop å‡ºæ¥éƒ½è¦éªŒè¯,\næ¥ä¸‹æ¥å°±æ˜¯éå†è¿™ä¸ªheapï¼Œå¦‚æœè¿™ä¸ªheapä¸æ˜¯ç©ºçš„ï¼Œæˆ‘ä»¬å°±å¼¹å‡ºï¼Œå¹¶ä¸”éªŒè¯ï¼š\nè¿™æ®µ while heap: æ˜¯æ•´ä¸ª merge_one_pretoken çš„æ ¸å¿ƒï¼šå †é‡Œç»´æŠ¤â€œå½“å‰å¯åˆå¹¶çš„ç›¸é‚» pairâ€ï¼Œæ¯æ¬¡å–å‡º rank æœ€å°ï¼ˆæœ€ä¼˜å…ˆï¼‰ çš„å€™é€‰è¿›è¡Œåˆå¹¶ï¼Œå¹¶åªæ›´æ–°åˆå¹¶ç‚¹é™„è¿‘çš„å€™é€‰ã€‚\nwhile heap:  # åªè¦è¿˜æœ‰å€™é€‰ pairï¼Œå°±ç»§ç»­å°è¯•åˆå¹¶\n    r, i = heapq.heappop(heap)  # å–å‡ºå½“å‰ rank æœ€å°çš„å€™é€‰ï¼š(rank, å·¦ç«¯ç‚¹ä½ç½® i)\n    j = nxt[i]  # å³ç«¯ç‚¹ä½ç½® j æ˜¯ i åœ¨é“¾è¡¨ä¸­çš„åç»§\n    if j == -1 or not alive[i] or not alive[j]:  # i/j æ— æ•ˆæˆ– i å·²åˆ°å°¾éƒ¨ï¼šè¿™æ˜¯è¿‡æœŸå€™é€‰\n        continue  # è·³è¿‡ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå †å…ƒç´ \n\n    # stale checkï¼šå †é‡Œçš„è®°å½•å¯èƒ½å·²è¿‡æœŸï¼ˆé‚»å±…å…³ç³»/ids å·²æ”¹å˜ï¼‰ï¼Œéœ€è¦é‡æ–°éªŒè¯\n    pair = (ids[i], ids[j])  # å½“å‰æ—¶åˆ» i å’Œ j å¯¹åº”çš„ token id ç»„æˆçš„ç›¸é‚» pair\n    cur_r = self.rank.get(pair)  # æŸ¥è¯¢è¿™ä¸ª pair åœ¨ merge è§„åˆ™ä¸­çš„ rankï¼ˆä¸å¯åˆå¹¶åˆ™ä¸º Noneï¼‰\n    if cur_r is None or cur_r != r:  # ç°åœ¨ä¸å¯åˆå¹¶ï¼Œæˆ– rank å·²ä¸åŒ¹é…ï¼šè¯´æ˜å †å…ƒç´ è¿‡æœŸ\n        continue  # è·³è¿‡è¯¥å€™é€‰\n\n    # æ‰§è¡Œåˆå¹¶ï¼šæŠŠ (ids[i], ids[j]) åˆæˆä¸€ä¸ªæ–° tokenï¼Œå¹¶å†™å›åˆ°ä½ç½® i\n    new_id = self.merge_to_new_id.get(pair)  # æŸ¥æ‰¾è¯¥ pair åˆå¹¶åçš„ token id\n    if new_id is None:  # ç†è®ºä¸Šä¸è¯¥å‘ç”Ÿï¼ˆrank æœ‰ä½†æ˜ å°„æ²¡å»ºå¥½ï¼‰ï¼Œå½“ä½œè¿‡æœŸ/å¼‚å¸¸å¤„ç†\n        continue  # è·³è¿‡\n    ids[i] = new_id  # ç”¨æ–° token id è¦†ç›–å·¦ç«¯ç‚¹ iï¼ˆi æˆä¸ºåˆå¹¶åçš„èŠ‚ç‚¹ï¼‰\n\n    # ä»é“¾è¡¨ä¸­åˆ é™¤ jï¼šj è¢« i åæ‰äº†\n    alive[j] = False  # æ ‡è®° j èŠ‚ç‚¹è¢«åˆ é™¤\n    nj = nxt[j]  # è®°ä½ j çš„åç»§èŠ‚ç‚¹\n    nxt[i] = nj  # è®© i ç›´æ¥æŒ‡å‘ njï¼ˆè·³è¿‡ jï¼‰\n    if nj != -1:  # å¦‚æœ nj å­˜åœ¨\n        prev[nj] = i  # æ›´æ–° nj çš„å‰é©±ä¸º iï¼Œä¿æŒé“¾è¡¨ä¸€è‡´\n\n    # å±€éƒ¨æ›´æ–°ï¼šåˆå¹¶åªä¼šå½±å“ i é™„è¿‘çš„ä¸¤ä¸ªç›¸é‚» pair\n    pi = prev[i]  # i çš„å‰é©±ä½ç½®\n    if pi != -1:  # å¦‚æœå‰é©±å­˜åœ¨\n        push_if_valid(pi)  # (pi, i) è¿™ä¸ª pair å¯èƒ½å˜å¾—å¯åˆå¹¶æˆ– rank æ”¹å˜\n    push_if_valid(i)  # (i, nxt[i]) è¿™ä¸ª pair ä¹Ÿå¯èƒ½å˜å¾—å¯åˆå¹¶æˆ– rank æ”¹å˜\næœ€åæˆ‘ä»¬åªéœ€è¦æŠŠé“¾è¡¨ç»“æ„è¿˜åŸæˆæœ€ç»ˆçš„tokenåºåˆ—å³å¯ï¼š\nåœ¨ BPE åˆå¹¶é˜¶æ®µï¼Œæˆ‘ä»¬ç”¨ prev / nxt / alive ç»´æŠ¤äº†ä¸€ä¸ªâ€œæ•°ç»„æ¨¡æ‹Ÿçš„åŒå‘é“¾è¡¨â€ã€‚åˆå¹¶æ—¶å¹¶ä¸ä¼šçœŸçš„åˆ é™¤ ids é‡Œçš„å…ƒç´ ï¼Œè€Œæ˜¯æŠŠè¢«åæ‰çš„ä½ç½®æ ‡è®°ä¸º alive=Falseï¼Œå¹¶é€šè¿‡ nxt è·³è¿‡å®ƒä»¬ã€‚\nå› æ­¤åœ¨æ‰€æœ‰åˆå¹¶å®Œæˆåï¼Œéœ€è¦æŠŠâ€œè¿˜æ´»ç€çš„èŠ‚ç‚¹â€æŒ‰é¡ºåºé‡æ–°æ”¶é›†æˆä¸€ä¸ªç´§å‡‘çš„è¾“å‡ºåºåˆ—ï¼š\nout: list[int] = []          # æœ€ç»ˆåˆå¹¶åçš„ token id åºåˆ—\nk = 0                        # ä»é“¾è¡¨å¤´ï¼ˆä½ç½® 0ï¼‰å¼€å§‹éå†\nwhile k != -1:               # -1 è¡¨ç¤ºåˆ°è¾¾é“¾è¡¨æœ«å°¾\n    if alive[k]:             # å¦‚æœè¯¥ä½ç½®è¿˜æ²¡æœ‰è¢«åˆå¹¶åˆ é™¤\n        out.append(ids[k])   # æŠŠå½“å‰ä½ç½®çš„ token id åŠ å…¥è¾“å‡º\n    k = nxt[k]               # è·³åˆ°ä¸‹ä¸€ä¸ªâ€œä»åœ¨é“¾è¡¨ä¸­çš„â€ä½ç½®\nè‡³æ­¤ï¼Œæˆ‘ä»¬ä»¥åŠå®Œæˆäº†BPEé˜¶æ®µçš„æ‰€æœ‰çš„å†…å®¹ï¼Œæ¥ä¸‹æ¥å°±æ˜¯è¦è®­ç»ƒï¼Œå¹¶å­˜å‚¨æˆ‘ä»¬é¢„å…ˆTokenå¥½çš„å†…å®¹\nuv run pytest tests/test_tokenizer.py",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#tokenize-and-save-file",
    "href": "posts/CS336/Ass01/ass01.html#tokenize-and-save-file",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.9 Tokenize and Save File",
    "text": "2.9 Tokenize and Save File\næœ‰äº† tokenizer.encode() ä¹‹åï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¸Œæœ›æŠŠä¸€æ•´ä¸ªæ–‡æœ¬æ–‡ä»¶ç¼–ç æˆ ç´§å‡‘çš„äºŒè¿›åˆ¶ï¼ˆ.binï¼‰ï¼Œæ–¹ä¾¿åç»­è®­ç»ƒæ—¶ç”¨ np.memmap ä¹‹ç±»çš„æ–¹å¼é«˜æ•ˆåŠ è½½ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½é‡æ–°åˆ†è¯ã€‚\nä¸‹é¢è¿™æ®µå‡½æ•°åšçš„äº‹æƒ…å¾ˆç®€å•ï¼šæŒ‰è¡Œè¯»å–æ–‡æœ¬ â†’ æŠŠæ¯è¡Œç¼–ç æˆ token ids â†’ ç”¨å›ºå®š dtype å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶ã€‚\ndef encode_file_to_bin(tokenizer, text_path, out_bin_path, dtype=np.uint16):\n    total_bytes = os.path.getsize(text_path)\n\n    with open(text_path, encoding=\"utf-8\") as f_in, open(out_bin_path, \"wb\") as f_out:\n        p_bar = tqdm(total=total_bytes, desc=\"Encoding to binary\", unit=\"B\", unit_scale=True)\n\n        for line in f_in:\n            token_ids = tokenizer.encode(line)          # 1) æŠŠä¸€è¡Œæ–‡æœ¬ç¼–ç æˆ token ids\n            arr = np.array(token_ids, dtype=dtype)      # 2) è½¬æˆ numpy æ•°ç»„ï¼ˆæ›´é€‚åˆå†™äºŒè¿›åˆ¶ï¼‰\n            arr.tofile(f_out)                           # 3) ç›´æ¥ä»¥äºŒè¿›åˆ¶å†™å…¥ .bin æ–‡ä»¶\n\n            p_bar.update(len(line.encode(\"utf-8\")))     \næ ¹æ®æˆ‘ä»¬çš„å®ç°ï¼Œåªéœ€è¦ä¸åˆ°30minså°±å¯ä»¥è®­ç»ƒå®ŒBPEã€‚\nåœ¨è¿™é‡Œ .bin é‡Œä¸ä¿å­˜è¡Œè¾¹ç•Œ/æ ·æœ¬è¾¹ç•Œ è®­ç»ƒæ—¶æŠŠå®ƒå½“ä½œä¸€ä¸ªé•¿åºåˆ—åš next-token predictionï¼ˆGPT é£æ ¼ï¼‰ï¼Œç”¨ block samplingï¼›\n\n\nQuestion 1: ä¸ºä»€ä¹ˆç”¨uint16å°±å¯ä»¥äº†å‘¢ï¼Ÿ\n\n\nåº”ä¸ºåœ¨BPEçš„è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°†vocab sizeè®¾ç½®ä¸º 10,000 æˆ–è€… 32,000 è¿œè¿œå°äº uint16çš„æœ€å¤§å€¼ 65,535å› æ­¤ç”¨uint16æ˜¯å®‰å…¨çš„ã€‚\n\n\næˆ‘ä»¬é€šè¿‡è¿è¡Œä»¥ä¸‹ä»£ç æ¥å®ŒæˆTinyStoryçš„Tokenizationä¸ä¿å­˜ï¼š\nuv run python ./train_bpe.py\nåœ¨è®­ç»ƒå®Œä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åˆ°çš„ä¸€ä¸‹çš„directory\ndatasets/\nâ””â”€â”€ tiny_stories/\n    â”œâ”€â”€ eval.bin\n    â”œâ”€â”€ merges.txt\n    â”œâ”€â”€ special_tokens.txt\n    â”œâ”€â”€ train.bin\n    â””â”€â”€ vocab.json\n\n\n\n\n\n\nNote\n\n\n\nå¦‚æœå¤§å®¶ä¸æƒ³è®­ç»ƒTokenizerï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½æˆ‘è®­ç»ƒå®Œçš„æ–‡ä»¶ï¼Œåªéœ€åœ¨ asssignment1-basics çš„ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹ä¸¤è¡Œï¼š\npip install -U huggingface_hub\nhf download YuYangZhang/TinyStory-Tokenized  --repo-type dataset --local-dir datasets/tiny_stories\nè¿™æ®µä»£ç ä¼šè‡ªåŠ¨ä»hugging faceä¸Šä¸‹è½½æ•°æ®ï¼Œå¹¶ä¸”ä¿å­˜è‡³ä»¥ä¸Šçš„directoryã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#part-01-summary",
    "href": "posts/CS336/Ass01/ass01.html#part-01-summary",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "2.10 Part 01 Summary",
    "text": "2.10 Part 01 Summary\næ€»çš„æ¥è¯´ï¼ŒPart 01 ç›¸æ¯”å¤§å®¶æ›´æœŸå¾…çš„ã€ŒLLM è®­ç»ƒä¸æ¨¡å‹ç»“æ„ã€éƒ¨åˆ†ï¼Œæ›´åå‘å·¥ç¨‹å®ç°ä¸æ€§èƒ½ä¼˜åŒ–ï¼šé€šè¿‡åˆé€‚çš„æ•°æ®ç»“æ„ä¸ç®—æ³•è®¾è®¡ï¼ˆä¾‹å¦‚ heapã€ç´¢å¼•è¡¨ã€åŒå‘é“¾è¡¨ã€å¹¶è¡Œç»Ÿè®¡ç­‰ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸æ”¹å˜ç®—æ³•(Algorithm 1) çš„å‰æä¸‹ï¼ŒæŠŠ BPE çš„è®­ç»ƒä¸æ¨ç†é€Ÿåº¦æå‡ä¸€ä¸ªæ•°é‡çº§ã€‚\nå¾ˆå¤šè¯»è€…ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰ä¼šè§‰å¾—è¿™ä¸€éƒ¨åˆ†â€œåˆé•¿åˆç»•â€ï¼Œä¸»è¦åŸå› å¾€å¾€ä¸æ˜¯å†…å®¹æœ¬èº«æœ‰å¤šéš¾ï¼Œè€Œæ˜¯å¯¹è¿™äº›å·¥ç¨‹ç»†èŠ‚è¿˜ä¸å¤Ÿç†Ÿæ‚‰ï¼šä¸€æ—¦æŠŠæ•°æ®ç»“æ„çš„ä½œç”¨ã€æ›´æ–°èŒƒå›´ã€ä»¥åŠ stale check çš„é€»è¾‘ä¸²èµ·æ¥ï¼Œæ•´ä½“ä¼šæ¸…æ™°å¾ˆå¤šã€‚æ‰€ä»¥å¦‚æœä½ ç¬¬ä¸€æ¬¡è¯»å®Œä»ç„¶è§‰å¾—æœ‰ç‚¹ä¹±ï¼Œè¿™æ˜¯éå¸¸æ­£å¸¸çš„â€”â€” è¯·ä¸è¦æ°”é¦ , ç²¾å½©çš„éƒ¨åˆ†è¿˜æ­£è¦å¼€å§‹ï¼\nTokenization æ˜¯è®­ç»ƒ LLM çš„ç¬¬ä¸€æ­¥ã€‚çœŸæ­£ç†è§£è¿™éƒ¨åˆ†ï¼Œä¼šç›´æ¥å¸®åŠ©ä½ åœ¨åç»­æ›´é¡ºç•…åœ°æŒæ¡ï¼š\n\nå¦‚ä½•è¿›è¡Œæ•°æ®åŠ è½½ä¸é‡‡æ ·ï¼ˆä¾‹å¦‚ .bin + memmapï¼‰\nå¦‚ä½•é«˜æ•ˆåœ° encode / decode\nä»¥åŠåœ¨æ›´è¿›é˜¶çš„è¯é¢˜é‡Œï¼Œå¦‚ä½•å›´ç»• tokenizer ä¸åºåˆ—è¡¨ç¤ºå»æ‰©å±•æ¨¡å‹çš„ context length\n\nä¸‹ä¸€éƒ¨åˆ†æˆ‘ä»¬å°†æŠŠ tokenizer ç”Ÿæˆçš„äºŒè¿›åˆ¶æ•°æ®æ¥å…¥è®­ç»ƒ pipelineï¼Œè¿›å…¥çœŸæ­£çš„ model training ç¯èŠ‚ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#linear-module",
    "href": "posts/CS336/Ass01/ass01.html#linear-module",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.1 Linear Module",
    "text": "3.1 Linear Module\nLinear Module åŸºæœ¬æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œçš„èµ·å§‹ç‚¹ï¼Œå®ƒçš„å®šä¹‰å¦‚ä¸‹:\n\\[\ny = Wx\n\\tag{1}\\]\nå…¶ä¸­ \\(W \\in \\mathbb{R}^{d_{\\text{out}}  \\times d_{\\text{in}}}\\) , \\(x \\in \\mathbb{R}^{d_{\\text{in}} \\times 1}\\) , \\(y \\in \\mathbb{R}^{d_{\\text{out}} \\times 1}\\)\n\n\nNOTE\n\n\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®ç°çš„ Linear Module ä¸ä»»åŠ¡ä¸­è¦æ±‚çš„ç•¥æœ‰ä¸åŒï¼Œ ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹ä¸¤ç‚¹ï¼š\n\næˆ‘ä»¬å°† weight çš„ shape è®¾ä¸º (in_features, out_features)ï¼Œ è¿™æ ·åœ¨ forward çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ @ è¿ç®—ç¬¦è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œä»£ç æ›´ç®€æ´ã€‚\næˆ‘ä»¬å°† bias è®¾ä¸ºå¯é€‰é¡¹ï¼Œé»˜è®¤ä¸ä½¿ç”¨ biasï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°æ¨¡æ‹Ÿ Transformer ä¸­çš„ Linear Layerã€‚\n\n\n\nclass Linear(nn.Module):\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        device: torch.device | None = None,\n        dtype: torch.dtype | None = None,\n        bias: bool = False,\n    ):\n        super().__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.weight = nn.Parameter(torch.empty((in_features, out_features), device=device, dtype=dtype))\n        self.bias = nn.Parameter(torch.empty(out_features, device=device, dtype=dtype)) if bias else None\n        self._init_weight()\n\n    def forward(self, x):\n        o = x @ self.weight\n\n        if self.bias is not None:\n            o = o + self.bias\n\n        return o\n    \n    def _init_weight(self):\n        mean = 0.0\n        std = 1.0 / (2 * (self.in_features + self.out_features) ** 0.5)\n        torch.nn.init.trunc_normal_(self.weight, mean=mean, std=std, a=-3 * std, b=3 * std)\nå…¶ä¸­ _init_weight() æ˜¯åˆå§‹åŒ–çš„æ–¹æ³•ï¼Œ åœ¨Assignment 1 ä¸­ä¸ºï¼š\n\\[\n\\mathcal{N}\\left( \\mu = 0, \\sigma^{2}=\\frac{2}{d_{\\text{in}} + d_{\\text{out}}} \\right)\n\\quad  \\text{truncated at}  [-3\\sigma, 3\\sigma ]\n\\]\nè¿™ç§åˆå§‹åŒ–çš„æ–¹å¼æ˜¯æœ€å¸¸è§çš„ï¼Œä¹Ÿæ˜¯æ¯”è¾ƒrobustçš„ï¼Œå½“ç„¶ï¼Œå¤§å®¶è¿˜å¯ä»¥å°è¯•ä¸åŒçš„åˆå§‹åŒ–çš„æ–¹å¼, ä¾‹å¦‚Xavier-initializationï¼Œ Kaiming-initializationç­‰ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#embedding-model",
    "href": "posts/CS336/Ass01/ass01.html#embedding-model",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.2 Embedding Model",
    "text": "3.2 Embedding Model\nè®°å¾—æˆ‘ä»¬åœ¨å‰é¢ç¬¬ä¸€ç« èŠ‚ï¼Œå®ç°äº†BPEçš„Tokenizationï¼Œå›é¡¾ä¸€ä¸‹ï¼Œ\n\n\nTL;DR: BPE Tokenization\n\n\nTokenizationçš„æ­¥éª¤å°±æ˜¯æŠŠæ–‡å­—ï¼Œè½¬åŒ–æˆä¸€ä¸ªä¸ªçš„IDsã€‚ ä½†æ˜¯è¿™ä¸ªIDsæ˜¯ä¸èƒ½è¢«æ¨¡å‹å¤„ç†çš„ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬åŒ–æˆä¸€ä¸ªä¸ªçš„Dense Vectorï¼Œè¿™ä¸ªå°±æ˜¯æ‰€è°“çš„ Embeddingã€‚\n\n\nEmbedding çš„æ•°å­¦å®šä¹‰å¦‚ä¸‹ï¼š \\[\n\\text{Embedding}(x) = W_{e}[x]\n\\tag{2}\\]\nå…¶ä¸­ \\(W_{e} \\in \\mathbb{R}^{V \\times d_{\\text{model}}}\\) æ˜¯ Embedding çŸ©é˜µï¼Œ\\(V\\) æ˜¯è¯æ±‡è¡¨çš„å¤§å°ï¼Œ\\(d_{\\text{model}}\\) æ˜¯æ¨¡å‹çš„éšè—ç»´åº¦ï¼Œ\\(x \\in \\mathbb{N}^{B \\times L}\\) æ˜¯è¾“å…¥çš„token IDsï¼Œ \\(B\\) æ˜¯batch sizeï¼Œ\\(L\\)æ˜¯åºåˆ—é•¿åº¦ã€‚\nä»£ç å®ç°å¦‚ä¸‹ï¼š\nclass Embedding(nn.Module):\n    def __init__(\n        self,\n        num_embeddings: int,\n        embedding_dim: int,\n        device: torch.device | None = None,\n        dtype: torch.dtype | None = None,\n    ):\n        super().__init__()\n\n        self.num_embeddings = num_embeddings\n        self.embedding_dim = embedding_dim\n\n        self.weight = nn.Parameter(torch.empty((num_embeddings, embedding_dim), device=device, dtype=dtype))\n\n        self._init_weight()\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        B, L = x.shape  # x: (B, L)\n        out = x.reshape(-1)  # (B*L,)\n        out = self.weight.index_select(0, out)  # (B*L, D)\n        out = out.reshape(B, L, self.embedding_dim)  # (B, L, D)\n\n        return out\nå¾ˆç®€å•çš„ä¹Ÿå¾ˆç›´è§‚ï¼Œå®ƒçš„æƒé‡åˆå§‹åŒ–çš„æ–¹å¼ä¸ºï¼š\n\\[\n\\mathcal{N}\\left( \\mu = 0, \\sigma^{2}=1 \\right)\n\\quad  \\text{truncated at}  [-3, 3]\n\\]\n\n\nNOTE\n\n\nå…¶å®åœ¨forwardä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ self.weight[x] è¿™ä¸€è¡Œä»£ç ï¼Œå°±å¯ä»¥å®ç° Embedding çš„åŠŸèƒ½ï¼Œ ä½†æ˜¯ä¸ºäº†æ›´æ¸…æ™°åœ°å±•ç¤º Embedding çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† index_select() æ¥å®ç°ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#rms-norm",
    "href": "posts/CS336/Ass01/ass01.html#rms-norm",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.3 RMS-Norm",
    "text": "3.3 RMS-Norm\nåœ¨ç°ä»£çš„Language Modelä¸­ï¼Œå¸¸è§çš„Normalizationçš„æ–¹æ³•æ˜¯ RMS-Norm(Zhang and Sennrich 2019)ï¼Œ å…¶æ•°å­¦å®šä¹‰å¦‚ä¸‹ï¼š\n\\[\n\\begin{split}\n\\text{RMSNorm}(a_{i}) &= \\frac{a_{i}}{\\text{RMS}(a)} g_{i} \\\\\n\\text{where} \\quad  \\text{RMS}(a) &= \\sqrt{ \\frac{1}{d_{\\text{model}}} \\sum_{i=1}^{d_{\\text{model}}}a_{i}^{2}  + \\epsilon}\n\\end{split}\n\\]\nå…¶ä¸­ \\(g\\) æ˜¯å¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°ï¼Œå®ƒçš„ç»´åº¦ä¸è¾“å…¥ \\(a\\) ç›¸åŒï¼Œ\\(\\epsilon\\) æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ•°å€¼ï¼Œé˜²æ­¢é™¤ä»¥0ã€‚\nå®ç°RMS-Normçš„æ–¹å¼ä¹Ÿå¾ˆç®€å•ï¼Œä¸è¿‡æœ‰ä¸€ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹å°±æ˜¯ï¼šå¦‚æœæˆ‘ä»¬ç”¨äº†Mixed Precision Trainingï¼Œå½“ç”¨ sqrt() æ—¶ï¼Œ å¯èƒ½ä¼šå¯¼è‡´Underflowï¼Œä¸ºäº†é¿å…è¿™ä¸€ç‚¹ï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°† activation upcaståˆ° float32ï¼Œ ç»“æŸçš„æ—¶å€™å†è¿”å›åŸæ¥çš„æ•°æ®ç±»å‹ã€‚å…·ä½“çš„è¯·çœ‹ä»£ç ï¼š\n\n\ncs336_basics/modules/norm.py\n\nclass RMSNorm(nn.Module):\n    def __init__(\n        self,\n        d_model: int,\n        eps: float = 1e-5,\n        device: torch.device | None = None,\n        dtype: torch.dtype | None = None,\n    ):\n        super().__init__()\n\n        self.d_model = d_model\n        self.eps = eps\n\n        self.weight = nn.Parameter(torch.ones(d_model, device=device, dtype=dtype))\n\n    def _rms(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return torch.sqrt(torch.mean(x**2, dim=-1, keepdim=True) + self.eps)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        input_dtype = x.dtype\n        x = x.to(torch.float32)\n\n        rms = self._rms(x)\n        x_normed = x / rms\n\n        return (x_normed * self.weight).to(input_dtype)\n\nNormalizationçš„ä½ç½®ä¹Ÿæ˜¯å¾ˆæœ‰è®²ç©¶çš„ï¼Œåœ¨ç°ä»£çš„LMä¸­ï¼Œé€šå¸¸ç”¨Pre-Normï¼Œè¿™ä¸€éƒ¨åˆ†ï¼Œç­‰æˆ‘ä»¬ä»‹ç»å®Œäº†æ‰€æœ‰çš„æ¨¡å—ä¹‹åå†æ¥ä»‹ç»ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#pointwise-feed-forward-network",
    "href": "posts/CS336/Ass01/ass01.html#pointwise-feed-forward-network",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.4 PointWise Feed Forward Network",
    "text": "3.4 PointWise Feed Forward Network\nåœ¨åŸå§‹ Transformer (Vaswani et al. 2023)é‡Œï¼ŒFFN æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„ä¸¤å±‚ç»“æ„ï¼šLinear â†’ ReLU â†’ Linearï¼Œå¹¶ä¸”ä¸­é—´éšå±‚ç»´åº¦é€šå¸¸å– d_ff = 4 * d_modelã€‚ä½†åˆ°äº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚ Llama 3ã€Qwen 2.5ï¼‰ï¼ŒFFN çš„è®¾è®¡å‡ºç°äº†ä¸¤ä¸ªå‡ ä¹â€œæ ‡é…â€çš„å˜åŒ–ï¼š\n\næ¢æ¿€æ´»å‡½æ•°\nå¼•å…¥é—¨æ§ï¼ˆgatingï¼‰æœºåˆ¶ã€‚\n\nä¸€ä¸ªå…¸å‹ä»£è¡¨å°±æ˜¯ SwiGLUï¼šå®ƒæŠŠ SiLU/Swish çš„å¹³æ»‘æ¿€æ´»å’Œ GLU çš„é—¨æ§ç›¸ä¹˜ç»“åˆèµ·æ¥ï¼Œå¹¶ä¸”å¾ˆå¤šå®ç°ä¼šåƒ PaLMã€LLaMA ä¸€æ ·å»æ‰çº¿æ€§å±‚ biasï¼ˆæ›´ç®€æ´ã€ä¹Ÿæ›´è´´è¿‘ä¸»æµè®­ç»ƒé…æ–¹ï¼‰ã€‚\nå…ˆçœ‹ SiLUï¼ˆä¹Ÿå¸¸å« Swishï¼‰ï¼Œå®šä¹‰å¾ˆç®€å•ï¼š\n\\[\n\\mathrm{SiLU}(x)=x\\cdot\\sigma(x)=\\frac{x}{1+e^{-x}}\n\\tag{3}\\]\nå®ƒå’Œ ReLU ä¸€æ ·èƒ½æä¾›éçº¿æ€§ï¼Œä½†åœ¨ 0 é™„è¿‘æ˜¯å¹³æ»‘çš„ï¼Œæ¢¯åº¦è¡Œä¸ºæ›´è¿ç»­ã€‚å†çœ‹ GLUï¼Œå®ƒç”¨ä¸€ä¸ª sigmoid åˆ†æ”¯å……å½“â€œé—¨â€ï¼Œå»è°ƒèŠ‚å¦ä¸€æ¡çº¿æ€§åˆ†æ”¯ï¼š\n\\[\n\\mathrm{GLU}(x, W_1, W_2)=\\sigma(W_1x)\\odot (W_2x)\n\\tag{4}\\]\nç›´è§‰ä¸Šï¼Œè¿™ç§é—¨æ§èƒ½ç»™æ¢¯åº¦æä¾›ä¸€æ¡æ›´â€œçº¿æ€§â€çš„é€šè·¯ï¼ŒåŒæ—¶ä¿ç•™éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ã€‚æŠŠä¸¤è€…æ‹¼èµ·æ¥å°±æ˜¯ SwiGLUåœ¨ FFN ä¸­çš„å†™æ³•ï¼š \\[\n\\mathrm{FFN}(x)=W_2\\big(\\mathrm{SiLU}(W_1x)\\odot (W_3x)\\big)\n\\tag{5}\\]\nå…¶ä¸­\\(x\\in\\mathbb{R}^{d_\\text{model}}\\)ï¼Œ\\(W_1,W_3\\in\\mathbb{R}^{d_\\text{ff}\\times d_\\text{model}}\\), \\(W_2\\in\\mathbb{R}^{d_\\text{model}\\times d_\\text{ff}}\\)ã€‚å®è·µé‡Œå¸¸è§çš„ç»éªŒè®¾å®šæ˜¯ \\(d_\\text{ff}=\\frac{8}{3}d_\\text{model}\\)\nä¹Ÿå°±æ˜¯è¯´ï¼Œç›¸æ¯”æ—©æœŸçš„ 4xï¼Œç°ä»£ LLM ç»å¸¸ç”¨ä¸€ä¸ªæ›´â€œæ€§ä»·æ¯”â€æ›´å¥½çš„å®½åº¦é…åˆé—¨æ§ç»“æ„ã€‚Shazeer (Shazeer 2020) çš„å®éªŒä¹Ÿè¡¨æ˜ï¼ŒSwiGLU å¾€å¾€èƒ½åœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šä¼˜äº ReLU æˆ–ä»… SiLUï¼ˆæ— é—¨æ§ï¼‰çš„åŸºçº¿â€”â€”å½“ç„¶ï¼Œæœ€ç»ˆè¿˜æ˜¯è¦å›åˆ°å®éªŒï¼šåœ¨åç»­å¯¹æ¯”ä¸åŒ FFN å˜ä½“æ—¶ï¼Œä½ ä¼šæ›´ç›´è§‚åœ°çœ‹åˆ°è¿™äº›è®¾è®¡åœ¨ lossã€æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæŒ‡æ ‡ä¸Šçš„å·®å¼‚ã€‚\n\n\n\n\n\n\nFigureÂ 3: ä¸åŒæ¿€æ´»å‡½æ•°æ ·å­\n\n\n\nä»£ç çš„å®ç°è¿˜æ˜¯å¾ˆç®€å•çš„ï¼š\n\n\ncs336_basics/modules/ffn.py\n\ndef silu(x: torch.Tensor) -&gt; torch.Tensor:\n    return x * torch.sigmoid(x)\n\n\nclass FFN(nn.Module):\n    def __init__(\n        self,\n        d_model: int,\n        d_ff: int,\n        device: torch.device | None = None,\n        dtype: torch.dtype | None = None,\n    ):\n        super().__init__()\n\n        from cs336_basics.modules.linear import Linear\n\n        self.up = Linear(d_model, d_ff, device=device, dtype=dtype)\n        self.down = Linear(d_ff, d_model, device=device, dtype=dtype)\n        self.gate = Linear(d_model, d_ff, device=device, dtype=dtype)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.down(silu(self.up(x)) * self.gate(x))",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#rope",
    "href": "posts/CS336/Ass01/ass01.html#rope",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.5 RoPE",
    "text": "3.5 RoPE\nTransformer æœ¬èº«å¯¹åºåˆ—çš„é¡ºåºå¹¶ä¸æ•æ„Ÿï¼Œå› æ­¤éœ€è¦æŠŠä½ç½®ä¿¡æ¯æ³¨å…¥åˆ°æ³¨æ„åŠ›æœºåˆ¶é‡Œã€‚é™¤äº†å¸¸è§çš„ç»å¯¹ä½ç½®ç¼–ç ï¼ˆabsolute PEï¼‰ï¼Œç°ä»£ LLM æ›´å¸¸ç”¨çš„ä¸€ç±»æ–¹æ³•æ˜¯ Rotary Position Embeddingsï¼ˆRoPE) (Su et al. 2023)ï¼šå®ƒä¸æ˜¯æŠŠä½ç½®å‘é‡â€œåŠ åˆ° embedding ä¸Šâ€ï¼Œè€Œæ˜¯å¯¹ Q/K å‘é‡åšæŒ‰ç»´åº¦æˆå¯¹çš„æ—‹è½¬ï¼Œä»è€Œè®©æ³¨æ„åŠ›å¤©ç„¶å…·å¤‡ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚\nRoPEçš„æ€æƒ³ä¹Ÿå¾ˆç®€å•ï¼šå¯¹ç¬¬ \\(i\\) ä¸ª token çš„ queryï¼š \\[\nq^{(i)} = W_q x^{(i)} \\in \\mathbb{R}^d\n\\tag{6}\\]\nRoPE ä¼šä¹˜ä¸Šä¸€ä¸ªä½ç½®ç›¸å…³çš„æ—‹è½¬çŸ©é˜µ \\(R_{i}\\): \\[\nq'^{(i)} = R_i q^{(i)} = R_i W_q x^{(i)}\n\\tag{7}\\]\nå…¶ä¸­ \\(R_i\\) ä¼šæŠŠå‘é‡æŒ‰ç»´åº¦ä¸¤ä¸¤åˆ†ç»„ï¼š\\((q_{1},q_{2}), (q_{3},q_{4}), \\dots\\)ï¼ŒæŠŠæ¯ä¸€å¯¹çœ‹ä½œä¸€ä¸ª 2D å‘é‡ï¼Œåœ¨å¹³é¢é‡Œæ—‹è½¬ä¸€ä¸ªè§’åº¦ \\(\\theta_{i,k}\\)ã€‚\n\n\n\n\n\n\nFigureÂ 4: RoPE æ—‹è½¬ç¤ºæ„å›¾ï¼šå¯¹æ¯ä¸€å¯¹ç»´åº¦ \\((q_{2k-1}, q_{2k})\\)ï¼ŒæŒ‰ä½ç½® \\(i\\) æ—‹è½¬è§’åº¦ \\(\\theta_{i,k}\\)ã€‚\n\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹å¦‚ä½•å®šä¹‰æ—‹è½¬è§’åº¦ \\(\\theta_{i,k}\\)ï¼Œä»¥åŠå¦‚ä½•æ„å»ºæ—‹è½¬çŸ©é˜µ \\(R_i\\)ã€‚\n\nå®šä¹‰æ—‹è½¬è§’åº¦ \\(\\theta_{i,k}\\) \næ ¹æ®RoPE(Su et al. 2023)çš„è®¾å®šï¼Œ å¯¹ç¬¬ \\(k\\) å¯¹ç»´åº¦ \\(k \\in \\{1,\\dots, d/2\\}\\)ï¼Œæ—‹è½¬è§’åº¦å®šä¹‰ä¸ºï¼š \\[\n\\theta_{i,k} = i \\cdot \\Theta^{-\\frac{2k-2}{d}}\n\\tag{8}\\]\nè¿™é‡Œ \\(\\Theta\\) æ˜¯ä¸€ä¸ªå¸¸æ•°æˆ‘ä»¬é€šå¸¸æŠŠ \\(\\Theta\\) è®¾ä¸º 10,000ï¼Œè¿™æ ·ç¬¬ \\(k\\) å¯¹ç»´åº¦çš„é¢‘ç‡æ˜¯ \\(\\frac{1}{10000^{(2k-2)/d}}\\)ï¼Œå’Œ Transformer ç»å¯¹ä½ç½®ç¼–ç é‡Œçš„é¢‘ç‡è®¾è®¡æ˜¯ä¸€è‡´çš„ã€‚\ninv_freq = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))\nç›´è§‰ä¸Šï¼š\n\nä¸åŒç»´åº¦å¯¹åº”ä¸åŒâ€œæ—‹è½¬é¢‘ç‡â€ï¼ˆåƒä¸€ç»„ä¸åŒæ³¢é•¿çš„æ­£å¼¦/ä½™å¼¦ï¼‰\nä½ç½®è¶Šé åï¼Œæ—‹è½¬è§’åº¦è¶Šå¤§, ç”¨äºç¼–ç æ›´é•¿è·ç¦»çš„ç›¸å¯¹ä½ç½®å…³ç³»\næœ€ç»ˆè®©æ³¨æ„åŠ›å¯ä»¥é€šè¿‡ Q/K çš„ç›¸å¯¹æ—‹è½¬ï¼Œç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯\n\n\nå®šä¹‰æ—‹è½¬å— \\(R^i_k\\) \nå…¶ä¸­ï¼Œæ¯ä¸€å¯¹ç»´åº¦ \\((q_{2k-1}, q_{2k})\\) å¯¹åº”ä¸€ä¸ª \\(2\\times 2\\) æ—‹è½¬å—ï¼š \\[\nR^i_k =\n\\begin{bmatrix}\n\\cos(\\theta_{i,k}) & -\\sin(\\theta_{i,k}) \\\\\n\\sin(\\theta_{i,k}) & \\cos(\\theta_{i,k})\n\\end{bmatrix}\n\\tag{9}\\]\n\næ•´ä½“æ—‹è½¬çŸ©é˜µ \\(R_i\\) \næ•´ä½“ \\(R_i\\) æ˜¯ä¸€ä¸ª \\(d\\times d\\) çš„å—å¯¹è§’çŸ©é˜µï¼Œç”± \\(d/2\\) ä¸ª\\(2\\times 2\\) å—ç»„æˆï¼ˆå…¶å®ƒä½ç½®ä¸º 0ï¼‰ã€‚æ•°å­¦ä¸Šå†™æˆï¼š\n\\[\nR_i=\n\\begin{bmatrix}\nR^i_1 & 0      & 0      & \\cdots & 0 \\\\\n0     & R^i_2  & 0      & \\cdots & 0 \\\\\n0     & 0      & R^i_3  & \\cdots & 0 \\\\\n\\vdots& \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0     & 0      & 0      & \\cdots & R^i_{d/2}\n\\end{bmatrix}\n\\tag{10}\\]\n\nè¿™æ ·ï¼Œå¯¹äºç¬¬ \\(j\\) ä¸ª token çš„ key å‘é‡ \\(k^{(j)}\\)ï¼ŒRoPE ä¹Ÿä¼šåšç±»ä¼¼çš„æ—‹è½¬ï¼š\n\\[\nk'^{(j)} = R_j k^{(j)}\n\\tag{11}\\]\nè¿™æ ·åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° \\(q'^{(i)} \\cdot k'^{(j)}\\) æ—¶ï¼Œä½ç½®å·®å¼‚ä¼šä»¥â€œç›¸å¯¹æ—‹è½¬â€çš„å½¢å¼ä½“ç°å‡ºæ¥ï¼Œè¿™ä¹Ÿæ˜¯ RoPE åœ¨é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸­éå¸¸å¸¸ç”¨çš„åŸå› ä¹‹ä¸€ã€‚\n\\[\nq'^{(i)} \\cdot k'^{(j)} = (R_i q^{(i)}) \\cdot (R_j k^{(j)}) = q^{(i)} \\cdot (R_i^T R_j k^{(j)})\n\\tag{12}\\]\n\n3.5.1 RoPE çš„å®ç°ç»†èŠ‚\nRoPE å±‚æ²¡æœ‰å¯å­¦ä¹ å‚æ•°ã€‚ä¸ºäº†æ•ˆç‡ï¼Œé€šå¸¸ä¼šï¼š\n\né¢„è®¡ç®—æ‰€æœ‰ \\(\\cos(\\theta_{i,k})\\) ä¸ \\(\\sin(\\theta_{i,k})\\)\nä½œä¸º buffer ç¼“å­˜åœ¨æ¨¡å—é‡Œï¼Œè€Œä¸æ˜¯ nn.Parameterï¼ˆå› ä¸ºå®ƒä»¬æ˜¯å›ºå®šçš„ï¼‰\nç”šè‡³å¯ä»¥è®©æ‰€æœ‰ Transformer å±‚å…±äº«åŒä¸€ä¸ª RoPE æ¨¡å—ï¼ˆè·¨å±‚å¤ç”¨ç¼“å­˜ï¼‰\n\nå®ç°ä¸Šå¸¸ç”¨ï¼š\n\nself.register_buffer(..., persistent=False) æ¥ä¿å­˜é¢„è®¡ç®—å¥½çš„ sin/cosï¼ˆä¸è¿› state_dict æˆ–ä¸ä½œä¸ºå¯è®­ç»ƒå‚æ•°ï¼‰\nåªè¦åºåˆ—é•¿åº¦/ç»´åº¦ä¸å˜ï¼Œè¿™äº›å€¼å¯ä»¥åœ¨ä¸åŒ batchã€ä¸åŒ layer é—´å¤ç”¨\n\nä¸è¿‡ï¼Œåœ¨å®é™…å®ç° RoPE æ—‹è½¬æ—¶ï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦æ˜¾å¼æ„å»ºå¤§å—å¯¹è§’çŸ©é˜µ \\(R_i\\)ï¼Œè€Œæ˜¯æŠŠå‘é‡æŒ‰ 2 ç»´ä¸€ç»„é…å¯¹ \\((x_{2k-1}, x_{2k})\\) ï¼Œå¯¹æ¯ä¸€ç»„åšä¸€ä¸ªå¹³é¢æ—‹è½¬ï¼š\n\\[\nR_{\\Theta,m}^{d} \\mathbf{x}\n=\n\\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\\\\\nx_4\\\\\n\\vdots\\\\\nx_{d-1}\\\\\nx_d\n\\end{pmatrix}\n\\otimes\n\\begin{pmatrix}\n\\cos(m\\theta_{1})\\\\\n\\cos(m\\theta_{1})\\\\\n\\cos(m\\theta_{2})\\\\\n\\cos(m\\theta_{2})\\\\\n\\vdots\\\\\n\\cos\\!\\big(m\\theta_{d/2}\\big)\\\\\n\\cos\\!\\big(m\\theta_{d/2}\\big)\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n- x_2\\\\\nx_1\\\\\n- x_4\\\\\nx_3\\\\\n\\vdots\\\\\n- x_d\\\\\nx_{d-1}\n\\end{pmatrix}\n\\otimes\n\\begin{pmatrix}\n\\sin(m\\theta_{1})\\\\\n\\sin(m\\theta_{1})\\\\\n\\sin(m\\theta_{2})\\\\\n\\sin(m\\theta_{2})\\\\\n\\vdots\\\\\n\\sin\\!\\big(m\\theta_{d/2}\\big)\\\\\n\\sin\\!\\big(m\\theta_{d/2}\\big)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_1 \\cos(m\\theta_{1}) - x_2 \\sin(m\\theta_{1})\\\\\nx_2 \\cos(m\\theta_{1}) + x_1 \\sin(m\\theta_{1})\\\\\nx_3 \\cos(m\\theta_{2}) - x_4 \\sin(m\\theta_{2})\\\\\nx_4 \\cos(m\\theta_{2}) + x_3 \\sin(m\\theta_{2})\\\\\n\\vdots\\\\\nx_{d-1} \\cos(m\\theta_{d/2}) - x_d \\sin(m\\theta_{d/2})\\\\\nx_d \\cos(m\\theta_{d/2}) + x_{d-1} \\sin(m\\theta_{d/2})\n\\end{pmatrix}\n\\]\nä»£ç çš„å®ç°ä¹Ÿå¾ˆç®€å•ï¼š\n\n\ncs336_basics/modules/rope.py\n\nclass RoPEEmbedding(nn.Module):\n    def __init__(\n        self,\n        theta: float,\n        d_k: int,\n        max_seq_len: int,\n        device: torch.device | None = None,\n    ):\n        super().__init__()\n\n        self.theta = theta\n        self.d_k = d_k\n        self.max_seq_len = max_seq_len\n\n        inv_freq = 1.0 / (theta ** (torch.arange(0, d_k, 2, device=device, dtype=torch.float32) / d_k)) \n\n        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n\n    def _rotate_half(self, x):\n        x = einops.rearrange(x, \"... (d j) -&gt; ... d j\", j=2) \n        x1, x2 = x.unbind(dim=-1) \n        return einops.rearrange(torch.stack((-x2, x1), dim=-1), \"... d j-&gt; ... (d j)\") \n\n    def forward(self, x: torch.Tensor, token_positions: int | None = None) -&gt; torch.Tensor:\n        if token_positions is None:\n            seq_len = x.shape[-2]\n            token_positions = torch.arange(seq_len, device=x.device)\n            token_positions = token_positions.unsqueeze(0)\n\n        theta = torch.einsum(\"...i , j -&gt; ... i j\", token_positions, self.inv_freq)\n        cos = torch.cos(theta).repeat_interleave(2, dim=-1) \n        sin = torch.sin(theta).repeat_interleave(2, dim=-1) \n\n        x_rotated = (x * cos) + (self._rotate_half(x) * sin)\n        return x_rotated\n\n\n\nNOTE: RoPE in Open Source Project\n\n\nåœ¨é˜…è¯»å…¶ä»–LLMçš„æºä»£ç æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šç¢°åˆ°ä»¥ä¸‹å½¢å¼çš„å®ç°ï¼š\ndef rotate_half(x: torch.Tensor) -&gt; torch.Tensor:\n    x1, x2 = x.chunk(2, dim=-1) \n    return torch.cat((-x2, x1), dim=-1) \n\n\ndef forward(self, x: torch.Tensor, token_positions: int | None = None) -&gt; torch.Tensor:\n    if token_positions is None:\n        seq_len = x.shape[-2]\n        token_positions = torch.arange(seq_len, device=x.device)\n        token_positions = token_positions.unsqueeze(0)\n\n    theta = torch.einsum(\"...i , j -&gt; ... i j\", token_positions, self.inv_freq)\n    theta = torch.cat([theta, theta], dim=-1) \n    cos = torch.cos(theta)\n    sin = torch.sin(theta)\n    x_rotated = (x * cos) + (self._rotate_half(x) * sin)\n    return x_rotated\nè¿™æ®µå®ç°çœ‹èµ·æ¥å’Œè®ºæ–‡é‡Œçš„ \\(R_i\\) å—å¯¹è§’çŸ©é˜µå…¬å¼ä¸ä¸€æ ·ï¼šè®ºæ–‡å†™çš„æ˜¯â€œæ¯ä¸¤ç»´ä¸€ç»„åš 2D æ—‹è½¬â€ï¼Œè€Œè¿™é‡ŒæŠŠå‘é‡æ‹†æˆä¸¤åŠ (x1, x2)ï¼Œå†ç”¨ rotate_half åšæ‹¼æ¥ï¼Œåƒæ˜¯åœ¨â€œæ•´ä½“æ¢ä½â€ã€‚\n\\[\n\\operatorname{rotate\\_half}(x) = (-x_{\\text{second half}},\\ x_{\\text{first half}})\n\\]\nè¿™å¯¹åº”çš„å°±æ˜¯â€œäºŒç»´æ—‹è½¬é‡Œé‚£ä¸ªæŠŠ \\((a,b)\\) å˜æˆ \\((-b,a)\\)â€çš„æ“ä½œï¼Œåªä¸è¿‡å®ƒæŠŠé…å¯¹æ–¹å¼ä»è®ºæ–‡å¸¸è§çš„â€œ(1,2)(3,4)â€¦é‚»æ¥é…å¯¹â€ï¼Œæ¢æˆäº†â€œ(å‰åŠ, ååŠ) çš„é…å¯¹â€ã€‚ åªè¦ cos/sin çš„é‡å¤æ–¹å¼ å’Œ rotate çš„é…å¯¹æ–¹å¼ ä¸€è‡´ï¼Œé…å¯¹æ˜¯é‚»æ¥è¿˜æ˜¯å‰ååŠï¼Œæœ¬è´¨éƒ½åœ¨åšåŒä¸€ä¸ª block-rotationã€‚\nè¿™ä¸¤ç§åªæ˜¯åæ ‡é‡æ’ï¼ˆpermutationï¼‰ä¸åŒï¼šå­˜åœ¨ä¸€ä¸ªç½®æ¢çŸ©é˜µ Pï¼Œä½¿å¾—\n\\[\nR_{\\text{half-split}} = P^\\top R_{\\text{adjacent}} P\n\\]\nå‡ ä½•ä¸Šä»ç„¶æ˜¯å¯¹æ¯ä¸ª 2D å­ç©ºé—´åšæ—‹è½¬ï¼Œæ‰€ä»¥ä¸€æ ·å¯è¡Œã€‚\n\n\nå½“ç„¶ï¼Œé™¤äº†ä¸Šé¢çš„è¿™ç§å½¢å¼ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æ„é€ Complex Numberçš„å½¢å¼æ¥å®ŒæˆVectorçš„æ—‹è½¬ï¼Œåœ¨è¿™é‡Œå°±ä¸å±•å¼€äº†ã€‚æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒLLaMAçš„Inference Codeã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#multi-headed-attention",
    "href": "posts/CS336/Ass01/ass01.html#multi-headed-attention",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.6 Multi-Headed Attention",
    "text": "3.6 Multi-Headed Attention\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥å®ç°Transformerä¸­ï¼Œæœ€é‡è¦ä¹Ÿæ˜¯ç›¸å¯¹æ¯”è¾ƒå¤æ‚çš„éƒ¨åˆ†ï¼ŒAttentionï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ä»€ä¹ˆæ˜¯Scaled Dot Product Attention\n\n3.6.1 Scaled Dot-Product Attention\nåœ¨ Transformer(Vaswani et al. 2023)ä¸­ï¼Œæœ€æ ¸å¿ƒçš„è®¡ç®—ä¹‹ä¸€å°±æ˜¯ scaled dot-product attentionã€‚å®ƒå¯ä»¥çœ‹ä½œï¼š\n\nè®¡ç®— query å’Œ key çš„ç›¸ä¼¼åº¦ï¼ˆæ‰“åˆ†ï¼‰ï¼Œ\næŠŠè¿™äº›åˆ†æ•°(logits)å½’ä¸€åŒ–æˆæ¦‚ç‡åˆ†å¸ƒï¼Œ\næœ€åç”¨è¿™ä¸ªåˆ†å¸ƒå¯¹ value åšåŠ æƒæ±‚å’Œã€‚\n\né¦–å…ˆæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•å°†åˆ†æ•°(logits)å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬éœ€è¦ç”¨åˆ°çš„å°±æ˜¯ Softmax å‡½æ•°\n\n3.6.1.1 Softmax Function\nSoftmax çš„å®šä¹‰æ˜¯ï¼š\n\\[\n\\mathrm{softmax}(v)_i=\\frac{\\exp(v_i)}{\\sum_{j=1}^{n}\\exp(v_j)}\n\\tag{13}\\]\nç›´è§‰ä¸Šï¼Œsoftmax ä¼šæŠŠä»»æ„å®æ•°å‘é‡å˜æˆä¸€ä¸ªéè´Ÿã€å’Œä¸º 1 çš„åˆ†å¸ƒï¼Œå› æ­¤å¸¸ç”¨äºæ³¨æ„åŠ›é‡Œçš„â€œæƒé‡å½’ä¸€åŒ–â€ã€‚ ç„¶è€Œï¼Œç›´æ¥ç®— softmax æœ‰ä¸€ä¸ª å¸¸è§æ•°å€¼é—®é¢˜ï¼šå½“ \\(v_i\\) å¾ˆå¤§æ—¶ï¼Œ\\(\\exp(v_i)\\) å¯èƒ½æº¢å‡ºå˜æˆ infï¼Œä»è€Œå¯¼è‡´ inf/inf = NaNã€‚ ä»”ç»†è§‚å¯Ÿæˆ‘ä»¬å¯ä»¥å‘ç°softmax å¯¹æ‰€æœ‰è¾“å…¥åŒæ—¶åŠ åŒä¸€ä¸ªå¸¸æ•°ä¸å˜ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹ä»»æ„å¸¸æ•° \\(c\\)ï¼š\n\\[\n\\mathrm{softmax}(v)=\\mathrm{softmax}(v+c).\n\\tag{14}\\]\nè¯æ˜å¾ˆç®€å•ï¼šåˆ†å­åˆ†æ¯éƒ½ä¼šå¤šä¹˜ä¸€ä¸ª \\(\\exp(c)\\)ï¼Œä¼šæŠµæ¶ˆæ‰ã€‚å› æ­¤å·¥ç¨‹å®ç°é‡Œé€šå¸¸å–ï¼š\n\\[\nc=-\\max_i v_i,\n\\tag{15}\\]\nä¹Ÿå°±æ˜¯æŠŠæœ€å¤§å€¼å‡åˆ° 0ï¼Œè¿™æ · \\(\\exp(\\cdot)\\) çš„æœ€å¤§è¾“å…¥ä¸º 0ï¼Œä¸ä¼šçˆ†æ‰ï¼š\n\\[\n\\mathrm{softmax}(v)_i\n=\n\\frac{\\exp(v_i-\\max(v))}{\\sum_j \\exp(v_j-\\max(v))}.\n\\tag{16}\\]\n\n\ncs336_basics/modules/attention.py\n\ndef stable_softmax(\n    logits: torch.Tensor,\n    dim: int = -1,\n) -&gt; torch.Tensor:\n    max_logits = torch.max(logits, dim=dim, keepdim=True).values\n    exp_logits = torch.exp(logits - max_logits)\n    sum_exp_logits = torch.sum(exp_logits, dim=dim, keepdim=True)\n    softmax = exp_logits / sum_exp_logits\n    return softmax\n\n\n\n3.6.1.2 Scaled Dot Product Attention\næ¥ç€ï¼Œæˆ‘ä»¬æ¥çœ‹Scaled Dot-Product Attentionï¼Œ å…¶æ•°å­¦å®šä¹‰ä¸ºï¼š\n\\[\n\\mathrm{Attention}(Q,K,V)=\\mathrm{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V,\n\\tag{17}\\]\nå…¶ä¸­ï¼š\n\n\\(Q\\in\\mathbb{R}^{n\\times d_k}\\)ï¼š\\(n\\) ä¸ª query\n\\(K\\in\\mathbb{R}^{m\\times d_k}\\)ï¼š\\(m\\) ä¸ª key\n\\(V\\in\\mathbb{R}^{m\\times d_v}\\)ï¼š\\(m\\) ä¸ª valueï¼ˆä¸ key ä¸€ä¸€å¯¹åº”ï¼‰\n\nè¿™é‡Œçš„ \\(\\frac{1}{\\sqrt{d_k}}\\) æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„ç¼©æ”¾é¡¹ï¼šå½“ \\(d_k\\) å˜å¤§æ—¶ï¼Œç‚¹ç§¯çš„æ–¹å·®ä¼šå˜å¤§ï¼Œsoftmax ä¼šæ›´å®¹æ˜“é¥±å’Œï¼ˆå˜å¾—æç«¯å°–é”ï¼‰ï¼Œç¼©æ”¾èƒ½è®©è®­ç»ƒæ›´ç¨³å®šã€‚\n\nWe suspect that for large values of \\(d_k\\), the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by \\(\\frac{1}{\\sqrt{d_k}}\\).  Attention Is All You Need, p.Â 4\n\næˆ‘ä»¬æ¥çœ‹ä¸‹é¢çš„å›¾ï¼Œå±•ç¤ºäº†ä¸åŒç¼©æ”¾å› å­å¯¹ softmax åˆ†å¸ƒçš„å½±å“ï¼š\n\n\n\n\n\n\nFigureÂ 5: Attention ä¸­çš„ç¼©æ”¾å› å­å¯¹ softmax åˆ†å¸ƒçš„å½±å“ï¼Œ å½“\\(d_k\\) è¾ƒå¤§æ—¶ï¼Œç¼©æ”¾èƒ½é˜²æ­¢ softmax è¿‡äºå°–é”ã€‚\n\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹ä»£ç å®ç°ï¼š\ndef scaled_dot_product_attention(\n    query: torch.Tensor,\n    key: torch.Tensor,\n    value: torch.Tensor,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) / (d_k**0.5)\n\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n\n    attn_weights = stable_softmax(scores, dim=-1)\n    output = torch.matmul(attn_weights, value)\n    return output\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°æœ‰ä¸€ä¸ªMaskingï¼Œè¿™ä¸ªmaskçš„ä½œç”¨æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ\n\n\n3.6.1.3 Causal Masking\nåœ¨å¾ˆå¤šåœºæ™¯ä¸‹æˆ‘ä»¬éœ€è¦ maskï¼ˆä¾‹å¦‚ causal LM ä¸­ä¸å…è®¸çœ‹æœªæ¥ tokenï¼Œæˆ– padding ä½ç½®ä¸å‚ä¸æ³¨æ„åŠ›ï¼‰ã€‚mask çš„å½¢çŠ¶æ˜¯ï¼š\n\\[\nM =\n\\begin{bmatrix}\nTrue & False & \\cdots & False \\\\\nTrue & True  & \\cdots & False \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nTrue & True  & \\cdots & True\n\\end{bmatrix}\n\\]\næ³¨æ„è¿™é‡Œæœ‰ä¸ªå°çº¦å®šï¼ˆå®¹æ˜“æ··æ·†ï¼‰ï¼š\n\nTrue è¡¨ç¤ºå…è®¸ attendï¼ˆä¿¡æ¯æµé€šï¼‰\n\nFalse è¡¨ç¤ºä¸å…è®¸ attendï¼ˆéœ€è¦å±è”½ï¼‰\n\n\n\n\n\n\n\nFigureÂ 6: Causal Mask ç¤ºä¾‹å›¾\n\n\n\nè®¡ç®—ä¸Šï¼Œæˆ‘ä»¬ä¸ä¼šçœŸçš„åˆ æ‰è¢«å±è”½çš„ key/valueï¼ˆé‚£æ ·æ•ˆç‡ä½ï¼‰ï¼Œè€Œæ˜¯åœ¨ softmax ä¹‹å‰çš„æ‰“åˆ†çŸ©é˜µä¸ŠåŠ¨æ‰‹è„šï¼šå¯¹æ‰€æœ‰ mask ä¸º False çš„ä½ç½®åŠ ä¸Š \\(-\\infty\\)ï¼š\n\\[\nS_{ij}=\n\\begin{cases}\nS_{ij}, & M_{ij}=\\mathrm{True}\\\\\n-\\infty, & M_{ij}=\\mathrm{False}\n\\end{cases}\n\\tag{18}\\]\nè¿™æ · softmax åï¼š\n\\[\n\\exp(-\\infty)=0\n\\tag{19}\\]\nå¯¹åº”æƒé‡ä¸¥æ ¼ä¸º 0ï¼Œè¢«å±è”½çš„ä½ç½®è‡ªç„¶ä¸ä¼šå¯¹è¾“å‡ºäº§ç”Ÿè´¡çŒ®ã€‚æœ€ç»ˆè¾“å‡ºæ˜¯ï¼š\n\\[\n\\mathrm{Attention}(Q,K,V)=\\mathrm{softmax}(S)V\n\\tag{20}\\]\nåœ¨è¯­è¨€æ¨¡å‹é‡Œï¼Œtoken \\(i\\) é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ—¶ä¸åº”è¯¥è®¿é—® \\(i\\) ä¹‹åçš„ token è¡¨ç¤ºï¼Œå¦åˆ™ä¼šæ³„éœ²ç­”æ¡ˆï¼Œè®­ç»ƒç›®æ ‡ä¼šè¢«â€œä½œå¼Šâ€è½»æ˜“å®Œæˆã€‚ å®ç°ä¸Šå¯ä»¥ç”¨\n\ntorch.triuï¼ˆä¸Šä¸‰è§’ï¼‰æ„é€  False åŒºåŸŸï¼Œ\nç”¨å¹¿æ’­æ¯”è¾ƒ j &lt;= iã€‚\n\n\n\ncs336_basics/modules/attention.py\n\n# åˆ©ç”¨ torch.tril åˆ›å»ºå› æœæ©ç \ndef _create_causal_mask(self, seq_len: int, device: torch.device) -&gt; torch.Tensor:\n    mask = torch.tril(torch.ones(seq_len, seq_len, device=device)).bool()\n    return mask.unsqueeze(0).unsqueeze(0)\n\n# åˆ©ç”¨å¹¿æ’­æ¯”è¾ƒåˆ›å»ºå› æœæ©ç \ndef _create_causal_mask(self, seq_len: int, device: torch.device) -&gt; torch.Tensor:\n    positions = torch.arange(seq_len, device=device)\n    mask = positions.unsqueeze(0) &lt;= positions.unsqueeze(1)\n    return mask.unsqueeze(0).unsqueeze(0)\n\ndef scaled_dot_product_attention(\n    query: torch.Tensor,\n    key: torch.Tensor,\n    value: torch.Tensor,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    ...\n\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n\n    ...\n\n\nAttention çš„æœ¬è´¨:\næ˜¯â€œç›¸ä¼¼åº¦æ‰“åˆ† + softmax å½’ä¸€åŒ– + å¯¹ V åŠ æƒæ±‚å’Œâ€ã€‚å·¥ç¨‹å®ç°æ—¶è¦ç‰¹åˆ«æ³¨æ„ softmax çš„æ•°å€¼ç¨³å®šæ€§ï¼ˆå‡æœ€å¤§å€¼ï¼‰å’Œ maskingï¼ˆsoftmax å‰åŠ  \\(-\\infty\\)ï¼‰ï¼Œè¿™ä¸¤ç‚¹å‡ ä¹å†³å®šäº†æ³¨æ„åŠ›å®ç°æ˜¯å¦ç¨³å®šã€æ˜¯å¦é«˜æ•ˆã€‚\n\n\n\n\n3.6.2 Multi Headed Attention\nåœ¨å®ç°äº†å•ä¸ªAttentionæ¨¡å—ä¹‹åï¼Œæˆ‘ä»¬çœ‹çœ‹è¿™äº›å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·ï¼Œå®ç°æˆ‘ä»¬çš„Multi Headed Attention\n\nInstead of performing a single attention function with \\(d_{\\text{model}}\\)-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to \\(d_k\\), \\(d_k\\) and \\(d_v\\) dimensions, respectively.  Attention Is All You Need, p.Â 4\n\nMulti-head attention çš„å®šä¹‰æ˜¯ï¼š\n\\[\n\\mathrm{MultiHead}(Q,K,V) = \\mathrm{Concat}(\\mathrm{head}_1,\\dots,\\mathrm{head}_h)\n\\tag{21}\\]\nå…¶ä¸­æ¯ä¸ª head éƒ½æ˜¯ä¸€æ¬¡æ ‡å‡† scaled dot-product attention (EquationÂ 17)ï¼š\n\\[\n\\mathrm{head}_i = \\mathrm{Attention}(Q_i, K_i, V_i)\n\\tag{22}\\]\nè¿™é‡Œçš„ \\(Q_i, K_i, V_i\\) æ˜¯æŠŠ \\(Q,K,V\\) æ²¿ embedding ç»´åº¦åˆ‡åˆ†å¾—åˆ°çš„ç¬¬ \\(i\\) ä¸ª sliceï¼ˆæ¯ä¸ª head çš„ç»´åº¦æ˜¯ \\(d_k\\) æˆ– \\(d_v\\)ï¼‰ã€‚\nåœ¨ self-attention åœºæ™¯ä¸­ï¼Œ\\(Q,K,V\\) éƒ½ç”±åŒä¸€ä¸ªè¾“å…¥ \\(x\\) æŠ•å½±å¾—åˆ°ï¼š\n\\[\n\\mathrm{MultiHeadSelfAttention}(x) = W_O \\cdot \\mathrm{MultiHead}(W_Q x,\\; W_K x,\\; W_V x)\n\\tag{23}\\]\nå¯å­¦ä¹ å‚æ•°ä¸ºï¼š\n\\[\nW_Q \\in \\mathbb{R}^{h d_k \\times d_{\\text{model}}},\\quad\nW_K \\in \\mathbb{R}^{h d_k \\times d_{\\text{model}}},\\quad\nW_V \\in \\mathbb{R}^{h d_v \\times d_{\\text{model}}},\\quad\nW_O \\in \\mathbb{R}^{d_{\\text{model}} \\times h d_v}.\n\\tag{24}\\]\nä¸€ä¸ªå¾ˆé‡è¦çš„å·¥ç¨‹è§†è§’æ˜¯ï¼šå› ä¸ºåé¢ä¼šæŠŠè¾“å‡ºç»´åº¦ reshape æˆ \\((h,\\text{head\\_dim})\\)ï¼Œæ‰€ä»¥ä½ å¯ä»¥æŠŠ \\(W_Q,W_K,W_V\\) çœ‹æˆâ€œæ¯ä¸ª head å„æœ‰ä¸€ä»½æŠ•å½±çŸ©é˜µâ€ï¼Œåªä¸è¿‡å®ƒä»¬åœ¨å®ç°ä¸Šè¢«æ‹¼åˆ°åŒä¸€ä¸ªå¤§çŸ©é˜µé‡Œã€‚\n\n\n3.6.3 Shape Transformations in Attention\nåœ¨ç»§ç»­å®Œæˆ MHA ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆç†æ¸…æ¥š shape å˜åŒ–ã€‚å‡è®¾ï¼š\n\nè¾“å…¥ \\(x\\) çš„ shape æ˜¯ (batch_size, seq_len, d_model)\nhead æ•°é‡æ˜¯ num_heads\næ¯ä¸ª head çš„ç»´åº¦æ˜¯ d_k = d_model // num_heads\n\né‚£ä¹ˆï¼Œè®¡ç®— \\(Q,K,V\\) çš„çº¿æ€§æŠ•å½±åï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬ reshape æˆ (batch_size, num_heads, seq_len, d_k)ï¼Œä»¥ä¾¿æ¯ä¸ª head ç‹¬ç«‹è®¡ç®—æ³¨æ„åŠ›ã€‚å®ç°ä¸Šé€šå¸¸ç”¨ä»¥ä¸‹ä¸¤æ­¥ï¼š\n\nå…ˆç”¨ view() æŠŠæœ€åä¸€ç»´æ‹†æˆ (num_heads, d_k)ï¼Œå˜æˆ (batch_size, seq_len, num_heads, d_k)\nå†ç”¨ transpose() æŠŠ num_heads ç»´åº¦ç§»åˆ°ç¬¬äºŒç»´ï¼Œå˜æˆ (batch_size, num_heads, seq_len, d_k)\n\nä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æˆ‘ä»¬çš„scores:\nQ (batch_size, seq_len, num_heads, d_k) @ K^T (batch_size, num_heads, d_k, seq_len)  -&gt; Score (batch_size, num_heads, seq_len, seq_len)\nsoftmax å’Œ maskï¼Œä¸ä¼šæ”¹å˜ shapeï¼Œæœ€åå¯¹ V åšåŠ æƒæ±‚å’Œåï¼Œè¾“å‡º shape æ˜¯ (batch_size, num_heads, seq_len, d_k)ã€‚æœ€åä¸€æ­¥æ˜¯æŠŠå¤šå¤´è¾“å‡ºæ‹¼å›åŸå§‹ç»´åº¦ï¼š\n\nå…ˆç”¨ transpose() æŠŠ num_heads ç»´åº¦ç§»å›ç¬¬ä¸‰ç»´ï¼Œå˜æˆ (batch_size, seq_len, num_heads, d_k)\nå†ç”¨ contiguous().view() æŠŠæœ€åä¸¤ç»´æ‹¼å›å»ï¼Œå˜æˆ (batch_size, seq_len, d_model)ã€‚\næœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚ \\(W_O\\) æŠ•å½±å›åŸå§‹ç»´åº¦ã€‚\næœ€ç»ˆè¾“å‡º shape æ˜¯ (batch_size, seq_len, d_model)ã€‚\n\nx : (B, S, D)\n    +--&gt; Q = x W_Q : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)\n    |\n    +--&gt; K = x W_K : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)\n    |\n    +--&gt; V = x W_V : (B,S,D) --&gt; view (B,S,H,d_k) --&gt; transpose -&gt; (B,H,S,d_k)\n\n             K^T : (B,H,d_k,S)\nscores = Q @ K^T  -----------------&gt; scores : (B,H,S,S)\n        (B,H,S,d_k) @ (B,H,d_k,S)\n\nscores / sqrt(d_k) ----------------&gt; (B,H,S,S)\n+ mask (add -inf) -----------------&gt; (B,H,S,S)\nsoftmax (last dim) ----------------&gt; attn : (B,H,S,S)\n\nout_heads = attn @ V  -------------&gt; out_heads : (B,H,S,d_k)\n            (B,H,S,S) @ (B,H,S,d_k)\n\ntranspose(1,2) --------------------&gt; (B,S,H,d_k)\ncontiguous().view(B,S,D) ----------&gt; out : (B,S,D)\nW_O (Linear) ----------------------&gt; y : (B,S,D)\n\n\n3.6.4 RoPE in Attention\nåœ¨ä½¿ç”¨ RoPE çš„ç‰ˆæœ¬ä¸­ï¼Œéœ€è¦å¯¹ Q å’Œ K åšåŒæ ·çš„ä½ç½®æ—‹è½¬ï¼š\n\nå¯¹æ¯ä¸ª head çš„ \\(Q\\) åº”ç”¨ RoPE\nå¯¹æ¯ä¸ª head çš„ \\(K\\) åº”ç”¨ RoPE\nä¸è¦å¯¹ \\(V\\) åº”ç”¨ RoPE\n\nåŸå› æ˜¯ï¼šRoPE å½±å“çš„æ˜¯â€œç›¸ä¼¼åº¦æ‰“åˆ†â€ï¼ˆ\\(QK^\\top\\)ï¼‰çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼›è€Œ \\(V\\) æ˜¯è¢«åŠ æƒæ±‡èšçš„å†…å®¹æœ¬èº«ï¼Œé€šå¸¸ä¸éœ€è¦åšæ—‹è½¬ã€‚\nå¦å¤–ï¼ŒRoPE çš„ä¸€ä¸ªå®ç°ç»†èŠ‚æ˜¯ï¼šåœ¨ multi-head ä¸­ï¼Œhead ç»´å¯ä»¥è§†ä¸º batch ç»´æ¥å¤„ç†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒåŒä¸€ä¸ªä½ç½® \\(i\\) å¯¹åº”çš„æ—‹è½¬ï¼ˆcos/sinï¼‰åº”è¯¥å¯¹ æ‰€æœ‰ head å…±äº«ï¼Œæ¯ä¸ª head ç‹¬ç«‹åš attentionï¼Œä½†æ—‹è½¬è§„åˆ™ä¸€è‡´ã€‚\næœ‰äº†è¿™äº›æ¨¡å—ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†æœ€ç»ˆçš„MHA\n\n\ncs336_basics/modules/attention.py\n\nclass MHA(nn.Module):\n    def __init__(\n        self,\n        d_model: int,\n        num_heads: int,\n        use_rope: bool = False,\n        theta: float = 10000.0,\n        max_seq_len: int = 2048,\n        device: torch.device | None = None,\n        dtype: torch.dtype | None = None,\n    ):\n        super().__init__()\n\n        from cs336_basics.modules.linear import Linear\n        from cs336_basics.modules.rope import RoPEEmbedding\n\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n\n        self.q_linear = Linear(d_model, d_model, device=device, dtype=dtype)\n        self.k_linear = Linear(d_model, d_model, device=device, dtype=dtype)\n        self.v_linear = Linear(d_model, d_model, device=device, dtype=dtype)\n        self.out_linear = Linear(d_model, d_model, device=device, dtype=dtype)\n\n        self.use_rope = use_rope\n        if use_rope:\n            self.rope = RoPEEmbedding(\n                theta=theta,\n                d_k=self.d_k,\n                max_seq_len=max_seq_len,\n                device=device,\n            )\n\n    def _create_causal_mask(self, seq_len: int, device: torch.device) -&gt; torch.Tensor:\n        mask = torch.tril(torch.ones(seq_len, seq_len, device=device)).bool()\n        return mask.unsqueeze(0).unsqueeze(0)\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        token_positions: torch.Tensor | None = None,\n    ) -&gt; torch.Tensor:\n        batch_size, seq_len, _ = x.size()\n        causal_mask = self._create_causal_mask(seq_len, x.device)\n\n        Q = self.q_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.k_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.v_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n\n        if self.use_rope:\n            Q, K = self.rope(Q, token_positions), self.rope(K, token_positions)\n\n        attn_output = scaled_dot_product_attention(Q, K, V, mask=causal_mask)\n\n        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n\n        output = self.out_linear(attn_output)\n\n        return output",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#transformer-block",
    "href": "posts/CS336/Ass01/ass01.html#transformer-block",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.7 Transformer Block",
    "text": "3.7 Transformer Block\næœ‰äº†è¿™äº›æ¨¡å—ï¼Œæˆ‘ä»¬å°±å¯ä»¥å’Œæ­ç§¯æœ¨ä¸€æ ·ï¼Œæ­å»ºæˆ‘ä»¬Transformer\nå¯¹è¾“å…¥ \\(x\\)ï¼Œç¬¬ä¸€å±‚çš„æ›´æ–°è§„åˆ™æ˜¯ï¼š\n\\[\ny = x + \\mathrm{MHA}(\\mathrm{RMSNorm}(x)).\n\\tag{25}\\]\nè¿™å¥è¯å¯ä»¥æ‹†å¼€ç†è§£ä¸ºä¸‰æ­¥ï¼š\n\n(1) å½’ä¸€åŒ–ï¼šå…ˆæŠŠè¾“å…¥ \\(x\\) åš RMSNormï¼Œå¾—åˆ°æ›´ç¨³å®šçš„è¾“å…¥åˆ†å¸ƒ\n\n(2) ä¸»æ“ä½œï¼šæŠŠå½’ä¸€åŒ–åçš„å‘é‡é€å…¥ MHAï¼Œè®¡ç®—æ³¨æ„åŠ›è¾“å‡º\n\n(3) æ®‹å·®ï¼šæŠŠæ³¨æ„åŠ›è¾“å‡ºåŠ å›åŸè¾“å…¥ \\(x\\)ï¼Œå½¢æˆ \\(y\\)\n\n\n3.7.0.1 Pre-Norm\nè¿™é‡Œæˆ‘ä»¬é‡‡ç”¨çš„æ˜¯ Pre-Norm ç»“æ„ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªå­å±‚ï¼ˆMHA æˆ– FFNï¼‰å‰åšå½’ä¸€åŒ–ã€‚Pre-Normç›¸å¯¹äº Post-Normï¼ˆå…ˆåšå­å±‚å†å½’ä¸€åŒ–ï¼‰æœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š\n\nè®­ç»ƒæ›´ç¨³å®šï¼šPre-Norm å¯ä»¥ç¼“è§£æ·±å±‚ Transformer çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—è®­ç»ƒæ›´ç¨³å®šã€‚\næ›´æ·±çš„æ¨¡å‹ï¼šPre-Norm å…è®¸æˆ‘ä»¬è®­ç»ƒæ›´æ·±çš„ Transformerï¼Œå› ä¸ºæ¯ä¸ªå­å±‚çš„è¾“å…¥éƒ½ç»è¿‡å½’ä¸€åŒ–ï¼Œå‡å°‘äº†å†…éƒ¨åå˜é‡åç§»ã€‚ 3ï¼Œ å¯¹Learning Rateæ›´ä¸æ•æ„Ÿï¼šPre-Norm ç»“æ„å¯¹å­¦ä¹ ç‡çš„é€‰æ‹©ä¸é‚£ä¹ˆæ•æ„Ÿï¼Œå…è®¸ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡è¿›è¡Œè®­ç»ƒã€‚\n\n\n\n\n\n\n\nDifference nomralization structures\n\n\n\nå½“ç„¶ï¼Œé™¤äº†Pre-Normä¹‹å¤–ï¼Œç°åœ¨ä¹Ÿæœ‰ä¸€äº›å˜ä½“ç»“æ„ï¼Œæ¯”å¦‚ Hybrid Norm(Zhuo et al. 2025)ï¼ˆç»“åˆ Pre-Norm å’Œ Post-Norm çš„ä¼˜ç‚¹ï¼‰ ä¸‹å›¾æ¯”è¾ƒå±•ç¤ºäº†ä¸åŒå½’ä¸€åŒ–ç»“æ„ï¼š\n\n\n\n\n\n\nFigureÂ 7: æ¯”è¾ƒä¸åŒçš„Normalizationçš„ç»“æ„ï¼Œa) Post-Norm ç»“æ„ï¼›b) Pre-Norm ç»“æ„ï¼› c) å¸¦ QK-Norm çš„ Pre-Norm ç»“æ„ï¼›d) HybridNorm ç»“æ„\n\n\n\n\n\nTransformer Block çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š\n\n\ncs336_basics/model.py\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.config = config\n\n        self.mha = MHA(\n            d_model=config.d_model,\n            num_heads=config.num_heads,\n            use_rope=config.use_rope,\n            theta=config.rope_theta,\n            max_seq_len=config.max_seq_len,\n        )\n        self.ffn = FFN(\n            d_model=config.d_model,\n            d_ff=config.d_ff,\n        )\n        self.norm1 = RMSNorm(config.d_model)\n        self.norm2 = RMSNorm(config.d_model)\n\n    def forward(self, x: torch.Tensor, token_positions: torch.Tensor | None = None) -&gt; torch.Tensor:\n        x = x + self.mha(self.norm1(x), token_positions=token_positions) \n        x = x + self.ffn(self.norm2(x)) \n        return x",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#output-layer",
    "href": "posts/CS336/Ass01/ass01.html#output-layer",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.8 Output Layer",
    "text": "3.8 Output Layer\nåœ¨å †å å®Œè‹¥å¹²ä¸ª Transformer blocks ä¹‹åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°æ¯ä¸ªä½ç½®çš„æœ€ç»ˆ hidden statesï¼š\n\\[\nH \\in \\mathbb{R}^{B \\times T \\times d_{\\text{model}}}\n\\tag{26}\\]\næ¥ä¸‹æ¥éœ€è¦ä¸€ä¸ª Output Layerï¼ˆLM Headï¼‰ æŠŠ hidden states æ˜ å°„åˆ°è¯è¡¨å¤§å°çš„ logitsï¼š\n\\[\n\\mathrm{logits} = H W_{\\text{out}}\n\\tag{27}\\]\nå…¶ä¸­ï¼š\n\\[\nW_{\\text{out}} \\in \\mathbb{R}^{d_{\\text{model}} \\times |\\mathcal{V}|}, \\quad\n\\mathrm{logits} \\in \\mathbb{R}^{B \\times T \\times |\\mathcal{V}|}.\n\\tag{28}\\]\nåœ¨å¾ˆå¤šç°ä»£ LLM ä¸­ï¼Œé€šå¸¸è¿˜ä¼šåœ¨è¾“å‡ºå±‚å‰åŠ ä¸€ä¸ªæœ€ç»ˆå½’ä¸€åŒ–ï¼ˆåŒæ ·æ˜¯ Pre-Norm é£æ ¼ï¼‰ï¼š\n\\[\n\\mathrm{logits} = \\mathrm{RMSNorm}(H)\\, W_{\\text{out}}.\n\\tag{29}\\]\n\n\ncs336_basics/model.py\n\nclass OutputLayer(nn.Module):\n    def __init__(self, d_model, vocab_size, use_norm: bool = False):\n        super().__init__()\n        self.linear = Linear(d_model, vocab_size)\n        self.norm = RMSNorm(d_model) if use_norm else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x = self.norm(x)\n        logits = self.linear(x)\n        return logits\n\n\n3.8.1 Weight Tying\nå¦‚æœæ¨¡å‹é‡Œæœ‰ token embedding çŸ©é˜µ \\(E \\in \\mathbb{R}^{|\\mathcal{V}|\\times d_{\\text{model}}}\\)ï¼Œé‚£ä¹ˆå¸¸è§çš„åšæ³•æ˜¯ å…±äº«è¾“å…¥ embedding å’Œè¾“å‡ºæŠ•å½±æƒé‡ï¼ˆweight tyingï¼‰ï¼š\n\\[\nW_{\\text{out}} = E^\\top.\n\\tag{30}\\]\nè¿™æ ·å¯ä»¥å‡å°‘å‚æ•°é‡ï¼Œå¹¶ä¸”ç»å¸¸å¸¦æ¥æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ä¸æ³›åŒ–æ•ˆæœã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#full-transformer-model",
    "href": "posts/CS336/Ass01/ass01.html#full-transformer-model",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.9 Full Transformer Model",
    "text": "3.9 Full Transformer Model\nå½“æˆ‘ä»¬å®ç°å®Œ embeddingã€Transformer blockï¼ˆMHA + FFNï¼‰ã€ä»¥åŠè¾“å‡ºå±‚ä¹‹åï¼Œå°±å¯ä»¥æŒ‰ç…§ FigureÂ 2 çš„é«˜å±‚ç»“æ„æŠŠæ•´ä¸ªè¯­è¨€æ¨¡å‹ä¸²èµ·æ¥äº†ã€‚æ•´ä½“æµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä¸‰æ­¥ï¼š\n\nToken Embeddingï¼šæŠŠ token id æ˜ å°„åˆ°å‘é‡è¡¨ç¤º\nå †å  num_layers ä¸ª Transformer Blocks\nÂ Output Layersï¼šæ˜ å°„åˆ°è¯è¡¨åˆ†å¸ƒ\n\nå…·ä½“çš„ä»£ç å¦‚ä¸‹ï¼š\n\n\ncs336_basics/model.py\n\nclass TransformerLM(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.config = config\n\n        self.token_embedding = nn.Embedding(config.vocab_size, config.d_model)\n        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config.num_layers)])\n        self.final_norm = RMSNorm(config.d_model)\n        self.output_layer = OutputLayer(config.d_model, config.vocab_size, use_norm=config.use_final_norm)\n\n        if config.tie_weights:\n            self._tie_weights()\n\n    def forward(self, x: torch.Tensor, token_positions: torch.Tensor | None = None) -&gt; torch.Tensor:\n        x = self.token_embedding(x)\n\n        for layer in self.layers:\n            x = layer(x, token_positions=token_positions)\n\n        x = self.final_norm(x)\n        logits = self.output_layer(x)\n        return logits\n\n    def _tie_weights(self):\n        self.output_layer.linear.weight = self.token_embedding.weight\n\ntoken ids â†’ embedding å¾—åˆ° \\(X_0\\) â†’ ç»è¿‡ \\(L\\) ä¸ª Transformer blocks å¾—åˆ° \\(H\\) â†’ è¾“å‡ºå¤´ï¼ˆnorm + linear + softmaxï¼‰å¾—åˆ°è¯è¡¨åˆ†å¸ƒï¼Œç”¨äº next-token predictionã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#part-02-summary",
    "href": "posts/CS336/Ass01/ass01.html#part-02-summary",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "3.10 Part 02 Summary",
    "text": "3.10 Part 02 Summary\næ€»çš„æ¥è¯´ï¼ŒPart 02 å°±æ˜¯åœ¨ Part 01 çš„ Tokenization ä¹‹åï¼ŒæŠŠâ€œèƒ½è®­ç»ƒçš„è¯­è¨€æ¨¡å‹â€çœŸæ­£æ­èµ·æ¥ï¼šæˆ‘ä»¬ä»æœ€åŸºç¡€çš„ Linear / Embedding å‡ºå‘ï¼Œé€æ­¥å®ç° RMSNormï¼ˆPre-Normï¼‰ã€ç°ä»£ LLM å¸¸ç”¨çš„ SwiGLU-FFNã€å†åˆ°æœ€æ ¸å¿ƒä¹Ÿæœ€å®¹æ˜“å†™é”™çš„ (RoPE + Causal) Multi-Head Self-Attentionï¼Œæœ€ç»ˆåƒæ­ç§¯æœ¨ä¸€æ ·ç»„è£…å‡ºå®Œæ•´çš„ TransformerBlockï¼Œå¹¶ä¸²è”æˆ TransformerLMï¼Œé€šè¿‡ Output Layer è¾“å‡º vocabulary logits ç”¨äº next-token predictionã€‚\nè¿™ä¸€éƒ¨åˆ†æœ€å€¼å¾—è®°ä½çš„å·¥ç¨‹è¦ç‚¹æœ‰ä¸‰ç±»ï¼š\n\nç¨³å®šæ€§ï¼ˆstabilityï¼‰ï¼š Softmax çš„æ•°å€¼ç¨³å®šï¼ˆå‡ maxï¼‰ã€Pre-Normï¼ˆRMSNorm æ”¾åœ¨å­å±‚å‰ï¼‰ã€ä»¥åŠ causal mask é˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²ï¼Œéƒ½æ˜¯â€œè®­ç»ƒèƒ½ä¸èƒ½è·‘èµ·æ¥â€çš„å…³é”®ã€‚\næ•ˆç‡ï¼ˆefficiencyï¼‰ï¼š Q/K/V æŠ•å½±åº”å½“æ˜¯ 3 æ¬¡çŸ©é˜µä¹˜æ³•ï¼ˆæ›´è¿›ä¸€æ­¥å¯ä»¥åˆæˆ 1 æ¬¡ï¼‰ï¼Œmask ç”¨ â€œsoftmax å‰åŠ  -â€ è€Œä¸æ˜¯åˆ‡å­åºåˆ—ï¼ŒRoPE ç”¨é¢„è®¡ç®—çš„ sin/cos buffer å¤ç”¨è·¨ batch/è·¨å±‚ï¼Œé¿å…æ˜¾å¼æ„é€  \\(d\\times d\\) æ—‹è½¬çŸ©é˜µã€‚\nç»“æ„ï¼ˆarchitectureï¼‰ï¼š ç°ä»£ LLM çš„ Block åŸºæœ¬éƒ½éµå¾ª â€œRMSNorm â†’ MHA/FFN â†’ Residualâ€ çš„ Pre-Norm æ¨¡å¼ï¼›FFN å¸¸ç”¨ SwiGLUï¼ˆæ¿€æ´» + gatingï¼‰ï¼›RoPE åªä½œç”¨åœ¨ Q/Kï¼ˆä¸ä½œç”¨åœ¨ Vï¼‰ï¼›æœ€åå†æ¥ä¸€ä¸ªè¾“å‡ºå¤´ï¼ˆå¯é€‰ final norm / weight tyingï¼‰æŠŠ hidden states æ˜ å°„åˆ°è¯è¡¨åˆ†å¸ƒã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#loss-perplexity",
    "href": "posts/CS336/Ass01/ass01.html#loss-perplexity",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "4.1 Loss & Perplexity",
    "text": "4.1 Loss & Perplexity\næˆ‘ä»¬å…ˆæ¥å®šä¹‰æˆ‘ä»¬çš„Loss Function,åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ï¼ŒLoss Functionï¼ˆæŸå¤±å‡½æ•°ï¼‰ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹ä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ã€‚å¯¹äºè¯­è¨€æ¨¡å‹ï¼Œå¸¸ç”¨çš„æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropy Lossï¼‰ã€‚\n\n4.1.1 Cross Entropy Loss\nåœ¨ç°ä»£å¸¸è§çš„è¯­è¨€æ¨¡å‹æ˜¯Next-Token Predictionæ¨¡å‹ï¼Œå…¶è®­ç»ƒç›®æ ‡æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼Œä¹Ÿå°±æ˜¯ç»™å®šå‰é¢ \\(t\\) ä¸ª tokenï¼Œé¢„æµ‹ç¬¬ \\(t+1\\) ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒï¼š\n\\[\nP(x_{t+1} | x_1, x_2, \\ldots, x_t)\n\\tag{31}\\]\nå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªé•¿åº¦ä¸º \\(T\\) çš„è®­ç»ƒåºåˆ— \\((x_1, x_2, \\ldots, x_T)\\)ï¼Œé‚£ä¹ˆæ¨¡å‹çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æ•´ä¸ªåºåˆ—çš„è”åˆæ¦‚ç‡ï¼š \\[\nP(x_1, x_2, \\ldots, x_T) = \\prod_{t=1}^{T} P(x_t | x_1, x_2, \\ldots, x_{t-1})\n\\tag{32}\\]\nä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropy Lossï¼‰æ¥è¡¡é‡æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚\nCross Entropy Loss å¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š\n\\[\n\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\ln(p_{i,c})\n\\tag{33}\\]\nå…¶ä¸­ï¼š\n\n\\(N\\) æ˜¯æ ·æœ¬æ•°é‡ï¼ˆåœ¨è¯­è¨€æ¨¡å‹ä¸­é€šå¸¸æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„ token æ•°é‡ï¼‰\n\\(C\\) æ˜¯ç±»åˆ«æ•°é‡ï¼ˆè¯è¡¨å¤§å°ï¼‰\n\\(y_{i,c}\\) æ˜¯æ ·æœ¬ \\(i\\) çš„çœŸå®æ ‡ç­¾çš„ one-hot ç¼–ç ï¼ˆå¦‚æœæ ·æœ¬ \\(i\\) çš„çœŸå®ç±»åˆ«æ˜¯ \\(c^*\\)ï¼Œåˆ™ \\(y_{i,c^*} = 1\\)ï¼Œå…¶ä»–ç±»åˆ«ä¸º 0ï¼‰\n\\(p_{i,c}\\) æ˜¯æ¨¡å‹å¯¹æ ·æœ¬ \\(i\\) é¢„æµ‹ä¸ºç±»åˆ« \\(c\\)çš„æ¦‚ç‡ã€‚\n\nå®ç°è¿™ä¸ªæŸå¤±å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šç»“åˆ softmax ä¸€èµ·ä½¿ç”¨ï¼Œå› ä¸ºæ¨¡å‹è¾“å‡ºçš„ logits éœ€è¦å…ˆç»è¿‡ softmax è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚\n\n\ncs336_basics/loss.py\n\ndef cross_entropy(logits: torch.Tensor, labels: torch.Tensor):\n    logits = logits - torch.max(logits, dim=1, keepdim=True).values\n    log_probs = logits - torch.log(torch.sum(torch.exp(logits), dim=1, keepdim=True))\n\n    labels = labels.unsqueeze(1)\n\n    loss = log_probs.gather(1, labels).squeeze(1) \n    loss = -loss.mean()\n    return loss\n\nå…¶ä¸­ log_probs.gather(1, labels) è¿™ä¸€è¡Œä»£ç çš„ä½œç”¨æ˜¯ä» log_probs å¼ é‡ä¸­æå–å‡ºæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„çœŸå®æ ‡ç­¾çš„å¯¹æ•°æ¦‚ç‡å€¼ã€‚å…·ä½“æ¥è¯´ï¼š\n\nlog_probs çš„ shape æ˜¯ (N, C)ï¼Œè¡¨ç¤º \\(N\\) ä¸ªæ ·æœ¬åœ¨ \\(C\\) ä¸ªç±»åˆ«ä¸Šçš„å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒã€‚\nlabels çš„ shape æ˜¯ (N, 1)ï¼Œè¡¨ç¤ºæ¯ä¸ªæ ·æœ¬çš„çœŸå®ç±»åˆ«ç´¢å¼•ã€‚\ngather(1, labels) ä¼šæ ¹æ® labels ä¸­çš„ç´¢å¼•ï¼Œä» log_probs çš„ç¬¬äºŒç»´ï¼ˆç±»åˆ«ç»´åº¦ï¼‰ä¸­æå–å¯¹åº”çš„å¯¹æ•°æ¦‚ç‡å€¼ï¼Œç»“æœçš„ shape æ˜¯ (N, 1)ã€‚\n\nåœ¨ä½¿ç”¨è¿™ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†æ¨¡å‹çš„è¾“å‡º logits å’Œå¯¹åº”çš„çœŸå®æ ‡ç­¾å±•å¼€æˆä¸€ç»´å‘é‡ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥ç®€åŒ–è®¡ç®—è¿‡ç¨‹ï¼Œä½¿å¾—æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹éƒ½è¢«è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„æ ·æœ¬ï¼Œä»è€Œæ–¹ä¾¿åœ°è®¡ç®—æ•´ä½“çš„æŸå¤±ã€‚\n\n\ncs336_basics/train_engine.py\n\nlogits = model(inputs)\nlogits = logits.view(-1, logits.size(-1))\ntargets = targets.view(-1)\n\n\n\n4.1.2 Perplexity\nåœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œé™¤äº†äº¤å‰ç†µæŸå¤±ï¼Œæˆ‘ä»¬è¿˜å¸¸ç”¨ä¸€ä¸ªæŒ‡æ ‡å«åšå›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å›°æƒ‘åº¦è¡¡é‡çš„æ˜¯æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„é¢„æµ‹èƒ½åŠ›ï¼Œæ•°å€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹è¶Šå¥½ã€‚ å®ƒçš„å®šä¹‰å¦‚ä¸‹ï¼š\n\\[\n\\mathrm{PPL} = \\exp\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\mathcal{L}_i\\right)\n\\tag{34}\\]\nå®ƒæ˜¯äº¤å‰ç†µæŸå¤±çš„æŒ‡æ•°å½¢å¼ï¼Œå…¶ä¸­ \\(\\mathcal{L}_i\\) æ˜¯ç¬¬ \\(i\\) ä¸ªæ ·æœ¬çš„äº¤å‰ç†µæŸå¤±ï¼Œ\\(N\\) æ˜¯æ ·æœ¬æ€»æ•°ï¼Œ ä¹Ÿå°±æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„ token æ•°é‡ã€‚ å®ƒçš„ç›´è§‚æ„ä¹‰æ˜¯ï¼šæ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª token æ—¶ï¼Œå¹³å‡æ¯ä¸ª token æœ‰å¤šå°‘ç§å¯èƒ½çš„é€‰æ‹©ã€‚ æˆ‘ä»¬å±•å¼€PPLçš„å®šä¹‰ï¼š\n\\[\n\\mathrm{PPL} = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\ln(p_{i,c^*})\\right) = \\left(\\prod_{i=1}^{N} \\frac{1}{p_{i,c^*}}\\right)^{\\frac{1}{N}}\n\\tag{35}\\]\nPPL ç­‰ä»·äºâ€œæ¨¡å‹ç»™çœŸå® token çš„æ¦‚ç‡ pâ€çš„å€’æ•° 1/p çš„å‡ ä½•å¹³å‡ï¼Œæ‰€ä»¥è¶Šå°è¡¨ç¤ºæ¨¡å‹å¹³å‡ç»™çœŸå€¼çš„æ¦‚ç‡è¶Šå¤§ã€‚\nè¿™ä¸ªçœ‹èµ·æ¥å¾ˆæŠ½è±¡ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…·ä½“ä¾‹å­ï¼š å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„è¯è¡¨ï¼Œåªæœ‰ 4 ä¸ª tokenï¼š{A, B, C, D}ã€‚ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªæµ‹è¯•åºåˆ— A B C Dï¼Œæ¨¡å‹åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹æ¦‚ç‡å¦‚ä¸‹ï¼š\n\né¢„æµ‹ B çš„æ¦‚ç‡ï¼š0.5\né¢„æµ‹ C çš„æ¦‚ç‡ï¼š0.25\né¢„æµ‹ D çš„æ¦‚ç‡ï¼š0.1\n\né‚£ä¹ˆï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è¿™ä¸ªåºåˆ—çš„å›°æƒ‘åº¦ï¼š \\[\n\\mathrm{PPL} = \\exp\\left(-\\frac{1}{3} (\\ln(0.5) + \\ln(0.25) + \\ln(0.1))\\right) \\approx 4.64\n\\tag{36}\\]\nè¿™æ„å‘³ç€ï¼Œæ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª token æ—¶ï¼Œå¹³å‡æ¯ä¸ª token æœ‰å¤§çº¦ 4.64 ç§å¯èƒ½çš„é€‰æ‹©ã€‚ å› ä¸ºè¯è¡¨åªæœ‰ 4 ä¸ª tokenï¼Œè¿™ä¸ªå›°æƒ‘åº¦è¡¨æ˜æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›è¿˜ä¸å¤Ÿå¥½ã€‚\nä»£ç å®ç°å¦‚ä¸‹ï¼š\n\n\ncs336_basics/loss.py\n\ndef perplexity(loss: torch.Tensor) -&gt; torch.Tensor:\n    return torch.exp(loss)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#optimizer-learning-rate-scheduler",
    "href": "posts/CS336/Ass01/ass01.html#optimizer-learning-rate-scheduler",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "4.2 Optimizer & Learning Rate Scheduler",
    "text": "4.2 Optimizer & Learning Rate Scheduler\næœ‰äº†Loss Functionä¹‹åï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥è¦å®šä¹‰Optimizerå’ŒLearning Rate Schedulerï¼Œæ¥æŒ‡å¯¼æ¨¡å‹å‚æ•°çš„æ›´æ–°ã€‚\n\n4.2.1 AdamW\nåœ¨è¿™ä¸ªä½œä¸šä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ AdamW(Loshchilov and Hutter 2019) ä½œä¸ºä¼˜åŒ–å™¨ã€‚AdamW æ˜¯ Adam ä¼˜åŒ–å™¨çš„ä¸€ä¸ªå˜ä½“ï¼Œå®ƒé€šè¿‡å°†æƒé‡è¡°å‡ï¼ˆweight decayï¼‰ä¸æ¢¯åº¦æ›´æ–°è§£è€¦æ¥æ”¹å–„æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\né¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Adamæ˜¯ä»€ä¹ˆï¼Œ Adam æ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œå®ƒç»“åˆäº†åŠ¨é‡ï¼ˆMomentumï¼‰å’ŒRMSPropçš„æ€æƒ³ï¼Œé€šè¿‡è®¡ç®—æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆå‡å€¼ï¼‰å’ŒäºŒé˜¶çŸ©ä¼°è®¡ï¼ˆæœªä¸­å¿ƒåŒ–çš„æ–¹å·®ï¼‰æ¥è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚Adam å¯¹æ¯ä¸ªå‚æ•° \\(\\theta\\) éƒ½ç»´æŠ¤ä¸¤ä»½çŠ¶æ€ï¼ˆstateï¼‰ï¼š\n\nä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰ \\(m_t\\)ï¼šæ¢¯åº¦çš„æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼ˆç±»ä¼¼ momentumï¼‰\näºŒé˜¶çŸ© \\(v_t\\)ï¼šæ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼ˆåˆ»ç”»æ¢¯åº¦å°ºåº¦ï¼‰\n\nå®ƒä»¬çš„æ›´æ–°è§„åˆ™å¦‚ä¸‹ï¼š\n\\[\n\\begin{split}\nm_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\\\\n\\theta_t &= \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} \\\\\n\\end{split}\n\\tag{37}\\]\nå…¶ä¸­ï¼Œ\\(g_t\\) æ˜¯å½“å‰æ¢¯åº¦ï¼Œ\\(\\beta_1\\) å’Œ \\(\\beta_2\\) æ˜¯æ§åˆ¶æ»‘åŠ¨å¹³å‡çš„è¶…å‚æ•°ï¼Œ\\(\\alpha\\) æ˜¯å­¦ä¹ ç‡ï¼Œ\\(\\epsilon\\) æ˜¯é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°ã€‚\\(\\hat{m}_t\\) å’Œ \\(\\hat{v}_t\\) æ˜¯åå·®ä¿®æ­£åçš„ä¼°è®¡ï¼š\n\\[\n\\begin{split}\n\\hat{m}_t &= \\frac{m_t}{1 - \\beta_1^t} \\\\\n\\hat{v}_t &= \\frac{v_t}{1 - \\beta_2^t} \\\\\n\\end{split}\n\\tag{38}\\]\nåœ¨ Adam ä¸­ï¼Œæƒé‡è¡°å‡ï¼ˆweight decayï¼‰é€šå¸¸ä¼šè¢«å®ç°æˆ L2 æ­£åˆ™ï¼šä¹Ÿå°±æ˜¯åœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥ \\(\\frac{\\lambda}{2}\\|\\theta\\|^2\\)ï¼Œ æŸå¤±å‡½æ•°å˜ä¸º\\(\\mathcal{L} = \\mathcal{L}_{\\text{original}} + \\frac{\\lambda}{2}\\|\\theta\\|^2\\), å…¶å¯¹åº”çš„æ¢¯åº¦é¢å¤–å¤šä¸€é¡¹ \\(\\lambda \\theta\\)ã€‚å› æ­¤ï¼Œæ¢¯åº¦ä¼šå˜æˆï¼š\n\\[\ng_t \\leftarrow g_t + \\lambda \\theta_{t-1}\n\\tag{39}\\]\nå¦‚æœç›´æ¥æŠŠè¿™ä¸ªä¿®æ”¹åçš„æ¢¯åº¦å¸¦å…¥ Adam çš„æ›´æ–°è§„åˆ™, æˆ‘ä»¬ä¼šå¾—åˆ°ï¼š\n$$\n\\[\\begin{split}\nm_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) (g_t + \\lambda \\theta_{t-1}) \\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) (g_t + \\lambda \\theta_{t-1})^2 \\\\\n\\theta_t &= \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} \\\\\n        &= \\theta_{t-1} - \\alpha\n\n\n\\end{split}\\]\n$${#eq-adam-with-l2}\nç›´è§‰ä¸Šï¼Œweight decay æƒ³åšçš„äº‹æƒ…å¾ˆç®€å•ï¼šæ¯ä¸€æ­¥éƒ½æŠŠå‚æ•°å¾€ 0 æ‹‰ä¸€ç‚¹ï¼Œå³è®©å‚æ•°è§„æ¨¡å—æ§ã€æå‡æ³›åŒ–, ä¹Ÿå°±æ˜¯è¯´ï¼Œä¹Ÿå°±æ˜¯è¡°å‡é¡¹ åªæ˜¯ä¸€æ¡ç‹¬ç«‹çš„çº¿æ€§æ”¶ç¼©ï¼Œä¸è¢«ä»»ä½•è‡ªé€‚åº”ç¼©æ”¾å½±å“ã€‚ ä½†åœ¨ Adam é‡Œï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚\nåœ¨ Adam é‡Œï¼Œæ›´æ–°ä¼šè¢« \\(\\sqrt{\\hat v_t}\\) è¿›è¡Œâ€œæŒ‰ç»´åº¦ç¼©æ”¾â€ã€‚è¿™æ„å‘³ç€ï¼š\n\næ­£åˆ™é¡¹ \\(\\lambda \\theta\\) ä¹Ÿä¼šè¿›å…¥ \\(\\hat m_t\\), \\(\\hat v_t\\) çš„è®¡ç®—\nè¿›è€Œå®ƒä¹Ÿä¼šè¢« ç¼©æ”¾\nç»“æœï¼šä¸åŒå‚æ•°ç»´åº¦çš„è¡°å‡å¼ºåº¦ä¸ä¸€è‡´ï¼ˆæŸäº›ç»´åº¦å‡ ä¹ä¸è¡°å‡ï¼ŒæŸäº›ç»´åº¦è¡°å‡è¿‡å¼ºï¼‰\n\næ¢å¥è¯è¯´ï¼šåœ¨ Adam è¿™ç§è‡ªé€‚åº”ä¼˜åŒ–å™¨é‡Œï¼Œâ€œL2 æ­£åˆ™ â‰  ä½ ä»¥ä¸ºçš„ weight decayâ€ã€‚(Loshchilov and Hutter 2019) çš„æ ¸å¿ƒè§‚å¯Ÿå°±æ˜¯ï¼šå¦‚æœæˆ‘ä»¬æƒ³è¦çœŸæ­£å®ç°â€œæŠŠå‚æ•°å¾€ 0 æ‹‰â€çš„æ­£åˆ™åŒ–æ•ˆæœï¼Œå°±åº”è¯¥æŠŠå®ƒä» Adam çš„æ¢¯åº¦æ›´æ–°ä¸­æ‹†å‡ºæ¥ã€‚\nAdamW çš„ç®—æ³•å¦‚ä»¥ä¸‹æ‰€ç¤ºï¼š\n\n\n\n\n\n\nFigureÂ 8: AdamW ç®—æ³•\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼ŒAdamW æŠŠ weight decay ä»æ¢¯åº¦æ›´æ–°ä¸­è§£è€¦å‡ºæ¥ï¼Œç›´æ¥åœ¨å‚æ•°æ›´æ–°æ—¶åšçº¿æ€§æ”¶ç¼©ï¼š \\[\n\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} - \\alpha \\lambda \\theta_{t-1}\n\\tag{40}\\] è¿™æ ·å°±ä¿è¯äº† weight decay çš„æ•ˆæœæ˜¯ä¸€è‡´çš„ï¼Œä¸ä¼šè¢«è‡ªé€‚åº”ç¼©æ”¾å½±å“ã€‚\nç†è§£äº† AdamW çš„åŸç†åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹å®ƒçš„ä»£ç å®ç°ï¼š\n\n\ncs336_basics/optim.py\n\nclass AdamW(torch.optim.Optimizer):\n    def __init__(\n        self,\n        params: Iterable[torch.nn.Parameter],\n        lr: float = 1e-3,\n        betas: tuple[float, float] = (0.9, 0.999),\n        eps: float = 1e-8,\n        weight_decay: float = 1e-2,\n    ):\n        if lr &lt; 0.0:\n            raise ValueError(f\"Invalid learning rate: {lr}\")\n        if eps &lt;= 0.0:\n            raise ValueError(f\"Invalid epsilon value: {eps}\")\n        if weight_decay &lt; 0.0:\n            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n        if not isinstance(betas, tuple) or len(betas) != 2:\n            raise ValueError(f\"betas must be a tuple of length 2, got: {betas}\")\n        beta1, beta2 = betas\n        if not (0.0 &lt;= beta1 &lt; 1.0):\n            raise ValueError(f\"Invalid beta1 value: {beta1}\")\n        if not (0.0 &lt;= beta2 &lt; 1.0):\n            raise ValueError(f\"Invalid beta2 value: {beta2}\")\n\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure: Optional[callable] = None):\n        \"\"\"Performs a single optimization step.\"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            lr: float = group[\"lr\"]\n            beta1, beta2 = group[\"betas\"]\n            eps: float = group[\"eps\"]\n            weight_decay: float = group[\"weight_decay\"]\n\n            for p in group[\"params\"]:\n                if p.grad is None:\n                    continue\n\n                grad = p.grad\n                if grad.is_sparse:\n                    raise RuntimeError(\"AdamW does not support sparse gradients\")\n\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"step\"] = 0\n                    state[\"exp_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    state[\"exp_avg_sq\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n\n                exp_avg = state[\"exp_avg\"]\n                exp_avg_sq = state[\"exp_avg_sq\"]\n\n                state[\"step\"] += 1\n                t = state[\"step\"]\n\n                # Update biased first and second moment estimates\n                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=(1.0 - beta2))\n\n                # Bias correction\n                bias_correction1 = 1.0 - beta1**t\n                bias_correction2 = 1.0 - beta2**t\n\n                # Compute step size\n                step_size = lr / bias_correction1\n\n                # Denominator: sqrt(v_hat) + eps\n                denom = (exp_avg_sq / bias_correction2).sqrt().add_(eps)\n\n                # Decoupled weight decay\n                if weight_decay != 0.0:\n                    p.mul_(1.0 - lr * weight_decay)\n\n                # Parameter update\n                p.addcdiv_(exp_avg, denom, value=-step_size)\n\n        return loss\n\n\n\n4.2.2 Cosine Annealing Learning Rate Scheduler\næœ‰äº†ä¼˜åŒ–å™¨ä¹‹åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªLearning Rate Scheduleræ¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ã€‚åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ€åˆé€‚çš„å­¦ä¹ ç‡ä¼šéšé˜¶æ®µå˜åŒ–ï¼š\n\nè®­ç»ƒæ—©æœŸï¼šæ¨¡å‹è¿˜æ²¡å­¦åˆ°ä¸œè¥¿ï¼Œå‚æ•°ç¦»ç›®æ ‡å¾ˆè¿œ\n\nç”¨ æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œæ›´æ–°æ›´å¿«ï¼Œloss ä¸‹é™æ›´å¿«\n\nè®­ç»ƒåæœŸï¼šæ¨¡å‹æ¥è¿‘æ”¶æ•›\n\nç”¨ æ›´å°çš„å­¦ä¹ ç‡ï¼Œé¿å…åœ¨æœ€ä¼˜ç‚¹é™„è¿‘éœ‡è¡ï¼Œæå‡ç¨³å®šæ€§ä¸æœ€ç»ˆæ•ˆæœ\n\n\nå› æ­¤æˆ‘ä»¬éœ€è¦Learning Rate Scheduleræ¥åœ¨ä¸åŒæ—¶æœŸè°ƒæ•´ä¸åŒçš„Learning Rateã€‚ä¸€ä¸ªå¸¸è§çš„Learning Rate Schedulerå«åš Cosine Annealing Schedulerï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š\n\nå®ƒæŠŠå­¦ä¹ ç‡ \\(\\alpha_t\\) åˆ†æˆ ä¸‰æ®µï¼š\n\nWarm-Up: ä» 0 çº¿æ€§æå‡åˆ° \\(\\alpha_{\\text{max}}\\) ï¼ˆé˜²æ­¢ä¸€å¼€å§‹æ¢¯åº¦å¤ªä¹±ï¼Œç›´æ¥å¤§ LR ä¼šä¸ç¨³å®šï¼‰\nCosine Annealing: ä» \\(\\alpha_{\\max}\\) å¹³æ»‘é™åˆ° \\(\\alpha_{\\min}\\) ï¼ˆä¸‹é™è¿‡ç¨‹æ›´å¹³æ»‘ï¼Œæ¯”â€œçªç„¶é™å­¦ä¹ ç‡â€æ›´ç¨³ï¼‰\nPost-Annealing: ä¿æŒ\\(\\alpha_{\\min}\\) ä¸å˜ ï¼ˆè®©è®­ç»ƒåœ¨ä½ LR ä¸‹æ…¢æ…¢ç²¾ä¿®ï¼ˆfine-tune é£æ ¼ï¼‰ï¼‰\n\n\næˆ‘ä»¬å…ˆæ¥å®šä¹‰å‡ ä¸ªç¬¦å·ï¼š\n\n\n\n\n\n\n\n\n\n\n\nç¬¦å·\nå«ä¹‰\n\n\n\n\n\\(t\\)\nå½“å‰è®­ç»ƒ stepï¼ˆè¿­ä»£æ¬¡æ•°ï¼‰\n\n\n\\(\\alpha_{\\max}\\)\næœ€å¤§å­¦ä¹ ç‡ï¼ˆå³°å€¼ï¼‰\n\n\n\\(\\alpha_{\\min}\\)\næœ€å°/æœ€ç»ˆå­¦ä¹ ç‡\n\n\n\\(T_w\\)\nwarm-up çš„æ­¥æ•°ï¼ˆé¢„çƒ­å¤šä¹…ï¼‰\n\n\n\\(T_c\\)\nCosine Annealingç»“æŸçš„æ­¥æ•°ï¼ˆåˆ°è¿™ä¸ª step å­¦ä¹ ç‡é™åˆ° \\(\\alpha_{\\min}\\)ï¼‰\n\n\n\\(\\alpha_t\\)\nå½“å‰å­¦ä¹ ç‡\n\n\n\n\n\nTableÂ 1: ç¬¦å·è¯´æ˜\n\n\n\n\næ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ä¸€ä¸‹å¦‚ä½•è°ƒæ•´è¿™ä¸‰ä¸ªä¸åŒçš„é˜¶æ®µï¼š\n\né˜¶æ®µ1: Warm-Up\nå½“ \\(t &lt; T_{w}\\) æ—¶ï¼Œæˆ‘ä»¬çº¿æ€§å¢é•¿åˆ° \\(\\alpha_{\\text{max}}\\)\n\\[\n\\alpha_t=\\frac{t}{T_w}\\alpha_{\\max}\n\\tag{41}\\]\n\né˜¶æ®µ2: Cosine Annealing\nè¿™ä¸ªæ˜¯ç›¸å¯¹å¤æ‚çš„é˜¶æ®µï¼Œåœ¨è¿™ä¸ªé˜¶æ®µæˆ‘ä»¬çš„å­¦ä¹ ç‡ç”¨ä½™å¼¦æ›²çº¿ä¸‹é™ï¼š\n\\[\n\\alpha_t=\\alpha_{\\min}+\\frac{1}{2}\\left(1+\\cos\\left(\\frac{t-T_w}{T_c-T_w}\\pi\\right)\\right)(\\alpha_{\\max}-\\alpha_{\\min})\n\\tag{42}\\]\nè¿™ä¸ªå¼å­åšäº†ä¸¤ä»¶äº‹ï¼š\n\nç”¨ \\(\\cos(\\cdot)\\) äº§ç”Ÿä¸€ä¸ªä» 1 å¹³æ»‘åˆ° -1 çš„æ›²çº¿\nå†æŠŠå®ƒæ˜ å°„æˆä¸€ä¸ªä» \\(\\alpha_{\\max}\\) å¹³æ»‘åˆ° \\(\\alpha_{\\min}\\) çš„å­¦ä¹ ç‡\n\næˆ‘ä»¬æŸ¥çœ‹ä¸€ä¸‹ä¸¤ä¸ªç«¯ç‚¹ï¼š\n\nå½“ \\(t = T_{w}\\): \\(\\cos(0) = 1\\), \\(\\alpha_{t} = \\alpha_{\\min} +\\alpha_{\\max} - \\alpha_{\\min} = \\alpha_{\\max}\\)\nå½“ \\(t = T_{c}\\): \\(\\cos(\\pi) = -1\\), \\(\\alpha_{t} = \\alpha_{\\min} +0 = \\alpha_{\\min}\\)\n\n\né˜¶æ®µ3: Post-Annealing\nå½“ \\(t \\geq T_{c}\\) æ—¶ï¼Œæˆ‘ä»¬å°† \\(\\alpha_{t}\\) è®¾å®šä¸º \\(\\alpha_{\\min}\\)ï¼Œä¸”ä¿æŒä¸å˜.\nä»£ç å®ç°ä¹Ÿå¾ˆç®€å•ï¼š\n\n\ncs336_basics/optim.py\n\ndef cosine_annealing_lr(\n    t: int,\n    alpha_max: float,\n    alpha_min: float,\n    Tw: int,\n    Tc: int,\n) -&gt; float:\n    # Warm-up\n    if Tw &gt; 0 and t &lt; Tw:\n        return (t / Tw) * alpha_max\n\n    # Cosine annealing (including the exact boundary t==Tw)\n    if t &lt;= Tc:\n        # If Tc == Tw, there is no annealing window; at t==Tw return alpha_max.\n        if Tc == Tw:\n            return alpha_max\n\n        progress = (t - Tw) / (Tc - Tw)  # in [0, 1]\n        return alpha_min + 0.5 * (1.0 + math.cos(math.pi * progress)) * (alpha_max - alpha_min)\n\n    # Post-annealing\n    return alpha_min\n\n\n\n\n\n\n\nFigureÂ 9: Figure: Cosine Annealing Learning Rate Scheduler Example  total_steps = 10000 , alpha_max = 0.001 , alpha_min = 1e-4 , Tw = 500 , Tc = total_steps // 2\n\n\n\n\n\n4.2.3 Gradient Clipping\nåœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæœ‰æ—¶ä¼šé‡åˆ°æŸäº› â€œç‰¹åˆ«éš¾/ç‰¹åˆ«æç«¯â€ çš„è®­ç»ƒæ ·æœ¬ï¼Œå®ƒä»¬ä¼šè®©æ¨¡å‹äº§ç”Ÿ éå¸¸å¤§çš„æ¢¯åº¦ã€‚å¦‚æœç›´æ¥ç”¨è¿™ç§æ¢¯åº¦æ›´æ–°å‚æ•°ï¼Œå¯èƒ½ä¼šå¯¼è‡´ï¼š\n\nLoss Spike: Loss çªç„¶çˆ†ç‚¸ï¼ˆæ•°å€¼ä¸ç¨³å®šï¼‰\nå‚æ•°æ›´æ–°æ­¥å­å¤ªå¤§ï¼Œå¯¼è‡´è®­ç»ƒå‘æ•£\nè®­ç»ƒæ›²çº¿æŠ–åŠ¨çš„å¾ˆå‰å®³ï¼Œéš¾ä»¥æ”¶æ•›\n\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®è·µä¸­å¸¸ç”¨ Gradient Clippingã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³éå¸¸ç®€å•ï¼š ::: {.callout-paper} æŠŠæ‰€æœ‰å‚æ•°çš„æ¢¯åº¦åˆèµ·æ¥ï¼Œè§†ä¸ºä¸€ä¸ªå‘é‡\\(g\\), è®¡ç®—å®ƒçš„ L2-Norm \\(\\|g\\|_{2}\\),æˆ‘ä»¬å¯ä»¥å°†å…¶ç†è§£ä¸ºæ•´ä½“æ¢¯åº¦çš„å¼ºåº¦/æ€»èƒ½é‡, ç„¶åè®¾å®šä¸€ä¸ªé˜ˆå€¼ \\(M\\)ï¼ˆæœ€å¤§å…è®¸çš„æ¢¯åº¦èŒƒæ•°ï¼‰ :::\nå› æ­¤ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§æƒ…å†µï¼š\n\n\\(\\|g\\|_{2} \\leq M\\): è¯´æ˜æ¢¯åº¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œç›´æ¥ä¿æŒåŸæ ·ã€‚\n\\(\\|g\\|_{2} &gt; M\\): è¯´æ˜è¿™ä¸ªæ¢¯åº¦è¿‡å¤§ï¼Œå¯èƒ½ä¼šé€ æˆé—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬ç­‰æ¯”ä¾‹ç¼©å°æ›´æ–°è¿™ä¸ªæ¢¯åº¦, ç¼©å°çš„ç³»æ•°æ˜¯ \\(\\frac{M}{\\|g\\|_{2} + \\epsilon}\\). æ›´æ–°åçš„æ¢¯åº¦ä¸ºï¼š\n\n\\[\ng \\leftarrow g \\cdot \\frac{M}{\\|g\\|_2 + \\epsilon}\n\\tag{43}\\]\né€šè¿‡è¿™ç§ç¼©æ”¾çš„æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ï¼š\n\næ–¹å‘ä¸å˜ï¼šè£å‰ªä¸ä¼šæ”¹å˜æ¢¯åº¦çš„æ–¹å‘ï¼ˆåªæ˜¯æ•´ä½“ç¼©æ”¾ï¼‰\næ­¥å­å˜å°ï¼šå½“æ¢¯åº¦å¤ªå¤§æ—¶ï¼Œç›¸å½“äºå¼ºè¡Œè®©æ›´æ–°ä¸è¦è·¨å¤ªå¤§æ­¥\næ›´ç¨³å®šï¼šå°¤å…¶å¯¹ RNNã€Transformer æˆ–è®­ç»ƒæ—©æœŸå¾ˆå¸¸è§çš„â€œæ¢¯åº¦çˆ†ç‚¸â€é—®é¢˜å¾ˆæœ‰å¸®åŠ©\n\nä»£ç å®ç°ä¹Ÿå¾ˆç®€å•ï¼Œç›´è§‚ï¼š\n\n\ncs336_basics/optim.py\n\n\n@torch.no_grad()\ndef gradient_clip(\n    parameters: Iterable[torch.nn.Parameter],\n    max_l2_norm: float,\n    eps: float = 1e-6,\n) -&gt; None:\n    # Calculate L2-Norm\n    total_norm = 0.0\n    for p in parameters:\n        if p.grad is not None:\n            param_norm = p.grad.data.norm(2)\n            total_norm += param_norm.item() ** 2\n    total_norm = total_norm**0.5\n\n    # Update gradient value accroding to the factor\n    clip_coef = max_l2_norm / (total_norm + eps)\n    if clip_coef &lt; 1.0:\n        for p in parameters:\n            if p.grad is not None:\n                p.grad.data.mul_(clip_coef)\n\n\n\n4.2.4 Put Together\næœ‰äº†è¿™ä¸‰ä¸ªä¼˜åŒ–çš„ç»„ä»¶ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠå®ƒä»¬æ”¾åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ­¥éª¤ï¼š\n\n\ncs336_basics/train_engine.py\n\ninputs, targets = data_loading_sequential(\n    x=x,\n    batch_size=train_config.batch_size,\n    context_length=model.config.max_seq_len,\n    device=train_config.device,\n    state=state,\n)\n\n# Forward pass\nwith ctx:\n    logits = model(inputs)\n    logits = logits.view(-1, logits.size(-1))\n    targets = targets.view(-1)\n    loss = cross_entropy(logits, targets)\n\n# Backward pass and optimization step\noptimizer.zero_grad(set_to_none=True)\nloss.backward()\n# Gradient clipping\ngradient_clip(model.parameters(), max_l2_norm=train_config.max_grad_norm)\n\n# Learning rate scheduling\nlr = cosine_annealing_lr(\n    t=step,\n    alpha_max=train_config.max_lr,\n    alpha_min=train_config.min_lr,\n    Tw=train_config.warmup_steps,\n    Tc=train_config.num_steps - train_config.warmup_steps,\n)\nfor param_group in optimizer.param_groups:\n    param_group[\"lr\"] = lr\noptimizer.step()",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#dataloader",
    "href": "posts/CS336/Ass01/ass01.html#dataloader",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "4.3 Dataloader",
    "text": "4.3 Dataloader\næœ‰äº†æ¨¡å‹å’Œä¼˜åŒ–å™¨ä¹‹åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªæ•°æ®åŠ è½½å™¨ï¼ˆDataloaderï¼‰æ¥æä¾›è®­ç»ƒæ•°æ®ã€‚åœ¨è¯­è¨€æ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œæ•°æ®é€šå¸¸æ˜¯æ–‡æœ¬åºåˆ—ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›æ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚è¿˜è®°å¾—ä¹‹å‰æˆ‘ä»¬åœ¨ Part 01 è®²è¿‡çš„ Tokenization å—ï¼Ÿæˆ‘ä»¬éœ€è¦å…ˆæŠŠæ–‡æœ¬è½¬æ¢ä¸º token idsï¼Œç„¶åå†ç»„ç»‡æˆé€‚åˆæ¨¡å‹è¾“å…¥çš„æ‰¹æ¬¡ã€‚æˆ‘ä»¬å·²ç»è®­ç»ƒå®ŒTokenizerï¼Œå¹¶ä¸”æŠŠæ–‡æœ¬è½¬æ¢æˆäº†token idsçš„å½¢å¼ä¿å­˜åœ¨.binæ–‡ä»¶ä¸­ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°æ®åŠ è½½å™¨æ¥ä»è¿™äº›token idsä¸­æå–å‡ºè®­ç»ƒæ ·æœ¬ã€‚\nåœ¨è¿™ä¸ªä½œä¸šä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é¡ºåºé‡‡æ ·ï¼ˆsequential samplingï¼‰æ–¹æ³•æ¥åŠ è½½æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¼šä» token ids ä¸­æŒ‰é¡ºåºæå–å‡ºé•¿åº¦ä¸º context_length çš„å­åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œç›®æ ‡æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚æˆ‘ä»¬ä¼šä¸æ–­åœ°ä»æ•°æ®ä¸­æå–è¿™æ ·çš„å­åºåˆ—ï¼Œç›´åˆ°è¾¾åˆ°æŒ‡å®šçš„æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ã€‚\n\n\n\n\n\n\nNote\n\n\n\nä½œä¸šä¸­ç”¨çš„æ˜¯Random Samplingï¼Œä¹Ÿå°±æ˜¯éšæœºæŒ‡å®šèµ·ç‚¹ï¼Œç„¶åæˆªå–context lengthé•¿åº¦çš„åºåˆ—ä½œä¸ºè¾“å…¥ã€‚\n\n\nä»£ç å®ç°å¦‚ä¸‹ï¼š\n\n\ncs336_basics/data.py\n\noriginal_data = np.memmap( \n    train_config.train_data_path, \n    dtype=np.uint16, \n    mode=\"r+\", \n)\nx_t = torch.from_numpy(original_data) \n\ndef get_batch_sequential(\n    x_t: torch.Tensor | np.ndarray,\n    batch_size: int,\n    context_length: int,\n    device: str | torch.device,\n    state: BatchState,\n    *,\n    stride: int | None = None,\n):\n    if stride is None:\n        stride = context_length\n\n    n = x_t.numel()\n    max_start = n - context_length - 1\n    if max_start &lt; 0:\n        raise ValueError(f\"Sequence too short: n={n}, context_length={context_length}\")\n\n    # Avoid per-sample modulo wrap. If we would run off the end, reset cursor.\n    last_start = state.pos + (batch_size - 1) * stride\n    end = last_start + context_length + 1\n    if end &gt; n:\n        state.pos = 0\n        last_start = (batch_size - 1) * stride\n        end = last_start + context_length + 1\n\n    base = x_t[state.pos : end]  # 1D contiguous slice\n\n    # 2D views: (B, T). Strides are in *elements* for PyTorch tensors.\n    inputs = base.as_strided(size=(batch_size, context_length), stride=(stride, 1)) \n    targets = base[1:].as_strided(size=(batch_size, context_length), stride=(stride, 1)) #&lt;&lt; \n\n    state.pos += batch_size * stride\n\n    # Transfer + cast (cast happens AFTER transfer =&gt; cheaper for CPU)\n    if (isinstance(device, torch.device) and device.type == \"cuda\") or (\n        isinstance(device, str) and \"cuda\" in device.lower()\n    ):\n        inputs = inputs.to(device, non_blocking=True).long() \n        targets = targets.to(device, non_blocking=True).long() \n    else:\n        inputs = inputs.long().to(device)\n        targets = targets.long().to(device)\n\n    return inputs, targets\n\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªéƒ¨åˆ†å¯èƒ½æ˜¯è®­ç»ƒæ—¶é—´ç“¶é¢ˆï¼Œå› ä¸ºæ•°æ®åŠ è½½å’Œé¢„å¤„ç†å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œå°¤å…¶æ˜¯å½“æ•°æ®é‡å¾ˆå¤§æ—¶ã€‚ æˆ‘ä»¬è¿ç”¨äº†ä»¥ä¸‹å‡ ä¸ªæŠ€å·§æ¥æå‡æ•°æ®åŠ è½½æ•ˆç‡ï¼š\n\nä½¿ç”¨ np.memmap æ¥å†…å­˜æ˜ å°„æ•°æ®æ–‡ä»¶ï¼Œè¿™æ ·å¯ä»¥é¿å…ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªæ•°æ®é›†åˆ°å†…å­˜ä¸­ï¼ŒèŠ‚çœå†…å­˜ç©ºé—´ã€‚\nä½¿ç”¨ as_strided æ¥åˆ›å»ºè¾“å…¥å’Œç›®æ ‡çš„è§†å›¾ï¼Œé¿å…äº†æ•°æ®çš„å¤åˆ¶ï¼Œæé«˜äº†æ•ˆç‡ã€‚\nä½¿ç”¨éé˜»å¡çš„æ•°æ®ä¼ è¾“ï¼ˆnon_blocking=Trueï¼‰æ¥åŠ é€Ÿæ•°æ®ä» CPU åˆ° GPU çš„ä¼ è¾“ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#checkpoint",
    "href": "posts/CS336/Ass01/ass01.html#checkpoint",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "4.4 Checkpoint",
    "text": "4.4 Checkpoint\nåœ¨è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ—¶ä¸æ—¶çš„ä¿æŒ Checkpoint, ä¸ºä»€ä¹ˆå‘¢ï¼Ÿå› ä¸ºè®­ç»ƒæ¨¡å‹ä¸åªæ˜¯â€œæŠŠ loss è®­åˆ°ä½â€è¿™ä¹ˆç®€å•ï¼Œæˆ‘ä»¬è¿˜ç»å¸¸éœ€è¦ï¼š\n\nä¸­é€”æ¢å¤è®­ç»ƒï¼šæ¯”å¦‚è®­ç»ƒè·‘åˆ°ä¸€åŠæœºå™¨æ–­äº†ã€ä½œä¸šè¶…æ—¶ã€æ„å¤–é€€å‡ºï¼Œ\nä¿ç•™ä¸­é—´æ¨¡å‹ï¼šæ–¹ä¾¿ä¹‹ååˆ†æè®­ç»ƒè¿‡ç¨‹ã€æ¯”è¾ƒä¸åŒé˜¶æ®µçš„æ¨¡å‹ã€åšä¸åŒé˜¶æ®µçš„é‡‡æ ·ï¼Œ Exponemtial Moving Average (EMA) ç­‰ç­‰\n\nCheckpoint çš„ç›®æ ‡æ˜¯ï¼šè®©ä½ èƒ½ä»ä¸­æ–­å¤„æ— ç¼ç»§ç»­è®­ç»ƒã€‚\nå› æ­¤è‡³å°‘è¦å­˜è¿™ä¸‰ç±»ä¸œè¥¿ï¼š\n\næ¨¡å‹å‚æ•°ï¼ˆmodel weightsï¼‰\n\næ²¡æœ‰å®ƒï¼Œå°±æ²¡æœ‰æ¨¡å‹æœ¬ä½“äº†\n\nä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer stateï¼‰\n\nä¾‹å¦‚ AdamW çš„ä¸€é˜¶/äºŒé˜¶åŠ¨é‡ï¼ˆmoment estimatesï¼‰\nä¸å­˜ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢å¤åè®­ç»ƒè½¨è¿¹ä¼šå˜ï¼ˆå› ä¸ºåŠ¨é‡æ²¡äº†ï¼‰\n\nå½“å‰è¿­ä»£æ­¥æ•°ï¼ˆiteration / stepï¼‰\n\nç”¨æ¥æ¢å¤å­¦ä¹ ç‡ schedule\nå¦åˆ™å­¦ä¹ ç‡ä¼šä»å¤´å¼€å§‹æˆ–é”™ä½\n\n\nå®ç°å¦‚ä¸‹ï¼š\n\n\ncs336_basics/utils.py\n\ndef save_checkpoint(\n    model: torch.nn.Module,\n    optimizer,\n    iteration,\n    out: str | os.PathLike | typing.BinaryIO | typing.IO[bytes],\n    verbose: bool = False,\n) -&gt; None:\n    state = {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"iteration\": iteration,\n    }\n\n    torch.save(state, out)\n\n    if verbose:\n        print_color(f\"Checkpoint saved to {out}\", \"blue\")\n\n\ndef load_checkpoint(\n    src: str | os.PathLike | typing.BinaryIO | typing.IO[bytes], model, optimizer, verbose: bool = False\n) -&gt; int:\n    state = torch.load(src, map_location=get_device())\n\n    model.load_state_dict(state[\"model_state_dict\"])\n    optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n\n    if verbose:\n        print_color(f\"Checkpoint loaded from {src}\", \"blue\")\n\n    return state[\"iteration\"]",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#training-looping",
    "href": "posts/CS336/Ass01/ass01.html#training-looping",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "4.5 Training Looping",
    "text": "4.5 Training Looping\næœ€åï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰çš„ç»„ä»¶æ”¾åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼š\n\n\ncs336_basics/train_engine.py\n\ndef train(model: torch.nn.Module, optimizer: torch.optim.Optimizer, train_config: TrainingConfig):\n    tokenizer = load_tokenizer_from_dir(train_config.dataset_dir)\n\n    # Load training dataset\n    original_data = np.memmap(\n        train_config.train_data_path,\n        dtype=np.uint16,\n        mode=\"r+\",\n    )\n    x = torch.from_numpy(original_data)\n\n    best_eval_loss = float(\"inf\")\n    ctx = get_ctx(train_config.use_mixed_precision, train_config.device)\n\n    # Training loop\n    state = BatchState(pos=0)\n    for step in range(train_config.num_steps):\n        # inputs, targets = dataloader\n        inputs, targets = data_loading_sequential(\n            x=x,\n            batch_size=train_config.batch_size,\n            context_length=model.config.max_seq_len,\n            device=train_config.device,\n            state=state,\n        )\n\n        # Forward pass\n        with ctx:\n            logits = model(inputs)\n            logits = logits.view(-1, logits.size(-1))\n            targets = targets.view(-1)\n            loss = cross_entropy(logits, targets)\n\n        # Backward pass and optimization step\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        # Gradient clipping\n        gradient_clip(model.parameters(), max_l2_norm=train_config.max_grad_norm)\n\n        # Learning rate scheduling\n        lr = cosine_annealing_lr(\n            t=step,\n            alpha_max=train_config.max_lr,\n            alpha_min=train_config.min_lr,\n            Tw=train_config.warmup_steps,\n            Tc=train_config.num_steps - train_config.warmup_steps,\n        )\n        for param_group in optimizer.param_groups:\n            param_group[\"lr\"] = lr\n        optimizer.step()\n\n        # Logging\n        if train_config.wandb_logging:\n            wandb.log(\n                {\n                    \"train/loss\": loss.item(),\n                    \"train/perplexity\": perplexity(loss).item(),\n                    \"train/lr\": lr,\n                },\n                step=step + 1,\n            )\n\n        print_color(\n            f\"Step {step + 1}/{train_config.num_steps}, Loss: {loss.item():.4f}, LR: {lr:.6f}\", \"green\"\n        )\n\n        if train_config.eval_log_interval &gt; 0 and (step + 1) % train_config.eval_log_interval == 0:\n            # Cleanup\n            del inputs, targets, logits, loss\n            clear_memory()\n\n            print_color(\"Evaluating model...\", \"blue\")\n            eval_loss, eval_perplexity = eval_model(model, train_config, step + 1)\n            wandb.log(\n                {\n                    \"eval/loss\": eval_loss.item(),\n                    \"eval/perplexity\": eval_perplexity.item(),\n                },\n                step=step + 1,\n            )\n            print_color(\n                f\"Eval Loss: {eval_loss.item():.4f}, Eval Perplexity: {eval_perplexity.item():.4f}\", \"blue\"\n            )\n            if eval_loss &lt; best_eval_loss:\n                best_eval_loss = eval_loss\n                print_color(f\"New best eval loss: {best_eval_loss:.4f}\", \"yellow\")\n                out_path = os.path.join(\n                    train_config.save_checkpoint_dir,\n                    train_config.model_name,\n                    f\"best_model_step_{step + 1}.pt\",\n                )\n                save_checkpoint(\n                    model=model,\n                    optimizer=optimizer,\n                    iteration=step + 1,\n                    out=out_path,\n                    verbose=True,\n                )\n\n        # Sample generation\n        if train_config.sampling_log_interval &gt; 0 and (step + 1) % train_config.sampling_log_interval == 0:\n            generated_outputs = generate(\n                model=model,\n                prompt=\"Once upon a time\",\n                tokenizer=tokenizer,\n                max_new_tokens=256,\n                top_k=50,\n                temperature=0.8,\n            )\n            generated_text = generated_outputs[\"generated_text\"]\n            print_color(f\"Generated text at step {step + 1}:\", \"cyan\")\n            print(\"Once upon a time\", end=\"\")\n            print_color(f\"{generated_text}\\n\", \"cyan\")",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#greedy-sampling",
    "href": "posts/CS336/Ass01/ass01.html#greedy-sampling",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "5.1 Greedy Sampling",
    "text": "5.1 Greedy Sampling\nGreedy Sampling æ˜¯æœ€ç®€å•çš„ä¸€ç§é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ token ä½œä¸ºä¸‹ä¸€ä¸ª tokenã€‚è™½ç„¶è¿™ç§æ–¹æ³•ç®€å•ä¸”é«˜æ•ˆï¼Œä½†å®ƒå¯èƒ½ä¼šå¯¼è‡´ç”Ÿæˆçš„æ–‡æœ¬ç¼ºä¹å¤šæ ·æ€§å’Œåˆ›é€ æ€§ï¼Œå› ä¸ºå®ƒæ€»æ˜¯é€‰æ‹©æœ€å¯èƒ½çš„é€‰é¡¹ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚\n\n\ncs336_basics/generation.py\n\nnext_token_id = next_token_logits.argmax(dim=-1, keepdim=True)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#top-k-sampling",
    "href": "posts/CS336/Ass01/ass01.html#top-k-sampling",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "5.2 Top-K Sampling",
    "text": "5.2 Top-K Sampling\nTop-K Sampling æ˜¯ä¸€ç§æ”¹è¿›çš„é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ K ä¸ª tokenï¼Œç„¶åä»è¿™ K ä¸ª token ä¸­æ ¹æ®å®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ã€‚è¿™æ ·å¯ä»¥å¢åŠ ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼ŒåŒæ—¶ä»ç„¶ä¿æŒä¸€å®šçš„è´¨é‡ã€‚\n\n\ncs336_basics/generation.py\n\ndef top_k_sampling(\n    logits: torch.Tensor,\n    top_k: int,\n):\n    if top_k &lt;= 0:\n        # sample from full distribution\n        probs = F.softmax(logits, dim=-1)\n        return torch.multinomial(probs, num_samples=1).squeeze(-1)\n\n    # 1. keep only top-k logits\n    top_k_logits, top_k_indices = torch.topk(logits, top_k, dim=-1)\n\n    filtered_logits = torch.full_like(logits, float(\"-inf\"))\n    filtered_logits.scatter_(dim=-1, index=top_k_indices, src=top_k_logits)\n\n    # 2. softmax over filtered logits\n    probs = F.softmax(filtered_logits, dim=-1)\n\n    # 3. sample\n    next_token = torch.multinomial(probs, num_samples=1)\n\n    return next_token",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#top-p-sampling",
    "href": "posts/CS336/Ass01/ass01.html#top-p-sampling",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "5.3 Top-P Sampling",
    "text": "5.3 Top-P Sampling\nTop-P Samplingï¼ˆä¹Ÿç§°ä¸º Nucleus Samplingï¼‰æ˜¯ä¸€ç§æ›´çµæ´»çš„é‡‡æ ·æ–¹æ³•ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹ä¼šé€‰æ‹©ç´¯è®¡æ¦‚ç‡è¾¾åˆ° P çš„æœ€å° token é›†åˆï¼Œç„¶åä»è¿™ä¸ªé›†åˆä¸­æ ¹æ®å®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ã€‚è¿™æ ·å¯ä»¥åŠ¨æ€è°ƒæ•´å€™é€‰ token çš„æ•°é‡ï¼Œæ—¢ä¿è¯äº†å¤šæ ·æ€§ï¼Œåˆé¿å…äº†é€‰æ‹©è¿‡äºç½•è§çš„ tokenã€‚\n\n\ncs336_basics/generation.py\n\ndef top_p_sampling(logits: torch.Tensor, top_p: float) -&gt; torch.Tensor:\n    \"\"\"\n    logits: (B, V)\n    returns: (B,) sampled token ids\n    \"\"\"\n    assert 0.0 &lt; top_p &lt;= 1.0\n\n    # sort\n    sorted_logits, sorted_indices = torch.sort(logits, dim=-1, descending=True)\n    sorted_probs = F.softmax(sorted_logits, dim=-1)\n    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n\n    # mask tokens with cumulative prob &gt; top_p (but keep at least 1 token)\n    sorted_indices_to_remove = cumulative_probs &gt; top_p\n    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n    sorted_indices_to_remove[..., 0] = False\n\n    # scatter mask back to original vocab positions\n    indices_to_remove = torch.zeros_like(logits, dtype=torch.bool)\n    indices_to_remove.scatter_(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n\n    filtered_logits = logits.masked_fill(indices_to_remove, float(\"-inf\"))\n\n    probs = F.softmax(filtered_logits, dim=-1)\n    next_token = torch.multinomial(probs, num_samples=1)\n\n    return next_token",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#temperature",
    "href": "posts/CS336/Ass01/ass01.html#temperature",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "5.4 Temperature",
    "text": "5.4 Temperature\nå½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è°ƒæ•´ temperature æ¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚Temperature æ˜¯ä¸€ä¸ªæ­£æ•°ï¼Œé€šå¸¸åœ¨ \\[ (0, \\infty) \\] èŒƒå›´å†…ã€‚å®ƒé€šè¿‡ç¼©æ”¾ logits æ¥å½±å“æ¦‚ç‡åˆ†å¸ƒï¼š\n\nå½“ temperature &lt; 1 æ—¶ï¼Œæ¦‚ç‡åˆ†å¸ƒä¼šå˜å¾—æ›´é™¡å³­ï¼Œæ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©é«˜æ¦‚ç‡çš„ tokenï¼Œç”Ÿæˆçš„æ–‡æœ¬æ›´ç¡®å®šæ€§ã€‚\nå½“ temperature &gt; 1 æ—¶ï¼Œæ¦‚ç‡åˆ†å¸ƒä¼šå˜å¾—æ›´å¹³å¦ï¼Œæ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©ä½æ¦‚ç‡çš„ tokenï¼Œç”Ÿæˆçš„æ–‡æœ¬æ›´å…·å¤šæ ·æ€§å’Œåˆ›é€ æ€§ã€‚\n\næ•°å­¦ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡é™¤ä»¥ temperature æ¥è°ƒæ•´ logitsï¼š\n\\[\n\\mathrm{softmax}_i(\\mathbf{z};T)\n=\\frac{\\exp\\left(\\frac{z_i}{T}\\right)}\n{\\sum_{j}\\exp\\left(\\frac{z_j}{T}\\right)}\n\\tag{44}\\]\n\n\n\n\n\n\nFigureÂ 10: Temperature å¯¹é‡‡æ ·åˆ†å¸ƒçš„å½±å“ç¤ºæ„å›¾",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#part-04-summary",
    "href": "posts/CS336/Ass01/ass01.html#part-04-summary",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "5.5 Part 04 Summary",
    "text": "5.5 Part 04 Summary\nåœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚æˆ‘ä»¬è®¨è®ºäº†å‡ ç§å¸¸ç”¨çš„é‡‡æ ·æ–¹æ³•ï¼ŒåŒ…æ‹¬ Greedy Samplingã€Top-K Sampling å’Œ Top-P Samplingï¼Œå¹¶ä»‹ç»äº†å¦‚ä½•é€šè¿‡è°ƒæ•´ temperature æ¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚é€šè¿‡è¿™äº›æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–ä¸”æœ‰è¶£çš„æ–‡æœ¬å†…å®¹ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Method\nDescription\nPros\nCons\n\n\n\n\nGreedy Sampling\né€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ token\nç®€å•é«˜æ•ˆ\nå¯èƒ½ç¼ºä¹å¤šæ ·æ€§ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜\n\n\nTop-K Sampling\nä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token ä¸­é‡‡æ ·, Kè¶Šå¤§å¤šæ ·æ€§è¶Šé«˜\nå¢åŠ å¤šæ ·æ€§\néœ€è¦é€‰æ‹©åˆé€‚çš„ K å€¼ï¼Œé€šå¸¸ K å€¼åœ¨ 10 åˆ° 50 ä¹‹é—´\n\n\nTop-P Sampling\nä»ç´¯è®¡æ¦‚ç‡è¾¾åˆ° P çš„ token é›†åˆä¸­é‡‡æ ·ï¼ŒPè¶Šå¤§å¤šæ ·æ€§è¶Šé«˜\nåŠ¨æ€è°ƒæ•´å€™é€‰ token æ•°é‡\néœ€è¦é€‰æ‹©åˆé€‚çš„ P å€¼ï¼Œé€šå¸¸ P å€¼åœ¨ 0.8 åˆ° 0.9 ä¹‹é—´\n\n\nTemperature Adjustment\né€šè¿‡è°ƒæ•´ temperature æ§åˆ¶éšæœºæ€§ï¼Œtemperature è¶Šå¤§å¤šæ ·æ€§è¶Šé«˜\nçµæ´»æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§\néœ€è¦é€‰æ‹©åˆé€‚çš„ temperature å€¼ï¼Œ é€šå¸¸åœ¨ 0.7 åˆ° 1.0 ä¹‹é—´\n\n\n\n\n\nTableÂ 2: æ€»ç»“ä¸åŒé‡‡æ ·æ–¹æ³•çš„ä¼˜ç¼ºç‚¹",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Ass01/ass01.html#plots",
    "href": "posts/CS336/Ass01/ass01.html#plots",
    "title": "Assignment 01: Tokenization & Language Modeling",
    "section": "6.1 Plots",
    "text": "6.1 Plots\n\n\n\n\n\n\n\n\n\nTraining Loss\n\n\n\n\n\n\n\nTraining Perplexity\n\n\n\n\n\n\n\n\n\nEvaluation Loss\n\n\n\n\n\n\n\nEvaluation Perplexity\n\n\n\n\n\n\nFigureÂ 11: Loss å’Œ Perplexity æ›²çº¿æ˜¾ç¤º\n\n\n\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å®Œæˆäº†10Kæ­¥çš„è®­ç»ƒä¹‹åï¼Œæ¨¡å‹çš„è®­ç»ƒæŸå¤±å’Œè¯„ä¼°æŸå¤±éƒ½æœ‰äº†æ˜æ˜¾çš„ä¸‹é™ï¼Œå›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ä¹Ÿæœ‰äº†æ˜¾è‘—çš„æå‡ã€‚è¿™è¡¨æ˜æ¨¡å‹å·²ç»å­¦ä¼šäº†ä¸€äº›è¯­è¨€æ¨¡å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚æœ€åçš„ç»“æœï¼š\neval/loss:0.7857699394226074\neval/perplexity:2.194427490234375\ntrain/loss:0.7850267291069031\ntrain/perplexity:2.192465543746948\næˆ‘ä»¬çœ‹çœ‹æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n\n\n\n\n\n\nFigureÂ 12: ç”Ÿæˆæ–‡æœ¬ç¤ºä¾‹, prompt=â€œOnce upon a timeâ€, max_new_tokens=256, top_k=50, temperature=0.8\n\n\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç”Ÿæˆçš„å¥å­ï¼Œæœ‰ä¸€å®šçš„è¿è´¯æ€§ï¼Œ ä½†æ˜¯æ•…äº‹å¹¶ä¸æ˜¯å®Œæ•´çš„ï¼Œä¸”æœ‰ä¸€å®šçš„é€»è¾‘æ··ä¹±ã€‚è¿™æ˜¯å› ä¸ºæ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œè®­ç»ƒæ­¥æ•°æœ‰é™ï¼Œæ— æ³•å®Œå…¨æ•æ‰åˆ°å¤æ‚çš„è¯­è¨€ç»“æ„å’Œæ•…äº‹æƒ…èŠ‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹å‡ ç§æ–¹å¼æ¥æå‡ç”Ÿæˆæ•ˆæœï¼š\n\nå¢åŠ è®­ç»ƒçš„stepsï¼šç°åœ¨æ˜¯10Kï¼Œå¦‚æœå¢åŠ åˆ°15Kï¼Œ20Kï¼Œæ•ˆæœåº”è¯¥ä¼šæ›´å¥½\nå¢å¤§Batch Sizeï¼šç›¸å¯¹çš„æ¥è¯´ï¼ŒBatch Sizeè¶Šå¤§ï¼ŒNoiseå°±è¶Šå°ï¼Œè®­ç»ƒå°±æ›´åŠ ç¨³å½“\nå¢åŠ Context Lengthï¼šå½“å‰çš„Context Lengthæ˜¯256ï¼Œå°†å…¶å¢å¤§åˆ°512ï¼Œæˆ–è€…æ›´å¤§ï¼Œå¯ä»¥è¦†ç›–ä¸€ä¸ªæ•´ä¸ªå®Œæ•´çš„æ•…äº‹ç»“æ„ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 01: BPE Tokenizer & Transformer LM"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html",
    "href": "posts/CS336/Lecture02/lec02.html",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "",
    "text": "Lecture 02 ä¸»è¦ä»‹ç»äº† PyTorch çš„åŸºç¡€çŸ¥è¯†å’Œä¸€äº›å®ç”¨çš„å·¥å…·åº“ï¼Œæ¯”å¦‚ einopsã€‚è¯¾ç¨‹å†…å®¹æ¶µç›–äº†å¼ é‡æ“ä½œã€æ•°æ®ç±»å‹ã€ä¼˜åŒ–å™¨ç­‰æ–¹é¢çš„å†…å®¹ã€‚å¹¶ä¸”æœ€é‡è¦çš„æ˜¯ï¼Œæå‡ºäº†ä¸€ä¸ª Resource Accountingï¼Œ å³è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦å¤šå¤§çš„å†…å­˜å’Œè®¡ç®—èµ„æºã€‚ é€šè¿‡ Resource Accountingï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ç†è§£æ¨¡å‹è®­ç»ƒçš„èµ„æºéœ€æ±‚ï¼Œä»è€Œä¼˜åŒ–æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒè¿‡ç¨‹ã€‚\nè¯¾ç¨‹è§†é¢‘å¦‚ä¸‹æ‰€ç¤ºï¼š",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#memory-accounting",
    "href": "posts/CS336/Lecture02/lec02.html#memory-accounting",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.1 Memory Accounting",
    "text": "1.1 Memory Accounting\næ‰€æœ‰çš„æ•°æ®ï¼ˆåŒ…æ‹¬æ¨¡å‹å‚æ•°ã€æ¿€æ´»å€¼ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰éƒ½æ˜¯ä»¥ Tensor çš„å½¢å¼å‚¨å­˜ã€‚æˆ‘ä»¬æœ‰å¾ˆå¤šç§æ–¹å¼åˆ›å»ºä¸€ä¸ª Tensorï¼Œæ¯”å¦‚ï¼š\nx = torch.tensor([[1., 2, 3], [4, 5, 6]])\nx= torch.randn(3, 4)\nx = torch.zeros(2, 5)\nx = torch.empty(10, 10)\næ¯ä¸ª Tensor éƒ½æœ‰ä¸€ä¸ªæ•°æ®ç±»å‹ (Data Type)ï¼Œé»˜è®¤çš„æ•°æ®ç±»å‹æ˜¯ float32 (ä¹Ÿç§°ä¸º FP32)ã€‚ä¸åŒçš„æ•°æ®ç±»å‹ä¼šå ç”¨ä¸åŒçš„å†…å­˜ç©ºé—´ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹å‡ ç§å¸¸è§çš„æ•°æ®ç±»å‹åŠå…¶å†…å­˜å ç”¨\n\n1.1.1 Common Data Types\nåœ¨äº†è§£ä¸åŒçš„Float Typesä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€ä¸‹æµ®ç‚¹æ•°çš„è¡¨ç¤ºæ–¹æ³•ã€‚è®¡ç®—æœºä¸­çš„æµ®ç‚¹æ•°é€šå¸¸é‡‡ç”¨ IEEE 754 æ ‡å‡†è¿›è¡Œè¡¨ç¤ºã€‚æµ®ç‚¹æ•°ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼šç¬¦å·ä½ (Sign Bit)ã€æŒ‡æ•°ä½ (Exponent Bits) å’Œå°¾æ•°ä½ (Mantissa Bits), ä¹Ÿå«Fraction ã€‚\n\n\n\n\n\n\nFigureÂ 1: æµ®ç‚¹æ•°çš„è¡¨ç¤º\n\n\n\næµ®ç‚¹æ•°çš„å€¼å¯ä»¥é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—ï¼š \\[\nnumber = (-1)^{Sign} \\times Base^{(Exponent - Bias)} \\times 1.Mantissa\n\\tag{1}\\]\nå…¶ä¸­ï¼ŒBase é€šå¸¸ä¸º2ï¼ŒBias æ˜¯ä¸€ä¸ªç”¨äºè°ƒæ•´æŒ‡æ•°çš„åç§»é‡ï¼Œå…·ä½“å–å†³äºæŒ‡æ•°ä½çš„é•¿åº¦, é€šå¸¸ä¸º2çš„æŒ‡æ•°ä½é•¿åº¦å‡1çš„å€¼ ä¸º127ã€‚\n = b_1Â·2^{-1} + b_2Â·2^{-2} + b_3Â·2^{-3} + â€¦ + b_{23}Â·2^{-23}\nå¯¹äº FigureÂ 1 ä¸­çš„æµ®ç‚¹æ•°è¡¨ç¤ºï¼š\n\nç¬¦å·ä½ (Sign) ä¸º 0ï¼Œè¡¨ç¤ºæ­£æ•°\næŒ‡æ•°ä½ (Exponent) ä¸º 01111100ï¼Œè½¬æ¢ä¸ºåè¿›åˆ¶ä¸º 124ï¼Œå‡å» Bias 127 å¾—åˆ° -3\nå°¾æ•°ä½ (Mantissa) ä¸º 01000000000000000000000 ï¼Œè½¬æ¢ä¸ºåè¿›åˆ¶ä¸º 0.25ï¼Œå› æ­¤ 1.Mantissa = 1 + 0.25 = 1.25\n\nå°†è¿™äº›å€¼ä»£å…¥å…¬å¼ EquationÂ 1 ä¸­ï¼Œå¯ä»¥è®¡ç®—å‡ºæµ®ç‚¹æ•°çš„å€¼ä¸ºï¼š \\[\nnumber = (-1)^0 \\times 2^{-3} \\times 1.25 = 0.15625\n\\]\næ¯”å¦‚ bias 10000000ï¼Œè½¬æ¢ä¸ºåè¿›åˆ¶ä¸º 128ï¼Œå‡å» Bias 127 å¾—åˆ° 1\n\n\n\n\n\n\nFigureÂ 2: é€šè¿‡è¿™ä¸ªåœ¨çº¿è®¡ç®—å™¨ï¼ŒéªŒè¯æµ®ç‚¹æ•°çš„è¡¨ç¤ºæ–¹æ³•ã€‚\n\n\n\næ˜ç™½äº†Float Numberçš„è®¡ç®—æ–¹æ³•ä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å‡ ç§å¸¸è§çš„æ•°æ®ç±»å‹åŠå…¶å†…å­˜å ç”¨ã€‚\n\n1.1.1.1 Float32\n\n\n\n\n\n\nFigureÂ 3: Float32 ä½¿ç”¨32ä½ (4å­—èŠ‚) æ¥è¡¨ç¤ºä¸€ä¸ªæµ®ç‚¹æ•°ã€‚å®ƒç”±1ä½ç¬¦å·ä½ã€8ä½æŒ‡æ•°ä½å’Œ23ä½å°¾æ•°ä½ç»„æˆï¼Œå¯ä»¥è¡¨ç¤ºå¤§çº¦7ä½åè¿›åˆ¶æœ‰æ•ˆæ•°å­—ã€‚\n\n\n\nFloat32 ä¹Ÿå« single precision æ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„æ•°æ®ç±»å‹ï¼Œå‡ ä¹æ‰€æœ‰çš„æ·±åº¦å­¦ä¹ æ¡†æ¶éƒ½é»˜è®¤ä½¿ç”¨ Float32 ä½œä¸ºå¼ é‡çš„æ•°æ®ç±»å‹ã€‚ Float32 å¯ä»¥è¡¨ç¤ºçš„æ•°å€¼èŒƒå›´å¤§çº¦åœ¨ 1.18e-38 åˆ° 3.4e+38 ä¹‹é—´ï¼Œè¶³ä»¥æ»¡è¶³å¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡çš„éœ€æ±‚ã€‚\nx = torch.tensor([1.0, 2.0, 3.0])\nprint(x.dtype)  # è¾“å‡º: torch.float32\nprint(x.element_size())  # è¾“å‡º: 4 (æ¯ä¸ªå…ƒç´ å ç”¨4å­—èŠ‚)\n\n\n\n\n\n\nFigureÂ 4: Float16 ä½¿ç”¨16ä½ (2å­—èŠ‚) æ¥è¡¨ç¤ºä¸€ä¸ªæµ®ç‚¹æ•°ã€‚å®ƒç”±1ä½ç¬¦å·ä½ã€5ä½æŒ‡æ•°ä½å’Œ10ä½å°¾æ•°ä½ç»„æˆï¼Œå¯ä»¥è¡¨ç¤ºå¤§çº¦3ä½åè¿›åˆ¶æœ‰æ•ˆæ•°å­—ã€‚\n\n\n\nFloat16 ä¹Ÿå« half precisionï¼Œä¸»è¦ç”¨äºå‡å°‘å†…å­˜å ç”¨å’ŒåŠ é€Ÿè®¡ç®—ã€‚ç›¸æ¯”äº Float32ï¼ŒFloat16 å¯ä»¥æ˜¾è‘—é™ä½å†…å­˜ä½¿ç”¨é‡ï¼Œä»è€Œå…è®¸æˆ‘ä»¬è®­ç»ƒæ›´å¤§çš„æ¨¡å‹æˆ–è€…ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡å¤§å° (Batch Size)ã€‚\nFloat16 å¯ä»¥è¡¨ç¤ºçš„æ•°å€¼èŒƒå›´å¤§çº¦åœ¨ 6.1e-5 åˆ° 6.5e+4 ä¹‹é—´ï¼Œç›¸æ¯”äº Float32 æœ‰ä¸€å®šçš„é™åˆ¶ï¼Œå°¤å…¶æ˜¯åœ¨è¡¨ç¤ºéå¸¸å°æˆ–è€…éå¸¸å¤§çš„æ•°å€¼æ—¶å¯èƒ½ä¼šå‡ºç°æº¢å‡ºï¼ˆOverflowï¼‰æˆ–è€…ä¸‹æº¢ï¼ˆUnderflowï¼‰çš„é—®é¢˜ã€‚å½“è¿™ä¸ªé—®é¢˜å‡ºç°æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå‡ºç°NaNçš„æƒ…å†µï¼Œç”±æ­¤å¯¼è‡´è®­ç»ƒå¤±è´¥ã€‚\n\n\n\n\n\n\nTip\n\n\n\nå½“æˆ‘ä»¬è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼ŒæŸå¤±å‡½æ•°å‡ºç°NaNçš„æƒ…å†µï¼Œé€šå¸¸æ˜¯å› ä¸ºæ•°å€¼æº¢å‡ºæˆ–è€…ä¸‹æº¢å¯¼è‡´çš„ã€‚\n\n\nIn [14]: x = torch.tensor([1e-8], dtype=torch.float16)\n\nIn [15]: x\nOut[15]: tensor([0.], dtype=torch.float16)\n\nIn [8]: x = torch.tensor([1e+8], dtype=torch.float16)\n\nIn [9]: x\nOut[9]: tensor([inf], dtype=torch.float16)\n\n\n1.1.1.2 BFloat16\n\n\n\n\n\n\nFigureÂ 5: BFloat16 ä½¿ç”¨16ä½ (2å­—èŠ‚) æ¥è¡¨ç¤ºä¸€ä¸ªæµ®ç‚¹æ•°ã€‚å®ƒç”±1ä½ç¬¦å·ä½ã€8ä½æŒ‡æ•°ä½å’Œ7ä½å°¾æ•°ä½ç»„æˆï¼Œå¯ä»¥è¡¨ç¤ºå¤§çº¦3ä½åè¿›åˆ¶æœ‰æ•ˆæ•°å­—ã€‚\n\n\n\nGoogle åœ¨2018å¹´æå‡ºäº† BFloat16 (Brain Float Point 16) æ•°æ®ç±»å‹ï¼Œä¸»è¦ç”¨äºæ·±åº¦å­¦ä¹ åŠ é€Ÿã€‚ç›¸æ¯”äº Float16ï¼ŒBFloat16 ä¿ç•™äº†ä¸ Float32 ç›¸åŒçš„æŒ‡æ•°ä½é•¿åº¦ï¼Œå› æ­¤å¯ä»¥è¡¨ç¤ºæ›´å¤§çš„æ•°å€¼èŒƒå›´ï¼Œä»è€Œå‡å°‘äº†æº¢å‡ºå’Œä¸‹æº¢çš„é£é™©ã€‚ç›¸å¯¹äºFloat32ï¼Œ BFloat16 çš„ç²¾åº¦è¾ƒä½ï¼Œä½†åœ¨è®¸å¤šæ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ï¼ŒBFloat16 çš„ç²¾åº¦å·²ç»è¶³å¤Ÿä½¿ç”¨ã€‚\nIn [11]: x\nOut[11]: tensor([1.0014e+08], dtype=torch.bfloat16)\n\nIn [12]: x = torch.tensor([1e-8], dtype=torch.bfloat16)\n\nIn [13]: x\nOut[13]: tensor([1.0012e-08], dtype=torch.bfloat16)\nIn [16]: torch.finfo(torch.float32)\nOut[16]: finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)\n\nIn [17]: torch.finfo(torch.float16)\nOut[17]: finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n\nIn [18]: torch.finfo(torch.bfloat16)\nOut[18]: finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n\n\n1.1.1.3 FP8\nFP8 æ˜¯ä¸€ç§8ä½æµ®ç‚¹æ•°è¡¨ç¤ºæ–¹æ³•ï¼Œé€šå¸¸ç”¨äºæç«¯å†…å­˜å—é™çš„åœºæ™¯ï¼ˆæ¯”å¦‚å°†æ¨¡å‹éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ï¼‰ã€‚FP8 æœ‰ä¸¤ç§ä¸»è¦æ ¼å¼ï¼šE4M3 å’Œ E5M2ã€‚\n\n\n\n\n\n\nFigureÂ 6: FP8 ä½¿ç”¨8ä½ (1å­—èŠ‚) æ¥è¡¨ç¤ºä¸€ä¸ªæµ®ç‚¹æ•°ã€‚E4M3 ç”±1ä½ç¬¦å·ä½ã€4ä½æŒ‡æ•°ä½å’Œ3ä½å°¾æ•°ä½ç»„æˆï¼›E5M2 ç”±1ä½ç¬¦å·ä½ã€5ä½æŒ‡æ•°ä½å’Œ2ä½å°¾æ•°ä½ç»„æˆã€‚\n\n\n\nE4M3 (range [-448, 448]) and E5M2 ([-57344, 57344]).\n\n\n1.1.1.4 Other Data Types\né™¤äº†ä¸Šè¿°å‡ ç§å¸¸è§çš„æ•°æ®ç±»å‹ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–çš„æ•°æ®ç±»å‹ï¼Œæ¯”å¦‚ int8 å’Œ int4ã€‚è¿™äº›æ•°æ®ç±»å‹é€šå¸¸ç”¨äºé‡åŒ– (Quantization) æŠ€æœ¯ï¼Œé€šè¿‡å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºæ•´æ•°æ¥å‡å°‘å†…å­˜å ç”¨å’ŒåŠ é€Ÿè®¡ç®—ã€‚\n\n\n\nData Type\nDescription\nBits per Value\nBytes per Value\n\n\n\n\nfloat32\nSingle Precision\n32\n4\n\n\nfloat16\nHalf Precision\n16\n2\n\n\nbfloat16\nBrain Float\n16\n2\n\n\nint8\n8-bit Integer\n8\n1\n\n\nint4\n4-bit Integer\n4\n0.5\n\n\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸åŒçš„æ•°æ®ç±»å‹æœ‰ä¸åŒçš„å†…å­˜å ç”¨ã€‚é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹å¯ä»¥å¸®åŠ©æˆ‘ä»¬åœ¨å†…å­˜å—é™çš„æƒ…å†µä¸‹è®­ç»ƒæ›´å¤§çš„æ¨¡å‹æˆ–è€…ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡å¤§å°ï¼š\n\nç”¨ float32 è¿›è¡Œè®­ç»ƒï¼Œé€‚ç”¨äºå¤§å¤šæ•°ä»»åŠ¡ï¼Œä½†å†…å­˜å ç”¨è¾ƒé«˜ã€‚\nç”¨ float16 è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨ï¼Œä½†éœ€è¦æ³¨æ„æ•°å€¼æº¢å‡ºå’Œä¸‹æº¢çš„é—®é¢˜ã€‚\nç”¨ bfloat16 è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥åœ¨å‡å°‘å†…å­˜å ç”¨çš„åŒæ—¶ï¼Œä¿æŒè¾ƒå¤§çš„æ•°å€¼èŒƒå›´ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚\nç”¨ int8 æˆ– int4 è¿›è¡Œé‡åŒ–è®­ç»ƒï¼Œå¯ä»¥æå¤§åœ°å‡å°‘å†…å­˜å ç”¨ï¼Œä½†éœ€è¦è¿›è¡Œé¢å¤–çš„é‡åŒ–å’Œåé‡åŒ–æ“ä½œï¼Œé€‚ç”¨äºéƒ¨ç½²é˜¶æ®µã€‚\n\nå› æ­¤åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é‡‡ç”¨ä¸€ç§Mixed Precision Trainingçš„æ–¹æ³•ï¼Œæ¥å¹³è¡¡å†…å­˜å ç”¨å’Œæ•°å€¼ç²¾åº¦çš„é—®é¢˜ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#compute-accounting",
    "href": "posts/CS336/Lecture02/lec02.html#compute-accounting",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.2 Compute Accounting",
    "text": "1.2 Compute Accounting\nåœ¨äº†è§£äº†å†…å­˜å ç”¨ä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹è®¡ç®—èµ„æºçš„éœ€æ±‚ã€‚è®¡ç®—èµ„æºä¸»è¦å–å†³äºæ¨¡å‹çš„å‚æ•°é‡å’Œè®­ç»ƒæ•°æ®çš„è§„æ¨¡ã€‚\n\n1.2.1 Tensor on GPUs\nå½“æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Tensor æ—¶ï¼Œå®ƒé»˜è®¤æ˜¯åœ¨ CPU ä¸Šåˆ›å»ºçš„ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦åœ¨ GPU ä¸Šè¿›è¡Œè®¡ç®—ï¼Œéœ€è¦å°† Tensor ç§»åŠ¨åˆ° GPU ä¸Šï¼š\nx = torch.tensor([1.0, 2.0, 3.0])\nx.device  # è¾“å‡º: cpu\nx = x.cuda()  # å°† Tensor ç§»åŠ¨åˆ° GPU ä¸Š\nx.device  # è¾“å‡º: cuda:0\n\n\n\n\n\n\nFigureÂ 7: æˆ‘ä»¬å°†Tensorä»CPUçš„RAMä¸Šï¼Œç§»åŠ¨åˆ°DRAMä¸Šã€‚\n\n\n\næˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åˆ›å»ºä¸€ä¸ªç›´æ¥åœ¨ GPU ä¸Šçš„ Tensorï¼š\nx = torch.tensor([1.0, 2.0, 3.0], device='cuda')\nå¯ä»¥é€šè¿‡GPUçš„å†…å­˜æƒ…å†µæ¥æŸ¥çœ‹å½“å‰ GPU ä¸Šçš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼š\nimport torch\nprint(torch.cuda.memory_summary())\nmemory_allocated = torch.cuda.memory_allocated() \nx = torch.tensor([1.0, 2.0, 3.0], device='cuda')\nmemory_allocated_after = torch.cuda.memory_allocated()\nprint(f\"Memory allocated before: {memory_allocated}, after: {memory_allocated_after}\")",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#tensor-operations",
    "href": "posts/CS336/Lecture02/lec02.html#tensor-operations",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.3 Tensor Operations",
    "text": "1.3 Tensor Operations\nPyTorch Tensor æ˜¯ä¸€ä¸ªPointerï¼ŒæŒ‡å‘ä¸€å—è¿ç»­çš„å†…å­˜åŒºåŸŸã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡stridesæ¥è®¿é—®Tensorä¸­çš„æ•°æ®ã€‚\n\n\n\n\n\n\nFigureÂ 8\n\n\n\nTensor æœ‰å¾ˆå¤šæ“ä½œï¼Œæ¯”å¦‚ reshape, permute, transpose ç­‰ç­‰ã€‚è¿™äº›æ“ä½œé€šå¸¸ä¸ä¼šæ”¹å˜æ•°æ®çš„å­˜å‚¨æ–¹å¼ï¼Œè€Œæ˜¯é€šè¿‡ä¿®æ”¹ strides æ¥å®ç°å¯¹æ•°æ®çš„ä¸åŒè§†å›¾ (View)ã€‚è¿™æ˜¯ååˆ†é«˜æ•ˆçš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦è¿›è¡Œæ•°æ®çš„å¤åˆ¶ (Copy)ï¼Œåªéœ€è¦ä¿®æ”¹ Tensor çš„å…ƒæ•°æ® (Metadata)ã€‚ä¸è¿‡éœ€è¦å°å¿ƒçš„æ˜¯ï¼Œå½“æˆ‘ä»¬ä¿®æ”¹ Tensor çš„æ•°æ®æ—¶ï¼Œå¯èƒ½ä¼šå½±å“åˆ°åŸå§‹æ•°æ®ï¼Œå› ä¸ºå®ƒä»¬å…±äº«åŒä¸€å—å†…å­˜åŒºåŸŸã€‚\næœ‰ä¸€äº›æ“ä½œä¼šå¯¼è‡´æ•°æ®å˜å¾—ä¸è¿ç»­ (Non-Contiguous)ï¼Œæ¯”å¦‚ transpose å’Œ permuteã€‚è¿™äº›æ“ä½œä¼šæ”¹å˜æ•°æ®çš„å­˜å‚¨é¡ºåºï¼Œä»è€Œå¯¼è‡´æ•°æ®åœ¨å†…å­˜ä¸­ä¸å†æ˜¯è¿ç»­å­˜å‚¨çš„ã€‚è¿™æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ contiguous() æ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„è¿ç»­å­˜å‚¨çš„ Tensorã€‚\n\n\n\n\n\n\nNote\n\n\n\n.transpose().contiguous() çš„æ“ä½œæˆ‘ä»¬åœ¨ä¸€ Attention çš„è®¡ç®—ä¸­ç»å¸¸ä¼šç”¨åˆ°ã€‚\n\n\nElement-wise æ“ä½œ (æ¯”å¦‚åŠ æ³•ã€ä¹˜æ³•ç­‰) é€šå¸¸è¦æ±‚è¾“å…¥çš„ Tensor æ˜¯è¿ç»­å­˜å‚¨çš„ã€‚å¦‚æœè¾“å…¥çš„ Tensor æ˜¯ä¸è¿ç»­çš„ï¼ŒPyTorch ä¼šè‡ªåŠ¨è°ƒç”¨ contiguous() æ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„è¿ç»­å­˜å‚¨çš„ Tensorï¼Œä»è€Œä¿è¯æ“ä½œçš„æ­£ç¡®æ€§ã€‚ï¼Œæ¯”å¦‚ï¼š\nx = torch.tensor([1, 4, 9])\nx.pow(2)\nx.sqrt()\nx.rsqrt()\nx + x \nx * 2\nx.triu()\n\n1.3.1 Matrix Multiplication\næœ€é‡è¦çš„ä¹Ÿæ˜¯æœ€å¸¸ç”¨çš„æ“ä½œä¹‹ä¸€æ˜¯çŸ©é˜µä¹˜æ³• (Matrix Multiplication)ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µä¹˜æ³•è¢«å¹¿æ³›åº”ç”¨äºç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­è¿‡ç¨‹ä¸­ã€‚\nA = torch.randn(3, 4)\nB = torch.randn(4, 5)\nC = torch.matmul(A, B)  # C çš„å½¢çŠ¶ä¸º (3,5)\nC = A @ B  # å¦ä¸€ç§çŸ©é˜µä¹˜æ³•çš„å†™æ³•\nC = A.mm(B)  # å¦ä¸€ç§çŸ©é˜µä¹˜æ³•çš„å†™æ³•",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#gradient-calculation",
    "href": "posts/CS336/Lecture02/lec02.html#gradient-calculation",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.4 Gradient Calculation",
    "text": "1.4 Gradient Calculation\näº†è§£äº†çŸ©é˜µä¹˜æ³•ä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•è®¡ç®—æ¢¯åº¦ (Gradient)ã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¢¯åº¦æ˜¯ç”¨æ¥æ›´æ–°æ¨¡å‹å‚æ•°çš„å…³é”®ã€‚PyTorch æä¾›äº†è‡ªåŠ¨å¾®åˆ† (Autograd) åŠŸèƒ½ï¼Œå¯ä»¥è‡ªåŠ¨è®¡ç®—å¼ é‡çš„æ¢¯åº¦ã€‚\nå‡è®¾æˆ‘ä»¬æœ‰ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œå±‚ï¼š\n\\[\nY = 0.5 * (X  W - 5)^2\n\\]\nåœ¨å‰ç½®çš„ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—è¾“å‡º Yï¼š\nx = torch.randn([1., 2, 3])  # è¾“å…¥å¼ é‡ X\nw = torch.randn([1., 2, 3], requires_grad=True)  # æƒé‡å¼ \ny = 0.5 * (x @ w - 5) ** 2  # å‰å‘ä¼ æ’­è®¡ç®—è¾“å‡º Y\npred_y = x @ w\nloss = 0.5 * (pred_y - 5) ** 2\nåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—æ¢¯åº¦ï¼š\nloss.backward()  # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\nprint(w.grad)  # è¾“å‡ºæƒé‡ w çš„æ¢¯åº¦",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#summary",
    "href": "posts/CS336/Lecture02/lec02.html#summary",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.5 Summary",
    "text": "1.5 Summary\nForward Pass: 2 * Number of data points * Number of parameters Backward Pass: 4 * Number of data points * Number of parameters\nTotal: 6 * Number of data points * Number of parameters\n\n1.5.1 Einops Library\nåœ¨å¤„ç†é«˜ç»´å¼ é‡æ—¶ï¼Œå¼ é‡çš„é‡æ’ (Rearrangement) å’Œå˜å½¢ (Reshaping) æ˜¯éå¸¸å¸¸è§çš„æ“ä½œã€‚ä¼ ç»Ÿçš„æ–¹æ³•é€šå¸¸éœ€è¦å¤šè¡Œä»£ç ï¼Œå¹¶ä¸”å®¹æ˜“å‡ºé”™ã€‚einops æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åº“ï¼Œå¯ä»¥ç®€åŒ–è¿™äº›æ“ä½œï¼Œä½¿ä»£ç æ›´åŠ ç®€æ´å’Œæ˜“è¯»ã€‚\n\n\n\n\n\n\n\nTip\n\n\n\nå¦‚æœä»¥ä¸Šçš„å†…å®¹æ¯”è¾ƒéš¾ä»¥ç†è§£çš„è¯ï¼Œå¯ä»¥è®¿é—®è¿™ä¸ªé“¾æ¥ã€‚ é‡Œé¢æœ‰éå¸¸è¯¦ç»†çš„einopsæ•™ç¨‹ï¼ŒåŒ…å«äº†å¾ˆå¤šä¾‹å­å’Œå¯è§†åŒ–çš„å›¾ç¤ºã€‚\n\n\nåœ¨è¿™é‡Œå°±ä¸å…·ä½“å±•å¼€äº†ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#tensor-flops",
    "href": "posts/CS336/Lecture02/lec02.html#tensor-flops",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "1.6 Tensor Flops",
    "text": "1.6 Tensor Flops\näº†è§£äº†å†…å­˜å ç”¨å’Œè®¡ç®—èµ„æºä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•è®¡ç®— Tensor çš„ FLOPs (Floating Point Operations)ã€‚FLOPs æ˜¯è¡¡é‡è®¡ç®—å¤æ‚åº¦çš„ä¸€ä¸ªé‡è¦æŒ‡æ ‡ï¼Œè¡¨ç¤ºæ¯ç§’é’Ÿå¯ä»¥æ‰§è¡Œå¤šå°‘æ¬¡æµ®ç‚¹è¿ç®—ã€‚å…¶ä¸­ä¸¤ä¸ªå¸¸è§çš„æŒ‡æ ‡æ˜¯ï¼š\n\nFLOPs: æ€»å…±éœ€è¦æ‰§è¡Œçš„æµ®ç‚¹è¿ç®—æ¬¡æ•°\nFLOP/s ä¹Ÿå†™ä½œFLOPSï¼š æ¯ç§’é’Ÿå¯ä»¥æ‰§è¡Œçš„æµ®ç‚¹è¿ç®—æ¬¡æ•°\n\nå¯¹äºä¸¤ä¸ª çŸ©é˜µ A (å½¢çŠ¶ä¸º m x n) å’Œ B (å½¢çŠ¶ä¸º n x p) çš„çŸ©é˜µä¹˜æ³• C = A @ Bï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡º FLOPs å¦‚ä¸‹ï¼š \\[\nFLOPs = 2 * m * n * p\n\\]\nå…¶ä¸­ï¼Œä¹˜æ³•æ“ä½œéœ€è¦ m * n * p æ¬¡ï¼Œ åŠ æ³•æ“ä½œä¹Ÿéœ€è¦ m * n * p æ¬¡ï¼Œå› æ­¤æ€»å…±éœ€è¦ 2 * m * n * p æ¬¡æµ®ç‚¹è¿ç®—ã€‚\nå¯¹äºå…¶ä»–çš„å¼ é‡æ“ä½œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç±»ä¼¼åœ°è®¡ç®— FLOPsã€‚äº†è§£ FLOPs å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯„ä¼°æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦ï¼Œä»è€Œä¼˜åŒ–æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒè¿‡ç¨‹ã€‚æ¯”å¦‚ï¼š\n\nElement-wise æ“ä½œ (æ¯”å¦‚åŠ æ³•ã€ä¹˜æ³•ç­‰) çš„ FLOPs é€šå¸¸ä¸å¼ é‡çš„å…ƒç´ æ•°é‡æˆæ­£æ¯” \\(\\mathcal{O}(m \\times n)\\)\nAddition of two matrices of shape (m, n): FLOPs = m * n\n\nç”±æ­¤å¯è§ï¼ŒçŸ©é˜µä¹˜æ³•çš„è®¡ç®—å¤æ‚åº¦è¿œé«˜äº Element-wise æ“ä½œï¼Œå› æ­¤åœ¨è®¾è®¡æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°½é‡å‡å°‘çŸ©é˜µä¹˜æ³•çš„æ¬¡æ•°ï¼Œä»è€Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#model-definition",
    "href": "posts/CS336/Lecture02/lec02.html#model-definition",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "2.1 Model definition",
    "text": "2.1 Model definition\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªæ¨¡å‹ã€‚æ¨¡å‹é€šå¸¸ç”±å¤šä¸ªå±‚ (Layer) ç»„æˆï¼Œæ¯ä¸ªå±‚éƒ½æœ‰è‡ªå·±çš„å‚æ•° (Parameters)ã€‚ç°ä»£çš„LLMæ¨¡å‹é€šå¸¸æ˜¯åŸºäº Transformer (Vaswani et al. 2023) æ¶æ„æ„å»ºçš„ã€‚ å…·ä½“çš„å†…å®¹ï¼Œä¼šåœ¨Lecture 03ä¸­è¯¦ç»†ä»‹ç»ï¼Œåœ¨è¿™é‡Œå°±å…ˆä¸å±•å¼€äº†ã€‚\n\n\n\n\n\n\nNote\n\n\n\nå¯¹äºTransformeræ¯”è¾ƒé™Œç”Ÿçš„åŒå­¦ï¼Œå¯ä»¥å‚è€ƒæˆ‘è¿™ä¸€ç¯‡ç¬”è®° 100-Paper with Code: 01 Transformer",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#parameter-initialization",
    "href": "posts/CS336/Lecture02/lec02.html#parameter-initialization",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "2.2 Parameter initialization",
    "text": "2.2 Parameter initialization\nå®šä¹‰å¥½æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°ã€‚å‚æ•°çš„åˆå§‹åŒ–æ–¹å¼ä¼šå½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ”¶æ•›é€Ÿåº¦ã€‚å¸¸è§çš„åˆå§‹åŒ–æ–¹æ³•æœ‰éšæœºåˆå§‹åŒ– (Random Initialization)ã€Xavier åˆå§‹åŒ– (Xavier Initialization) å’Œ He åˆå§‹åŒ– (He Initialization) ç­‰ç­‰ã€‚\nè®¸å¤šåŠ é€Ÿå™¨ï¼ˆæ¯”å¦‚ GPU å’Œ TPUï¼‰éƒ½å¯¹çŸ©é˜µä¹˜æ³•è¿›è¡Œäº†é«˜åº¦ä¼˜åŒ–ï¼Œåˆ©ç”¨å¹¶è¡Œè®¡ç®—å’Œä¸“ç”¨ç¡¬ä»¶å•å…ƒæ¥åŠ é€ŸçŸ©é˜µä¹˜æ³•çš„è®¡ç®—è¿‡ç¨‹ã€‚å› æ­¤ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå°½é‡å°†è®¡ç®—ä»»åŠ¡è½¬åŒ–ä¸ºçŸ©é˜µä¹˜æ³•ï¼Œå¯ä»¥æ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#optimizer-selection",
    "href": "posts/CS336/Lecture02/lec02.html#optimizer-selection",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "2.3 Optimizer Selection",
    "text": "2.3 Optimizer Selection\nåœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªä¼˜åŒ–å™¨ (Optimizer) æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚ å¸¸è§çš„ä¼˜åŒ–å™¨æœ‰éšæœºæ¢¯åº¦ä¸‹é™ (SGD)ã€åŠ¨é‡æ³• (Momentum)ã€Adam å’Œ AdamW ç­‰ç­‰ã€‚ä¸åŒçš„ä¼˜åŒ–å™¨æœ‰ä¸åŒçš„æ›´æ–°è§„åˆ™å’Œè¶…å‚æ•° (Hyperparameters)ï¼Œé€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¿«åœ°æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#loss-function",
    "href": "posts/CS336/Lecture02/lec02.html#loss-function",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "2.4 Loss Function",
    "text": "2.4 Loss Function\nåœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•° (Loss Function) æ¥è¡¡é‡æ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ã€‚å¸¸è§çš„æŸå¤±å‡½æ•°æœ‰å‡æ–¹è¯¯å·® (Mean Squared Error, MSE)ã€äº¤å‰ç†µæŸå¤± (Cross Entropy Loss) ç­‰ç­‰ã€‚é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ä¼˜åŒ–",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture02/lec02.html#training-loop",
    "href": "posts/CS336/Lecture02/lec02.html#training-loop",
    "title": "Lecture 02: PyTorch Basics & Resource Accounts",
    "section": "2.5 Training Loop",
    "text": "2.5 Training Loop\nå½“æˆ‘ä»¬å®šä¹‰å¥½æ¨¡å‹ã€åˆå§‹åŒ–å‚æ•°ã€é€‰æ‹©ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ã€‚è®­ç»ƒè¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\nåŠ è½½æ•°æ® (Data Loading): ä»æ•°æ®é›†ä¸­åŠ è½½è®­ç»ƒæ•°æ®ï¼Œé€šå¸¸ä½¿ç”¨æ‰¹é‡ (Batch) çš„æ–¹å¼è¿›è¡ŒåŠ è½½ã€‚ å‰å‘ä¼ æ’­ (Forward Pass): å°†è¾“å…¥æ•°æ®ä¼ é€’ç»™æ¨¡å‹ï¼Œè®¡ç®—æ¨¡å‹çš„è¾“å‡ºã€‚ è®¡ç®—æŸå¤± (Loss Calculation): ä½¿ç”¨æŸå¤±å‡½æ•°è®¡ç®—æ¨¡å‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ã€‚ åå‘ä¼ æ’­ (Backward Pass): è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ã€‚ å‚æ•°æ›´æ–° (Parameter Update): ä½¿ç”¨ä¼˜åŒ–å™¨æ ¹æ®è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚\né‡å¤ä»¥ä¸Šæ­¥éª¤ï¼Œç›´åˆ°æ¨¡å‹æ”¶æ•›æˆ–è€…è¾¾åˆ°é¢„å®šçš„è®­ç»ƒè½®æ•° (Epochs)ã€‚\n\n2.5.1 Randomness Control\nåœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œéšæœºæ€§ (Randomness) æ˜¯ä¸å¯é¿å…çš„ã€‚æ¯”å¦‚ï¼Œå‚æ•°çš„åˆå§‹åŒ–ã€æ•°æ®çš„æ‰“ä¹± (Shuffling) å’Œæ‰¹é‡çš„é€‰æ‹© (Batch Selection)ç­‰æ“ä½œéƒ½æ¶‰åŠåˆ°éšæœºæ€§ã€‚ä¸ºäº†ä¿è¯å®éªŒçš„å¯é‡å¤æ€§ (Reproducibility)ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦æ§åˆ¶éšæœºæ•°ç”Ÿæˆå™¨ (Random Number Generator, RNG) çš„ç§å­ (Seed)ã€‚\nimport random\nimport numpy as np\nimport torch\n\ndef seed_everything(seed):    \n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nseed_everything(42)\n\n\n2.5.2 Data Loading\n\n\n2.5.3 Checkpointing\nåœ¨è®­ç»ƒå¤§å‹æ¨¡å‹æ—¶ï¼Œè®­ç»ƒè¿‡ç¨‹å¯èƒ½ä¼šéå¸¸è€—æ—¶ï¼Œå¹¶ä¸”å®¹æ˜“å—åˆ°å„ç§æ„å¤–æƒ…å†µçš„å½±å“ï¼Œæ¯”å¦‚æ–­ç”µã€ç³»ç»Ÿå´©æºƒç­‰ã€‚ä¸ºäº†é¿å…è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®ä¸¢å¤±ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨æ£€æŸ¥ç‚¹ (Checkpointing) æŠ€æœ¯æ¥ä¿å­˜æ¨¡å‹çš„çŠ¶æ€ã€‚\nModel Checkpointing é€šå¸¸ä¿å­˜ä»¥ä¸‹å‡ ä¸ªæ–¹é¢çš„ä¿¡æ¯ï¼š\n\næ¨¡å‹å‚æ•° (Model Parameters): ä¿å­˜æ¨¡å‹çš„æƒé‡å’Œåç½®ç­‰å‚æ•°ã€‚\nä¼˜åŒ–å™¨çŠ¶æ€ (Optimizer State): ä¿å­˜ä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼Œæ¯”å¦‚åŠ¨é‡ (Momentum ) å’Œå­¦ä¹ ç‡ (Learning Rate) ç­‰ä¿¡æ¯ã€‚\nå­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€ (Learning Rate Scheduler State): ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨çš„çŠ¶æ€ã€‚\nè®­ç»ƒè¿›åº¦ (Training Progress): ä¿å­˜å½“å‰çš„è®­ç»ƒè½®æ•° (Epochs) å’Œæ‰¹é‡ç´¢å¼• (Batch Index) ç­‰ä¿¡æ¯ã€‚\n\nåœ¨ GPU ä¸Šè¿›è¡Œè®¡ç®—æ—¶ï¼Œæ•°æ®ä¼ è¾“çš„é€Ÿåº¦é€šå¸¸æ˜¯ä¸€ä¸ªç“¶é¢ˆã€‚ä¸ºäº†æé«˜æ•°æ®ä¼ è¾“çš„æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Pinned Memory (ä¹Ÿå« Page-Locked Memory)ã€‚Pinned Memory æ˜¯ä¸€ç§ç‰¹æ®Šçš„å†…å­˜åŒºåŸŸï¼Œå¯ä»¥åŠ é€Ÿä¸»æœº (Host) å’Œè®¾å¤‡ (Device) ä¹‹é—´çš„æ•°æ®ä¼ è¾“ã€‚\n\n\n\n\n\n\nFigureÂ 9: å¦‚å›¾æ‰€ç¤ºï¼ŒPinned memory å¯ä»¥ä½œä¸ºè®¾å¤‡(Device)åˆ°ä¸»æœº(Host)æ‹·è´çš„ä¸­è½¬åŒºï¼Œç›´æ¥åœ¨ pinned memory ä¸­åˆ†é…ä¸»æœºæ•°ç»„ï¼Œå°±èƒ½é¿å… pageable å†…å­˜ä¸ pinned å†…å­˜ä¹‹é—´çš„é¢å¤–æ‹·è´å¼€é”€ï¼Œä»è€Œæå‡æ•°æ®ä¼ è¾“æ•ˆç‡ã€‚\n\n\n\nè¿™ç¯‡æ–‡ç« ä¸­ä»‹ç»äº†4ç§å¸¸è§çš„åŠ é€Ÿæ•°æ®ä¼ è¾“çš„æ–¹æ³•ï¼š\n\nåˆ©ç”¨ Numpy Memmap å¤„ç†å¤§æ•°æ®é›†: é€šè¿‡å†…å­˜æ˜ å°„æŠ€æœ¯ï¼Œåªå°†æ•°æ®é›†çš„ä¸€éƒ¨åˆ†åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨ï¼Œæé«˜æ•°æ®åŠ è½½é€Ÿåº¦ã€‚\nå¤šåˆ©ç”¨ torch.from_numpy å‡½æ•°: ç›´æ¥å°† NumPy æ•°ç»„è½¬æ¢ä¸º PyTorch å¼ é‡ï¼Œé¿å…ä¸å¿…è¦çš„æ•°æ®å¤åˆ¶ï¼Œæé«˜æ•°æ®ä¼ è¾“æ•ˆç‡ã€‚\nå°† num_workers è®¾ç½®ä¸ºå¤§äº0: é€šè¿‡å¤šçº¿ç¨‹æ•°æ®åŠ è½½ï¼Œæé«˜æ•°æ®é¢„å¤„ç†å’ŒåŠ è½½çš„å¹¶è¡Œåº¦ï¼Œå‡å°‘æ•°æ®åŠ è½½æ—¶é—´ã€‚\nä½¿ç”¨ Pinned Memory åŠ é€Ÿä¸»æœºä¸è®¾å¤‡ä¹‹é—´çš„æ•°æ®ä¼ è¾“: é€šè¿‡å°†æ•°æ®å­˜å‚¨åœ¨å›ºå®šå†…å­˜ä¸­ï¼Œå‡å°‘æ•°æ®ä¼ è¾“çš„å»¶è¿Ÿï¼Œæé«˜\n\nfrom torch.utils.data import DataLoader\n\n# some code\n\nloader = DataLoader(your_dataset, ..., pin_memory=True)\ndata_iter = iter(loader)\n\nnext_batch = data_iter.next() # start loading the first batch\nnext_batch = [ _.cuda(non_blocking=True) for _ in next_batch ]  # with pin_memory=True and non_blocking=True, this will copy data to GPU non blockingly\n\nfor i in range(len(loader)):\n    batch = next_batch \n    if i + 2 != len(loader): \n        # start copying data of next batch\n        next_batch = data_iter.next()\n        next_batch = [ _.cuda(async=True) for _ in next_batch]\nè¿™å‡ ä¸ªæ–¹æ³•å¯ä»¥æ˜¾è‘—æå‡æ•°æ®ä¼ è¾“å’ŒåŠ è½½çš„æ•ˆç‡ï¼Œå°¤å…¶åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶æ•ˆæœå°¤ä¸ºæ˜æ˜¾ã€‚åœ¨æˆ‘ä»¬å®ŒæˆAssignment 01æ—¶ï¼Œä¼šç”¨åˆ°è¿™äº›æŠ€å·§æ¥ä¼˜åŒ–æ•°æ®åŠ è½½è¿‡ç¨‹ã€‚\n\n\n2.5.4 Mixed Precision Training\nåœ¨ä¹‹å‰çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸åŒçš„æ•°æ®ç±»å‹åŠå…¶å†…å­˜å ç”¨ã€‚åœ¨å®é™…çš„æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šé‡‡ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (Mixed Precision Training) çš„æ–¹æ³•ï¼Œæ¥å¹³è¡¡å†…å­˜å ç”¨å’Œæ•°å€¼ç²¾åº¦çš„é—®é¢˜ã€‚\né‚£é‚£äº›éœ€è¦æ··åˆç²¾åº¦è®­ç»ƒå‘¢ï¼Ÿé€šå¸¸åœ¨ä»¥ä¸‹å‡ ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šè€ƒè™‘ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š\n\nbfloat16 æˆ–è€… fp8 ä½œä¸ºå‰å‘çš„è®¡ç®—æ•°æ®ç±»å‹ï¼ˆactivationsï¼‰\nfloat32 ä½œä¸ºæ¢¯åº¦è®¡ç®—çš„æ•°æ®ç±»å‹, å¹¶ä¸”æ˜¯ç”¨ float32 æ¥æ›´æ–°å‚æ•°\nä¼˜åŒ–å™¨çŠ¶æ€ (Optimizer States) ä½¿ç”¨ float32 æ¥å­˜å‚¨\n\nMicikevicius et al. (2018) æå‡ºäº†ä¸€ç§æ··åˆç²¾åº¦è®­ç»ƒçš„æ–¹æ³•ï¼Œç§°ä¸º Loss Scalingã€‚Loss Scaling çš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡æ”¾å¤§æŸå¤±å‡½æ•°çš„å€¼ï¼Œæ¥é¿å…åœ¨ä½¿ç”¨ä½ç²¾åº¦æ•°æ®ç±»å‹æ—¶å‡ºç°æ•°å€¼ä¸‹æº¢ (Underflow) çš„é—®é¢˜ã€‚\nLoss Scaling çš„å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š\n\nåœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„å€¼ï¼Œå¹¶å°†å…¶ä¹˜ä»¥ä¸€ä¸ªæ”¾å¤§å› å­ (Scaling Factor)ã€‚\nåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œå¹¶å°†å…¶é™¤ä»¥æ”¾å¤§å› å­ã€‚\nä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹å‚æ•°ã€‚ ä¸è¿‡ï¼Œå½“æˆ‘ä»¬ç”¨ bfloat16 è¿›è¡Œå‰å‘è®¡ç®—æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä¸éœ€è¦ä½¿ç”¨ Loss Scalingï¼Œå› ä¸º bfloat16 å·²ç»æœ‰è¶³å¤Ÿçš„æ•°å€¼èŒƒå›´æ¥é¿å…ä¸‹æº¢çš„é—®é¢˜ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 02: PyTorch Basics & Resource Accounts"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html",
    "href": "posts/CS336/Lecture16&17/lec16.html",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "",
    "text": "åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†PPOä»¥åŠDPOçš„ç®—æ³•ï¼Œæˆ‘ä»¬å› æ­¤ä¹Ÿä»GPTå¾—åˆ°äº†ChatGPTã€‚ä½†è¿™è·ç¦»ç°åœ¨çš„ Reasoning Modelï¼Œè¿˜æœ‰ä¸€æ®µè·ç¦»ã€‚åœ¨è¿™èŠ‚è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ æ–°çš„ä¸€ç³»åˆ—ç®—æ³•ï¼Œä¹Ÿå°±æ˜¯RLVR(Reinforcement Learning from Verified Rewards)ï¼Œé€šè¿‡è¿™äº›ç®—æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä»ChatGPTçªç ´åˆ°ChatGPT-o1ã€‚\nåœ¨äº†è§£RLVRä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹ï¼Œä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨PPOå’ŒDPOæ¥åšLLMçš„æ¨ç†å¼ºåŒ–å­¦ä¹ ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#why-not-ppo",
    "href": "posts/CS336/Lecture16&17/lec16.html#why-not-ppo",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "1.1 Why Not PPO?",
    "text": "1.1 Why Not PPO?\nPPOç†è®ºä¸Šå°±ä¸€ä¸ªclipç›®æ ‡ï¼Œä½†è½åœ°è¦å¤„ç†å¾ˆå¤šç»„ä»¶, åŒ…æ‹¬ï¼š\n\nrollouté‡‡æ ·/ç¼“å­˜ã€old logprobã€ratioã€clipã€KL penalty/target KL\nadvantageä¼°è®¡ï¼ˆGAEï¼‰ã€returnè®¡ç®—\n\nå¯¹LLMæ¥è¯´ï¼Œrolloutå¾ˆè´µï¼ˆæ¨ç†ç”Ÿæˆtokenï¼‰ï¼Œæ‰€ä»¥è¿˜ä¼šå¼•å…¥â€œé‡‡ä¸€æ¬¡rolloutï¼Œæ›´æ–°å¤šæ¬¡â€çš„æœºåˆ¶ï¼Œè¿™åˆæŠŠå®ç°å¤æ‚åº¦ç»§ç»­æŠ¬é«˜ã€‚å¹¶ä¸”ï¼Œæœ€ä¸»è¦çš„é—®é¢˜æ˜¯ï¼š\n\nPPOé€šå¸¸éœ€è¦ä¸€ä¸ª value function æ¥è®¡ç®—Advantage.\n\nè¿™æ„å‘³ç€ï¼š\n\né¢å¤–çš„æ¨¡å‹ï¼ˆvalue modelï¼‰+å†…å­˜å¼€é”€\né¢å¤–çš„è®­ç»ƒç›®æ ‡ï¼ˆvalue lossï¼‰\n\n\nâ€œValue model (memory hungry, involves additional tuning)â€",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#why-not-dpo",
    "href": "posts/CS336/Lecture16&17/lec16.html#why-not-dpo",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "1.2 Why Not DPO?",
    "text": "1.2 Why Not DPO?\nDPOçš„å¼ºé¡¹æ˜¯åå¥½å¯¹æ¯”æ•°æ® \\((p, y_i, y_j)\\)ï¼Œä½†åœ¨å¯éªŒè¯å¥–åŠ±çš„æ¨ç†RLé‡Œï¼Œæ•°æ®å¸¸è§æ˜¯ï¼š\n\nä¸€ä¸ªpromptï¼Œ\nä¸€ä¸ªå›ç­”ï¼Œ\nreward=0/1ï¼ˆå¯¹/é”™ï¼‰æˆ–åˆ†æ•°\n\næ•°æ®ä¸æ˜¯å¤©ç„¶çš„pairwiseåå¥½ï¼Œè€Œæ˜¯pointwise rewardã€‚å¦å¤–ï¼ŒDPOå¸¸è§ä½¿ç”¨æ–¹å¼åOff-Policyï¼šå…ˆæ”¶é›†å¯¹æ¯”æ•°æ®ï¼Œå†è®­ç»ƒã€‚è€Œæ¨ç†RLé€šå¸¸æ›´åƒåœ¨çº¿ï¼šæ¨¡å‹ä¸æ–­å˜å¼º â†’ ä¸æ–­rollout â†’ ä¸æ–­ç”¨æœ€æ–°ç­–ç•¥ç”Ÿæˆæ–°æ•°æ®è®­ç»ƒï¼ˆon-policyå‘³é“æ›´å¼ºï¼‰ã€‚GRPO/PPOå¤©ç„¶é€‚é…è¿™ç§å¾ªç¯ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#grpo-objective",
    "href": "posts/CS336/Lecture16&17/lec16.html#grpo-objective",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "3.1 GRPO Objective",
    "text": "3.1 GRPO Objective\nGRPO çš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š \\[\n\\mathcal{J}_{\\text{GRPO}}(\\pi_\\theta) = \\frac{1}{G}\\sum_{i=1}^{G}\n\\textcolor{red}{\\frac{1}{|o_i|}} \\sum_{t = 1}^{|o_i|}\n\\Bigg\\{\n\\min \\Big[\n     \\rho(o_{i,t}) \\hat{A}_{i, t},\n     \\text{clip}\\Big(\n            \\rho(o_{i,t}), 1 - \\epsilon_{\\text{clip}}, 1 + \\epsilon_{\\text{clip}}\n        \\Big) \\hat{A}_{i, t}\n    \\Big]    \n\\Bigg\\} + \\textcolor{gray}{\\beta \\, \\text{KL}\\big(\\pi_\\theta || \\pi_{\\text{ref}}\\big)}\n\\tag{1}\\]\nå…¶ä¸­ï¼š\n\\[\n\\rho(o_{i,t}) = \\frac{\\pi_\\theta(o_{i,t}|q, o_{i,&lt;t})}{\\pi_{\\text{ref}}(o_{i,t}|q, o_{i,&lt;t})}\n\\tag{2}\\]\næ˜¯importance sampling ratioï¼Œç”¨æ¥æŠŠå½“å‰ç­–ç•¥å’Œreference policyè”ç³»èµ·æ¥ã€‚\n\\(\\textcolor{gray}{\\beta \\, \\text{KL}\\big(\\pi_\\theta || \\pi_{\\text{ref}}\\big)}\\) æ˜¯ KL penaltyï¼Œç”¨æ¥é˜²æ­¢å½“å‰ç­–ç•¥åç¦»å‚è€ƒç­–ç•¥å¤ªè¿œã€‚(ä¸è¿‡åœ¨å®é™…çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¿½ç•¥è¿™ä¸ªKL penalityï¼Œå› ä¸ºGRPOçš„é‡‡æ ·æœ¬èº«å°±æ˜¯ä»å‚è€ƒç­–ç•¥é‡‡æ ·çš„ï¼Œæ‰€ä»¥åç¦»ä¸ä¼šå¤ªå¤§)\nå¯¹æ¯ä¸ª prompt é‡‡æ ·ä¸€ç»„ï¼ˆgroupï¼‰å›ç­”,\n\nç”¨ç»„å†…ç›¸å¯¹å¥–åŠ±å½“ advantageï¼ˆåŸºçº¿ï¼‰ï¼Œ\nå†åš policy-gradient æ›´æ–°ï¼ŒåŒæ—¶ç”¨ KL çº¦æŸä¸è¦åç¦»å‚è€ƒç­–ç•¥( ä¸è¿‡åœ¨å®é™…å®ç°ä¸­ï¼ŒKL penaltyæ˜¯åŠ åœ¨lossé‡Œï¼Œè€Œä¸æ˜¯ç¡¬çº¦æŸ )ã€‚\n\næˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Pythonä»£ç å®ç°ï¼š\ndef compute_loss_grpo(\n    log_probs: torch.Tensor,      # (B, G, T) log probs under current policy\n    old_log_probs: torch.Tensor,  # (B, G, T) log probs under old policy (detached)\n    response_mask: torch.Tensor,  # (B, G, T) mask for valid response tokens\n    advantage: torch.Tensor,    # (B, G) advantage per response\n    clip_range: float = 0.2,\n):\n    B, G, T = log_probs.size()\n\n    important_ratio = torch.exp(log_probs - old_log_probs)  # (B, G, T)\n\n    # Broadcast advantage to token level\n    advantage_tok = advantage.unsqueeze(-1).expand_as(important_ratio)  # (B, G, T)\n\n    unclipped = important_ratio * advantage_tok\n    clipped = torch.clamp(important_ratio, 1 - clip_range, 1 + clip_range) * advantage_tok\n\n    pg_loss_tok = -torch.min(unclipped, clipped)  # (B, G, T)\n\n    # Length normalization (GRPO does this)\n    len_per_response = response_mask.sum(dim=-1)  # (B, G)\n    pg_loss_tok = pg_loss_tok * response_mask  # mask out non-response tokens\n    pg_loss_seq = pg_loss_tok.sum(dim=-1) / len_per_response  # (B, G)\n\n    # Final loss: mean over batch and group\n    loss = pg_loss_seq.sum()\n    loss = loss / (B * G)\n    # loss = pg_loss_seq.mean()  # alternative: mean over all tokens\n\n    return loss\nå…·ä½“çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä¼šæŠŠæŒ‰å›ç­”é•¿åº¦å½’ä¸€åŒ–ï¼ˆpg_loss_seq = pg_loss_tok.sum(dim=-1) / len_per_responseï¼‰ï¼Œè¿™æ˜¯GRPOçš„ä¸€ä¸ªå…³é”®è®¾è®¡ï¼Œæˆ‘ä»¬åé¢ä¼šé‡ç‚¹è®²ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#advantage-calculation-in-grpo",
    "href": "posts/CS336/Lecture16&17/lec16.html#advantage-calculation-in-grpo",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "3.2 Advantage Calculation in GRPO",
    "text": "3.2 Advantage Calculation in GRPO\næ¥ä¸‹æ¥æˆ‘ä»¬é‡ç‚¹çœ‹çœ‹ GRPO çš„ Advantage è®¡ç®—ï¼š\n\nå¯¹æ¯ä¸ª promptï¼ˆæ¯”å¦‚ä¸€é“æ•°å­¦é¢˜ï¼‰ï¼š\n\né‡‡æ · G ä¸ªå›ç­”ï¼š\\(\\{y_1, y_2, \\dots, y_G\\}\\)\nè¿™ä¸ª prompt å°±æ˜¯ä¸€ç»„ï¼ˆgroupï¼‰ï¼Œç»„å†…å›ç­”å…±äº«åŒä¸€éš¾åº¦, å¹¶ä¸”æœ‰äº† \\(\\{(p, y_1, r_1), (p, y_2, r_2), \\dots, (p, y_G, r_G)\\}\\)ï¼Œå…¶ä¸­ \\(r_i\\) æ˜¯å›ç­” \\(y_i\\) çš„å¥–åŠ±ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡ç»„å†…ç»Ÿè®¡é‡ï¼Œæ¥è®¡ç®— Advantageï¼š \\[\n\\hat{A}_{i, t}=\\frac{r_i-\\mu}{\\sigma + \\epsilon } \\quad \\text{where} \\quad \\mu=\\frac{1}{G}\\sum_{j=1}^{G} r_j, \\quad \\sigma=\\sqrt{\\frac{1}{G}\\sum_{j=1}^{G}(r_j-\\mu)^2}\n\\tag{3}\\]\nå…¶ä¸­ï¼š\n\nç”¨ ç»„å†…å‡å€¼ \\(\\mu\\) å½“ baselineï¼ˆåæ˜ é¢˜ç›®éš¾åº¦ï¼‰\nç”¨ ç»„å†…æ–¹å·® \\(\\sigma\\) åšå½’ä¸€åŒ–ï¼ˆæ§åˆ¶æ›´æ–°å°ºåº¦ï¼‰\n\\(\\epsilon\\) æ˜¯ä¸€ä¸ªå°å¸¸æ•°ï¼Œé˜²æ­¢é™¤é›¶\n\nå…¶ä¸­ï¼Œ\\(\\hat{A}_{i, t}\\) æ˜¯å›ç­” \\(y_i\\) åœ¨æ—¶é—´æ­¥ \\(t\\) çš„ advantage, ä¹Ÿå°±æ˜¯æ¯ä¸ªaction(token \\(o_{i,t}\\)) å¯¹åº”çš„ Advantage, åœ¨GRPOä¸­ï¼ŒåŒä¸€ä¸ªå›ç­” \\(y_i\\) çš„æ‰€æœ‰tokenå…±äº«åŒä¸€ä¸ª advantageå€¼ã€‚\ndef compute_advantage(\n    rewards: torch.Tensor,  # (B, G)\n    epsilon: float = 1e-4\n):\n    mu = rewards.mean(dim=1, keepdim=True)  # (B, 1)\n    sigma = rewards.std(dim=1, keepdim=True)  # (B, 1)\n\n    advantage = (rewards - mu) / (sigma + epsilon)  # (B, G)\n    return advantage",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#grpo-algorithm",
    "href": "posts/CS336/Lecture16&17/lec16.html#grpo-algorithm",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "3.3 GRPO Algorithm",
    "text": "3.3 GRPO Algorithm\näº†è§£äº†GRPOçš„Objective Function (EquationÂ 1) å’ŒAdvantageè®¡ç®—(EquationÂ 3) åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹GRPOçš„æ•´ä½“ç®—æ³•æµç¨‹ï¼š\n\n\n\\begin{algorithm} \\caption{Iterative Group Relative Policy Optimization (GRPO)}\\begin{algorithmic} \\Require initial policy model $\\pi_{\\theta_{\\text{init}}}$; reward model(s) $r_\\phi$; task prompts $\\mathcal{D}$; hyperparameters $\\epsilon, \\beta, \\mu$; group size $G$; iterations $I$; steps $M$ \\Ensure trained policy $\\pi_\\theta$ \\State $\\pi_\\theta \\gets \\pi_{\\theta_{\\text{init}}}$ \\For{$\\text{iteration} = 1, \\ldots, I$} \\State $\\pi_{\\text{ref}} \\gets \\pi_\\theta$ \\Comment{reference (anchor) policy} \\For{$\\text{step} = 1, \\ldots, M$} \\State Sample a batch $\\mathcal{D}_b$ from $\\mathcal{D}$ \\State $\\pi_{\\theta_{\\text{old}}} \\gets \\pi_\\theta$ \\Comment{snapshot old policy} \\ForAll{$q \\in \\mathcal{D}_b$} \\State Sample $G$ outputs $\\{o_i\\}_{i=1}^{G} \\sim \\pi_{\\theta_{\\text{old}}}(\\cdot \\mid q)$ \\State Compute rewards $\\{r_i\\}_{i=1}^{G}$ by $r_i \\gets r_\\phi(q, o_i)$ \\State Compute group-relative advantages $\\{\\hat{A}_{i,t}\\}$ for each token $t$ in each $o_i$ \\EndFor \\For{$\\text{GRPO-iter} = 1, \\ldots, \\mu$} \\State Update $\\pi_\\theta$ by maximizing the GRPO objective \\EndFor \\State Update $r_\\phi$ via continuous training using a replay mechanism \\EndFor \\EndFor \\State \\Return $\\pi_\\theta$ \\end{algorithmic} \\end{algorithm}\n\n\nå¯¹äºæ¯æ¬¡è¿­ä»£ï¼š\n\nå…ˆæŠŠå½“å‰ç­–ç•¥ \\(\\pi_\\theta\\) ä½œä¸ºå‚è€ƒç­–ç•¥ \\(\\pi_{\\text{ref}}\\)ï¼ˆanchor policyï¼‰\nç„¶åï¼Œå¯¹äºæ¯ä¸ª prompt \\(q\\)ï¼š\n\nä»æ—§ç­–ç•¥ \\(\\pi_{\\theta_{\\text{old}}}\\) é‡‡æ · \\(G\\) æ¡å›ç­” \\(\\{o_i\\}\\)\nè®¡ç®—æ¯æ¡å›ç­”çš„å¥–åŠ± \\(\\{r_i\\}\\)ï¼ˆé€šè¿‡å¥–åŠ±æ¨¡å‹ï¼‰\nè®¡ç®—ç»„å†…ç›¸å¯¹ä¼˜åŠ¿ \\(\\{\\hat{A}_{i,t}\\}\\)\næœ€åï¼Œç”¨ GRPO ç›®æ ‡å‡½æ•°æ›´æ–°ç­–ç•¥ \\(\\pi_\\theta\\)\n\n\nè¿™ç§è®¾è®¡é¿å…äº† PPO é‡Œå¯¹ Value Function çš„ä¾èµ–ï¼Œä»è€Œç®€åŒ–äº†è®­ç»ƒæµç¨‹ï¼Œ åŒæ—¶æˆ‘ä»¬çœ‹åˆ°ï¼Œå¯¹äºæ¯ä¸ªRolloutï¼Œæˆ‘ä»¬åªæ›´æ–°ä¸€æ¬¡ç­–ç•¥(On-Policy)ï¼Œè€Œä¸æ˜¯å¤šæ¬¡ï¼Œè¿™ä¹Ÿé™ä½äº†å®ç°å¤æ‚åº¦ã€‚ï¼ˆä¸è¿‡è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„Trade-Offï¼Œæˆ‘ä»¬å¯ä»¥å¯¹äºåŒä¸€ç»„æ•°æ®å¤šæ¬¡æ›´æ–°ç­–ç•¥ï¼ˆOff-Policyï¼‰ï¼Œä»è€Œæå‡æ ·æœ¬æ•ˆç‡ï¼Œä½†ä¼šå¢åŠ å®ç°å¤æ‚åº¦ï¼‰",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#bias-in-grpo",
    "href": "posts/CS336/Lecture16&17/lec16.html#bias-in-grpo",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "3.4 Bias in GRPO",
    "text": "3.4 Bias in GRPO\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥è‡ªå·±åˆ†æä¸€ä¸‹GRPOçš„Objective Function (EquationÂ 1) ï¼Œå¯ä»¥å‘ç°ï¼Œå®ƒå…¶å®å­˜åœ¨ä¸¤ä¸ªBiasï¼š\n\nBiased Gradientï¼šGRPOçš„æ¢¯åº¦ä¼°è®¡æ˜¯æœ‰åçš„\nLength Normalization Biasï¼šæŒ‰å›ç­”é•¿åº¦å½’ä¸€åŒ–å¼•å…¥çš„åç½®\n\næˆ‘ä»¬æ¥å…·ä½“åˆ†æä¸€ä¸‹è¿™ä¸¤ä¸ªBiasã€‚\n\n\n\n\n\n\nFigureÂ 3: è¯¥å›¾å±•ç¤ºäº† GRPO çš„ä¸¤ç±»ä¼˜åŒ–åç½®ï¼šå¯¹åŒä¸€é—®é¢˜ \\(q\\) é‡‡æ ·å¤šæ¡å›ç­” \\(o_i\\) åï¼ŒGRPO çš„â€œæœ‰æ•ˆ advantageâ€æ»¡è¶³ \\(a_{i,t}=\\frac{1}{\\mathrm{std}(R)}\\cdot \\frac{\\tilde A_{i,t}}{|o_i|}\\)ï¼Œå…¶ä¸­ \\(\\tilde A_{i,t}=R(q,o_i)-\\mathrm{mean}(R)\\) æ˜¯ç»„å†…ä¸­å¿ƒåŒ–ï¼ˆç›¸å¯¹ï¼‰å¥–åŠ±ï¼›ç”±äºé¢å¤–é™¤ä»¥ç»„å†…å¥–åŠ±æ ‡å‡†å·® \\(\\mathrm{std}(R)\\) ä¸å›ç­”é•¿åº¦ \\(|o_i|\\)ï¼Œè®­ç»ƒä¼šå¯¹ä¸åŒé—®é¢˜ä¸ä¸åŒé•¿åº¦å›ç­”æ–½åŠ ä¸åŒæƒé‡ï¼šè“è‰²åœ†ç‚¹å¤§å°è¡¨ç¤º \\(1/\\mathrm{std}(R)\\) å¯¹â€œé—®é¢˜çº§â€æ›´æ–°å¼ºåº¦çš„ç¼©æ”¾ï¼Œæ©™è‰²ç®­å¤´é•¿åº¦è¡¨ç¤º \\(\\tilde A_{i,t}/|o_i|\\) å¯¹â€œå›ç­”çº§â€æ›´æ–°å¹…åº¦çš„ç¼©æ”¾ï¼ˆç®­å¤´å‘ä¸Šä¸ºæ­£ advantageã€å‘ä¸‹ä¸ºè´Ÿï¼‰ï¼Œä»è€Œä½¿ä¼˜åŒ–åå‘æŸäº›é¢˜ç›®ä¸æŸäº›é•¿åº¦çš„è¾“å‡ºã€‚\n\n\n\n\n3.4.1 Biased Gradient\nç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ GRPO çš„æ¢¯åº¦ä¼°è®¡æ˜¯biasedï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå®ƒä½¿ç”¨äº†ä¾èµ–é‡‡æ ·ç»“æœçš„ baselineã€‚ æˆ‘ä»¬çŸ¥é“ï¼Œè¦ä¿æŒä¸€ä¸ªun-biasedæ¢¯åº¦ä¼°è®¡ï¼Œbaseline åªèƒ½æ˜¯ä¸ä¾èµ–åŠ¨ä½œçš„å¸¸æ•°ï¼Œå®ƒå¯ä»¥æ˜¯Value Functionçš„ä¼°è®¡ï¼Œæˆ–è€…ä¸€ä¸ªå¸¸æ•°ï¼Œä½†ä¸èƒ½æ˜¯ä¾èµ–é‡‡æ ·ç»“æœçš„é‡ã€‚\nå…·ä½“æ¥è¯´ï¼š\nPolicy Gradient Theorem å‘Šè¯‰æˆ‘ä»¬ï¼Œç­–ç•¥æ¢¯åº¦æ˜¯ï¼š \\[\n\\nabla_\\theta J(\\pi_\\theta) = \\mathbb{E}_{ y \\sim \\pi_\\theta(\\cdot|x)} \\Big[ \\textcolor{green}{r(x, y)} \\nabla_\\theta \\log \\pi_\\theta(y|x) \\Big]\n\\tag{4}\\]\n\n\nNOTE\n\n\nåœ¨è¿™é‡Œï¼Œ\\(x\\) æ˜¯ç¯å¢ƒçŠ¶æ€ï¼ˆåœ¨LLMä¸­æ˜¯promptï¼‰ï¼Œ\\(y\\) æ˜¯åŠ¨ä½œï¼ˆåœ¨LLMä¸­æ˜¯tokenåºåˆ—ï¼‰ï¼Œ\\(r(x,y)\\) æ˜¯å¥–åŠ±å‡½æ•°ï¼Œ\\(\\pi_\\theta(y|x)\\) æ˜¯ç­–ç•¥ï¼ˆåœ¨LLMä¸­æ˜¯è¯­è¨€æ¨¡å‹ï¼‰ã€‚ ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬å¿½ç•¥äº†çŠ¶æ€åˆ†å¸ƒ \\(D\\)ï¼Œå‡è®¾ \\(x\\) æ˜¯å›ºå®šçš„ã€‚å®é™…ä¸­ï¼Œæˆ‘ä»¬ä¼šå¯¹ \\(x\\) ä¹Ÿå–æœŸæœ›ï¼š \\[\n\\nabla_\\theta J(\\pi_\\theta) = \\mathbb{E}_{\\textcolor{red}{x \\sim D}, y \\sim \\pi_\\theta(\\cdot|x)} \\Big[ r(x, y) \\nabla_\\theta \\log \\pi_\\theta(y|x) \\Big]\n\\]\n\n\nå¦‚æœæˆ‘ä»¬å¼•å…¥ä¸€ä¸ª baseline \\(b(x)\\)ï¼Œå¹¶ä¸”å®ƒä¸ä¾èµ–åŠ¨ä½œï¼Œé‚£ä¹ˆæ¢¯åº¦å˜æˆï¼š \\[\n\\nabla_\\theta J(\\pi_\\theta) = \\mathbb{E}_{ y \\sim \\pi_\\theta(\\cdot|x)} \\Big[  \\textcolor{green}{\\Big(r(x, y) - b(x)\\Big)} \\nabla_\\theta \\log \\pi_\\theta(y|x) \\Big]\n\\tag{5}\\]\nåªè¦ \\(b(x)\\) ä¸ä¾èµ– \\(y\\)ï¼ˆaction, åœ¨LLMä¸­å°±æ˜¯tokenï¼‰ï¼Œè¿™ä¸ªæ¢¯åº¦ä¼°è®¡å°±æ˜¯un-biasedã€‚\n\\[\n\\begin{split}\n\\mathbb{E}_{y \\sim \\pi_\\theta(\\cdot|x)} \\Big[ b(x) \\nabla_\\theta \\log \\pi_\\theta(y|x) \\Big]\n& = b(x) \\mathbb{E}_{y \\sim \\pi_\\theta(\\cdot|x)} \\Big[  \\nabla_\\theta \\log \\pi_\\theta(y|x) \\Big]  \\\\\n&= b(x) \\sum_y \\pi_\\theta(y|x)\\,\\nabla_\\theta \\log \\pi_\\theta(y|x) \\\\\n&= b(x) \\sum_y \\nabla_\\theta \\pi_\\theta(y|x) \\quad \\text{(Log-Derivative Trick)} \\\\\n&= b(x) \\nabla_\\theta \\sum_y \\pi_\\theta(y|x) \\\\\n&= b(x) \\nabla_\\theta 1 \\\\\n&= 0  \\\\\n\\end{split}\n\\tag{6}\\]\nä½†æ˜¯ GRPO é‡Œçš„ \\(\\sigma(y_{1:G})\\) ä¾èµ–äºç»„å†…æ‰€æœ‰é‡‡æ ·å›ç­”çš„å¥–åŠ± \\(\\{r_1, r_2, \\dots, r_G\\}\\)ï¼Œè€Œè¿™äº›å¥–åŠ±æœ¬èº«åˆä¾èµ–äºé‡‡æ ·å›ç­” \\(\\{y_1, y_2, \\dots, y_G\\}\\), äºæ˜¯ï¼Œæˆ‘ä»¬çš„æ¢¯åº¦å˜æˆï¼š\n\\[\n\\nabla_\\theta J(\\pi_\\theta) = \\mathbb{E}_{y_{1:G} \\sim \\pi_\\theta}\\Big[\\underbrace{\\frac{r_i-\\mu(y_{1:G})}{\\sigma(y_{1:G})}}_{\\text{ä¾èµ–é‡‡æ ·}}\\,\\nabla_\\theta\\log\\pi_\\theta(y_i|x)\\Big]\n\\tag{7}\\]\næˆ‘ä»¬æ¥çœ‹çœ‹ï¼Œè¿™ä¸ªæ¢¯åº¦ä¸ºä»€ä¹ˆæ˜¯æœ‰åçš„ï¼š \\[\n\\mathbb E_{y_{1:G}}\\left[\\frac{r_i-\\mu(y_{1:G})}{\\sigma(y_{1:G})}\\,\\nabla_\\theta\\log\\pi_\\theta(y_i|x)\\right]\n\\neq\n\\underbrace{\\mathbb E\\left[\\frac{r_i-\\mu(y_{1:G})}{\\sigma(y_{1:G})}\\right]}_{\\text{ä¸èƒ½æå‡ºæ¥}}\n\\cdot\n\\underbrace{\\mathbb E[\\nabla_\\theta\\log\\pi_\\theta(y_i|x)]}_{=0}\n\\tag{8}\\]\nå› ä¸º \\(\\frac{r_i-\\mu(y_{1:G})}{\\sigma(y_{1:G})}\\) ä¹Ÿä¾èµ–äºé‡‡æ ·ç»“æœ \\(y_{1:G}\\)ï¼Œæ‰€ä»¥ä¸ \\(\\nabla_\\theta\\log\\pi_\\theta(y_i|x)\\) ä¸èƒ½æ‹†å¼€æœŸæœ›ï¼Œä»è€Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡æœ‰åã€‚\n\n\nNOTE\n\n\nå½“ä¸¤ä¸ªéšæœºå˜é‡ \\(X, Y\\) ç‹¬ç«‹æ—¶ï¼Œ\\(\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y]\\)ï¼›ä½†å½“ \\(X, Y\\) ä¸ç‹¬ç«‹æ—¶ï¼Œè¿™ä¸ªç­‰å¼ä¸æˆç«‹ã€‚è¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆï¼Œåœ¨ EquationÂ 6 ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ \\(b(x)\\) æå‡ºæ¥ï¼Œå› ä¸ºå®ƒä¸ä¾èµ– \\(y\\)ï¼Œæ‰€ä»¥ä¸ \\(\\nabla_\\theta \\log \\pi_\\theta(y|x)\\) ç‹¬ç«‹ï¼›ä½†åœ¨ EquationÂ 8 ä¸­ï¼Œ\\(\\frac{r_i-\\mu(y_{1:G})}{\\sigma(y_{1:G})}\\) ä¾èµ–äºé‡‡æ ·ç»“æœ \\(y_{1:G}\\)ï¼Œæ‰€ä»¥ä¸ \\(\\nabla_\\theta\\log\\pi_\\theta(y_i|x)\\) ä¸ç‹¬ç«‹ï¼Œä¸èƒ½æ‹†å¼€æœŸæœ›ã€‚\n\n\nè¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬çš„æ¢¯åº¦ä¼°è®¡å°±ä¸å†æ˜¯un-biasedçš„ï¼Œè€Œæ˜¯è¢«ä¸€ä¸ªä¸é‡‡æ ·ç›¸å…³çš„éšæœºå› å­é‡æ–°åŠ æƒäº†ã€‚\nBias ä¸»è¦å‡ºåœ¨äº† \\(\\sigma\\) ä¸Šï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥å…·ä½“åˆ†æå®ƒå¸¦æ¥çš„å½±å“:\n\nå½“æŸä¸ª prompt çš„ group é‡Œ å¥–åŠ±æ–¹å·®å¾ˆå°ï¼ˆç»„å†…Rewardå…¨å¯¹æˆ–è€…å…¨é”™ï¼‰æ—¶ï¼Œ\\(\\frac{1}{\\sigma}\\) ä¼šéå¸¸å¤§ â†’ è¿™ä¸ª prompt å¯¹æ¢¯åº¦æ›´æ–°çš„æƒé‡è¢«æ”¾å¤§ã€‚\nå½“å¥–åŠ±æ–¹å·®å¤§æ—¶ï¼Œæ›´æ–°è¢«ç¼©å°ã€‚\n\nè¿™å°±ä¼šå¯¼è‡´ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šæ›´å…³æ³¨â€œæç«¯é¢˜â€ï¼ˆå…¨å¯¹/å…¨é”™ï¼‰ï¼Œè€Œä¸æ˜¯â€œä¸­ç­‰éš¾åº¦ã€æœ€èƒ½å­¦åˆ°ä¸œè¥¿çš„é¢˜â€ã€‚\n\n\nQuestion: ä¸ºä»€ä¹ˆï¼Œ\\(\\mu\\)ï¼ˆç»„å†…å‡å€¼ï¼‰ä¸ä¼šå¸¦æ¥Biaså‘¢ï¼Ÿ\n\n\nå› ä¸º \\(\\mu\\) åªæ˜¯ä¸€ä¸ªå¹³ç§»ï¼Œå®ƒä¸ä¼šæ”¹å˜æ¢¯åº¦çš„æƒé‡ï¼Œåªä¼šæ”¹å˜æ¢¯åº¦çš„æ–¹å‘ï¼ˆè®©æ¨¡å‹æ›´å…³æ³¨ç›¸å¯¹æ›´å¥½çš„å›ç­”ï¼‰ã€‚è€Œ \\(\\sigma\\) æ˜¯ä¸€ä¸ªç¼©æ”¾ï¼Œå®ƒä¼šæ”¹å˜æ¢¯åº¦çš„æƒé‡ï¼Œä»è€Œå¼•å…¥Biasã€‚\n\n\n\n\n3.4.2 Length Normalization Bias\nåœ¨ EquationÂ 1 ä¸­ï¼Œæœ‰ä¸€ä¸ª æŒ‰å›ç­”é•¿åº¦å½’ä¸€åŒ– çš„é¡¹ \\(\\frac{1}{|o_i|}\\)ï¼Œä¹Ÿå°±æ˜¯æŠŠæ¯æ¡å›ç­”çš„ token-loss å¹³å‡åŒ–ã€‚\nè¿™ä¼šå¸¦æ¥response-level length biasï¼šå½“æŠŠä¸€æ¡å›ç­”çš„æ¢¯åº¦æŒ‰é•¿åº¦å¹³å‡æ—¶ï¼Œä¼šæ”¹å˜â€œåŒæ ·ä¸€æ¡å›ç­”â€åœ¨ä¼˜åŒ–ä¸­çš„æœ‰æ•ˆæƒé‡ã€‚ï¼ˆå¾ˆæŠ½è±¡å¯¹ä¸å¯¹ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸¤ä¸ªå…·ä½“æƒ…å†µï¼‰\n\nä¼˜åŠ¿ä¸ºæ­£ï¼ˆç­”å¯¹/æ›´å¥½ï¼Œ\\(\\hat{A} &gt; 0\\)ï¼‰ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ›´æ–°æ–¹å‘æ˜¯â€œæé«˜è¿™æ¡å›ç­”æ¦‚ç‡â€ï¼Œä½†é™¤ä»¥å›ç­”é•¿åº¦ \\(|o_i|\\)ï¼Œè¿™æ„å‘³ç€è¶ŠçŸ­çš„å›ç­”ï¼Œå•ä½é•¿åº¦çš„æ¢¯åº¦è¶Šå¤§ï¼Œ æ¯ä¸ª token çš„è´¡çŒ®æ›´å¤§ã€‚äºæ˜¯ï¼Œæ¨¡å‹å­¦åˆ°ï¼šæ­£ç¡®ç­”æ¡ˆè¦å°½é‡çŸ­ï¼ˆå› ä¸ºæ›´â€œåˆ’ç®—â€ï¼‰ã€‚\nä¼˜åŠ¿ä¸ºè´Ÿï¼ˆç­”é”™/æ›´å·®ï¼Œ\\(\\hat{A} &lt; 0\\)ï¼‰ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ›´æ–°æ–¹å‘æ˜¯â€œé™ä½è¿™æ¡å›ç­”æ¦‚ç‡â€ï¼ˆæƒ©ç½šï¼‰ï¼Œä½†é™¤ä»¥å›ç­”é•¿åº¦ \\(|o_i|\\)ï¼Œè¿™æ„å‘³ç€è¶Šé•¿çš„å›ç­”ï¼Œæƒ©ç½šè¢«æ‘Šè–„ï¼Œæ¯ä¸ª token çš„è´Ÿæ›´æ–°æ›´å°ã€‚äºæ˜¯ï¼Œæ¨¡å‹å­¦åˆ°ï¼šé”™è¯¯ç­”æ¡ˆåè€Œæ›´æ„¿æ„å†™é•¿ï¼ˆå› ä¸ºâ€œå—ç½šæ›´è½»â€ï¼‰ã€‚\n\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰æ—¶å€™CoTè¶Šæ¥è¶Šé•¿ï¼Œä½†æ˜¯Rewardè¿˜æ˜¯ä¸å‡åé™çš„ç°è±¡â€”â€”æ¨¡å‹å­¦ä¼šäº†é€šè¿‡è¾“å‡ºæ›´é•¿çš„å›ç­”æ¥â€œè§„é¿æƒ©ç½šâ€ï¼Œè€Œä¸æ˜¯é€šè¿‡æé«˜å›ç­”è´¨é‡æ¥è·å¾—æ›´é«˜çš„å¥–åŠ±ã€‚\n\n\n\n\n\n\nFigureÂ 4: è¯¥å¼ å›¾å±•ç¤ºäº† DeepSeek-R1-Zero åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å¹³å‡æ¯æ¡å›ç­”é•¿åº¦éšè®­ç»ƒæ­¥æ•°çš„å˜åŒ–ã€‚æ¨ªè½´æ˜¯è®­ç»ƒæ­¥æ•°ï¼ˆStepsï¼‰ï¼Œçºµè½´æ˜¯å¹³å‡æ¯æ¡ response çš„é•¿åº¦ï¼ˆtoken æ•°ï¼‰ã€‚å¯ä»¥çœ‹åˆ°ï¼Œéšç€è®­ç»ƒæ¨è¿›ï¼Œæ¨¡å‹è¾“å‡ºé•¿åº¦å‘ˆæŒç»­ä¸Šå‡è¶‹åŠ¿ï¼šä»è®­ç»ƒåˆæœŸçš„å‡ ç™¾åˆ°ä¸Šåƒ tokenï¼Œé€æ­¥å¢é•¿åˆ°åæœŸçš„ä¸€ä¸‡ç”šè‡³æ¥è¿‘ä¸¤ä¸‡ tokenï¼ŒåŒæ—¶æ³¢åŠ¨å¹…åº¦ä¹Ÿæ˜æ˜¾æ‰©å¤§ã€‚è¿™ä¸€ç°è±¡ç›´è§‚åæ˜ äº† R1-Zero åœ¨ä»…ä½¿ç”¨å¯éªŒè¯å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ æ—¶ï¼Œæ¨¡å‹å€¾å‘äºç”Ÿæˆè¶Šæ¥è¶Šé•¿çš„æ¨ç†é“¾ï¼ˆCoTï¼‰ï¼Œä½“ç°å‡ºå…¸å‹çš„â€œé•¿åº¦è†¨èƒ€â€è¡Œä¸ºï¼Œè€Œä¸ä¸€å®šå¯¹åº”æ›´é«˜çš„å®é™…è§£é¢˜æ•ˆç‡ã€‚\n\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹ Dr.GRPO(Liu et al. 2025) æ˜¯å¦‚ä½•è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜çš„ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#dr.grpo",
    "href": "posts/CS336/Lecture16&17/lec16.html#dr.grpo",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "3.5 Dr.GRPO",
    "text": "3.5 Dr.GRPO\nDr.GRPO æ˜¯ GRPO çš„ä¸€ä¸ªå˜ä½“ï¼Œè§£å†³äº†ä¸Šé¢æåˆ°çš„ä¸¤ä¸ªé—®é¢˜ï¼š\n\nå»æ‰ \\(\\frac{1}{\\sigma}\\)ï¼Œé¿å… biased gradient\nå»æ‰æŒ‰å›ç­”é•¿åº¦å½’ä¸€åŒ–ï¼Œé¿å…é•¿åº¦åç½®\n\næˆ‘ä»¬æ¥çœ‹çœ‹æ”¹åŠ¨ä¹‹åçš„ç›®æ ‡å‡½æ•°:\n\\[\n\\mathcal{J}_{\\text{Dr.GRPO}}(\\pi_\\theta) = \\frac{1}{G}\\sum_{i=1}^{G}\n\\sum_{t = 1}^{|o_i|}\n\\Bigg\\{\n\\min \\Big[\n     \\rho(o_{i,t}) \\hat{A}_{i, t},\n     \\text{clip}\\Big(\n            \\rho(o_{i,t}), 1 - \\epsilon_{\\text{clip}}, 1 + \\epsilon_{\\text{clip}}\n        \\Big) \\hat{A}_{i, t}\n    \\Big]    \n\\Bigg\\}\n\\tag{9}\\]\nå…¶ä¸­ï¼ŒAdvantage å˜æˆï¼š\n\\[\n\\hat{A}_{i, t} = r_i - \\mu \\quad \\text{where} \\quad \\mu = \\frac{1}{G}\\sum_{j=1}^{G} r_j\n\\tag{10}\\]\nä¹Ÿå°±æ˜¯åªç”¨ç»„å†…å‡å€¼å½“ baselineï¼Œä¸åšæ–¹å·®å½’ä¸€åŒ–ã€‚\nå¦ä¸€ä¸ªæ”¹åŠ¨æ˜¯å»æ‰äº†æŒ‰å›ç­”é•¿åº¦å½’ä¸€åŒ–ï¼Œä¹Ÿå°±æ˜¯ä¸å†é™¤ä»¥ \\(|o_i|\\)ï¼Œ ç›´æ¥å¯¹æ‰€æœ‰ token çš„ policy-gradient loss æ±‚å’Œã€‚ ä¸è¿‡åœ¨å®ç°ä¸­ï¼Œä¼šé™¤ä»¥ä¸€ä¸ªMAX_TOKENSï¼ˆæœ€å¤§tokenæ•°ï¼‰æ¥ç¨³å®šè®­ç»ƒï¼Œä½†è¿™ä¸ªæ˜¯ä¸ªå¸¸æ•°ï¼Œä¸ä¼šå¼•å…¥é•¿åº¦åç½®ã€‚\næˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç \ndef compute_loss_grpo(\n    log_probs: torch.Tensor,      # (B, G, T) log probs under current policy\n    old_log_probs: torch.Tensor,  # (B, G, T) log probs under old policy (detached)\n    response_mask: torch.Tensor,  # (B, G, T) mask for valid response tokens\n    advantage: torch.Tensor,    # (B, G) advantage per response\n    clip_range: float = 0.2,\n    max_tokens: int = 1024,\n):\n    B, G, T = log_probs.size()\n\n    important_ratio = torch.exp(log_probs - old_log_probs)  # (B, G, T)\n\n    # Broadcast advantage to token level\n    advantage_tok = advantage.unsqueeze(-1).expand_as(important_ratio)  # (B, G, T)\n\n    unclipped = important_ratio * advantage_tok\n    clipped = torch.clamp(important_ratio, 1 - clip_range, 1 + clip_range) * advantage_tok\n\n    pg_loss_tok = -torch.min(unclipped, clipped)  # (B, G, T)\n\n    # Length normalization (GRPO does this)\n    pg_loss_tok = pg_loss_tok * response_mask  # mask out non-response tokens \n    pg_loss_seq = pg_loss_tok.sum(dim=-1) / max_tokens  # (B, G) \n\n    # Final loss: mean over batch and group\n    loss = pg_loss_seq.sum()\n    loss = loss / (B * G)\n    # loss = pg_loss_seq.mean()  # alternative: mean over all tokens\n\n    return loss\n\n\n\n\n\n\nFigureÂ 5: ä¸»è¦çœ‹å›¾ä¸­çº¢è‰²éƒ¨åˆ†ï¼ŒDr.GRPOåœ¨é”™è¯¯å›ç­”æ—¶ï¼Œä¸å†æŒ‰é•¿åº¦å½’ä¸€åŒ–ï¼Œè¿™æ ·é•¿å›ç­”ä¸ä¼šè¢«â€œæƒ©ç½šæ›´è½»â€ï¼Œä»è€Œé¿å…äº†æ¨¡å‹å­¦ä¼šå†™é•¿é”™è¯¯å›ç­”çš„ç°è±¡ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#deepseek-r1",
    "href": "posts/CS336/Lecture16&17/lec16.html#deepseek-r1",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "4.1 DeepSeek-R1",
    "text": "4.1 DeepSeek-R1\nDeepSeek-R1 åœ¨2025å¹´æ˜¥èŠ‚æœŸé—´å‘å¸ƒï¼ˆè¿˜è®°å¾—å½“æ—¶é“ºå¤©ç›–åœ°å…¨æ˜¯DeepSeekçš„æ–°é—»ï¼Œè¿‡å¹´éƒ½è¢«å·åˆ°ï¼‰ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªç”¨ GRPO åšæ•°å­¦æ¨ç†å¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥ä¸€ä¸‹DeepSeek R1 (DeepSeek-AI et al. 2025)æ˜¯å¦‚ä½•è®­ç»ƒçš„ã€‚\n\n\nWARNING: å…³äºDeepSeek-R1 Paperä¸è¯¾å ‚ä¸Šçš„ä¸åŒ\n\n\nDeepSeek R1 åœ¨æœ€è¿‘ï¼ˆ2026å¹´1æœˆï¼‰é‡æ–°Releaseäº†å®ƒä»¬æ–°çš„è®­ç»ƒç»†èŠ‚è®ºæ–‡ï¼Œè¯¥ç¬”è®°åŸºäºæœ€æ–°è®ºæ–‡å†…å®¹è¿›è¡Œæ•´ç†ã€‚è€Œè¯¾ç¨‹ä¸­æ˜¯åŸºäºæœ€åˆçš„æŠ€æœ¯æŠ¥å‘Šè¿›è¡Œè®²è§£ï¼ŒäºŒè€…åœ¨ç»†èŠ‚ä¸Šå¯èƒ½å­˜åœ¨å·®å¼‚ã€‚\n\n\né¦–å…ˆï¼Œæˆ‘çœ‹ä¸€ä¸‹DeepSeek R1çš„æ•´ä½“pipelineï¼š\n\n\n\n\n\n\nFigureÂ 6\n\n\n\nDeepSeek R1 å¹¶ä¸æ˜¯ä¸€æ¬¡æ€§é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€æ¡å¤šé˜¶æ®µã€é€æ­¥å¢å¼ºæ¨ç†èƒ½åŠ›çš„è®­ç»ƒæµæ°´çº¿ã€‚\n\n4.1.1 From DeepSeek-V3 to DeepSeek-R1-Zero\nä» DeepSeek V3 Base å‡ºå‘ï¼Œç ”ç©¶è€…é¦–å…ˆè¿›è¡Œäº†å‡ ä¹â€œçº¯ RLâ€çš„å®éªŒï¼ˆR1-zeroï¼‰ï¼šä»…åœ¨æ¨ç†ç±» prompt ä¸Šï¼Œç”¨ accuracy ä¸ format è¿™ç±»å¯éªŒè¯çš„ outcome-level å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ŒéªŒè¯ä¸€ä¸ªå…³é”®å‡è®¾â€”â€”åœ¨æ²¡æœ‰ process supervision çš„æƒ…å†µä¸‹ï¼ŒRL æ˜¯å¦è¶³ä»¥æ¿€æ´»æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚\n\nSpecifically, we apply the RL technique on the DeepSeek-V3 base to train DeepSeek-R1-Zero. During training, we design a straightforward template, to require DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer. We intentionally limit our constraints to this structural format, avoiding any content-specific biases to ensure that we can accurately observe the modelâ€™s natural progression during the RL process.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.4 \n\nç»“æœè¡¨æ˜æ¨ç†èƒ½åŠ›ç¡®å®å¯ä»¥è¢«æ¿€å‘ï¼ŒåŒæ—¶å‘ç°äº† â€œaha momentâ€ ç°è±¡ï¼šæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šçªç„¶å¼€å§‹ç”Ÿæˆæ›´é•¿ã€æ›´å¤æ‚çš„ CoTï¼Œä¼´éšæ¨ç†æ­£ç¡®ç‡çš„æ˜¾è‘—æå‡ã€‚\n\nNotably, during training, DeepSeek-R1-Zero exhibits an â€œaha momentâ€ characterized by a sudden increase in the use of the word â€œwaitâ€ during reflections  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.5 \n\nDeeoSeek R1-zero çš„æˆåŠŸéªŒè¯äº† RLVR æ€è·¯çš„å¯è¡Œæ€§ï¼šå³ä½¿æ²¡æœ‰ process-level supervisionï¼Œä»…å‡­ outcome-level çš„å¯éªŒè¯å¥–åŠ±ï¼ŒRL ä¹Ÿèƒ½æ¿€å‘ LLM çš„æ¨ç†èƒ½åŠ›ã€‚\n\nThe self-evolution of DeepSeek-R1-Zero underscores the power and beauty of RL: rather than explicitly teaching the model how to solve a problem, we simply provide it with the right incentives, and it autonomously develops advanced problem-solving strategies.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.5 \n\nä¸è¿‡è¯¾ç¨‹ä¸­æåˆ°ï¼ŒCoT å˜é•¿ã€â€œaha/backtrackingâ€ç­‰ç°è±¡ï¼›å¯èƒ½æ˜¯æ¥è‡ªç›®æ ‡/å®ç°ç»†èŠ‚çš„åç½®ï¼Œä¸ä¸€å®šæ˜¯â€œå­¦ä¼šæ›´æ·±æ€è€ƒâ€çš„å¿…ç„¶ï¼Œ â€œahaâ€è¿™ç±»æ–‡æœ¬ä¹Ÿå¯èƒ½åœ¨åº•åº§æ¨¡å‹ä¸Šå¶å‘å‡ºç°ï¼Œä¸å¿…è¿‡åº¦ç¥åŒ–â€œæ¶Œç°â€ã€‚\n\n\n\n\n\n\nFigureÂ 7: shows two examples to demonstrate that the DeepSeek-V3-Base model already exhibits the so-called â€œaha momentâ€ even before the RL-tuning (Image Source (Liu et al. 2025))\n\n\n\nåœ¨è¿™ä¸ªé˜¶æ®µï¼ŒDeepSeek R1-zero çš„è®­ç»ƒé‡‡ç”¨äº† GRPO Algorithm 1 ç®—æ³•ï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„å¥–åŠ±å‡½æ•°ï¼š\n\nOutcome-level å¥–åŠ±ï¼šä¸»è¦åŒ…æ‹¬ accuracy å¥–åŠ±ï¼ˆç­”æ¡ˆæ­£ç¡®ä¸å¦ï¼‰å’Œ format å¥–åŠ±ï¼ˆè¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼‰\n\n\n\n4.1.2 From DeepSeek-R1-Zero to DeepSeek-R1\nDeepSeek-R1-zero å¾ˆå¥½ï¼Œä½†æ˜¯å®ƒå­˜åœ¨å‡ ä¸ªé—®é¢˜ï¼š\n\nAlthough DeepSeek-R1-Zero exhibits strong reasoning capabilities, it faces several issues. DeepSeek-R1-Zero struggles with challenges like poor readability, and language mixing, as DeepSeek-V3-Base is trained on multiple languages, especially English and Chinese.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.6 \n\nå› æ­¤ï¼Œåœ¨R1-zeroçš„åŸºç¡€ä¸Šï¼ŒDeepSeekå›¢é˜Ÿè®¾è®¡äº† DeepSeek-R1 çš„è®­ç»ƒæ–¹æ¡ˆï¼Œæ¥æå‡æ¨¡å‹çš„è¡¨è¾¾è´¨é‡ä¸è¡Œä¸º ç¨³å®šæ€§ã€‚å…·ä½“æ¥è¯´ï¼š\n\nSFT å†·å¯åŠ¨ï¼šåˆ©ç”¨ R1-zero é‡‡æ ·å¾—åˆ°çš„å¤§é‡æ¨ç†è½¨è¿¹ï¼Œç»è¿‡è¿‡æ»¤ä¸äººå·¥/æ¨¡å‹ç²¾ä¿®åï¼Œå¯¹ V3 Base è¿›è¡Œ Cold-start Long CoT çš„ SFTï¼Œå¾—åˆ° R1 Dev ç³»åˆ—æ¨¡å‹ï¼›\nå¤šè½® GRPO å¼ RLï¼šéšåå†é€šè¿‡å¤šè½® GRPO å¼ RLï¼Œå¼•å…¥è¯­è¨€ä¸€è‡´æ€§å¥–åŠ±ã€åå¥½å¥–åŠ±ä»¥åŠæ›´ä¸°å¯Œçš„ä»»åŠ¡åˆ†å¸ƒï¼Œé€æ­¥æŠŠæ¨¡å‹ä»â€œåªä¼šè§£é¢˜â€æ¨å‘â€œæ¨ç†å¼ºã€è¡¨è¾¾ç¨³å®šã€è¡Œä¸ºå¯æ§â€çš„äº§å“çº§æ¨¡å‹ã€‚\n\n\nIn the initial stage, we collect thousands of cold-start data that exhibits a conversational, human-aligned thinking process. RL training is then applied to improve the model performance with the conversational thinking process and language consistency. Subsequently, we apply rejection sampling and SFT once more. This stage incorporates both reasoning and nonreasoning datasets into the SFT process, enabling the model to not only excel in reasoning tasks but also demonstrate advanced writing capabilities. To further align the model with human preferences, we implement a secondary RL stage designed to enhance the modelâ€™s helpfulness and harmlessness while simultaneously refining its reasoning capabilities.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.6 \n\nåŒæ—¶ï¼ŒDeepSeek R1 ä¹Ÿåœ¨å¥–åŠ±è®¾è®¡ä¸Šåšäº†æ”¹è¿›ï¼š\n\nå¤šç»´å¥–åŠ±è®¾è®¡ï¼šä¸ä»…åŒ…å«å¯éªŒè¯çš„ outcome-level å¥–åŠ±ï¼ˆaccuracyã€formatï¼‰ï¼Œè¿˜å¼•å…¥äº†Language consistency rewardã€Preference / non-verifiable rewardsï¼ˆé€šè¿‡å¯¹æ¯”å­¦ä¹ è®­ç»ƒçš„åå¥½æ¨¡å‹ï¼‰ç­‰ï¼Œæ›´å…¨é¢åœ°è¡¡é‡æ¨¡å‹è¾“å‡ºè´¨é‡ï¼›\nå¥–åŠ±æ··åˆä¸è°ƒä¼˜ï¼šé€šè¿‡å¯¹ä¸åŒå¥–åŠ±è¿›è¡ŒåŠ æƒæ··åˆä¸è°ƒä¼˜ï¼Œç¡®ä¿æ¨¡å‹åœ¨æå‡æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œä¹Ÿèƒ½å…¼é¡¾è¡¨è¾¾è´¨é‡ä¸è¡Œä¸ºç¨³å®šæ€§ã€‚\næŒç»­çš„å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼šåœ¨ RL è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒæŒç»­æ›´æ–°å¥–åŠ±æ¨¡å‹ï¼Œä»¥é€‚åº”æ¨¡å‹èƒ½åŠ›çš„æå‡ä¸ä»»åŠ¡åˆ†å¸ƒçš„å˜åŒ–ã€‚\n\n\n\n4.1.3 DeepSeek Distillation\nåœ¨ DeepSeek R1 è®­ç»ƒå®Œæˆåï¼Œç ”ç©¶è€…è¿˜è¿›è¡Œäº†è’¸é¦ï¼ˆdistillationï¼‰ï¼Œä»¥æå‡æ¨¡å‹çš„æ¨ç†æ•ˆç‡ä¸å®ç”¨æ€§.\n\nTo enable broader access to powerful AI at a lower energy cost, we have distilled several smaller models and made them publicly available.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.2 \n\nå…·ä½“çš„æ–¹æ³•å°±æ˜¯ï¼šç”¨ R1 ä½œä¸º teacher æ¨¡å‹ï¼Œç”Ÿæˆå¤§é‡é«˜è´¨é‡çš„æ¨ç†æ ·æœ¬ï¼Œç„¶åå¯¹æ›´å°çš„ student æ¨¡å‹è¿›è¡Œ SFT è’¸é¦è®­ç»ƒã€‚\n\nFor distilled models, we apply only SFT and do not include an RL stage, even though incorporating RL could substantially boost model performance.  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, p.60",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#kimi-1.5",
    "href": "posts/CS336/Lecture16&17/lec16.html#kimi-1.5",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "4.2 Kimi 1.5",
    "text": "4.2 Kimi 1.5\nå’Œ DeepSeek R1 æ›´åƒâ€œé…æ–¹é©±åŠ¨ï¼ˆSFTâ†’RLâ†’å†å¯¹é½ï¼‰â€ä¸åŒï¼Œè¯¾ç¨‹æŠŠ Kimi 1.5 çš„ç»éªŒæ€»ç»“æˆä¸€å¥è¯ï¼šdata is kingã€‚Kimi çš„æ ¸å¿ƒä¸æ˜¯æå‡ºå…¨æ–° RL ç®—æ³•ï¼Œè€Œæ˜¯æŠŠâ€œå¯éªŒè¯å¥–åŠ±æ¨ç† RLâ€å˜æˆä¸€æ¡æ›´å·¥ç¨‹åŒ–çš„æ•°æ®ç®¡çº¿ï¼šå…ˆå¯¹ä»»åŠ¡åšè·¨é¢†åŸŸåˆ†ç±»ä¸åˆ†å¸ƒå¹³è¡¡ï¼Œé¿å…æ¨¡å‹åªåœ¨å•ä¸€ç±»å‹é¢˜ä¸Šå˜å¼ºï¼›åŒæ—¶ä¸»åŠ¨å‰”é™¤å®¹æ˜“é€šè¿‡éšæœºçŒœæµ‹è·å¾—å¥–åŠ±çš„é¢˜å‹ï¼ˆä¾‹å¦‚é€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ï¼‰ï¼Œä¼˜å…ˆä¿ç•™çŸ­ç­”æ¡ˆã€å¯è¢«è§„åˆ™/åˆ¤å®šå™¨é«˜ç²¾åº¦éªŒè¯çš„ä»»åŠ¡ï¼Œä»¥å‡å°‘ reward hacking çš„ç©ºé—´ã€‚\næœ€å…³é”®çš„ä¸€æ­¥æ˜¯ best-of-n éš¾åº¦ç­›é€‰ï¼šç”¨å½“å‰è¿˜ä¸å¤Ÿå¼ºçš„ SFT æ¨¡å‹å¯¹æ¯é“é¢˜é‡‡æ ·å¤šæ¬¡ï¼ˆè¯¾ä¸Šä¸¾ä¾‹ç±»ä¼¼ best-of-8ï¼‰ï¼Œç„¶ååªä¿ç•™â€œé‡‡æ ·å¤šæ¬¡ä»ç„¶å¤±è´¥â€çš„é¢˜ï¼ˆfail best-of-nï¼‰ã€‚ç›´è§‰ä¸Šï¼Œè¿™ç›¸å½“äºæŠŠè®­ç»ƒæ•°æ®é™åˆ¶åœ¨â€œå½“å‰æ¨¡å‹ç¡®å®ä¸ä¼šï¼Œä½†åˆå¯èƒ½å­¦ä¼šâ€çš„å¯å­¦åŒºé—´ï¼Œæ˜¾å¼åšå‡ºä¸€ç§ curriculum çš„é›å½¢ï¼šå¤ªå®¹æ˜“çš„é¢˜å­¦ä¸åˆ°ä¸œè¥¿ï¼Œå¤ªéš¾çš„é¢˜åªä¼šäº§ç”Ÿå¤§é‡ 0 rewardï¼›è€Œç»è¿‡ç­›é€‰çš„é¢˜æ›´å¯èƒ½æä¾›ç¨³å®šçš„å­¦ä¹ ä¿¡å·ã€‚è¯¾ç¨‹çš„ takeaway æ˜¯ï¼šåœ¨ RLVR åœºæ™¯é‡Œï¼Œæ•°æ®éš¾åº¦æ§åˆ¶å¾€å¾€æ¯”ç®—æ³• tweak æ›´å†³å®šè®­ç»ƒæ•ˆç‡å’Œæœ€ç»ˆè¡Œä¸ºã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#qwen3",
    "href": "posts/CS336/Lecture16&17/lec16.html#qwen3",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "4.3 Qwen3",
    "text": "4.3 Qwen3\nè¯¾ç¨‹åœ¨è®² Qwen3 æ—¶ï¼Œå¼ºè°ƒå®ƒçš„äº®ç‚¹ä¸åªæ˜¯â€œä¹Ÿç”¨äº† RLVR/GRPOâ€ï¼Œè€Œæ˜¯æŠŠæ¨ç†æ¨¡å‹åœ¨çœŸå®ä½¿ç”¨åœºæ™¯é‡Œçš„ä¸€ä¸ªæ ¸å¿ƒçŸ›ç›¾æ‘†åˆ°å°é¢ä¸Šï¼šæ¨ç†è¶Šå¼ºï¼Œå¾€å¾€è¶Šè´µï¼ˆæ›´é•¿çš„ CoTã€æ›´é«˜çš„ test-time computeï¼‰ã€‚å› æ­¤ Qwen3 çš„æ€è·¯æ›´åƒæ˜¯æŠŠâ€œæ¨ç†èƒ½åŠ›â€å’Œâ€œæ¨ç†æˆæœ¬â€ä¸€èµ·çº³å…¥è®­ç»ƒç›®æ ‡ï¼šä¸€æ–¹é¢æ²¿ç”¨ â€œSFTï¼ˆé•¿ CoT å†·å¯åŠ¨ï¼‰â†’ å¯éªŒè¯å¥–åŠ± RLï¼ˆæå‡æ¨ç†æ­£ç¡®æ€§ï¼‰â†’ å†åšé€šç”¨å¯¹é½â€ çš„ä¸»çº¿ï¼›å¦ä¸€æ–¹é¢é€šè¿‡è®­ç»ƒä¸æ•°æ®/å¥–åŠ±è®¾è®¡ï¼Œè®©æ¨¡å‹å­¦ä¼šåœ¨ä¸åŒé—®é¢˜ä¸Šè‡ªé€‚åº”åœ°é€‰æ‹©æ¨ç†å¼ºåº¦â€”â€”è¯¥è®¤çœŸæ¨æ—¶èƒ½æ¨å¾—æ·±ï¼Œä¸éœ€è¦æ¨ç†æ—¶ä¹Ÿèƒ½èµ°æ›´çŸ­ã€æ›´ä¾¿å®œçš„è·¯å¾„ã€‚\nä»è¯¾ç¨‹è§†è§’çœ‹ï¼ŒQwen3 ä½“ç°äº†ä¸€ç§å¾ˆå®ç”¨çš„äº§å“åŒ–å–å‘ï¼šæ¨ç†æ¨¡å‹æœ€ç»ˆè¦åœ¨â€œæ­£ç¡®ç‡â€å’Œâ€œæˆæœ¬/å»¶è¿Ÿâ€ä¹‹é—´åšæƒè¡¡ï¼Œå•çº¯è¿½æ±‚ CoT å˜é•¿å¹¶ä¸ç­‰ä»·äºæ›´å¥½ã€‚ä¸ DeepSeek R1 æ›´å¼ºè°ƒâ€œç”¨ RL æ¿€æ´»æ¨ç†â€ä»¥åŠ Kimi æ›´å¼ºè°ƒâ€œç”¨æ•°æ®ç­›é€‰åš curriculumâ€ç›¸æ¯”ï¼ŒQwen3 æ›´åƒæ˜¯åœ¨æ¢ç´¢ï¼šå¦‚ä½•æŠŠâ€œè®¡ç®—é¢„ç®—å¯æ§â€å˜æˆæ¨¡å‹è¡Œä¸ºçš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œé¿å… RL è®­ç»ƒæŠŠ CoT æ‹‰çˆ†ã€æˆæœ¬å¤±æ§çš„å‰¯ä½œç”¨ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#data-goal",
    "href": "posts/CS336/Lecture16&17/lec16.html#data-goal",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.1 Data & Goal",
    "text": "5.1 Data & Goal\nä»»åŠ¡ï¼šæ’åºï¼ˆSortingï¼‰\n\nPromptï¼šé•¿åº¦ä¸º LLL çš„æ•´æ•°åºåˆ—ï¼Œä¾‹å¦‚ [3, 1, 2, 0]\nResponseï¼šæ¨¡å‹è¾“å‡ºåŒæ ·é•¿åº¦ LLL çš„åºåˆ—ï¼Œå¸Œæœ›æ˜¯æ’åºåçš„ç»“æœ [0, 1, 2, 3]\ngroup ç»“æ„ï¼ˆGRPO çš„å…³é”®ï¼‰ï¼šå¯¹åŒä¸€ä¸ª promptï¼Œé‡‡æ · \\(k\\) æ¡ response \\(\\{a^{(1)}, a^{(2)}, \\dots, a^{(K)}\\}\\) å½¢æˆä¸€ç»„ï¼Œç”¨äºè®¡ç®—ç»„å†… baselineï¼ˆå‡å€¼/æ ‡å‡†å·®ï¼‰ã€‚\n\ndef gen_prompts(batch_size: int, seq_len: int, vocab_size: int, device) -&gt; torch.Tensor:\n    return torch.randint(low=0, high=vocab_size, size=(batch_size, seq_len), device=device)\n\n\ndef sorted_ground_truth(prompt: torch.Tensor) -&gt; torch.Tensor:\n    return torch.sort(prompt, dim=-1).values",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#reward",
    "href": "posts/CS336/Lecture16&17/lec16.html#reward",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.2 Reward",
    "text": "5.2 Reward\né¦–å…ˆæˆ‘ä»¬éœ€è¦å®šä¹‰ reward å‡½æ•°ã€‚Lecture é‡Œå¼ºè°ƒï¼šå¦‚æœ reward åªç»™ 0/1ï¼ˆå®Œå…¨æ­£ç¡®/é”™è¯¯ï¼‰ï¼Œä¼šå¯¼è‡´ç¨€ç–å¥–åŠ±ï¼Œè®­ç»ƒå¾ˆå®¹æ˜“å¡ä½ã€‚å› æ­¤è¿™é‡Œä½¿ç”¨ partial creditæ¥è®©å­¦ä¹ æ›´å¹³æ»‘ã€‚\n\n5.2.1 Reward v2ï¼šInclusion + Adjacent Sorted Pairsï¼ˆè¯¾å ‚é‡‡ç”¨çš„æ›´ç»†å¥–åŠ±ï¼‰\nç»™å®š prompt \\(x\\) å’Œ response \\(y\\)ï¼š\n\nInclusion rewardï¼šprompt é‡Œçš„ token åœ¨ response é‡Œå‡ºç°å°±ç»™åˆ†ï¼ˆæŒ‰è®¡æ•°ï¼Œå¤šé‡é›†ï¼‰\n\n\\[\n\\text{Inclusion reward:} \\quad R_{\\text{inc}}(x,y)=\\sum_{t} \\min(\\text{count}_x(t), \\text{count}_y(t))\n\\tag{11}\\]\n\nAdjacent sorted pairsï¼šç»Ÿè®¡ response ä¸­ç›¸é‚»å¯¹æ»¡è¶³éé™åºçš„ä¸ªæ•°\n\n\\[\n\\text{Adjacent sorted pairs:} \\quad R_{\\text{adj}}(y)=\\sum_{i=1}^{L-1}\\mathbb{I}[y_i \\le y_{i+1}]\n\\tag{12}\\]\næ€» rewardï¼š\n\\[\n\\text{Total reward:} \\quad R(x,y)=R_{\\text{inc}}(x,y)+R_{\\text{adj}}(y)\n\\tag{13}\\]\n\nè¯¾å ‚ä¹Ÿæåˆ°ï¼šè¿™ç§ reward å¯èƒ½å­˜åœ¨â€œæ¼æ´â€ï¼ˆreward hackï¼‰ï¼Œå› æ­¤ reward è®¾è®¡æœ¬èº«å°±æ˜¯ RL çš„éš¾ç‚¹ä¹‹ä¸€ã€‚\n\ndef sort_distance_reward(prompt: list[int], response: list[int]) -&gt; float:\n    assert len(prompt) == len(response)\n    ground_truth = sorted(prompt)\n    return sum(1 for x, y in zip(response, ground_truth) if x == y)\n\n\ndef sort_inclusion_ordering_reward(prompt: list[int], response: list[int]) -&gt; float:\n    \"\"\"\n    Return how close response is to ground_truth = sorted(prompt).\n    \"\"\"\n    assert len(prompt) == len(response)\n    # Give one point for each token in the prompt that shows up in the response\n    inclusion_reward = sum(1 for x in prompt if x in response)  # @inspect inclusion_reward\n    # Give one point for each adjacent pair in response that's sorted\n    ordering_reward = sum(1 for x, y in zip(response, response[1:]) if x &lt;= y)  # @inspect ordering_reward\n    return inclusion_reward + ordering_reward",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#model",
    "href": "posts/CS336/Lecture16&17/lec16.html#model",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.3 Model",
    "text": "5.3 Model\nå¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å°±å®šä¸€ä¸ªç®€å•çš„æ¨¡å‹ï¼š\nclass ToySortPolicy(nn.Module):\n    def __init__(self, vocab_size: int, embedding_dim: int, prompt_length: int, response_length: int):\n        super().__init__()\n\n        self.embedding_dim = embedding_dim\n        self.emb = nn.Embedding(vocab_size, embedding_dim)\n        self.enc = nn.Parameter(\n            torch.randn(prompt_length, embedding_dim, embedding_dim) / math.sqrt(embedding_dim)\n        )\n        self.dec = nn.Parameter(\n            torch.randn(response_length, embedding_dim, embedding_dim) / math.sqrt(embedding_dim)\n        )\n        self.out = nn.Linear(embedding_dim, vocab_size)\n\n    def forward(self, prompt):\n        x = self.emb(prompt)  # (B,L,d1)\n        h = torch.einsum(\"bld,ldm-&gt;bm\", x, self.enc)  # (B,d2)\n        z = torch.einsum(\"bm,lmd-&gt;bld\", h, self.dec)  # (B,L,d1)\n        return self.out(z)  # (B,L,V)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#algorithm",
    "href": "posts/CS336/Lecture16&17/lec16.html#algorithm",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.4 Algorithm",
    "text": "5.4 Algorithm\ndef grpo(cfg: GRPOCfg = GRPOCfg()):\n    dev = get_device()\n    set_seed(cfg.seed)\n\n    policy = ToySortPolicy(cfg.V, cfg.L, cfg.L, cfg.L).to(dev)\n    opt = torch.optim.Adam(policy.parameters(), lr=cfg.lr)\n\n    reward_fn = REWARD_FN_MAP[cfg.reward_fn]\n\n    # reference model (slow-moving anchor for KL)\n    ref = ToySortPolicy(cfg.V, cfg.L, cfg.L, cfg.L).to(dev)\n    ref.load_state_dict(policy.state_dict())\n    ref.eval()\n\n    for it in range(cfg.outer_iters):\n        # update reference model slowly\n        if cfg.use_kl and it &gt; 0 and (it % cfg.ref_update_every == 0):\n            ref.load_state_dict(policy.state_dict())\n            ref.eval()\n\n        # ---------- OUTER: rollout + rewards + deltas + freeze old/ref logps\n        prompt = gen_prompts(cfg.B, cfg.L, cfg.V, dev)  # (B,L)\n\n        with torch.no_grad():\n            responses = sample_responses(policy, prompt, cfg.K, cfg.temperature)  # (B,K,L)\n            rewards = compute_reward(prompt, responses, reward_fn)  # (B,K)\n            deltas = compute_deltas(rewards, cfg.delta_mode)  # (B,K)\n\n            # IMPORTANT: freeze old logps (detach)\n            old_logp_token = compute_log_probs(prompt, responses, policy).detach()  # (B,K,L)\n\n            # freeze ref logps for KL (detach)\n            ref_logp_token = compute_log_probs(prompt, responses, ref).detach() if cfg.use_kl else None\n\n        # ---------- INNER: multiple gradient steps on same samples\n        for _ in range(cfg.inner_steps):\n            opt.zero_grad(set_to_none=True)\n\n            logp_token = compute_log_probs(prompt, responses, policy)  # (B,K,L)\n\n            loss = compute_loss(\n                log_probs=logp_token,\n                old_log_probs=old_logp_token,\n                deltas=deltas,\n                mode=cfg.loss_mode,\n            )\n\n            if cfg.use_kl:\n                loss = loss + cfg.kl_beta * compute_kl_penalty(logp_token, ref_logp_token)\n\n            loss.backward()\n            opt.step()\n\n        if (it % cfg.print_every) == 0 or it == cfg.outer_iters - 1:\n            with torch.no_grad():\n                print(\n                    f\"iter {it:04d} | \"\n                    f\"reward mean {rewards.mean().item():.3f} \"\n                    f\"(min {rewards.min().item():.1f}, max {rewards.max().item():.1f}) | \"\n                    f\"loss {loss.item():.4f}\"\n                )\n\n    return policy",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#training",
    "href": "posts/CS336/Lecture16&17/lec16.html#training",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.5 Training",
    "text": "5.5 Training\n@dataclass\nclass GRPOCfg:\n    V: int = 10  # vocab size (token values 0..V-1)\n    L: int = 4  # sequence length\n    B: int = 128  # batch prompts per outer iter\n    K: int = 8  # responses per prompt (group size)\n    outer_iters: int = 200\n    inner_steps: int = 4\n\n    lr: float = 2e-2\n    temperature: float = 1.0\n\n    delta_mode: Literal[\"raw\", \"centered_rewards\", \"normalized_rewards\", \"max_rewards\"] = \"centered_rewards\"\n    loss_mode: Literal[\"naive\", \"unclipped\", \"clipped\"] = \"clipped\"\n    clip_eps: float = 0.2\n\n    use_kl: bool = True\n    kl_beta: float = 0.02\n    ref_update_every: int = 30\n\n    seed: int = 0\n    print_every: int = 20\n\n    reward_fn: Literal[\"distance\", \"inclusion_ordering\"] = \"inclusion_ordering\"",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture16&17/lec16.html#results",
    "href": "posts/CS336/Lecture16&17/lec16.html#results",
    "title": "Lecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰",
    "section": "5.6 Results",
    "text": "5.6 Results\niter 0000 | reward mean 3.070 (min 0.0, max 7.0) | loss 0.0138\niter 0020 | reward mean 3.250 (min 0.0, max 6.0) | loss 0.0034\niter 0040 | reward mean 3.396 (min 0.0, max 7.0) | loss 0.0008\niter 0060 | reward mean 3.625 (min 0.0, max 7.0) | loss 0.0016\niter 0080 | reward mean 3.813 (min 1.0, max 7.0) | loss 0.0059\niter 0100 | reward mean 4.071 (min 1.0, max 7.0) | loss 0.0043\niter 0120 | reward mean 4.278 (min 1.0, max 7.0) | loss 0.0030\niter 0140 | reward mean 4.497 (min 1.0, max 7.0) | loss 0.0058\niter 0160 | reward mean 4.710 (min 1.0, max 7.0) | loss 0.0058\niter 0180 | reward mean 4.859 (min 2.0, max 7.0) | loss 0.0033\niter 0199 | reward mean 4.964 (min 2.0, max 7.0) | loss 0.0067\n\n\n=== sample check ===\nprompt: [4, 2, 4, 4] | pred: [0, 2, 4, 6] | gt: [2, 4, 4, 4] | sort reward: 1 | inclusion+ordering reward: 7\nprompt: [6, 8, 1, 9] | pred: [8, 9, 1, 1] | gt: [1, 6, 8, 9] | sort reward: 0 | inclusion+ordering reward: 5\nprompt: [4, 3, 8, 7] | pred: [0, 3, 6, 7] | gt: [3, 4, 7, 8] | sort reward: 0 | inclusion+ordering reward: 5\nprompt: [6, 0, 5, 6] | pred: [0, 5, 7, 9] | gt: [0, 5, 6, 6] | sort reward: 2 | inclusion+ordering reward: 5\nprompt: [3, 1, 4, 6] | pred: [1, 1, 4, 7] | gt: [1, 3, 4, 6] | sort reward: 2 | inclusion+ordering reward: 5\nprompt: [2, 7, 8, 0] | pred: [3, 7, 7, 8] | gt: [0, 2, 7, 8] | sort reward: 2 | inclusion+ordering reward: 5\nprompt: [7, 9, 1, 2] | pred: [9, 9, 1, 9] | gt: [1, 2, 7, 9] | sort reward: 1 | inclusion+ordering reward: 4\nprompt: [3, 6, 0, 2] | pred: [1, 1, 3, 7] | gt: [0, 2, 3, 6] | sort reward: 1 | inclusion+ordering reward: 4\nå…¨éƒ¨çš„ä»£ç å¯ä»¥åœ¨è¿™ä¸ªNotebookä¸­çœ‹åˆ°",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 16 & 17: LLM Alignment SFT & RLVR(GRPO)"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture05&06/lec05.html",
    "href": "posts/CS336/Lecture05&06/lec05.html",
    "title": "Lecture 05 & 06: GPUs, Kernels & Flash Attention",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 05&06: GPU Optimization, Triton & FlashAttention"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html",
    "href": "posts/100-AI-Papers/08-vae/VAE.html",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#experiment",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#experiment",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "1.1 Experiment",
    "text": "1.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#latent-variable-models",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#latent-variable-models",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "6.1 Latent Variable Models",
    "text": "6.1 Latent Variable Models\nåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸å¤„ç† é«˜ç»´ã€å¤æ‚ã€å¸¦å™ªå£°çš„çœŸå®ä¸–ç•Œæ•°æ®ï¼šå›¾åƒã€è¯­éŸ³ã€æ–‡æœ¬â€¦â€¦ è¿™äº›æ•°æ®çš„èƒŒåï¼Œå…¶å®å¸¸å¸¸æœ‰ä¸€äº› æœªè¢«ç›´æ¥è§‚æµ‹åˆ°çš„éšè—ç»“æ„ â€”â€” è¿™å°±æ˜¯ â€œLatent Variablesâ€ï¼ˆæ½œå˜é‡ï¼‰ã€‚\næƒ³è±¡ä¸€ä¸‹ï¼Œä½ çœ‹ä¸€å¼ äººè„¸ç…§ç‰‡ã€‚ç…§ç‰‡æ˜¯è§‚æµ‹å˜é‡ï¼ˆobserved variableï¼‰ã€‚ ä½†æ˜¯è®©è¿™å¼ è„¸â€œçœ‹èµ·æ¥åƒæŸä¸ªäººâ€çš„ï¼Œæ˜¯ä¸€äº›ä¸èƒ½ç›´æ¥çœ‹åˆ°çš„å› ç´ ï¼š â€¢ å…‰ç…§ï¼ˆlightingï¼‰ â€¢ æƒ…ç»ªï¼ˆexpressionï¼‰ â€¢ å§¿æ€ï¼ˆposeï¼‰ â€¢ è„¸éƒ¨ç‰¹å¾ï¼ˆidentityï¼‰ â€¢ èƒŒæ™¯ï¼ˆbackgroundï¼‰\nè¿™äº›å› ç´ è™½ç„¶æ²¡æœ‰åœ¨æ•°æ®ä¸­æ˜¾å¼æ ‡æ³¨ï¼Œå´çœŸå®å­˜åœ¨ï¼Œå¹¶å†³å®šäº†æˆ‘ä»¬çœ‹åˆ°çš„å›¾åƒã€‚ æ½œå˜é‡æ¨¡å‹çš„ç›®æ ‡ï¼Œå°±æ˜¯ç”¨æ•°å­¦æ–¹å¼æŠŠè¿™äº›â€œéšè—å› ç´ â€å»ºæ¨¡å‡ºæ¥ã€‚\n\nLatent Variable Modelï¼ˆLVMï¼‰æ˜¯ä¸€ç±» å‡è®¾è§‚æµ‹æ•°æ®æ˜¯ç”±ä¸€äº›éšè—å˜é‡ç”Ÿæˆçš„æ¦‚ç‡æ¨¡å‹ã€‚ æ¯”å¦‚æˆ‘ä»¬çœ‹åˆ°çš„æ•°æ®\\(\\mathrm{x} \\in \\mathbb{R}^{d}\\), é‚£å®ƒæœ‰ç›¸å¯¹åº”çš„éšè—å˜é‡ \\(z \\in \\mathbb{R}^{k}\\) å…¶ä¸­ \\(k \\ll d\\) . \\(z\\) æ˜¯æˆ‘ä»¬è§‚å¯Ÿä¸åˆ°çš„ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ Latent Variable.\nåœ¨ä½¿ç”¨Latent Variable Modelæ—¶ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå…³é”®çš„ä»»åŠ¡ï¼š 1. Inference: æ ¹æ® \\(\\mathrm{x}\\) æˆ‘ä»¬æ¥æ¨æ–­å‡º \\(\\mathrm{z}\\) æ˜¯ä»€ä¹ˆï¼Œæ¯”å¦‚ï¼Œç»™å®šä¸€å¼ äººè„¸çš„ç…§ç‰‡ï¼Œè¿™ä¸ªæ¨¡å‹éœ€è¦æ‰¾å‡º - è¿™å¼ è„¸æ˜¯ç”·ç”Ÿè¿˜æ˜¯å¥³ç”Ÿ - è¡¨æƒ…æ˜¯å¼€å¿ƒè¿˜æ˜¯æ‚²ä¼¤ - æ˜¯ä»€ä¹ˆæ ·çš„å§¿åŠ¿ åœ¨æ•°å­¦ä¸Šï¼Œå°±æ˜¯æ±‚åéªŒåˆ†å¸ƒ \\(p(\\mathrm{z} | \\mathrm{x})\\) 2. Generation: é€šè¿‡ \\(\\mathrm{z}\\)ï¼Œ æˆ‘ä»¬æ¥ç”Ÿæˆä¸€ä¸ª \\(\\mathrm{x}\\)ã€‚ è¿™ä¸ªå°±æ˜¯ç”Ÿæˆæ¨¡å‹ã€‚\nLatent Variable Model æ˜¯ç°ä»£ç”Ÿæˆå¼æ¨¡å‹çš„åŸºçŸ³ï¼ŒåŸºæœ¬ä¸Šæ‰€æœ‰çš„ç”Ÿæˆå¼æ¨¡å‹ï¼Œæ¯”å¦‚ GANï¼Œ DDPMï¼Œ Flow Model ç­‰ï¼Œéƒ½æ˜¯ä»¥Latent Variable Modelä¸ºåŸºç¡€ï¼Œåœ¨æ­¤æ¡ä»¶ä¸‹ï¼Œé€šè¿‡ä¸åŒæ±‚ Latent Variable çš„æ–¹æ³•ï¼Œæ¥è§£å†³è¿™ç§é—®é¢˜ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#autoencoder",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#autoencoder",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "6.2 AutoEncoder",
    "text": "6.2 AutoEncoder\n\nAutoEncoder æ˜¯ä¸€ç§Self-Supervised Learning çš„æ–¹æ³•ã€‚ å®ƒå¯ä»¥è®©ç¥ç»ç½‘ç»œå­¦ä¼šå‹ç¼©ï¼Œå¹¶ä¸”åœ¨è¿˜åŸæ•°æ®ï¼Œé€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å­¦ä¹ åˆ°çš„ä½çº¬åº¦çš„Latent Variable \\(\\mathrm{z}\\)ã€‚ AutoEncoder ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯Latent Variable Modelçš„ä¸€ç§å­¦ä¹ æ–¹æ³•ã€‚ AutoEncoder ä¹Ÿé€šå¸¸ç”¨åœ¨Representation Learning è¡¨å¾å­¦ä¹ ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#kl-divergence",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#kl-divergence",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "6.3 KL-Divergence",
    "text": "6.3 KL-Divergence\nKL æ•£åº¦ï¼ˆKullbackâ€“Leibler Divergenceï¼‰æ˜¯ç”¨æ¥è¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´å·®å¼‚çš„ä¸€ç§åº¦é‡æ–¹æ³•ã€‚å®šä¹‰å¦‚ä¸‹: \\[\nD_{KL}(Q \\| P) = \\mathbb{E}_{x \\sim Q}\\left[ \\log \\frac{Q(x)}{P(x)} \\right]\n\\]\nç›´è§‚çš„è§£é‡ŠKL-Divergenceå°±æ˜¯: - å¦‚æœæ•°æ® \\(x\\) æ˜¯ä» \\(Q\\) åˆ†å¸ƒä¸­æ¥çš„ï¼Œä½†å¦‚æœæˆ‘ä»¬ç”¨ \\(P\\) åˆ†å¸ƒ æ¥è§£é‡Šè¿™äº›æ•°æ®ï¼Œä¼šæŸå¤±å¤šå°‘ä¿¡æ¯é‡\nå¯¹äºé«˜æ–¯åˆ†å¸ƒï¼ˆGaussian Distributionï¼‰ï¼Œæˆ‘ä»¬KL- Divergenceæœ‰ä»¥ä¸‹çš„å½¢å¼ï¼š\n$$\nD_{KL}(Q | P) = $$\nå¦‚æœæ˜¯Diagonal Gaussianï¼Œ é‚£ä¹ˆKL-Divergence å¯ä»¥ç®€åŒ–ä¸ºï¼š $$ D_{KL}(q ,|, p)\n_{i=1}^{d} $$\n\\[\nD_{KL}(q(\\mathbf{z}) \\ \\| \\  \\mathcal{N}(0, I)) =\n\\frac{1}{2}\n\\sum_{i=1}^{d}\n\\left(\n\\mu_{q,i}^2 + \\sigma_{q,i}^2 - \\log \\sigma_{q,i}^2 - 1\n\\right)\n\\]\néœ€è¦æ³¨æ„çš„ä¸€ä¸ªç‚¹æ˜¯ï¼ŒKL-Divergenceæ˜¯ä¸å¯¹ç§°çš„ï¼Œ \\[\nD_{KL}(Q \\| P) \\neq D_{KL}(P \\| Q)\n\\]\nä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å¼ºè°ƒè¿™ä¸€ç‚¹ï¼Œæ˜¯å› ä¸ºï¼š å¯¹äºä¸åŒä½ç½®çš„Qï¼ŒPæˆ‘ä»¬æ‰€æ±‚çš„æ˜¯ä¸ä¸€æ ·çš„ï¼Œç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç”¨ \\(\\|\\) åé¢çš„åˆ†å¸ƒï¼Œæ¥approximate \\(\\|\\) å‰é¢çš„åˆ†å¸ƒï¼Œå…·ä½“å¦‚ä¸‹å›¾ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#variational-inference",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#variational-inference",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "6.4 Variational Inference",
    "text": "6.4 Variational Inference\nVariational Inferenceï¼ˆVIï¼Œå˜åˆ†æ¨æ–­ï¼‰æ˜¯ä¸€ç§ç”¨å¯ä¼˜åŒ–ã€æ˜“è®¡ç®—çš„åˆ†å¸ƒæ¥è¿‘ä¼¼ä¸€ä¸ªéš¾ä»¥æ±‚è§£çš„åéªŒåˆ†å¸ƒï¼Œé€šè¿‡æœ€å°åŒ–ä¸¤è€…ä¹‹é—´çš„ KL è·ç¦»ï¼Œä»è€Œå®ç°é«˜æ•ˆæ¦‚ç‡æ¨æ–­çš„æ–¹æ³•ã€‚ åœ¨ Latent Variable æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬æƒ³æ±‚ï¼š \\[\np (\\mathrm{z} | \\mathrm{x}) = \\frac{p(\\mathrm{x}, \\mathrm{z})}{p(\\mathrm{x})}\n\\]\né€šå¸¸ \\(p(\\mathrm{x})\\) æ˜¯ä¸å¯æ±‚çš„ï¼Œå› ä¸º: \\[\np(\\mathrm{x}) = \\int p(\\mathrm{x}, \\mathrm{z}) d\\mathrm{z}\n\\] é€šå¸¸æ˜¯ä¸å¯èƒ½ç›´æ¥æ±‚çš„ã€‚å› æ­¤æˆ‘ä»¬é‡‡å–ä¸€ç§ â€œæ›²çº¿æ•‘å›½â€ çš„æ–¹å¼ï¼š æˆ‘ä»¬ä¸å»è®¡ç®—çœŸæ­£çš„åéªŒï¼Œè€Œæ˜¯æ‰¾ä¸€ä¸ª å¯è®¡ç®—å¹¶ä¸”å¯ä¼˜åŒ–çš„åˆ†å¸ƒæ¥è¿‘ä¼¼å®ƒï¼š \\[\nq(z | x) \\approx p(z | x)\n\\] å®ç°èµ·æ¥ä¹Ÿæ˜¯å¾ˆç®€å•çš„ 1. é€‰ä¸€ä¸ªå¯è®¡ç®—çš„åˆ†å¸ƒæ— ï¼ˆVariational Familyï¼‰ 2. è®©å®ƒå°½å¯èƒ½çš„æ¥è¿‘çœŸå®çš„åéªŒï¼š \\[\n\\underset{\\phi}{\\min}  D_{KL}(q_{\\phi}(z | x ) \\| p(z | x))\n\\]\nç›´è§‚çš„æ¥è¯´ï¼ŒVariational Inference å°±æ˜¯ï¼šä¸è¿‡ä¸æ–­æ‹‰å‡ï¼Œæ—‹è½¬ï¼Œä¸€ä¸ªæ¤­åœ†å‹ \\(q\\), æ¥ä½¿å®ƒå°½å¯èƒ½çš„å¯ä»¥å’Œäº‘æœµå½¢çŠ¶çš„ \\(p\\) æ¥é‡å "
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#re-parameterization-trick",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#re-parameterization-trick",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "7.1 Re-parameterization Trick",
    "text": "7.1 Re-parameterization Trick\n å¦‚ä¸Šå›¾å¯è§ï¼Œ\\(z\\) æ˜¯ç”± \\(x, \\phi\\) å†³å®šçš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ”¹å–æ€ä¹ˆæ ·çš„ \\(g_{\\phi}(x, \\epsilon)\\) å‘¢ã€‚æ–‡ç« ä¸­ç»™å‡ºäº†3ä¸ªåŸºæœ¬çš„æ–¹æ³•ï¼š 1. æ–¹æ³•1 2. 2 3. c\n\n\n\n\n\n\nREINFORCE\n\n\n\nå¯¹äº Re-Parametrization Trickæ˜¯é’ˆå¯¹ \\(z\\) æ˜¯ Continuousçš„æƒ…å†µï¼Œå¦‚æœ \\(z\\) æ˜¯ç¦»æ•£ï¼ˆDiscrete) çš„ é‚£ä¹ˆæˆ‘ä»¬åˆ™å¯ä»¥ä½¿ç”¨ REINFOCE çš„æ–¹æ³•ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#amortized-inference",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#amortized-inference",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "7.2 Amortized Inference",
    "text": "7.2 Amortized Inference\nè¿˜æœ‰ä¸€ä¸ªæ¯”è¾ƒå®¹æ˜“è¢«å¿½ç•¥çš„ä¸€ç‚¹å°±æ˜¯ï¼ŒVAE è¿˜è¿ç”¨äº†Amortized Inferenceã€‚ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿ\nä¼ ç»Ÿçš„å˜åˆ†æ¨æ–­ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸€ä¸ªè§‚æµ‹æ ·æœ¬ x å•ç‹¬ä¼˜åŒ–ä¸€ä¸ªå˜åˆ†åˆ†å¸ƒ q(z|x) çš„å‚æ•°ï¼Œè¿™æ„å‘³ç€æ¯æ¥ä¸€ä¸ªæ–°æ ·æœ¬éƒ½è¦é‡æ–°åšä¸€éå˜åˆ†ä¼˜åŒ–ï¼Œæˆæœ¬éå¸¸é«˜ã€‚è€Œåœ¨ VAE ä¸­ï¼Œæˆ‘ä»¬ä¸å†ä¸ºæ¯ä¸ªæ ·æœ¬å•ç‹¬ä¼˜åŒ–åéªŒï¼Œè€Œæ˜¯è®­ç»ƒä¸€ä¸ª å…±äº«çš„æ¨æ–­ç½‘ç»œï¼ˆEncoderï¼‰ æ¥é¢„æµ‹ q_(z|x) çš„å‚æ•°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹é€šè¿‡å­¦ä¹ ä¸€ä¸ªå‡½æ•° f_(x) æ¥ä¸€æ¬¡æ€§â€œæ‘Šé”€â€æ‰€æœ‰æ ·æœ¬çš„æ¨æ–­æˆæœ¬ï¼Œä½¿å¾—å¯¹ä»»æ„æ–°æ ·æœ¬ xï¼Œåªéœ€ä¸€æ¬¡å‰å‘ä¼ æ’­å°±èƒ½å¾—åˆ°è¿‘ä¼¼åéªŒï¼Œä¸å†éœ€è¦æ˜‚è´µçš„ per-sample ä¼˜åŒ–ã€‚è¿™ç§æ–¹å¼æå¤§åœ°æå‡äº†æ¨æ–­æ•ˆç‡ï¼Œä¹Ÿè®©å˜åˆ†æ¨æ–­èƒ½å¤Ÿåœ¨æ·±åº¦å­¦ä¹ è§„æ¨¡ä¸Šè½åœ°ã€‚\nä¹Ÿå°±æ˜¯ç”¨ç¥ç»ç½‘ç»œæ¥ä¸€æ¬¡æ€§å­¦ä¹ åéªŒ\n å°†ä¸Šé¢çš„å‡ ä¸ªç»“åˆèµ·æ¥ï¼Œæˆ‘ä»¬å°±å¾—åˆ°çš„äº† Auto-Encoding VB Algorithmã€‚\n## å’Œ AutoEncoderçš„å…³ç³»"
  },
  {
    "objectID": "posts/100-AI-Papers/08-vae/VAE.html#experiements",
    "href": "posts/100-AI-Papers/08-vae/VAE.html#experiements",
    "title": "08: Auto-Encoding Variational Bayes (VAE)",
    "section": "7.3 Experiements",
    "text": "7.3 Experiements\nVAE Loss can be defined as this one:\nclass VAELoss(nn.Module):\n    def __init__(self, rec_loss=\"bce\", kl_beta=1.0):\n        super().__init__()\n\n        self.rec_loss = rec_loss.lower()\n        self.kl_beta = kl_beta\n\n        self.eval()\n\n    def forward(self, x, x_recon, mu, logvar):\n        B = x.shape[0]\n        if self.rec_loss == \"bce\":\n            rec = F.binary_cross_entropy(x_recon, x, reduction=\"sum\")\n        elif self.rec_loss == \"mse\":\n            rec = F.mse_loss(x_recon, x, reduction=\"sum\")\n\n        # KL divergence: D_KL(q(z|x) || p(z))\n        kl = 0.5 * torch.sum(logvar.exp() + mu.pow(2) - logvar - 1)\n\n        total = (rec + self.kl_beta * kl) / B\n\n        return total, {\n            \"recon\": rec.detach().cpu() / B,\n            \"kl\": kl.detach().cpu() / B,\n        }\nThe Loss curve and illustration examples:"
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "",
    "text": "æˆ‘ä»¬å¼€å§‹ç¬¬ä¸€ç¯‡è®ºæ–‡çš„å­¦ä¹ ï¼š ã€ŠAttention is All You Needã€‹ (Vaswani et al. 2023)ï¼Œä¹Ÿå°±æ˜¯ä¼ è¯´ä¸­çš„Transformeræ¨¡å‹ã€‚Transformeræ¨¡å‹çš„æå‡ºï¼Œå½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»¥åŠæ›´å¹¿æ³›çš„é¢†åŸŸã€‚è¯¥æ¶æ„å®Œå…¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶(Attention)ï¼Œä¸å†ä¾èµ–å¾ªç¯ï¼ˆRNNï¼‰æˆ–å·ç§¯ï¼ˆCNNï¼‰ï¼Œå› æ­¤åœ¨è®­ç»ƒæ—¶æ›´æ˜“å¹¶è¡ŒåŒ–ã€æ•ˆç‡æ›´é«˜ã€‚Transformer å·²æˆä¸ºä¼—å¤šå‰æ²¿æ¨¡å‹çš„åŸºç¡€ï¼Œä¸ä»…åœ¨ NLP ä¸­è¡¨ç°çªå‡ºï¼Œä¹Ÿæ‰©å±•åˆ°è®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸã€‚æ¯”å¦‚ ChatGPTã€DeepSeek ç­‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰éƒ½ä»¥ Transformer ä¸ºæ ¸å¿ƒæ¶æ„ã€‚æ‰€ä»¥æˆ‘ä»¬è‡ªç„¶å°±æŠŠå®ƒå½“ä½œæˆ‘ä»¬ç¬¬ä¸€ç¯‡æ–‡ç« çš„é¦–é€‰ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#softmax-function",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#softmax-function",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "1.1 Softmax Function",
    "text": "1.1 Softmax Function\nSoftmax Function æ˜¯ä¸€ä¸ª å°†å®æ•°å‘é‡è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ çš„å‡½æ•°ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š\n\\[\n\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n\\tag{1}\\]\nå…¶ä¸­ï¼Œ\\(z_i\\) æ˜¯è¾“å…¥å‘é‡çš„ç¬¬ \\(i\\) ä¸ªå…ƒç´ ï¼Œ\\(e\\) æ˜¯è‡ªç„¶å¯¹æ•°çš„åº•æ•°ã€‚Softmax å‡½æ•°çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œæ‰€æœ‰è¾“å‡ºå€¼çš„å’Œä¸º 1ã€‚\ndef softmax(z):\n    exp_z = torch.exp(z)\n    return exp_z / torch.sum(exp_z)",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#vector-similarity",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#vector-similarity",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "1.2 Vector Similarity",
    "text": "1.2 Vector Similarity\nåœ¨Transformerä¸­ï¼Œè®¡ç®—å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§æ˜¯ä¸€ä¸ªé‡è¦çš„æ­¥éª¤ï¼Œå¸¸ç”¨çš„æ–¹æ³•æœ‰ç‚¹ç§¯ï¼ˆDot Productï¼‰å’Œä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ã€‚åœ¨Transformerä¸­ï¼Œä¸»è¦ä½¿ç”¨Dot Productæ¥è¡¡é‡å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥ç®€å•å›é¡¾ä¸€ä¸‹Dot Productçš„è®¡ç®—æ–¹æ³•ï¼š\n\\[\n\\text{Dot Product}(A, B) = \\sum_{i=1}^{n} A_i \\cdot B_i\n\\tag{2}\\]\nå…¶ä¸­ï¼Œ\\(A\\) å’Œ \\(B\\) æ˜¯ä¸¤ä¸ªå‘é‡ï¼Œ\\(n\\) æ˜¯å‘é‡çš„ç»´åº¦ï¼Œ\\(A_i\\) å’Œ \\(B_i\\) åˆ†åˆ«æ˜¯å‘é‡ \\(A\\) å’Œ \\(B\\) åœ¨ç¬¬ \\(i\\) ä¸ªç»´åº¦çš„åˆ†é‡ï¼š\n\nDot Product çš„å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºä¸¤ä¸ªå‘é‡è¶Šç›¸ä¼¼ã€‚\nDot Product çš„å€¼è¶Šå°ï¼Œè¡¨ç¤ºä¸¤ä¸ªå‘é‡è¶Šä¸ç›¸ä¼¼ã€‚\n\nDot Productä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ Unnormalized Cosine Similarityï¼Œå› ä¸ºå®ƒæ²¡æœ‰å¯¹å‘é‡è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚\næˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨çŸ©é˜µä¹˜æ³•æ¥è®¡ç®—å¤šä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼š\n\\[\n\\text{Dot Product Matrix}(A, B) = A B^\\top\n\\tag{3}\\]\nå…¶ä¸­ï¼Œ\\(A\\) æ˜¯ä¸€ä¸ª \\(m \\times n\\) çš„çŸ©é˜µï¼Œ\\(B\\) æ˜¯ä¸€ä¸ª \\(p \\times n\\) çš„çŸ©é˜µï¼Œ\\(B^\\top\\) æ˜¯ \\(B\\) çš„è½¬ç½®çŸ©é˜µï¼Œç»“æœæ˜¯ä¸€ä¸ª \\(m \\times p\\) çš„çŸ©é˜µï¼Œè¡¨ç¤º \\(A\\) ä¸­çš„æ¯ä¸ªå‘é‡ä¸ \\(B\\) ä¸­çš„æ¯ä¸ªå‘é‡ä¹‹é—´çš„ç‚¹ç§¯ã€‚\ndef dot_product_matrix(A, B):\n    return torch.matmul(A, B.T)",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-word-embedding",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-word-embedding",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.1 Word Embedding Layer",
    "text": "2.1 Word Embedding Layer\nWord Embedding åŸºæœ¬æ˜¯æ‰€æœ‰è¯­è¨€æ¨¡å‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒçš„ä½œç”¨æ˜¯ å°†ç¦»æ•£çš„è¯æ±‡è½¬æ¢ä¸ºè¿ç»­çš„å‘é‡è¡¨ç¤ºã€‚è¿™æ ·ï¼Œæ¨¡å‹å°±å¯ä»¥åœ¨ä¸€ä¸ªé«˜ç»´ç©ºé—´ä¸­å¤„ç†è¯æ±‡ä¹‹é—´çš„å…³ç³»å’Œç›¸ä¼¼æ€§ã€‚æˆ‘ä»¬é€šå¸¸ä½¿ç”¨ä¸€ä¸ªåµŒå…¥çŸ©é˜µï¼ˆEmbedding Matrixï¼‰æ¥å®ç°è¿™ä¸€ç‚¹:\n\\[\n\\text{Embedding}(w) = W_{e}[w]\n\\tag{4}\\]\nå…¶ä¸­ï¼Œ\\(W_{e} \\in \\mathbb{R}^{V \\times d}\\) æ˜¯åµŒå…¥çŸ©é˜µ, \\(w \\in {0, 1, \\dots, V-1}\\) æ˜¯è¯æ±‡åœ¨è¯è¡¨ä¸­çš„ç´¢å¼•ï¼Œ\\(d\\) æ˜¯åµŒå…¥ç»´åº¦ï¼Œ\\(V\\) æ˜¯è¯æ±‡è¡¨å¤§å°ã€‚ è¯¥æ“ä½œç­‰ä»·äºå°†è¯æ±‡ \\(w\\) çš„ One-Hot Encoding ä¸åµŒå…¥çŸ©é˜µç›¸ä¹˜ï¼Œå³ï¼š\n\\[\n\\text{Embedding}(w) = W_{e}^{\\top} \\cdot \\text{one hot}(w), \\quad \\text{one hot}(w) \\in \\mathbb{R}^{V}\n\\tag{5}\\]\nä»å®ç°è§’åº¦çœ‹ï¼Œè¿™ä¸€è¿‡ç¨‹å¯ä»¥ç›´æ¥ç†è§£ä¸ºï¼šé€šè¿‡è¯æ±‡ç´¢å¼• \\(w\\)ï¼Œä»åµŒå…¥çŸ©é˜µ \\(W_e\\) ä¸­å–å‡ºç¬¬ \\(w\\) è¡Œä½œä¸ºè¯¥è¯çš„å‘é‡è¡¨ç¤ºã€‚\næ›´ç›´è§‚çš„æ–¹å¼å°±æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒçœ‹ä½œä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼ˆLookup Tableï¼‰ï¼Œé€šè¿‡è¯æ±‡çš„ç´¢å¼•ç›´æ¥è·å–å¯¹åº”çš„åµŒå…¥å‘é‡ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä»£ç å®ç°ï¼š\nclass navie_embedding(nn.Module):\n    def __init__(self, v, d):\n        super().__init__()\n        self.embedding = nn.Parameter(torch.randn(v, d)) # åˆå§‹åŒ–Embedding Table\n    \n    def forward(self, x):\n        # x: (batch_size, seq_len)\n        \n        # ç¬¬ä¸€ç§æ–¹æ³•: \n        # return self.embedding[x]  # ç›´æ¥ç´¢å¼•è·å–åµŒå…¥å‘é‡\n\n        # ç¬¬äºŒç§æ–¹æ³•: One Hot Encoding\n        # x_one_hot = F.one_hot(x, num_classes=self.embedding.size(0)).float() # (batch_size, seq_len, v)\n        # return torch.matmul(x_one_hot, self.embedding) # (batch_size, seq_len, d)\n\n        # ç¬¬ä¸‰ç§æ–¹æ³•ï¼Œåˆ©ç”¨Gatherå‡½æ•°\n        # batch_size, seq_len = x.size()\n        # x = x.unsqueeze(-1).expand(-1, -1, self.embedding.size(1)) # (batch_size, seq_len, d)\n        # return torch.gather(self.embedding.unsqueeze(0).expand(batch_size, -1, -1), 1, x) # (batch_size, seq_len, d)\nåœ¨ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç®€å•çš„åµŒå…¥å±‚ navie_embeddingï¼Œå®ƒæ¥å—è¯æ±‡è¡¨å¤§å° v å’ŒåµŒå…¥ç»´åº¦ d ä½œä¸ºå‚æ•°ã€‚æˆ‘ä»¬åˆå§‹åŒ–äº†ä¸€ä¸ªåµŒå…¥çŸ©é˜µ self.embeddingï¼Œå¹¶åœ¨å‰å‘ä¼ æ’­ä¸­é€šè¿‡ç´¢å¼•ã€One-Hot ç¼–ç æˆ– gather å‡½æ•°æ¥è·å–å¯¹åº”çš„åµŒå…¥å‘é‡ã€‚\nåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨ PyTorch æä¾›çš„ nn.Embedding ç±»æ¥ç®€åŒ–è¿™ä¸€è¿‡ç¨‹ï¼š\nclass WordEmbedding(nn.Module):\n    def __init__(self, vocab_size, d_model):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n    \n    def forward(self, x):\n        return self.embedding(x)\nåœ¨ Transformer ä¸­ï¼Œè¯åµŒå…¥å±‚ä¸ä»…ç”¨äºå°†è¾“å…¥è¯æ±‡è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œè¿˜ç”¨äºå°†è§£ç å™¨çš„è¾“å‡ºè¯æ±‡è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚ä¸ºäº†ä¿æŒè¾“å…¥å’Œè¾“å‡ºçš„ä¸€è‡´æ€§ï¼ŒTransformer é‡‡ç”¨äº†Weight Tyingçš„ç­–ç•¥: å³Output Layerçš„æƒé‡çŸ©é˜µä¸Embedding Layerçš„æƒé‡çŸ©é˜µå…±äº«:\n\\[\n\\text{Output Layer Weight} = \\text{Embedding Layer Weight}^\\top\n\\tag{6}\\]\nå¹¶ä¸”åœ¨åˆå§‹åŒ–æ—¶ï¼Œå¯¹åµŒå…¥å‘é‡è¿›è¡Œäº†ç¼©æ”¾å¤„ç†ï¼Œå³ä¹˜ä»¥ \\(\\sqrt{d_{model}}\\)ï¼Œä»¥ç¡®ä¿åµŒå…¥å‘é‡çš„å°ºåº¦é€‚åˆåç»­çš„æ³¨æ„åŠ›è®¡ç®—\n\nIn our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation. In the embedding layers, we multiply those weights by \\(\\sqrt{d_{model}}\\).  Attention is all you need, p.5",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-postion-embedding",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-postion-embedding",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.2 Position Embedding Layer",
    "text": "2.2 Position Embedding Layer\n\nSince our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add â€œpositional encodingsâ€ to the input embeddings at the bottoms of the encoder and decoder stacks.  Attention is all you need, p.6 \n\nTransformeræ¨¡å‹ä¸­æ²¡æœ‰ä½¿ç”¨RNNæˆ–CNNï¼Œå› æ­¤ç¼ºä¹å¯¹åºåˆ—ä¸­è¯æ±‡é¡ºåºçš„å»ºæ¨¡èƒ½åŠ›ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒTransformeræ˜¯ Permutation Invariant çš„æ¨¡å‹ï¼Œå®ƒæ— æ³•åŒºåˆ†è¾“å…¥åºåˆ—ä¸­è¯æ±‡çš„é¡ºåºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒTransformerå¼•å…¥äº†ä½ç½®ç¼–ç ï¼ˆPosition Embeddingï¼‰æ¥æ³¨å…¥ä½ç½®ä¿¡æ¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥è¯æ±‡åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚ å…¶ä¸­ï¼Œä½ç½®ç¼–ç æœ‰ä¸¤ç§ä¸»è¦çš„æ–¹æ³•: ç»å¯¹ä½ç½®ç¼–ç å’Œç›¸å¯¹ä½ç½®ç¼–ç ã€‚åœ¨åŸå§‹çš„Transformerè®ºæ–‡ä¸­ï¼Œä½¿ç”¨çš„æ˜¯ç»å¯¹ä½ç½®ç¼–ç :\n\\[\n\\begin{split}\nPE_{(pos, 2i)} & = \\sin (pos / 10,000^{2i / d_{model}}) \\\\\nPE_{(pos, 2i+1)} & = \\cos (pos / 10,000^{2i+1 / d_{model}})\n\\end{split}\n\\tag{7}\\]\nå…¶ä¸­ï¼Œ\\(pos\\) æ˜¯è¯æ±‡åœ¨åºåˆ—ä¸­çš„ä½ç½®ï¼Œ\\(i \\in [0, d_{model} / 2 )\\) æ˜¯åµŒå…¥ç»´åº¦çš„ç´¢å¼•ï¼Œ\\(d_{model}\\) æ˜¯åµŒå…¥ç»´åº¦çš„å¤§å°ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªä½ç½®ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„å‘é‡è¡¨ç¤ºã€‚\nä»”ç»†è§‚å¯Ÿä¸Šé¢çš„å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°:\n\nä½ç½®ç¼–ç çš„ç»´åº¦ä¸è¯æ±‡åµŒå…¥çš„ ç»´åº¦ç›¸åŒï¼Œè¿™æ ·å¯ä»¥ æ–¹ä¾¿åœ°å°†ä¸¤è€…ç›¸åŠ ã€‚\nä½¿ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°å¯ä»¥ç¡®ä¿ä¸åŒä½ç½®çš„ç¼–ç å…·æœ‰ä¸åŒçš„é¢‘ç‡ï¼Œä»è€Œæ•æ‰åˆ°ä¸åŒçš„ä½ç½®ä¿¡æ¯ã€‚\nè¿™ç§æ–¹æ³•è¿˜å…·æœ‰ä¸€ä¸ªä¼˜ç‚¹ï¼Œå³å®ƒå¯ä»¥æ¨å¹¿åˆ°æ¯”è®­ç»ƒæ—¶æ›´é•¿çš„åºåˆ—ï¼Œå› ä¸ºä½ç½®ç¼–ç æ˜¯åŸºäºä½ç½®è®¡ç®—çš„ï¼Œè€Œä¸æ˜¯ä¾èµ–äºå…·ä½“çš„è¯æ±‡ã€‚\n\n\n\nQuestion: ä¸ºä»€ä¹ˆæ˜¯ä¸Word Vectorç›¸åŠ ï¼Œè€Œä¸æ˜¯ç›¸ä¹˜æˆ–è€… concat å‘¢ï¼Ÿ\n\n\nå¦‚æœç”¨ç›¸ä¹˜ \\(\\odot\\), é‚£ä¹ˆä½ç½®ç¼–ç ä¸­ä¸º0çš„ç»´åº¦ä¼šç›´æ¥å°†è¯å‘é‡çš„å¯¹åº”ç»´åº¦ç½®ä¸º0ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€‚\nå¦‚æœç”¨concat, é‚£ä¹ˆè¯å‘é‡å’Œä½ç½®ç¼–ç çš„ç»´åº¦ä¼šå¢åŠ ä¸€å€ï¼Œå¯¼è‡´åç»­çš„Attentionè®¡ç®—å¤æ‚åº¦å¢åŠ ï¼ŒåŒæ—¶ä¹Ÿä¼šæ”¹å˜æ¨¡å‹çš„å‚æ•°è§„æ¨¡ï¼Œå½±å“è®­ç»ƒæ•ˆæœã€‚\nç”¨ç›¸åŠ çš„æ–¹å¼ï¼Œå¯ä»¥ä¿æŒè¯å‘é‡çš„ç»´åº¦ä¸å˜ï¼ŒåŒæ—¶å°†ä½ç½®ä¿¡æ¯æ³¨å…¥åˆ°è¯å‘é‡ä¸­ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŒæ—¶åˆ©ç”¨è¯æ±‡ä¿¡æ¯å’Œä½ç½®ä¿¡æ¯è¿›è¡Œå­¦ä¹ ã€‚\n\n\næˆ‘ä»¬æ¥ä»”ç»†çœ‹ä¸€ä¸‹EquationÂ 7ï¼Œå‡è®¾æˆ‘ä»¬å›ºå®šä½ç½® \\(pos=1\\)ï¼Œå¹¶ä¸”åµŒå…¥ç»´åº¦ \\(d_{model}=6\\)ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºå¯¹åº”çš„ä½ç½®ä¿¡æ¯ï¼š\npos = 1\nd_model = 6\npe = torch.zeros(d_model)\nfor i in range(d_model // 2):\n    pe[2 * i] = torch.sin(pos / (10000 ** (2 * i / d_model)))\n    pe[2 * i + 1] = torch.cos(pos / (10000 ** (2 * i + 1 / d_model)))\nprint(pe)\nè®¡ç®—çš„æ–¹å¼å¾ˆç®€å•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹åœ¨Transformerä¸­ï¼Œæˆ‘ä»¬å¦‚ä½•å®ç°å®ƒã€‚åœ¨å®é™…çš„å®ç°å½“ä¸­ï¼Œä¼šåˆ©ç”¨ä¸€äº›æ•°å­¦çš„æŠ€å·§æ¥é˜²æ­¢Overflow:\n\\[\n\\frac{1}{(10000^{2i/d_{model}})} = e^{\\ln(10000^{- 2i/d_{model}})} = e^{-(2i/d_{model}) \\cdot \\ln(10000)}\n\\tag{8}\\]\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n\n        position = torch.arange(0, max_len).unsqueeze(1) # (max_len, 1)\n        i = torch.arange(0, d_model, 2)  # (d_model/2,)\n        div_term = torch.exp(i * (-math.log(10000.0) / d_model)) # (d_model/2,)\n\n        pe = torch.zeros(max_len, d_model)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1), :]\n        return x\n\n\n\n\n\n\n\n\n\n\n\n(a) Display Position Embedding in Low Dimension, with sequence length 100\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigureÂ 2: Display Position Embedding in High Dimension, with sequence length 100\n\n\n\nä» FigureÂ 2 ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼šSinusoidal PE æ˜¯ä¸€ä¸ªã€Œå¤šå°ºåº¦è¡¨ç¤ºã€ï¼Œä¸åŒçš„ç»´åº¦å¯¹åº”ä¸åŒçš„é¢‘ç‡ï¼Œä»è€Œæ•æ‰åˆ°ä¸åŒçš„ä½ç½®ä¿¡æ¯ï¼š\n\nä½ç»´ â†’ é«˜é¢‘ â†’ å±€éƒ¨ã€ç²¾ç»†ä½ç½®ä¿¡æ¯\né«˜ç»´ â†’ ä½é¢‘ â†’ å…¨å±€ã€é•¿è·ç¦»ä½ç½®ä¿¡æ¯\n\n\n2.2.1 Why Sinusoidal Position Embedding?\n\nWe chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of P Epos. We also experimented with using learned positional embeddings.  Attention is all you need, p.6 \n\nè®ºæ–‡ä¸­æåˆ°çš„ç¬¬ä¸€ä¸ªå¥½å¤„å°±æ˜¯ï¼šç›¸å¯¹ä½ç½®ç¼–ç ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªä½ç½® \\(pos\\) å’Œ \\(pos + k\\)ï¼Œå…¶ä¸­ \\(k\\) æ˜¯ä¸€ä¸ªå›ºå®šçš„åç§»é‡ã€‚é‚£ä¹ˆæ ¹æ®EquationÂ 7ï¼Œæˆ‘ä»¬å¯ä»¥è¡¨ç¤ºä¸º: \\[\n\\begin{split}\nPE_{(pos \\textcolor{orange}{+ k}, 2i:2i+1)}\n&=\n\\begin{bmatrix}\n\\sin\\big((pos+k)\\,\\omega_i\\big)\\\\\n\\cos\\big((pos+k)\\,\\omega_i\\big)\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n\\sin(pos\\,\\omega_i)\\cos(k\\,\\omega_i)+\\cos(pos\\,\\omega_i)\\sin(k\\,\\omega_i)\\\\\n\\cos(pos\\,\\omega_i)\\cos(k\\,\\omega_i)-\\sin(pos\\,\\omega_i)\\sin(k\\,\\omega_i)\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n\\cos(k\\,\\omega_i) & \\sin(k\\,\\omega_i)\\\\\n-\\sin(k\\,\\omega_i) & \\cos(k\\,\\omega_i)\n\\end{bmatrix}\n\\textcolor{orange}{\n    \\begin{bmatrix}\n    \\sin(pos\\,\\omega_i)\\\\\n    \\cos(pos\\,\\omega_i)\n    \\end{bmatrix}\n} \\\\\n&= \\begin{bmatrix}\n\\cos(k\\,\\omega_i) & \\sin(k\\,\\omega_i)\\\\\n-\\sin(k\\,\\omega_i) & \\cos(k\\,\\omega_i)\n\\end{bmatrix} \\textcolor{orange}{PE_{(pos, 2i:2i+1)}}\n\\end{split}\n\\tag{9}\\]\nå…¶ä¸­ï¼Œ \\(\\omega_i = 1 / 10,000^{2i/d_{model}}\\)ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä½ç½® \\(pos + k\\) çš„ç¼–ç å¯ä»¥è¡¨ç¤ºä¸ºä½ç½® \\(pos\\) çš„ç¼–ç é€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢å¾—åˆ°çš„ç»“æœã€‚è¿™æ„å‘³ç€æ¨¡å‹å¯ä»¥é€šè¿‡å­¦ä¹ è¿™ä¸ªçº¿æ€§å˜æ¢æ¥æ•æ‰ç›¸å¯¹ä½ç½®å…³ç³»ã€‚ \\(\\begin{bmatrix}\n\\cos(k\\,\\omega_i) & \\sin(k\\,\\omega_i)\\\\\n-\\sin(k\\,\\omega_i) & \\cos(k\\,\\omega_i)\n\\end{bmatrix}\\) æ˜¯ä¸€ä¸ªæ—‹è½¬çŸ©é˜µï¼Œè¡¨ç¤ºåœ¨äºŒç»´ç©ºé—´ä¸­çš„æ—‹è½¬å˜æ¢.\n\n\nNOTE: Rotate Matrix\n\n\nRotate Matrix æ˜¯ä¸€ç§äºŒç»´ç©ºé—´ä¸­çš„çº¿æ€§å˜æ¢ï¼Œç”¨äºè¡¨ç¤ºç‚¹ç»•åŸç‚¹æ—‹è½¬ä¸€å®šè§’åº¦çš„æ“ä½œã€‚å¯¹äºä¸€ä¸ªè§’åº¦ \\(\\theta\\)ï¼Œå…¶æ—‹è½¬çŸ©é˜µå®šä¹‰å¦‚ä¸‹: \\[\nR(\\theta) = \\begin{bmatrix}\n\\cos(\\theta) & -\\sin(\\theta)\\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{bmatrix}\n\\]\nå½“æˆ‘ä»¬å°†ä¸€ä¸ªäºŒç»´å‘é‡ \\(v = \\begin{bmatrix} x \\\\ y \\end{bmatrix}\\) ä¹˜ä»¥æ—‹è½¬çŸ©é˜µ \\(R(\\theta)\\) æ—¶ï¼Œå¾—åˆ°çš„æ–°å‘é‡ \\(v'\\) è¡¨ç¤ºåŸå§‹å‘é‡ç»•åŸç‚¹æ—‹è½¬äº† \\(\\theta\\) è§’åº¦: \\[\nv' = R(\\theta) \\cdot v = \\begin{bmatrix}\n\\cos(\\theta) & -\\sin(\\theta)\\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{bmatrix} \\cdot \\begin{bmatrix}\nx \\\\ y\n\\end{bmatrix} = \\begin{bmatrix}\nx \\cos(\\theta) - y \\sin(\\theta) \\\\\nx \\sin(\\theta) + y \\cos(\\theta)\n\\end{bmatrix}\n\\]\nä¹‹åæˆ‘ä»¬è¦å­¦ä¹ çš„RoPE (Su et al. 2023)ï¼Œä¹Ÿæ˜¯åŸºäºè¿™ä¸ªæ€§è´¨æ¥è®¾è®¡çš„ã€‚\n\n\n\nç¬¬äºŒä¸ªå¥½å¤„æ˜¯ï¼šå¯æ¨å¹¿æ€§ã€‚ç”±äºä½ç½®ç¼–ç æ˜¯åŸºäºä½ç½®è®¡ç®—çš„ï¼Œè€Œä¸æ˜¯ä¾èµ–äºå…·ä½“çš„è¯æ±‡ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥æ¨å¹¿åˆ°æ¯”è®­ç»ƒæ—¶æ›´é•¿çš„åºåˆ—ã€‚è¿™å¯¹äºå¤„ç†é•¿æ–‡æœ¬æˆ–é•¿åºåˆ—ä»»åŠ¡éå¸¸æœ‰ç”¨ã€‚\n\nWe chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training.  Attention is all you need, p.6 \n\nå‡è®¾æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹è§è¿‡çš„æœ€å¤§åºåˆ—é•¿åº¦æ˜¯ \\(L_{train}\\)ï¼Œé‚£ä¹ˆåœ¨æµ‹è¯•æ—¶ï¼Œå¦‚æœé‡åˆ°ä¸€ä¸ªæ›´é•¿çš„åºåˆ—ï¼Œé•¿åº¦ä¸º \\(L_{test} &gt; L_{train}\\)ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨ç›¸åŒçš„å…¬å¼æ¥è®¡ç®—ä½ç½®ç¼–ç : \\[\nPE_{(pos, 2i)} = \\sin (pos / 10,000^{2i / d_{model}}), \\quad pos \\in [0, L_{test}-1]\n\\tag{10}\\]\nä¸è¿‡ä¸ªäººè®¤ä¸ºï¼Œå¯æ‹“å±•çš„è¿˜æœ‰ä¸€ä¸ªåŸå› æ˜¯ï¼šç”±äº (\\(pos+k\\)) çš„ç¼–ç å¯ä»¥è¡¨ç¤ºä¸ºä»…ä¾èµ– \\(k\\) çš„çº¿æ€§å˜æ¢ä½œç”¨åœ¨ \\(pos\\) çš„ç¼–ç ä¸Šï¼Œæ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ â€œç›¸å¯¹ä½ç§»â€çš„è§„å¾‹ï¼Œä»è€Œåœ¨æ›´é•¿åºåˆ—ä¸Šå…·å¤‡ä¸€å®šå¤–æ¨èƒ½åŠ›ï¼ˆè®ºæ–‡ç”¨è¯ä¸º may allowï¼Œè¡¨ç¤ºå€¾å‘æ€§è€Œéä¸¥æ ¼ä¿è¯ï¼‰ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-attention",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-attention",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.3 Attention Layer",
    "text": "2.3 Attention Layer\nAttentionæœºåˆ¶æ˜¯Transformerçš„æ ¸å¿ƒç»„ä»¶ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶åŠ¨æ€åœ°å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒéƒ¨åˆ†ã€‚Attentionæœºåˆ¶çš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡è®¡ç®—æŸ¥è¯¢ï¼ˆQueryï¼‰ã€é”®ï¼ˆKeyï¼‰å’Œå€¼ï¼ˆValueï¼‰ä¹‹é—´çš„ç›¸ä¼¼æ€§EquationÂ 3 æ¥å†³å®šå¦‚ä½•åŠ æƒè¾“å…¥ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼ŒAttentionçš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\boxed{\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q K^\\top}{\\sqrt{d_k}}\\right) V}\n\\tag{11}\\]\nç”¨ä»£ç æ¥è¡¨ç¤ºå°±æ˜¯:\ndef scaled_dot_product_attention(q, k, v):\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n    attn = F.softmax(scores, dim=-1)\n    output = torch.matmul(attn, v)\n    return output, attn\næˆ‘ä»¬æ¥æ‹†çœ‹çœ‹ä¸€ä¸‹è¿™ä¸ªå…¬å¼ï¼Œç”±å››éƒ¨åˆ†ç»„æˆ:\n\n\\(Q K^\\top\\): è®¡ç®—Queryå’ŒKeyä¹‹é—´çš„ç‚¹ç§¯ï¼Œå¾—åˆ°ç›¸ä¼¼æ€§çŸ©é˜µï¼Œè¡¨ç¤ºæ¯ä¸ªæŸ¥è¯¢ä¸æ‰€æœ‰é”®çš„ç›¸å…³æ€§ã€‚\n\\(\\frac{1}{\\sqrt{d_k}}\\): è¿™æ˜¯ä¸€ä¸ªç¼©æ”¾å› å­ï¼Œç”¨äºé˜²æ­¢ç‚¹ç§¯å€¼è¿‡å¤§ï¼Œå¯¼è‡´Softmaxå‡½æ•°çš„æ¢¯åº¦å˜å¾—éå¸¸å°ï¼Œä»è€Œå½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚è¿™é‡Œï¼Œ\\(d_k\\) æ˜¯é”®å‘é‡çš„ç»´åº¦ã€‚\n\\(\\text{softmax}(\\cdot)\\): å¯¹ç›¸ä¼¼æ€§çŸ©é˜µè¿›è¡Œå½’ä¸€åŒ–ï¼Œå¾—åˆ°æ¯ä¸ªæŸ¥è¯¢å¯¹æ‰€æœ‰é”®çš„æ³¨æ„åŠ›æƒé‡ã€‚\n\\(\\cdot V\\): ä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹å€¼è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºè¡¨ç¤ºã€‚\n\n\n\\(Q K^\\top\\)\nAttentionçš„ç¬¬ä¸€æ­¥ï¼Œå°±æ˜¯è®¡ç®—Queryå’ŒKeyä¹‹é—´çš„ç‚¹ç§¯ (EquationÂ 3) ï¼Œå¾—åˆ°ç›¸ä¼¼æ€§çŸ©é˜µ, è¡¨ç¤ºæ¯ä¸ªæŸ¥è¯¢ä¸æ‰€æœ‰é”®çš„ç›¸å…³æ€§ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæŸ¥è¯¢çŸ©é˜µ \\(Q \\in \\mathbb{R}^{n \\times d_k}\\) å’Œä¸€ä¸ªé”®çŸ©é˜µ \\(K \\in \\mathbb{R}^{m \\times d_k}\\)ï¼Œé‚£ä¹ˆç‚¹ç§¯çŸ©é˜µ \\(Q K^\\top\\) çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\nQ K^\\top = \\begin{bmatrix}\nq_1 \\\\\nq_2 \\\\\n\\vdots \\\\\nq_n\n\\end{bmatrix}\n\\begin{bmatrix}\nk_1^\\top & k_2^\\top & \\cdots & k_m^\\top\n\\end{bmatrix} =\n\\begin{bmatrix}\nq_1 k_1^\\top & q_1 k_2^\\top & \\cdots & q_1 k_m^\\top \\\\\nq_2 k_1^\\top & q_2 k_2^\\top & \\cdots & q_2 k_m^\\top \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nq_n k_1^\\top & q_n k_2^\\top & \\cdots & q_n k_m^\\top\n\\end{bmatrix}\n\\tag{12}\\]\nå…¶ä¸­ï¼Œ\\(q_i \\in \\mathbb{R}^{1 \\times d_k}\\) æ˜¯æŸ¥è¯¢çŸ©é˜µ \\(Q\\) çš„ç¬¬ \\(i\\) è¡Œï¼Œ\\(k_j \\in \\mathbb{R}^{1 \\times d_k}\\) æ˜¯é”®çŸ©é˜µ \\(K\\) çš„ç¬¬ \\(j\\) è¡Œã€‚ç»“æœçŸ©é˜µ \\(Q K^\\top \\in \\mathbb{R}^{n \\times m}\\) çš„æ¯ä¸ªå…ƒç´  \\((i, j)\\) è¡¨ç¤ºæŸ¥è¯¢ \\(q_i\\) ä¸é”® \\(k_j\\) ä¹‹é—´çš„ç‚¹ç§¯ã€‚ \\(QK^\\top\\) çš„ä½œç”¨å°±æ˜¯å‘Šè¯‰æˆ‘ä»¬ï¼Œæ¯ä¸ªæŸ¥è¯¢å‘é‡ä¸æ‰€æœ‰é”®å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œç”¨äºä¹‹åä»å€¼å‘é‡ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚\n\nDot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.  Attention is all you need, p.4 \n\n\n\\(\\frac{1}{\\sqrt{d_k}}\\)\nAttentionçš„ç¬¬äºŒæ­¥ï¼Œæ˜¯å¯¹ç‚¹ç§¯çŸ©é˜µè¿›è¡Œç¼©æ”¾ï¼Œä½¿ç”¨ \\(\\frac{1}{\\sqrt{d_k}}\\) ä½œä¸ºç¼©æ”¾å› å­ã€‚å‡è®¾ \\(q, k \\sim \\mathcal{N}(0, I)\\)ï¼Œé‚£ä¹ˆç‚¹ç§¯ \\(q k^\\top\\) çš„æœŸæœ›å’Œæ–¹å·®åˆ†åˆ«ä¸º:\n\\[\n\\mathbb{E}[q k^\\top] = 0, \\quad \\text{Var}(q k^\\top) = d_k\n\\tag{13}\\]\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç‚¹ç§¯çš„æ–¹å·®ä¸é”®å‘é‡çš„ç»´åº¦ \\(d_k\\) æˆæ­£æ¯”ã€‚éšç€ \\(d_k\\) çš„å¢åŠ ï¼Œç‚¹ç§¯ logits çš„å°ºåº¦ä¼šä¸æ–­æ”¾å¤§ï¼Œä½¿å¾— softmax çš„è¾“å…¥æ›´å®¹æ˜“è¿›å…¥é¥±å’ŒåŒºï¼ˆsaturation regimeï¼‰ï¼Œæ­¤æ—¶æŸäº›ä½ç½®çš„æ¦‚ç‡æ¥è¿‘ 1ï¼Œå…¶ä½™æ¥è¿‘ 0ã€‚åœ¨è¯¥åŒºåŸŸå†…ï¼Œsoftmax çš„æ¢¯åº¦ä¼šæ˜¾è‘—å˜å°ï¼Œä»è€Œå¯¼è‡´åå‘ä¼ æ’­ä¸ç¨³å®šã€è®­ç»ƒæ•ˆç‡ä¸‹é™ã€‚é€šè¿‡é™¤ä»¥ \\(\\sqrt{d_k}\\)ï¼Œå¯ä»¥å°†ç‚¹ç§¯ logits çš„æ–¹å·®é‡æ–°å½’ä¸€åŒ–åˆ° \\(O(1)\\) çš„å°ºåº¦ï¼Œä½¿ softmax å§‹ç»ˆå·¥ä½œåœ¨æ¢¯åº¦è¾ƒä¸ºæ•æ„Ÿçš„åŒºåŸŸï¼Œä»è€Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚\n\n\n\n\n\n\nFigureÂ 3: Effect of different scaling factor \\(\\frac{1}{\\sqrt{d_k}}\\) on the distribution of dot-product valuesã€‚å¯ä»¥çœ‹åˆ°ï¼Œæœªç¼©æ”¾çš„ç‚¹ç§¯å€¼åˆ†å¸ƒåœ¨å‡ ä¸ªç‚¹ä¸Šï¼Œéšç€ç»´åº¦å¢åŠ ï¼Œåˆ†å¸ƒå˜å¾—æ›´åˆ†æ•£ï¼Œå¯¼è‡´softmaxæ›´å®¹æ˜“é¥±å’Œã€‚å¼•å…¥ç¼©æ”¾å› å­åï¼Œç‚¹ç§¯å€¼åˆ†å¸ƒä¿æŒç¨³å®šï¼Œæœ‰åŠ©äºsoftmaxçš„ç¨³å®šæ€§ã€‚\n\n\n\nå› æ­¤è¿™ä¸ªæœ‰æ—¶å€™æˆ‘ä»¬ç§°ä¹‹ä¸º â€œScale Dot-Product Attentionâ€ã€‚é€šè¿‡å¼•å…¥ç¼©æ”¾å› å­ \\(\\frac{1}{\\sqrt{d_k}}\\)ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç‚¹ç§¯çš„æ–¹å·®æ§åˆ¶åœ¨ä¸€ä¸ªåˆç†çš„èŒƒå›´å†…ï¼Œä»è€Œç¨³å®šSoftmaxå‡½æ•°çš„è¾“å‡ºï¼Œæ”¹å–„æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚\n\n\nNOTE Gradient of Softmax\n\n\n\\[\n\\frac{\\partial \\,\\text{softmax}_i}{\\partial z_j} = \\text{softmax}_i (\\delta_{ij} - \\text{softmax}_j)\n\\]\nå…¶ä¸­ï¼Œ \\(\\delta_{ij}\\) æ˜¯ Kronecker Deltaï¼Œå½“ \\(i=j\\) æ—¶ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚\nå½“æŸä¸€é¡¹ \\(\\text{softmax}_i \\approx 1\\) æ—¶ï¼š\n\n\\(\\text{softmax}_i (1 - \\text{softmax}_i) \\approx 0\\)\nå…¶ä»–é¡¹ \\(\\text{softmax}_j \\approx 0\\)\n\næ‰€ä»¥æ‰€æœ‰çš„æ¢¯åº¦éƒ½æ¥è¿‘äº0\n\n\n\n\n\n\n\n\nFigureÂ 4: Gradient of Softmax with different scaling factor \\(\\frac{1}{\\sqrt{d_k}}\\)\n\n\n\n\nç¬¬ä¸‰é¡¹ \\(\\text{softmax}(\\cdot)\\)\nAttentionçš„ç¬¬ä¸‰æ­¥ï¼Œæ˜¯å¯¹ç¼©æ”¾åçš„ç‚¹ç§¯çŸ©é˜µè¿›è¡ŒSoftmaxå½’ä¸€åŒ–ï¼Œå¾—åˆ°æ¯ä¸ªæŸ¥è¯¢å¯¹æ‰€æœ‰é”®çš„æ³¨æ„åŠ›æƒé‡ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç¼©æ”¾åçš„ç‚¹ç§¯çŸ©é˜µ \\(S = \\frac{Q K^\\top}{\\sqrt{d_k}}\\)ã€‚ è¿™éƒ¨åˆ†å¾ˆç›´è§‚ï¼Œæˆ‘ä»¬å¯¹çŸ©é˜µ \\(S\\) çš„æ¯ä¸€è¡Œåº”ç”¨Softmaxå‡½æ•°ï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡çŸ©é˜µ \\(A\\):\n\\[\nA_{ij} = \\frac{e^{S_{ij}}}{\\sum_{k} e^{S_{ik}}}\n\\tag{14}\\]\nå…¶ä¸­ï¼Œ\\(A_{ij}\\) è¡¨ç¤ºæŸ¥è¯¢ \\(q_i\\) å¯¹é”® \\(k_j\\) çš„æ³¨æ„åŠ›æƒé‡ã€‚é€šè¿‡Softmaxå½’ä¸€åŒ–ï¼Œæˆ‘ä»¬ç¡®ä¿æ¯ä¸ªæŸ¥è¯¢çš„æ³¨æ„åŠ›æƒé‡ä¹‹å’Œä¸º1ï¼Œä»è€Œå¯ä»¥å°†å…¶è§£é‡Šä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚è¿™äº›æ³¨æ„åŠ›æƒé‡åæ˜ äº†æ¯ä¸ªæŸ¥è¯¢ä¸æ‰€æœ‰é”®ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¸®åŠ©æ¨¡å‹åŠ¨æ€åœ°å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒéƒ¨åˆ†ã€‚\n\nç¬¬å››é¡¹ \\(\\cdot V\\)\nAttentionçš„æœ€åä¸€æ­¥ï¼Œæ˜¯ä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹å€¼è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºè¡¨ç¤ºã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå€¼çŸ©é˜µ \\(V \\in \\mathbb{R}^{m \\times d_v}\\) å’Œæ³¨æ„åŠ›æƒé‡çŸ©é˜µ \\(A \\in \\mathbb{R}^{n \\times m}\\)ï¼Œé‚£ä¹ˆè¾“å‡ºçŸ©é˜µ \\(O \\in \\mathbb{R}^{n \\times d_v}\\) çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\nO = A V = \\begin{bmatrix}\nA_{11} & A_{12} & \\cdots & A_{1m} \\\\\nA_{21} & A_{22} & \\cdots & A_{2m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{n1} & A_{n2} & \\cdots & A_{nm}\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1 \\\\\nv_2 \\\\\n\\vdots \\\\\nv_m\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\sum_{j=1}^{m} A_{1j} v_j \\\\\n\\sum_{j=1}^{m} A_{2j} v_j \\\\\n\\vdots \\\\       \n\\sum_{j=1}^{m} A_{nj} v_j\n\\end{bmatrix}\n\\tag{15}\\] å…¶ä¸­ï¼Œ\\(v_j \\in \\mathbb{R}^{1 \\times d_v}\\) æ˜¯å€¼çŸ©é˜µ \\(V\\) çš„ç¬¬ \\(j\\) è¡Œã€‚ç»“æœçŸ©é˜µ \\(O \\in \\mathbb{R}^{n \\times d_v}\\) çš„æ¯ä¸€è¡Œè¡¨ç¤ºå¯¹åº”æŸ¥è¯¢çš„åŠ æƒå€¼å‘é‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ³¨æ„åŠ›æƒé‡åŠ¨æ€åœ°èšåˆè¾“å…¥ä¿¡æ¯ï¼Œä»è€Œç”Ÿæˆæ›´å…·è¡¨è¾¾åŠ›çš„è¾“å‡ºè¡¨ç¤ºã€‚\n\næ‹†çœ‹æ¥çœ‹ï¼ŒAttentionä¹Ÿæ²¡æœ‰æƒ³è±¡çš„è¿™ä¹ˆå¤æ‚ã€‚å®ƒä¸»è¦æ˜¯é€šè¿‡è®¡ç®—æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæ¥å†³å®šå¦‚ä½•åŠ æƒè¾“å…¥çš„å€¼ï¼Œä»è€Œç”Ÿæˆè¾“å‡ºè¡¨ç¤ºã€‚\nAttention å°±åƒåšèœï¼š\n\nQuery å†³å®šä½ æƒ³åšä»€ä¹ˆï¼Œ\nKey å†³å®šæ¯ä¸ªé£Ÿæçš„ç‰¹ç‚¹ï¼Œ\n\\(QK^\\top\\) æ˜¯æŠŠæ‰€æœ‰é£Ÿææ‘†åœ¨æ¡Œä¸Šï¼Œçœ‹çœ‹å“ªäº›æ¯”è¾ƒMatchä½ çš„éœ€æ±‚ï¼Œ\n\\(\\frac{1}{\\sqrt{d_k}}\\) æ˜¯è°ƒæ•´é£Ÿæçš„åˆ†é‡ï¼Œ\nSoftmax å†³å®šç”¨å¤šå°‘ï¼Œ\nValue å†³å®šæœ€ç»ˆå‘³é“ã€‚\n\nå®ƒä¸åƒ RNN æˆ–è€… CNN\n\nä½ ä¸æ˜¯æŒ‰â€œé£Ÿæé¡ºåºâ€å¤„ç†ï¼ˆä¸æ˜¯ RNNï¼‰\nä¹Ÿä¸æ˜¯åªçœ‹ç›¸é‚»å‡ æ ·ï¼ˆä¸æ˜¯ CNNï¼‰\nè€Œæ˜¯ ä¸€æ¬¡æ€§çœ‹å®Œæ•´æ¡Œé£Ÿæï¼Œå†å†³å®šé‡ç‚¹\n\n\n\n2.3.1 Multi-Head Attention\nMulti Head Attention å°±æ˜¯åœ¨ Attention çš„åŸºç¡€ä¸Šï¼Œå¹¶è¡Œåœ°è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼ˆAttention Headï¼‰ï¼Œä»è€Œæ•æ‰è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒå­ç©ºé—´ä¿¡æ¯ã€‚å…¶ä¸­æ¯ä¸€ä¸ªHeadï¼Œéƒ½æ˜¯ç‹¬ç«‹çš„ Self-Attention æœºåˆ¶ã€‚Multi-Head Attention çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\text{head}_2, \\dots, \\text{head}_h) W^O\n\\tag{16}\\]\nå…¶ä¸­ï¼Œæ¯ä¸ªæ³¨æ„åŠ›å¤´ \\(\\text{head}_i\\) çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹: \\[\n\\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\n\\tag{17}\\]\næ¯ä¸ªHeadç‹¬ç«‹çš„è¿è¡Œï¼Œç„¶åå°†æ‰€æœ‰Headçš„è¾“å‡ºè¿›è¡Œæ‹¼æ¥ï¼ˆConcatï¼‰ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢ \\(W^O\\) å¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºè¡¨ç¤ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒMulti-Head Attention èƒ½å¤ŸåŒæ—¶å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒéƒ¨åˆ†ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\n\nMulti-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.  Attention is all you need, p.5 \n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, config: ModelConfig, is_causal: bool):\n        super().__init__()\n\n        self.is_causal = is_causal\n        self.num_heads = config.num_heads\n        self.head_dim = config.d_model // config.num_heads\n        assert self.head_dim * self.num_heads == config.d_model, \"d_model must be divisible by num_heads\"\n\n        self.q_proj = nn.Linear(config.d_model, config.d_model)\n        self.k_proj = nn.Linear(config.d_model, config.d_model)\n        self.v_proj = nn.Linear(config.d_model, config.d_model)\n    \n    def forward(self, q, k, v):\n        b, q_len, _ = q.size()\n        kv_len = k.size(1)\n\n        # é€šè¿‡åˆ›å»ºviewå’Œtransposeå°†q, k, væ‹†åˆ†æˆå¤šä¸ªhead\n        q = self.q_proj(q).view(b, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n        k = self.k_proj(k).view(b, kv_len, self.num_heads, self.head_dim).transpose(1, 2)\n        v = self.v_proj(v).view(b, kv_len, self.num_heads, self.head_dim).transpose(1, 2)\n\n\n2.3.2 Self-Attention Layer\nSelf-Attention, é¡¾åæ€ä¹‰ï¼Œæ˜¯æŒ‡åœ¨è®¡ç®—Attentionæ—¶ï¼ŒæŸ¥è¯¢ï¼ˆQueryï¼‰ã€é”®ï¼ˆKeyï¼‰å’Œå€¼ï¼ˆValueï¼‰éƒ½æ¥è‡ªåŒä¸€ä¸ªåºåˆ—ã€‚è¿™ç§æœºåˆ¶å…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶ï¼ŒåŠ¨æ€åœ°å…³æ³¨åºåˆ—ä¸­çš„ä¸åŒä½ç½®ï¼Œä»è€Œæ•æ‰åˆ°åºåˆ—å†…éƒ¨çš„ä¾èµ–å…³ç³»ã€‚Self-Attentionçš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q K^\\top}{\\sqrt{d_k}}\\right) V\n\\tag{18}\\]\nåœ¨æ²¡æœ‰ä»»ä½•æ©ç çš„æƒ…å†µä¸‹ï¼ŒSelf-Attentionå…è®¸æ¯ä¸ªä½ç½®çš„æŸ¥è¯¢å‘é‡å…³æ³¨åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®ï¼ŒåŒ…æ‹¬å½“å‰ä½ç½®å’Œæœªæ¥ä½ç½®çš„ä¿¡æ¯ã€‚è¿™ç§æœºåˆ¶ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°é•¿è·ç¦»çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\nout = self.attention(x, x, x) # Self-Attention\n\n\n2.3.3 Causal Self-Attention Layer\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q K^\\top}{\\sqrt{d_k}} \\textcolor{red}{+ M}\\right) V\n\\tag{19}\\]\nå…¶ä¸­ï¼Œ\\(M \\in \\mathbb{R}^{n \\times n}\\) æ˜¯ä¸€ä¸ªæ©ç çŸ©é˜µï¼ˆMask Matrixï¼‰ï¼Œç”¨äºé˜»æ­¢æ¨¡å‹åœ¨ç”Ÿæˆåºåˆ—æ—¶è®¿é—®æœªæ¥çš„ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæ©ç çŸ©é˜µ \\(M\\) çš„å®šä¹‰å¦‚ä¸‹:\n\\[\nM_{ij} = \\begin{cases}\n-\\infty, & \\text{if } j &gt; i \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\tag{20}\\] è¿™ä¸ªæ©ç çŸ©é˜µç¡®ä¿äº†åœ¨è®¡ç®—æ³¨æ„åŠ›æƒé‡æ—¶ï¼ŒæŸ¥è¯¢ä½ç½® \\(i\\) åªèƒ½å…³æ³¨åˆ°é”®ä½ç½® \\(j \\leq i\\) çš„ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†è‡ªå›å½’ï¼ˆAuto-Regressiveï¼‰çš„ç‰¹æ€§ï¼Œé˜²æ­¢ä¿¡æ¯æ³„éœ²ã€‚\ndef create_causal_mask(q_len: int, k_len: int) -&gt; torch.Tensor:\n    return torch.tril(torch.ones((q_len, k_len), dtype=torch.bool))\n\nWe need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to \\(-\\infty\\)) all values in the input of the softmax which correspond to illegal connections.  Attention is all you need, p.5 \n\n\n\n\n\n\n\n\n\n\n\n\n(a) Causal Mask in Attention\n\n\n\n\n\n\n\n\n\n\n\n(b) Casual Mask with Padding Positions\n\n\n\n\n\n\n\nFigureÂ 5: åœ¨ FigureÂ 5 (a) ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ©ç çŸ©é˜µ \\(M\\) çš„ç»“æ„ã€‚ä¸Šä¸‰è§’éƒ¨åˆ†è¢«è®¾ç½®ä¸º \\(-\\infty\\)ï¼Œè¡¨ç¤ºè¿™äº›ä½ç½®çš„æ³¨æ„åŠ›æƒé‡åœ¨ç»è¿‡ Softmax å½’ä¸€åŒ–åå°†å˜ä¸º 0ï¼Œä»è€Œé˜»æ­¢æ¨¡å‹å…³æ³¨æœªæ¥çš„ä¿¡æ¯ã€‚åœ¨ FigureÂ 5 (b) ä¸­ï¼Œ\\((t_5, t_6, t_7)\\) æ˜¯å¡«å……ä½ç½®ï¼ˆPadding Positionsï¼‰ï¼Œè¿™äº›ä½ç½®åŒæ ·è¢«æ©ç æ‰ï¼Œç¡®ä¿æ¨¡å‹ä¸ä¼šå…³æ³¨åˆ°è¿™äº›æ— æ•ˆçš„ä¿¡æ¯ã€‚\n\n\n\n\n\nNOTE: Padding Mask\n\n\né™¤äº†Causal Maskä¹‹å¤–, åœ¨å®é™…åº”ç”¨ä¸­, æˆ‘ä»¬è¿˜éœ€è¦å¤„ç†å˜é•¿åºåˆ—ä¸­çš„å¡«å……ä½ç½®(Padding Positions)ã€‚è¿™äº›ä½ç½®é€šå¸¸ç”¨ç‰¹æ®Šçš„å¡«å……å€¼(å¦‚0)è¡¨ç¤º, ä¸åŒ…å«æœ‰æ•ˆä¿¡æ¯ã€‚åœ¨è®¡ç®—Attentionæ—¶, æˆ‘ä»¬éœ€è¦ç¡®ä¿æ¨¡å‹ä¸ä¼šå…³æ³¨åˆ°è¿™äº›å¡«å……ä½ç½®, å› æ­¤æˆ‘ä»¬å¼•å…¥äº†Padding Maskã€‚ åœ¨è®¡ç®—Attentionä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†Padding Maskä¸Causal Maskç»“åˆä½¿ç”¨, å½¢æˆä¸€ä¸ªç»¼åˆçš„æ©ç çŸ©é˜µ FigureÂ 5 (b) ã€‚å…·ä½“æ¥è¯´, å¯¹äºå¡«å……ä½ç½®, æˆ‘ä»¬åŒæ ·å°†å¯¹åº”çš„æ³¨æ„åŠ›æƒé‡è®¾ç½®ä¸º \\(-\\infty\\)ï¼Œç¡®ä¿è¿™äº›ä½ç½®åœ¨ç»è¿‡Softmaxå½’ä¸€åŒ–åä¸ä¼šè¢«å…³æ³¨åˆ°ã€‚\nclass MultiHeadAttention(nn.Module):\n    ...\n    def construct_mask(self, pad_mask, q_len: int, k_len: int, device):\n        # True=allowed, False=masked\n        mask = None\n\n        # causal mask (decoder self-attention only)\n        if self.is_causal:\n            causal_mask = create_causal_mask(q_len, k_len)\n            causal_mask = causal_mask.to(device)\n            mask = causal_mask[None, None, :, :]\n\n        if pad_mask is not None:\n            # True means allowed\n            pad_mask = pad_mask[:, None, None, :].to(device)  # Shape: (batch, 1, 1, kv_len)\n            mask = pad_mask if mask is None else (mask & pad_mask)\n\n        return mask\n    def forward(self, q, k, v, pad_mask=None):\n        ...\n        mask = self.construct_mask(pad_mask, q_len, kv_len, q.device)\n        out, attn = scaled_dot_product_attention(q, k, v, mask)\n        ...\n\n\nç”¨ä»£ç æ¥è¡¨ç¤ºCausal Self-Attentionï¼Œ æˆ‘ä»¬åªéœ€è¦åšåŸæ¥çš„åŸºç¡€ä¸Šï¼Œåœ¨è®¡ç®—Softmaxä¹‹å‰ï¼Œæ·»åŠ æ©ç çŸ©é˜µ \\(M\\) å³å¯:\ndef scaled_dot_product_attention(\n    q, \n    k, \n    v, \n    mask=None \n    ):\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n    \n    if mask is not None: \n        scores = scores.masked_fill(mask == 0, float(\"-inf\")) \n        \n    attn = F.softmax(scores, dim=-1)\n    output = torch.matmul(attn, v)\n    return output, attn\nå…¶ä¸­maskå‚æ•°æ˜¯ Padding Mask ä¸ Causal Mask çš„ç»“åˆã€‚\n\n\n2.3.4 Cross Attention Layer\nCross-Attention æ˜¯æŒ‡åœ¨è®¡ç®— Attention æ—¶ï¼ŒæŸ¥è¯¢ï¼ˆQueryï¼‰æ¥è‡ªè§£ç å™¨çš„è¾“å…¥åºåˆ—ï¼Œè€Œé”®ï¼ˆKeyï¼‰å’Œå€¼ï¼ˆValueï¼‰æ¥è‡ªç¼–ç å™¨çš„è¾“å‡ºåºåˆ—ã€‚è¿™ç§æœºåˆ¶å…è®¸è§£ç å™¨åœ¨ç”Ÿæˆè¾“å‡ºåºåˆ—æ—¶ï¼ŒåŠ¨æ€åœ°å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒéƒ¨åˆ†ï¼Œä»è€Œæ•æ‰åˆ°è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚Cross-Attention çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\text{Attention}(Q_{dec}, \\textcolor{red}{K_{enc}}, \\textcolor{red}{V_{enc}}) = \\text{softmax}\\left(\\frac{Q_{dec} \\textcolor{red}{K_{enc}^\\top}}{\\sqrt{d_k}}\\right) \\textcolor{red}{V_{enc}}\n\\tag{21}\\]\nout = self.attention(decoder_x, encoder_x, encoder_x) # Cross-Att\n\n\n2.3.5 Time Complexity of Attention\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ Self-Attention çš„æ—¶é—´å¤æ‚åº¦ã€‚å‡è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸º \\(n\\)ï¼ŒåµŒå…¥ç»´åº¦ä¸º \\(d\\)ï¼Œé‚£ä¹ˆ Self-Attention çš„æ—¶é—´å¤æ‚åº¦ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†:\n\nè®¡ç®—ç‚¹ç§¯çŸ©é˜µ \\(Q K^\\top\\) çš„æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(n^2 d)\\)ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡ä¸æ‰€æœ‰é”®å‘é‡è¿›è¡Œç‚¹ç§¯è®¡ç®—ï¼Œå…±æœ‰ \\(n\\) ä¸ªæŸ¥è¯¢å’Œ \\(n\\) ä¸ªé”®ï¼Œæ¯ä¸ªç‚¹ç§¯è®¡ç®—çš„æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(d)\\)ã€‚\nè®¡ç®— Softmax çš„æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(n^2)\\)ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡çš„ç‚¹ç§¯ç»“æœè¿›è¡Œå½’ä¸€åŒ–ï¼Œå…±æœ‰ \\(n\\) ä¸ªæŸ¥è¯¢ï¼Œæ¯ä¸ªæŸ¥è¯¢éœ€è¦å¯¹ \\(n\\) ä¸ªé”®è¿›è¡Œå½’ä¸€åŒ–ã€‚\nè®¡ç®—åŠ æƒå’Œ $ V$ çš„æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(n^2 d)\\)ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡ä¸æ‰€æœ‰å€¼å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œ å…±æœ‰ \\(n\\) ä¸ªæŸ¥è¯¢å’Œ \\(n\\) ä¸ªå€¼ï¼Œæ¯ä¸ªåŠ æƒæ±‚å’Œçš„æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(d)\\)ã€‚\n\n\\[\n\\begin{array}{|l|l|}\n\\hline\n\\textbf{Step} & \\textbf{Time Complexity} \\\\\n\\hline\nQK^\\top & \\mathcal{O}(n^2 d) \\\\\n\\text{softmax}(QK^\\top) & \\mathcal{O}(n^2) \\\\\n\\text{attention} \\times V & \\mathcal{O}(n^2 d) \\\\\n\\hline\n\\textbf{Total} & \\mathcal{O}(n^2 d) \\\\\n\\hline\n\\end{array}\n\\tag{22}\\]\nç»¼ä¸Šæ‰€è¿°ï¼ŒSelf-Attention çš„æ€»æ—¶é—´å¤æ‚åº¦ä¸º \\(\\mathcal{O}(n^2 d)\\)ã€‚éšç€è¾“å…¥åºåˆ—é•¿åº¦ \\(n\\) çš„å¢åŠ ï¼Œæ—¶é—´å¤æ‚åº¦å‘ˆäºŒæ¬¡å¢é•¿ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´åœ¨å¤„ç†é•¿åºåˆ—æ—¶è®¡ç®—å¼€é”€è¾ƒå¤§ã€‚å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†å„ç§ä¼˜åŒ–æ–¹æ³•ï¼Œå¦‚ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰ã€å±€éƒ¨æ³¨æ„åŠ›ï¼ˆLocal Attentionï¼‰ç­‰ï¼Œä»¥é™ä½ Self-Attention çš„æ—¶é—´å¤æ‚åº¦ï¼Œæé«˜æ¨¡å‹çš„æ•ˆç‡ã€‚\n\n\nWarning: ç†è§£Attention Complexityçš„é‡è¦æ€§\n\n\nç†è§£Attentionçš„Complexityå¾ˆé‡è¦, å› ä¸ºå®ƒç›´æ¥å½±å“åˆ°Transformeræ¨¡å‹çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚ä¹Ÿå°±æ˜¯è¯´, å½“å¤„ç†é•¿åºåˆ—æ—¶, Attentionçš„è®¡ç®—å¤æ‚åº¦ä¼šæ˜¾è‘—å¢åŠ , è¿™å¯èƒ½å¯¼è‡´è®­ç»ƒå’Œæ¨ç†çš„æ—¶é—´æˆæœ¬å˜å¾—éå¸¸é«˜ã€‚å› æ­¤, ç ”ç©¶äººå‘˜æå‡ºäº†å„ç§ä¼˜åŒ–æ–¹æ³•, å¦‚ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰ã€å±€éƒ¨æ³¨æ„åŠ›ï¼ˆLocal Attentionï¼‰ï¼ŒLinear Attentionï¼ŒFlash Attentionï¼ŒåŒ…æ‹¬Deep Sparse Attentionç­‰ï¼Œéƒ½æ˜¯ä¸ºäº†é™ä½Attentionçš„è®¡ç®—å¤æ‚åº¦ï¼Œä»è€Œæå‡Transformeråœ¨å¤„ç†é•¿åºåˆ—æ—¶çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚å¯ä»¥è¯´ï¼Œç†è§£äº†Attentionçš„Complexity, å°±ç†è§£äº†Transformerçš„æ•ˆç‡ç“¶é¢ˆæ‰€åœ¨ã€‚\n\n\n\n\n\n\n\n\nFigureÂ 6: Discussion on Time Complexity and Maximum Sequence Length of Self-Attention\n\n\n\n\n\n\n\nç­‰ä¸€ç­‰ï¼Œç¨³ä¸€ç¨³ï¼Œå¿ä¸€å¿\nRNNçš„æ—¶é—´å¤æ‚åº¦æ˜¯\\(\\mathcal{O}(n d^2)\\)ï¼ŒTransformerçš„æ—¶é—´å¤æ‚åº¦æ˜¯ \\(\\mathcal{O}(n^2 d)\\)ï¼Œé‚£RNNä¸æ˜¯æ›´å¿«å—ï¼Ÿ\nä¸ä¸€å®š! Transformer å¾€å¾€æ›´å¿«çš„å…³é”®ä¸åœ¨äºæŠŠæ€»å¤æ‚åº¦å˜æˆ \\(\\mathcal{O}(1)\\)ï¼Œè€Œåœ¨äºæŠŠâ€œåºåˆ—ç»´åº¦ä¸Šçš„è®¡ç®—â€ä»å¿…é¡»ä¸²è¡Œï¼Œå˜æˆå¯å¹¶è¡Œçš„çŸ©é˜µè¿ç®—ä¹Ÿå°±æ˜¯FigureÂ 6é‡Œçš„ Sequential Operations å¯¹æ¯”ï¼‰ã€‚å› æ­¤åœ¨ GPU/TPU ä¸Šï¼ŒTransformer çš„ååé€šå¸¸æ›´é«˜ã€‚\n\nå¹¶è¡Œè®¡ç®— / å¹¶è¡Œæ·±åº¦ï¼ˆcritical pathï¼‰ï¼šRNN å­˜åœ¨ä¸¥æ ¼çš„æ—¶é—´æ­¥ä¾èµ–ï¼Œå¿…é¡»æŒ‰æ­¥è®¡ç®—ï¼Œå¯¼è‡´å¹¶è¡Œæ·±åº¦éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼ˆ\\(\\mathcal{O}(n)\\)ï¼‰ï¼›è€Œ Self-Attention åœ¨ä¸€ä¸ªå±‚å†…å¯ä»¥ç”¨å‡ æ¬¡çŸ©é˜µä¹˜æ³•åŒæ—¶å¤„ç†æ‰€æœ‰ä½ç½®ï¼Œå› æ­¤å¹¶è¡Œæ·±åº¦æ˜¯å¸¸æ•°çº§\\(\\mathcal{O}(1)\\)ã€‚\nç“¶é¢ˆä¸åŒï¼ˆ\\(d\\) vs \\(n\\)ï¼‰ï¼šRNN å¯¹éšè—ç»´ \\(d\\) çš„ä¸»è¦æˆæœ¬æ˜¯äºŒæ¬¡ï¼ˆ\\(\\mathcal{O}(n d^2)\\)ï¼‰ï¼Œè€Œ attention å¯¹ \\(d\\) è¿‘ä¼¼ä¸€æ¬¡ã€ä½†å¯¹åºåˆ—é•¿åº¦ \\(n\\) æ˜¯äºŒæ¬¡ï¼ˆ\\(\\mathcal{O}(n^2 d)\\)ï¼‰ã€‚æ‰€ä»¥å½“åºåˆ—éå¸¸é•¿æ—¶ï¼Œattention çš„ \\(n^2\\) ä¼šæˆä¸ºç“¶é¢ˆï¼Œå®è·µä¸­å¸¸ç”¨\n\nFlashAttention(Dao et al. 2022) (ä¼˜åŒ–å¸¸æ•°ä¸æ˜¾å­˜/IO)\nWindow / restricted attentionï¼ˆå°†å…¨å±€æ³¨æ„åŠ›æ”¹ä¸ºå±€éƒ¨çª—å£ï¼Œç±»ä¼¼å›¾FigureÂ 6 ä¸­çš„â€œrestricted self-attentionâ€é‚£ä¸€è¡Œï¼‰æ¥è¿›ä¸€æ­¥æå‡é•¿åºåˆ—æ•ˆç‡ã€‚\n\n\n\n\nä¸€å¥è¯æ€»ç»“Attentionå°±æ˜¯:\n\nAttention is Weighted Sum of Values, where Weights are from Softmax of Scaled Dot-Product of Queries and Keys.",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-normalization",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-normalization",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.4 Normalization Layer",
    "text": "2.4 Normalization Layer\nLayer Normalization (Ba, Kiros, and Hinton 2016) æ˜¯ä¸€ç§ç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œçš„å½’ä¸€åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨æé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œé€Ÿåº¦ã€‚ä¸æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰ä¸åŒï¼ŒLayer Normalization æ˜¯åœ¨æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦ä¸Š (\\(d_{model}\\)) è¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨æ‰¹é‡ç»´åº¦ä¸Šè¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™ä½¿å¾— Layer Normalization ç‰¹åˆ«é€‚ç”¨äºå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œ Transformer ç­‰æ¨¡å‹ã€‚\n\n\nQuestionï¼šä¸ºä»€ä¹ˆLayer Normalizationæ›´é€‚åˆSequence Modelingï¼Ÿ\n\n\n\nåºåˆ—é•¿åº¦å˜åŒ–: åœ¨å¤„ç†å˜é•¿åºåˆ—æ—¶ï¼Œæ‰¹é‡å½’ä¸€åŒ–å¯èƒ½ä¼šå—åˆ°ä¸åŒé•¿åº¦åºåˆ—çš„å½±å“ï¼Œè€Œ Layer Normalization å¯ä»¥ç‹¬ç«‹äºåºåˆ—é•¿åº¦è¿›è¡Œå½’ä¸€åŒ–ã€‚\næ—¶é—´æ­¥ä¾èµ–: åœ¨ RNN ä¸­ï¼Œæ—¶é—´æ­¥ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œæ‰¹é‡å½’ä¸€åŒ–å¯èƒ½ä¼šç ´åè¿™ç§ä¾èµ–å…³ç³»ï¼Œè€Œ Layer Normalization ä¿æŒäº†æ—¶é—´æ­¥ä¹‹é—´çš„ç‹¬ç«‹æ€§ã€‚\nå°æ‰¹é‡å¤§å°: åœ¨æŸäº›ä»»åŠ¡ä¸­ï¼Œæ‰¹é‡å¤§å°å¯èƒ½éå¸¸å°ï¼Œç”šè‡³ä¸º1ï¼Œè¿™ä½¿å¾—æ‰¹é‡å½’ä¸€åŒ–æ•ˆæœä¸ä½³ï¼Œè€Œ Layer Normalization ä¸ä¾èµ–äºæ‰¹é‡å¤§å°ã€‚\n\n\n\nLayer Normalization çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\begin{split}\n\\mu & = \\frac{1}{d} \\sum_{i=1}^{d} x_i \\\\\n\\sigma^2 & = \\frac{1}{d} \\sum_{i=1}^{d} (x_i - \\mu)^2 \\\\\n\\hat{x_i} & = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\\ny_i & = \\gamma \\odot \\hat{x_i} + \\beta\n\\end{split}\n\\tag{23}\\]\nå…¶ä¸­ï¼Œ\\(x_i\\) æ˜¯è¾“å…¥å‘é‡çš„ç¬¬ \\(i\\) ä¸ªå…ƒç´ ï¼Œ\\(d\\) æ˜¯å‘é‡çš„ç»´åº¦ï¼Œ\\(\\mu\\) å’Œ \\(\\sigma^2\\) åˆ†åˆ«æ˜¯å‡å€¼å’Œæ–¹å·®ï¼Œ\\(\\epsilon\\) æ˜¯ä¸€ä¸ªå°å¸¸æ•°ï¼Œç”¨äºé˜²æ­¢é™¤é›¶é”™è¯¯ï¼Œ\\(\\gamma \\in \\mathbb{R}^d\\) å’Œ \\(\\beta \\in \\mathbb{R}^d\\) æ˜¯å¯å­¦ä¹ çš„å‚æ•°ï¼Œç”¨äºç¼©æ”¾å’Œå¹³ç§»å½’ä¸€åŒ–åçš„è¾“å‡ºã€‚\nclass LayerNorm(nn.Module):\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.gamma = nn.Parameter(torch.ones(dim))\n        self.beta = nn.Parameter(torch.zeros(dim))\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        mean = x.mean(-1, keepdim=True)\n        var = x.var(-1, keepdim=True, unbiased=False)\n\n        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n        return self.gamma * x_hat + self.beta\n\n\nQuestion: ä¸ºä»€ä¹ˆ \\(\\gamma\\) å’Œ \\(\\beta\\) æ˜¯å¿…è¦çš„? å¹¶ä¸”è¦åˆå§‹åŒ–ä¸º1å’Œ0?\n\n\nä¸ºä»€ä¹ˆæ˜¯å¿…è¦çš„ï¼Ÿ\nåœ¨Normalizationä¹‹å \\(\\hat{x_i}\\) æ˜¯å½’ä¸€åŒ–çš„è¾“å‡º, å…¶å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚è¿™å¾ˆç¨³å®šï¼Œä½†ä¹Ÿæœ‰ä¸€ä¸ªå‰¯ä½œç”¨ï¼šæ¨¡å‹å¤±å»äº†â€œæƒ³è¦å¤šå¤§å°ºåº¦/ä»€ä¹ˆå‡å€¼â€çš„è‡ªç”±åº¦ã€‚å¦‚æœæ²¡æœ‰ \\(\\gamma\\) å’Œ \\(\\beta\\)ï¼Œæ¨¡å‹å°†å¤±å»å¯¹åŸå§‹æ•°æ®åˆ†å¸ƒçš„è¡¨è¾¾èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥ \\(\\gamma\\) å’Œ \\(\\beta\\)ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°é€‚åˆå½“å‰ä»»åŠ¡çš„ç¼©æ”¾å’Œå¹³ç§»ï¼Œä»è€Œæ¢å¤æˆ–è°ƒæ•´æ•°æ®çš„åˆ†å¸ƒã€‚\nä¸ºä»€ä¹ˆåˆå§‹åŒ–ä¸º1å’Œ0ï¼Ÿ\nåˆå§‹åŒ–æˆ \\(\\gamma=1, \\beta=0\\) æ—¶ï¼Œ\\(y_i = \\hat{x_i}\\)ï¼Œå³åˆå§‹æ—¶ Layer Normalization çš„è¾“å‡ºä¸å½’ä¸€åŒ–åçš„è¾“å…¥ç›¸åŒã€‚è¿™ç§åˆå§‹åŒ–æ–¹å¼ç¡®ä¿äº†åœ¨è®­ç»ƒå¼€å§‹æ—¶ï¼ŒLayer Normalization ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œä»»ä½•ç¼©æ”¾æˆ–å¹³ç§»ï¼Œä»è€Œé¿å…äº†å¯¹æ¨¡å‹è®­ç»ƒçš„å¹²æ‰°ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ \\(\\gamma\\) å’Œ \\(\\beta\\) çš„å€¼ï¼Œä»¥é€‚åº”å…·ä½“ä»»åŠ¡çš„éœ€æ±‚ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-feed-forward",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-feed-forward",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.5 Feed Forward Layer",
    "text": "2.5 Feed Forward Layer\nåœ¨Transformerä¸­ï¼Œå‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeed Forward Network, FFNï¼‰æ˜¯æ¯ä¸ªç¼–ç å™¨å’Œè§£ç å™¨å±‚ä¸­çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å¯¹æ¯ä¸ªä½ç½®çš„è¡¨ç¤ºè¿›è¡Œéçº¿æ€§å˜æ¢ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚å‰é¦ˆç¥ç»ç½‘ç»œé€šå¸¸ç”±ä¸¤ä¸ªçº¿æ€§å˜æ¢å’Œä¸€ä¸ªéçº¿æ€§æ¿€æ´»å‡½æ•°ç»„æˆï¼Œå…·ä½“è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹: \\[\n\\text{FFN}(\\mathrm{x}) = \\underset{}{\\max} (0, \\mathrm{x} W_{1} + b_{1}) W_{2} + b_{2}\n\\tag{24}\\]\nå…¶ä¸­ï¼Œ\\(\\mathrm{x} \\in \\mathbb{R}^{d_{model}}\\) æ˜¯è¾“å…¥å‘é‡ï¼Œ\\(W_{1} \\in \\mathbb{R}^{d_{model} \\times d_{ff}}\\) å’Œ \\(W_{2} \\in \\mathbb{R}^{d_{ff} \\times d_{model}}\\) æ˜¯æƒé‡çŸ©é˜µï¼Œ\\(b_{1} \\in \\mathbb{R}^{d_{ff}}\\) å’Œ \\(b_{2} \\in \\mathbb{R}^{d_{model}}\\) æ˜¯åç½®å‘é‡ï¼Œ\\(d_{ff}\\) æ˜¯å‰é¦ˆç½‘ç»œçš„éšè—å±‚ç»´åº¦ï¼Œé€šå¸¸å¤§äº \\(d_{model}\\)ï¼Œåœ¨åŸå§‹çš„Transformerè®ºæ–‡ä¸­ï¼Œ\\(d_{ff}\\) é€šå¸¸è®¾ç½®ä¸º \\(4 \\times d_{model}\\)ã€‚\nä¸ºä»€ä¹ˆè¦ä½¿ç”¨å‰é¦ˆç¥ç»ç½‘ç»œï¼Ÿä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªåŸå› :\n\néçº¿æ€§å˜æ¢: å‰é¦ˆç¥ç»ç½‘ç»œå¼•å…¥äº†éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUï¼‰ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„éçº¿æ€§å…³ç³»ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\nä½ç½®ç‹¬ç«‹æ€§: å‰é¦ˆç¥ç»ç½‘ç»œå¯¹æ¯ä¸ªä½ç½®çš„è¡¨ç¤ºè¿›è¡Œç‹¬ç«‹çš„å˜æ¢ï¼Œè¿™æœ‰åŠ©äºæ¨¡å‹æ•æ‰æ¯ä¸ªä½ç½®çš„ç‰¹å¾ï¼Œè€Œä¸å—å…¶ä»–ä½ç½®çš„å½±å“ã€‚\nå¢åŠ æ¨¡å‹å®¹é‡: é€šè¿‡å¢åŠ å‰é¦ˆç¥ç»ç½‘ç»œçš„éšè—å±‚ç»´åº¦ \\(d_{ff}\\)ï¼Œå¯ä»¥æ˜¾è‘—å¢åŠ æ¨¡å‹çš„å®¹é‡ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ€§èƒ½ã€‚\n\nclass FFN(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.fc1 = nn.Linear(config.d_model, config.d_ff)\n        self.fc2 = nn.Linear(config.d_ff, config.d_model)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#residual-connection",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#residual-connection",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.6 Residual Connection",
    "text": "2.6 Residual Connection\nå½“ç„¶ï¼Œå¦‚æœè¦è®­ç»ƒä¸€ä¸ªDEEP Transformeræ¨¡å‹ï¼Œé¿ä¸å¼€çš„å°±æ˜¯Residual Connection (He et al. 2015), å®ƒçš„ä½œç”¨æ˜¯ç¼“è§£æ·±å±‚ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä»è€Œä½¿å¾—æ›´æ·±å±‚çš„ç½‘ç»œèƒ½å¤Ÿè¢«æœ‰æ•ˆè®­ç»ƒã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡å¼•å…¥è·³è·ƒè¿æ¥ï¼ˆSkip Connectionï¼‰ï¼Œå°†è¾“å…¥ç›´æ¥æ·»åŠ åˆ°è¾“å‡ºä¸Šï¼Œä»è€Œå½¢æˆä¸€ä¸ªâ€œæ·å¾„â€ï¼Œä½¿å¾—æ¢¯åº¦å¯ä»¥ç›´æ¥ä¼ é€’åˆ°æ›´æ—©çš„å±‚ã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå­å±‚ï¼ˆSublayerï¼‰ï¼Œå…¶è¾“å…¥ä¸º \\(\\mathbf   {x}\\)ï¼Œè¾“å‡ºä¸º \\(\\mathrm{Sublayer}(\\mathbf{x})\\)ï¼Œé‚£ä¹ˆå¼•å…¥æ®‹å·®è¿æ¥åçš„è¾“å‡º \\(\\mathbf{y}\\) å¯ä»¥è¡¨ç¤ºä¸º:\n\\[\n\\mathbf{y} = \\text{LayerNorm}(\\mathbf{x} + \\mathrm{Sublayer}(\\mathbf{x}))\n\\]\n\n2.6.1 Backpropagation through Residual Connection\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥ç®€å•åˆ†æä¸€ä¸‹ï¼Œæ®‹å·®è¿æ¥æ˜¯å¦‚ä½•å¸®åŠ©ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæŸå¤±å‡½æ•° \\(\\mathcal{L}\\)ï¼Œ\n\\[\n\\mathbf{y} = \\mathbf{x} + \\mathrm{Sublayer}(\\mathbf{x})\n\\tag{25}\\]\næˆ‘ä»¬æƒ³è¦è®¡ç®—æŸå¤±å‡½æ•°å¯¹è¾“å…¥ \\(\\mathbf{x}\\) çš„æ¢¯åº¦ \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}}\\)ã€‚æ ¹æ®é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°:\n\\[\n\\begin{split}\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}}\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial}{\\partial \\mathbf{x}}\\left(\\mathbf{x}+\\mathrm{Sublayer}(\\mathbf{x})\\right) \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\left(\\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{x}} +\n\\frac{\\partial \\mathrm{Sublayer}(\\mathbf{x})}{\\partial \\mathbf{x}} \\right) \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\left( \\mathbf{I} + \\frac{\\partial \\mathrm{Sublayer}(\\mathbf{x})}{\\partial \\mathbf{x}} \\right) \\\\\n&= \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}}}_{\\text{straight path}} +\n\\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\cdot\n\\frac{\\partial\\,\\mathrm{Sublayer}(\\mathbf{x})}{\\partial \\mathbf{x}}}_{\\text{through the sub-layer}}\n\\end{split}\n\\tag{26}\\]\nå…¶ä¸­ï¼Œ\\(y\\) æ˜¯æ®‹å·®è¿æ¥çš„è¾“å‡ºï¼Œ\\(\\mathbf{I}\\) æ˜¯å•ä½çŸ©é˜µã€‚å¯ä»¥çœ‹åˆ°ï¼Œæ¢¯åº¦ \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}}\\) åŒ…å«äº†ä¸¤éƒ¨åˆ†:\n\nStraight Path: è¿™éƒ¨åˆ†æ¢¯åº¦ç›´æ¥æ¥è‡ªäºæŸå¤±å‡½æ•°å¯¹è¾“å‡º \\(\\mathbf{y}\\) çš„æ¢¯åº¦ \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}}\\)ï¼Œå®ƒä¸ç»è¿‡ä»»ä½•å­å±‚çš„å˜æ¢ï¼Œå› æ­¤ä¸ä¼šå—åˆ°æ¢¯åº¦æ¶ˆå¤±çš„å½±å“ã€‚\nThrough the Sub-layer: è¿™éƒ¨åˆ†æ¢¯åº¦é€šè¿‡å­å±‚çš„å˜æ¢ä¼ æ’­ï¼Œå¯èƒ½ä¼šå—åˆ°æ¢¯åº¦æ¶ˆå¤±çš„å½±å“ã€‚\n\né€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥ï¼Œæ¨¡å‹å¯ä»¥ç¡®ä¿æ¢¯åº¦åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è‡³å°‘æœ‰ä¸€éƒ¨åˆ†ï¼ˆStraight Pathï¼‰èƒ½å¤Ÿç›´æ¥ä¼ é€’åˆ°æ›´æ—©çš„å±‚ï¼Œä»è€Œç¼“è§£äº†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ã€‚è¿™ä½¿å¾—æ·±å±‚ç½‘ç»œèƒ½å¤Ÿè¢«æœ‰æ•ˆè®­ç»ƒï¼Œä»è€Œæå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-output-layer",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#sec-output-layer",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.7 Output Layer",
    "text": "2.7 Output Layer\nåœ¨Transformerçš„è¾“å‡ºå±‚ï¼Œé€šå¸¸ä¼šä½¿ç”¨ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆLinear Layerï¼‰å°†è§£ç å™¨çš„è¾“å‡ºè½¬æ¢ä¸ºè¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œç„¶åé€šè¿‡Softmaxå‡½æ•°EquationÂ 1 å°†å…¶è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œç”Ÿæˆæœ€ç»ˆçš„é¢„æµ‹ç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾è§£ç å™¨çš„è¾“å‡ºä¸º \\(\\mathbf{h} \\in \\mathbb{R}^{d_{model}}\\)ï¼Œè¯æ±‡è¡¨å¤§å°ä¸º \\(V\\)ï¼Œé‚£ä¹ˆè¾“å‡ºå±‚çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\mathbf{y} = \\text{Softmax}(\\mathbf{h} W_{o} + b_o)\n\\tag{27}\\]\nå…¶ä¸­ï¼Œ\\(W_{o} \\in \\mathbb{R}^{d_{model} \\times V}\\) æ˜¯çº¿æ€§å±‚çš„æƒé‡çŸ©é˜µï¼Œ\\(b_o \\in \\mathbb{R}^{V}\\) æ˜¯åç½®å‘é‡ï¼Œ\\(\\mathbf{y} \\in \\mathbb{R}^{V}\\) æ˜¯æœ€ç»ˆçš„é¢„æµ‹ç»“æœï¼Œè¡¨ç¤ºæ¯ä¸ªè¯æ±‡çš„æ¦‚ç‡åˆ†å¸ƒã€‚\nclass Transformer(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n        ...\n        self.output_layer = nn.Linear(config.d_model, config.tgt_vocab_size)\n    \n    def forward(self, original, target):\n        ...\n        logits = self.output_layer(y_dec)\n        return logits",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#encoder-decoder-layer",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#encoder-decoder-layer",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.8 Encoder & Decoder Layer",
    "text": "2.8 Encoder & Decoder Layer\næœ‰äº†è¿™äº›åŸºç¡€ç»„ä»¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥å’Œå ç§¯æœ¨ä¸€æ ·ï¼Œæ¥æ­å»ºTransformerçš„Encoderå’ŒDecoderå±‚äº†ã€‚\nEncoder å¯ä»¥è¡¨ç¤ºä¸º:\n\\[\n\\begin{split}\n\\text{EncoderLayer}_{i}(\\mathrm{x}) & = \\text{LayerNorm}_{i}\\left(\\mathrm{x} + \\text{MultiHeadSelfAttention}_{i}(\\mathrm{x}, \\mathrm{x},\\mathrm{x})\\right) \\\\\n\\text{EncoderLayer}_{i}(\\mathrm{x}) & = \\text{LayerNorm}_{i}\\left(\\mathrm{x} + \\text{FFN}_{i}(\\mathrm{x})\\right) \\\\\n\\end{split}\n\\tag{28}\\]\nå…¶ä¸­ï¼Œ\\(\\mathrm{x}\\) æ˜¯è¾“å…¥å‘é‡ï¼Œ\\(\\text{MultiHeadSelfAttention}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªç¼–ç å™¨å±‚çš„å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œ\\(\\text{FFN}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªç¼–ç å™¨å±‚çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œ\\(\\text{LayerNorm}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªç¼–ç å™¨å±‚çš„å±‚å½’ä¸€åŒ–ã€‚\nclass EncoderBlock(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.attn = MultiHeadAttention(config, is_causal=False)\n        self.ln1 = LayerNorm(config.d_model)\n\n        self.ffn = FFN(config)\n        self.ln2 = LayerNorm(config.d_model)\n\n        self.dropout = nn.Dropout(config.dropout)\n\n    def forward(self, x: torch.Tensor, pad_mask=None) -&gt; torch.Tensor:\n        attn_output, _ = self.attn(x, x, x, pad_mask=pad_mask)\n        x = self.ln1(x + self.dropout(attn_output))\n        ffn_output = self.ffn(x)\n        x = self.ln2(x + ffn_output)\n\n        return x\n\nclass Encoder(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.layers = nn.ModuleList([EncoderBlock(config) for _ in range(config.num_layers)])\n\n    def forward(self, x: torch.Tensor, pad_mask=None) -&gt; torch.Tensor:\n        for layer in self.layers:\n            x = layer(x, pad_mask=pad_mask)\n        return x\nä¸‹å›¾å±•ç¤ºäº†Encoder Layerçš„è¿‡ç¨‹ï¼š\n\n\n\n\n\n\nFigureÂ 7: Encoding Layer Process\n\n\n\nDecoder å¯ä»¥è¡¨ç¤ºä¸º: \\[\n\\begin{split}\n\\text{DecoderLayer}_{i}(\\mathrm{y}, \\mathrm{x}) & = \\text{LayerNorm}_{i}\\left(\\mathrm{y} + \\text{CausalMultiHeadSelfAttention}_{i}(\\mathrm{y}, \\mathrm{y}, \\mathrm{y})\\right) \\\\\n\\text{DecoderLayer}_{i}(\\mathrm{y}, \\mathrm{x}) & = \\text{LayerNorm}_{i}\\left(\\mathrm{y} + \\text{CrossAttention}_{i}(\\mathrm{y}, \\mathrm{x}_{enc}, \\mathrm{x}_{enc})\\right) \\\\\n\\text{DecoderLayer}_{i}(\\mathrm{y}, \\mathrm{x}) & = \\text{LayerNorm}_{i}\\left(\\mathrm{y} + \\text{FFN}_{i}(\\mathrm{y})\\right) \\\\\n\\end{split}\n\\tag{29}\\]\nå…¶ä¸­ï¼Œ\\(\\mathrm{y}\\) æ˜¯è§£ç å™¨çš„è¾“å…¥å‘é‡ï¼Œ\\(\\mathrm{x}_{enc}\\) æ˜¯ç¼–ç å™¨çš„è¾“å‡ºå‘é‡ï¼Œ\\(\\text{CausalMultiHeadSelfAttention}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªè§£ç å™¨å±‚çš„å› æœå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œ\\(\\text{CrossAttention}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªè§£ç å™¨å±‚çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œ\\(\\text{FFN}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªè§£ç å™¨å±‚çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œ\\(\\text{LayerNorm}_{i}\\) æ˜¯ç¬¬ \\(i\\) ä¸ªè§£ç å™¨å±‚çš„å±‚å½’ä¸€åŒ–ã€‚\nclass DecoderBlock(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.self_attn = MultiHeadAttention(config, is_causal=True)\n        self.ln1 = LayerNorm(config.d_model)\n\n        self.cross_attn = MultiHeadAttention(config, is_causal=False)\n        self.ln2 = LayerNorm(config.d_model)\n\n        self.ffn = FFN(config)\n        self.ln3 = LayerNorm(config.d_model)\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        enc_output: torch.Tensor,\n        src_pad_mask=None,\n        tgt_pad_mask=None,\n    ) -&gt; torch.Tensor:\n        self_attn_output, _ = self.self_attn(x, x, x, pad_mask=tgt_pad_mask)\n        x = self.ln1(x + self_attn_output)\n\n        cross_attn_output, _ = self.cross_attn(x, enc_output, enc_output, pad_mask=src_pad_mask)\n        x = self.ln2(x + cross_attn_output)\n\n        ffn_output = self.ffn(x)\n        x = self.ln3(x + ffn_output)\n\n        return x\n\nclass Decoder(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.layers = nn.ModuleList([DecoderBlock(config) for _ in range(config.num_layers)])\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        enc_output: torch.Tensor,\n        src_pad_mask=None,\n        tgt_pad_mask=None,\n    ) -&gt; torch.Tensor:\n        for layer in self.layers:\n            x = layer(\n                x,\n                enc_output,\n                src_pad_mask=src_pad_mask,\n                tgt_pad_mask=tgt_pad_mask,\n            )\n        return x\nä¸‹å›¾å±•ç¤ºäº†Decoder Layerçš„è¿‡ç¨‹ï¼š\n\n\n\n\n\n\nFigureÂ 8: Decoding Layer Process\n\n\n\né€šè¿‡å †å å¤šä¸ªç¼–ç å™¨å±‚å’Œè§£ç å™¨å±‚ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ„å»ºå‡ºå®Œæ•´çš„Transformeræ¨¡å‹ã€‚\nclass Transformer(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.vocab_embedding = WordEmbedding(config.vocab_size, config.d_model)\n        self.positional_embedding = PositionalEmbedding(config)\n\n        self.encoder = Encoder(config)\n        self.decoder = Decoder(config)\n\n        self.output_proj = nn.Linear(config.d_model, config.vocab_size, bias=False)\n\n        self.apply(self._init_weights)\n        self._tie_weights()\n\n    def _tie_weights(self):\n        self.output_proj.weight = self.vocab_embedding.embedding.weight\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n\n        elif isinstance(module, nn.Embedding):\n            nn.init.xavier_uniform_(module.weight)\n\n        elif isinstance(module, LayerNorm):\n            nn.init.ones_(module.gamma)\n            nn.init.zeros_(module.beta)\n\n    def forward(\n        self,\n        src_input: torch.Tensor,\n        tgt_input: torch.Tensor,\n        src_pad_mask=None,\n        tgt_pad_mask=None,\n    ) -&gt; torch.Tensor:\n        # Get Src and Tgt embeddings\n        src_embeddings = self.vocab_embedding(src_input) * math.sqrt(\n            self.vocab_embedding.embedding.embedding_dim\n        ) + self.positional_embedding(src_input)\n        tgt_embeddings = self.vocab_embedding(tgt_input) * math.sqrt(\n            self.vocab_embedding.embedding.embedding_dim\n        ) + self.positional_embedding(tgt_input)\n\n        # Feed through Encoder\n        enc_output = self.encoder(src_embeddings, pad_mask=src_pad_mask)\n\n        # Feed through Decoder with Encoder output\n        dec_output = self.decoder(\n            tgt_embeddings,\n            enc_output,\n            src_pad_mask=src_pad_mask,\n            tgt_pad_mask=tgt_pad_mask,\n        )\n\n        logits = self.output_proj(dec_output)\n        return logits",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#others",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#others",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "2.9 Others",
    "text": "2.9 Others\nå½“ç„¶ï¼Œé™¤äº†ä»¥ä¸Šçš„ä¸€ä¸ªéƒ¨åˆ†ï¼ŒTransformerä¸­è¿˜æœ‰å‡ ä¸ªå€¼å¾—ä¸€æçš„éƒ¨åˆ†,æ¯”å¦‚:\n\nDropout Layer: ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ\nLabel Smoothing: ç”¨äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›\n\n\n2.9.1 Dropout Layer\nDropout (Dropout2014srivastava?) æ˜¯ä¸€ç§å¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨é˜²æ­¢ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿‡æ‹Ÿåˆã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºåœ°â€œä¸¢å¼ƒâ€ä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œå³å°†å®ƒä»¬çš„è¾“å‡ºè®¾ç½®ä¸ºé›¶ï¼Œä»è€Œå‡å°‘ç¥ç»å…ƒä¹‹é—´çš„ç›¸äº’ä¾èµ–ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œå±‚çš„è¾“å…¥å‘é‡ \\(\\mathbf{x} \\in \\mathbb{R}^{d}\\)ï¼ŒDropout çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\begin{split}\n\\mathbf{r} & \\sim \\text{Bernoulli}(p) \\\\\n\\hat{\\mathbf{x}} & = \\mathbf{x} \\odot \\mathbf{r} \\\\\n\\mathbf{y} & = \\frac{1}{p} \\hat{\\mathbf{x}}\n\\end{split}\n\\tag{30}\\]\nå…¶ä¸­ï¼Œ\\(\\mathbf{r} \\in \\mathbb{R}^{d}\\) æ˜¯ä¸€ä¸ªä¸è¾“å…¥å‘é‡ \\(\\mathbf{x}\\) å½¢çŠ¶ç›¸åŒçš„äºŒè¿›åˆ¶æ©ç å‘é‡ï¼Œå…¶æ¯ä¸ªå…ƒç´ ç‹¬ç«‹åœ°æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œå–å€¼ä¸º1çš„æ¦‚ç‡ä¸º \\(p\\)ï¼ˆä¿ç•™æ¦‚ç‡ï¼‰ï¼Œå–å€¼ä¸º0çš„æ¦‚ç‡ä¸º \\(1-p\\)ï¼ˆä¸¢å¼ƒæ¦‚ç‡ï¼‰ã€‚\\(\\odot\\) è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•æ“ä½œï¼Œ\\(\\hat{\\mathbf{x}}\\) æ˜¯ç»è¿‡ Dropout å¤„ç†åçš„è¾“å…¥å‘é‡ï¼Œ\\(\\mathbf{y}\\) æ˜¯æœ€ç»ˆçš„è¾“å‡ºå‘é‡ï¼Œé€šè¿‡é™¤ä»¥ä¿ç•™æ¦‚ç‡ \\(p\\) æ¥è¿›è¡Œç¼©æ”¾ï¼Œä»¥ä¿æŒè¾“å‡ºçš„æœŸæœ›å€¼ä¸å˜ã€‚\nç”¨Pythonå®ç°Dropoutå¦‚ä¸‹:\nclass Dropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p = p\n    def forward(self, x):\n        if self.training:\n            mask = (torch.rand_like(x) &lt; self.p).float()\n            return (x * mask) / self.p\n        else:\n            return x\n\n\n2.9.2 Label Smoothing\nLabel Smoothing (RethinkingInception2016szegedy?) æ˜¯ä¸€ç§ç”¨äºåˆ†ç±»ä»»åŠ¡çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯å°†ç›®æ ‡æ ‡ç­¾ä»â€œç¡¬æ ‡ç­¾â€ï¼ˆone-hot encodingï¼‰è½¬æ¢ä¸ºâ€œè½¯æ ‡ç­¾â€ï¼Œå³åœ¨ç›®æ ‡æ ‡ç­¾ä¸­å¼•å…¥ä¸€å®šçš„å¹³æ»‘åº¦ï¼Œä»è€Œé˜²æ­¢æ¨¡å‹è¿‡äºè‡ªä¿¡åœ°é¢„æµ‹æŸä¸ªç±»åˆ«ã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œç±»åˆ«æ€»æ•°ä¸º \\(C\\)ï¼ŒåŸå§‹çš„ç›®æ ‡æ ‡ç­¾ä¸º \\(\\mathbf{y} \\in \\mathbb{R}^{C}\\)ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªå…ƒç´ ä¸º1ï¼Œå…¶ä½™å…ƒç´ ä¸º0ï¼ˆone-hot encodingï¼‰ã€‚Label Smoothing çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹:\n\\[\n\\mathbf{y}_{smooth} = (1 - \\epsilon) \\mathbf{y} + \\frac{\\epsilon}{C}\n\\tag{31}\\]\nå…¶ä¸­ï¼Œ\\(\\epsilon\\) æ˜¯å¹³æ»‘å‚æ•°ï¼Œæ§åˆ¶æ ‡ç­¾çš„å¹³æ»‘ç¨‹åº¦ï¼Œ\\(\\mathbf{y}_{smooth} \\in \\mathbb{R}^{C}\\) æ˜¯ç»è¿‡ Label Smoothing å¤„ç†åçš„ç›®æ ‡æ ‡ç­¾ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#dataset",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#dataset",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.1 Dataset",
    "text": "3.1 Dataset\né¦–å…ˆï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨çš„Ted Talksçš„æ•°æ®é›†ä¸­çš„è‹±æ–‡-ä¸­æ–‡Pairsï¼Œå®ƒåŒ…å«äº†å¤§é‡çš„TEDæ¼”è®²è§†é¢‘çš„å­—å¹•æ–‡æœ¬ï¼Œæ¶µç›–äº†å¤šä¸ªé¢†åŸŸå’Œä¸»é¢˜ã€‚æˆ‘ä»¬çœ‹ä¸€ä¸‹å…¶ä¸­å‡ ä¸ªä¾‹å­ï¼š\n[{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\",\n  'zh': 'éå¸¸è°¢è°¢ï¼Œå…‹é‡Œæ–¯ã€‚çš„ç¡®éå¸¸è£å¹¸ èƒ½æœ‰ç¬¬äºŒæ¬¡ç«™åœ¨è¿™ä¸ªå°ä¸Šçš„æœºä¼šï¼Œæˆ‘çœŸæ˜¯éå¸¸æ„Ÿæ¿€ã€‚'},\n {'en': 'I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.',\n  'zh': 'è¿™ä¸ªä¼šè®®çœŸæ˜¯è®©æˆ‘æ„Ÿåˆ°æƒŠå¹ä¸å·²ï¼Œæˆ‘è¿˜è¦è°¢è°¢ä½ ä»¬ç•™ä¸‹çš„ å…³äºæˆ‘ä¸Šæ¬¡æ¼”è®²çš„ç²¾å½©è¯„è®º'},\n {'en': 'And I say that sincerely, partly because  I need that.  Put yourselves in my position.',\n  'zh': 'æˆ‘æ˜¯éå¸¸çœŸè¯šçš„ï¼Œéƒ¨åˆ†åŸå› æ˜¯å› ä¸º----æˆ‘çš„ç¡®éå¸¸éœ€è¦ï¼ ä½ è®¾èº«å¤„åœ°ä¸ºæˆ‘æƒ³æƒ³ï¼'},\n {'en': 'I flew on Air Force Two for eight years.', 'zh': 'æˆ‘åäº†8å¹´çš„ç©ºå†›äºŒå·ã€‚'},\n {'en': 'Now I have to take off my shoes or boots to get on an airplane!',\n  'zh': 'ä¸è¿‡ç°åœ¨ä¸Šé£æœºå‰æˆ‘åˆ™è¦è„±æ‰æˆ‘çš„é‹å­'}]\nå…¶ä¸­ train_dataset æœ‰231,266æ¡æ•°æ®ï¼Œtest_dataset æœ‰ 8,549 æ¡æ•°æ®ã€‚\n\n3.1.1 Tokenizer & Vocabulary\nåœ¨è®ºæ–‡ä¸­ï¼ŒTarget å’Œ Source ä½¿ç”¨åŒä¸€ä¸ªTokenizerï¼Œå¹¶ä¸”å…±äº«åŒä¸€ä¸ªè¯è¡¨ï¼ˆVocabularyï¼‰ã€‚å¹¶ä¸”ä½¿ç”¨ BPE (Byte Pair Encoding) (Sennrich, Haddow, and Birch 2016) æ¥è¿›è¡Œåˆ†è¯å’Œæ„å»ºè¯è¡¨ã€‚\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç”¨Hugging Faceçš„transformersåº“ä¸­çš„Tokenizeræ¥è¿›è¡Œåˆ†è¯å’Œæ„å»ºè¯è¡¨ï¼Œè¯è¡¨å¤§å°è®¾ç½®ä¸º10,000ã€‚\ndef load_or_train_joint_bpe_tokenizer(\n    vocab_size: int,\n    save_prefix: str,\n    save_name: str = \"bpe_joint.json\",\n    src_corpus_file: str = \"train_src.txt\",\n    tgt_corpus_file: str = \"train_tgt.txt\",\n):\n    save_path = f\"{save_prefix}_{save_name}\"\n\n    if os.path.exists(save_path):\n        print(f\"Loading tokenizer from {save_path}\")\n        return Tokenizer.from_file(save_path)\n\n    # Train ONE tokenizer on BOTH corpora (concatenated dataset)\n    tokenizer = Tokenizer(models.BPE(unk_token=\"&lt;unk&gt;\"))\n    tokenizer.normalizer = NFKC()\n    tokenizer.pre_tokenizer = ByteLevel(add_prefix_space=True)\n    tokenizer.decoder = ByteLevelDecoder()\n\n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[\"&lt;pad&gt;\", \"&lt;unk&gt;\", \"&lt;s&gt;\", \"&lt;/s&gt;\"],\n    )\n\n    tokenizer.train([src_corpus_file, tgt_corpus_file], trainer)\n    tokenizer.save(save_path)\n    print(f\"Saved tokenizer to {save_path}\")\n\n    return tokenizer\nåœ¨è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬æå‰å¤„ç†å¥½æ•°æ®é›†ï¼Œä¿å­˜ä¸ºPTæ ¼å¼ï¼Œæ–¹ä¾¿åç»­çš„è®­ç»ƒä½¿ç”¨ã€‚\ndef encode_file_to_pt(\n    tokenizer,\n    in_path: str,\n    out_path: str,\n    add_special_tokens: bool = True,\n    bos_token: str = \"&lt;s&gt;\",\n    eos_token: str = \"&lt;/s&gt;\",\n    max_lines: int | None = None,\n):\n    if os.path.exists(out_path):\n        print(f\"{out_path} already exists\")\n        return\n\n    bos_id = tokenizer.token_to_id(bos_token)\n    eos_id = tokenizer.token_to_id(eos_token)\n\n    all_ids = []\n    with open(in_path, \"r\", encoding=\"utf-8\") as f:\n        for i, line in enumerate(f):\n            if max_lines is not None and i &gt;= max_lines:\n                break\n            text = line.rstrip(\"\\n\")\n            enc = tokenizer.encode(text)\n            ids = enc.ids\n\n            if add_special_tokens:\n                ids = [bos_id] + ids + [eos_id]\n\n            all_ids.append(torch.tensor(ids, dtype=torch.int32))\n\n    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n    torch.save(all_ids, out_path)\n    print(f\"Saved {len(all_ids)} sequences to {out_path}\")\n\n\nencode_file_to_pt(tokenizer, \"train_src.txt\", \"train_src_ids.pt\")\nencode_file_to_pt(tokenizer, \"train_tgt.txt\", \"train_tgt_ids.pt\")\nencode_file_to_pt(tokenizer, \"test_src.txt\", \"test_src_ids.pt\")\nencode_file_to_pt(tokenizer, \"test_tgt.txt\", \"test_tgt_ids.pt\")\n\n\n3.1.2 Padding Samples\nè‡³æ­¤ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å°±å‡†å¤‡å¥½äº†ã€‚åœ¨åç»­çš„è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åŠ è½½è¿™äº›é¢„å¤„ç†å¥½çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œéœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œæˆ‘ä»¬åœ¨åŠ è½½æ•°æ®é›†æ—¶ï¼Œéœ€è¦å¯¹è¾“å…¥åºåˆ—è¿›è¡ŒPaddingï¼Œä»¥ç¡®ä¿æ¯ä¸ªBatchä¸­çš„åºåˆ—é•¿åº¦ä¸€è‡´ã€‚åœ¨è®ºæ–‡ä¸­æœ‰ä¸€ä¸ªæ–¹å¼ï¼Œå°±æ˜¯å°†é•¿åº¦å·®ä¸å¤šçš„åºåˆ—æ”¾åœ¨åŒä¸€ä¸ªBatchä¸­ï¼Œè¿™æ ·å¯ä»¥å‡å°‘Paddingçš„æ•°é‡ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª Sampler æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚\nclass BucketBatchSampler(Sampler[list[int]]):\n    \"\"\"\n    Yields batches of indices where sequences have similar lengths.\n    length_fn: function(idx) -&gt; int\n    \"\"\"\n\n    def __init__(\n        self,\n        lengths,\n        batch_size: int,\n        bucket_size: int = 2048,\n        shuffle: bool = True,\n        drop_last: bool = False,\n        seed: int = 0,\n    ):\n        self.lengths = list(lengths)\n        self.batch_size = batch_size\n        self.bucket_size = bucket_size\n        self.shuffle = shuffle\n        self.drop_last = drop_last\n        self.seed = seed\n\n    def __iter__(self):\n        rng = random.Random(self.seed)\n\n        indices = list(range(len(self.lengths)))\n        if self.shuffle:\n            rng.shuffle(indices)\n\n        # chunk into buckets\n        for b_start in range(0, len(indices), self.bucket_size):\n            bucket = indices[b_start : b_start + self.bucket_size]\n            # sort inside bucket by length\n            bucket.sort(key=lambda i: self.lengths[i])\n\n            # make batches\n            batches = [bucket[i : i + self.batch_size] for i in range(0, len(bucket), self.batch_size)]\n            if self.drop_last and len(batches) &gt; 0 and len(batches[-1]) &lt; self.batch_size:\n                batches = batches[:-1]\n\n            if self.shuffle:\n                rng.shuffle(batches)\n\n            for batch in batches:\n                yield batch\n\n        # update seed so next epoch reshuffles differently\n        self.seed += 1\n\n    def __len__(self):\n        n = len(self.lengths)\n        if self.drop_last:\n            return n // self.batch_size\n        return math.ceil(n / self.batch_size)\nè¿™ä¸ª BucketBatchSampler ä¼šæ ¹æ®åºåˆ—çš„é•¿åº¦å°†å®ƒä»¬åˆ†é…åˆ°ä¸åŒçš„Bucketä¸­ï¼Œç„¶ååœ¨æ¯ä¸ªBucketå†…æŒ‰é•¿åº¦æ’åºï¼Œæœ€åç”ŸæˆBatchã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æ¯ä¸ªBatchä¸­çš„åºåˆ—é•¿åº¦ç›¸ä¼¼ï¼Œä»è€Œå‡å°‘Paddingçš„æ•°é‡ã€‚\næœ‰äº†ä¸€ä¸ªBatchä¹‹åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ª collate_fn æ¥å¯¹Batchä¸­çš„åºåˆ—è¿›è¡ŒPadding:\n\ndef translation_collate(batch, pad_id: int, sos_id: int, eos_id: int, max_len: int | None = None):\n    src_list = [item[\"src_ids\"] for item in batch]\n    tgt_list = [item[\"tgt_ids\"] for item in batch]\n\n    if max_len is not None:\n        src_list = [x[:max_len] for x in src_list]\n        tgt_list = [x[:max_len] for x in tgt_list]  # leave room for EOS\n\n    decoder_list = [t[:-1] for t in tgt_list]\n    labels_list = [t[1:] for t in tgt_list]\n\n    src_max = max(x.numel() for x in src_list)\n    dec_max = max(x.numel() for x in decoder_list)\n\n    def pad_1d(x: torch.Tensor, L: int):\n        x = x.to(torch.long)\n        if x.numel() == L:\n            return x\n        return torch.cat([x, x.new_full((L - x.numel(),), pad_id, dtype=torch.long)])\n\n    encoder_input_ids = torch.stack([pad_1d(x, src_max) for x in src_list], dim=0)\n    decoder_input_ids = torch.stack([pad_1d(x, dec_max) for x in decoder_list], dim=0)\n    labels = torch.stack([pad_1d(x, dec_max) for x in labels_list], dim=0)\n\n    return {\n        \"encoder_input_ids\": encoder_input_ids,\n        \"decoder_input_ids\": decoder_input_ids,\n        \"labels\": labels,\n        \"encoder_mask\": create_padding_mask(encoder_input_ids, pad_id),\n        \"decoder_mask\": create_padding_mask(decoder_input_ids, pad_id),\n    }\nåœ¨è¿™ä¸ª collate_fn ä¸­ï¼Œæˆ‘ä»¬è¿˜åŒæ—¶æ„é€ äº†Labelsï¼Œ Labelsæ˜¯Decoderè¾“å…¥åºåˆ—å³ç§»ä¸€ä½å¾—åˆ°çš„[t[1:] for t in tgt_list]ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒæ—¶ï¼Œèƒ½å¤Ÿæ­£ç¡®åœ°é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚\nè‡³æ­¤ï¼Œæˆ‘ä»¬çš„æ•°æ®é¢„å¤„ç†å’ŒBatchå‡†å¤‡å·¥ä½œå°±å®Œæˆäº†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹æ¨¡å‹çš„è®­ç»ƒç»†èŠ‚ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#weight-initialization",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#weight-initialization",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.2 Weight Initialization",
    "text": "3.2 Weight Initialization\nåœ¨è®ºæ–‡ä¸­ï¼Œæ²¡æœ‰æåˆ°å¦‚ä½•Initializeçš„ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ç”¨Xavier initialization, æ¥åˆå§‹åŒ–Transformeræ¨¡å‹çš„æƒé‡å‚æ•°ã€‚Xavieråˆå§‹åŒ–æ—¨åœ¨ä¿æŒæ¯å±‚ç¥ç»ç½‘ç»œçš„è¾“å…¥å’Œè¾“å‡ºçš„æ–¹å·®ç›¸ç­‰ï¼Œä»è€Œé¿å…æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œå±‚ï¼Œå…¶è¾“å…¥ç»´åº¦ä¸º \\(n_{in}\\)ï¼Œè¾“å‡ºç»´åº¦ä¸º \\(n_{out}\\)ï¼Œé‚£ä¹ˆXavieråˆå§‹åŒ–çš„æƒé‡çŸ©é˜µ \\(W\\) çš„æ¯ä¸ªå…ƒç´ å¯ä»¥ä»ä»¥ä¸‹å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·:\n\\[\nW_{i,j} \\sim \\mathcal{U}\\left(-\\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}}\\right)\n\\tag{32}\\]\ndef _init_weights(self, module):\n    if isinstance(module, nn.Linear):\n        nn.init.xavier_uniform_(module.weight)\n        if module.bias is not None:\n            nn.init.zeros_(module.bias)\n\n    elif isinstance(module, nn.Embedding):\n        nn.init.xavier_uniform_(module.weight)\nå…·ä½“çš„åŸå› ä¸ºä»€ä¹ˆXavier initializationæœ‰æ•ˆï¼Œåœ¨è¿™é‡Œå°±ä¸å¤šèµ˜è¿°äº†ï¼Œä¹‹åå¯èƒ½ä¼šæœ‰ä¸“é—¨çš„æ–‡ç« æ¥ä»‹ç»è¿™ä¸ªå†…å®¹ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#optimizer",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#optimizer",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.3 Optimizer",
    "text": "3.3 Optimizer\nTransformerçš„è®ºæ–‡ä¸­ï¼Œç”¨çš„æ˜¯Adam Optimizer (Kingma and Ba 2017), å®ƒæ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œç»“åˆäº†åŠ¨é‡æ³•å’ŒRMSPropçš„ä¼˜ç‚¹ã€‚Adamé€šè¿‡è®¡ç®—æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆåŠ¨é‡ï¼‰å’ŒäºŒé˜¶çŸ©ä¼°è®¡ï¼ˆæ¢¯åº¦çš„å¹³æ–¹çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼‰æ¥è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ï¼Œä»è€Œæé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚Adamçš„æ›´æ–°è§„åˆ™å¦‚ä¸‹:\n\n\n\\begin{algorithm} \\caption{Adam with L2 Regularization(Weight Decay)} \\begin{algorithmic} \\Require Parameters $\\theta_0$ \\Require Learning rate $\\alpha$, betas $(\\beta_1,\\beta_2)$ \\Require Weight decay coefficient $\\lambda$ \\State Initialize $m_0 \\gets 0$, $v_0 \\gets 0$, $t \\gets 0$ \\While{not converged} \\State $t \\gets t + 1$ \\State Compute gradient $g_t \\gets \\nabla_{\\theta}\\mathcal{L}(\\theta_{t-1})$ \\State Apply L2 regularization: $g_t^{\\text{wd}} \\gets g_t + \\lambda \\theta_{t-1}$ \\State First moment: $m_t \\gets \\beta_1 m_{t-1} + (1-\\beta_1) g_t^{\\text{wd}}$ \\State Second moment: $v_t \\gets \\beta_2 v_{t-1} + (1-\\beta_2)\\left(g_t^{\\text{wd}}\\right)^2$ \\State Bias-corrected moments: $\\hat m_t \\gets \\dfrac{m_t}{1-\\beta_1^t}$, $\\hat v_t \\gets \\dfrac{v_t}{1-\\beta_2^t}$ \\State Parameter update: $\\theta_t \\gets \\theta_{t-1} - \\alpha \\dfrac{\\hat m_t}{\\sqrt{\\hat v_t} + \\epsilon}$ \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\nç”¨Pythonå®ç°Adam Optimizerå¦‚ä¸‹:\nclass Adam:\n    def __init__(self, params, lr, betas=(0.9, 0.98), weight_decay=0.01, eps=1e-9):\n        self.params = list(params)\n        self.lr = lr\n        self.betas = betas\n        self.weight_decay = weight_decay\n        self.eps = eps\n\n        self.state = {}\n        for p in self.params:\n            self.state[p] = {\n                \"step\": 0,\n                \"m\": torch.zeros_like(p.data),\n                \"v\": torch.zeros_like(p.data),\n            }\n\n    def update_lr(self, new_lr):\n        self.lr = new_lr\n\n    def step(self):\n        for p in self.params:\n            if p.grad is None:\n                continue\n\n            grad = p.grad.data\n            state = self.state[p]\n\n            state[\"step\"] += 1\n            beta1, beta2 = self.betas\n\n            # Update biased first moment estimate\n            state[\"m\"] = beta1 * state[\"m\"] + (1 - beta1) * grad\n            # Update biased second raw moment estimate\n            state[\"v\"] = beta2 * state[\"v\"] + (1 - beta2) * (grad * grad)\n\n            # Compute bias-corrected first moment estimate\n            m_hat = state[\"m\"] / (1 - beta1 ** state[\"step\"])\n            # Compute bias-corrected second raw moment estimate\n            v_hat = state[\"v\"] / (1 - beta2 ** state[\"step\"])\n\n            # Update parameters\n            p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n\n            # Apply weight decay\n            if self.weight_decay &gt; 0:\n                p.data -= self.lr * self.weight_decay * p.data\n\n    def zero_grad(self):\n        for p in self.params:\n            if p.grad is not None:\n                p.grad.detach_()\n                p.grad.zero_()\n\n\nNOTE: Adam Optimizer\n\n\nå¯¹äºä¸äº†çš„Adamçš„åŒå­¦ï¼Œä¹Ÿä¸ç”¨å¤ªæ‹…å¿ƒï¼Œä¹‹åæˆ‘ä»¬ä¼šæœ‰ä¸€ç³»åˆ—çš„æ–‡ç« ï¼Œä¸“é—¨ä»‹ç»è¿™äº›ä¼˜åŒ–å™¨çš„ï¼ŒåŒ…æ‹¬Adam(Kingma and Ba 2017)ï¼ŒAdamW(Loshchilov and Hutter 2019)ï¼Œä»¥åŠæœ€è¿‘æ¯”è¾ƒç«çš„Muon(Jordan et al. 2024)ç­‰ã€‚\n\n\n\n3.3.1 Learning Rate Scheduler\nåœ¨Transformerçš„è®ºæ–‡ä¸­ï¼Œä½œè€…åˆ©ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆLearning Rate Schedulerï¼‰ï¼Œå®ƒåœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µé€æ¸å¢åŠ å­¦ä¹ ç‡ï¼Œç„¶ååœ¨è¾¾åˆ°é¢„è®¾çš„æ­¥æ•°åé€æ¸å‡å°å­¦ä¹ ç‡ã€‚å…·ä½“æ¥è¯´ï¼Œå­¦ä¹ ç‡çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:\n\\[\n\\text{lrate} = d_{model}^{-0.5} \\cdot \\min\\left(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5}\\right)\n\\tag{33}\\]\nå…¶ä¸­ï¼Œ\\(d_{model}\\) æ˜¯æ¨¡å‹çš„éšè—å±‚ç»´åº¦ï¼Œ\\(step\\_num\\) æ˜¯å½“å‰çš„è®­ç»ƒæ­¥æ•°ï¼Œ\\(warmup\\_steps\\) æ˜¯é¢„è®¾çš„é¢„çƒ­æ­¥æ•°ã€‚åœ¨è®­ç»ƒçš„å‰ \\(warmup\\_steps\\) æ­¥ä¸­ï¼Œå­¦ä¹ ç‡çº¿æ€§å¢åŠ ï¼›åœ¨ä¹‹åçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå­¦ä¹ ç‡æŒ‰ç…§ \\(step\\_num^{-0.5}\\) çš„æ¯”ä¾‹é€æ¸å‡å°ã€‚\n\n\n\n\n\n\nFigureÂ 9: Visualization of Learning Rate Scheduler\n\n\n\ndef get_lr(cur_step, warmup_steps, d_model):\n    lrate = (d_model**-0.5) * min(cur_step**-0.5, cur_step * (warmup_steps**-1.5))\n    return lrate",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#loss-function",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#loss-function",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.4 Loss Function",
    "text": "3.4 Loss Function\nåœ¨Transformeræ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆCross Entropy Lossï¼‰ä½œä¸ºä¸»è¦çš„æŸå¤±å‡½æ•°ã€‚äº¤å‰ç†µæŸå¤±å‡½æ•°ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®æ ‡ç­¾åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œå…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªåŒ…å« \\(N\\) ä¸ªæ ·æœ¬çš„è®­ç»ƒé›†ï¼Œæ¯ä¸ªæ ·æœ¬çš„çœŸå®æ ‡ç­¾ä¸º \\(y_i\\)ï¼Œæ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸º \\(\\hat{y}_i\\)ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:\n\\[\n\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})\n\\tag{34}\\]\nå…¶ä¸­ï¼Œ\\(C\\) æ˜¯ç±»åˆ«çš„æ€»æ•°ï¼Œ\\(y_{i,c}\\) æ˜¯æ ·æœ¬ \\(i\\) åœ¨ç±»åˆ« \\(c\\) ä¸Šçš„çœŸå®æ ‡ç­¾ï¼ˆone-hot encodingï¼‰ï¼Œ\\(\\hat{y}_{i,c}\\) æ˜¯æ¨¡å‹å¯¹æ ·æœ¬ \\(i\\) åœ¨ç±»åˆ« \\(c\\) ä¸Šçš„é¢„æµ‹æ¦‚ç‡ã€‚\nç»“åˆLabel Smoothing EquationÂ 31, äº¤å‰ç†µæŸå¤±å‡½æ•°çš„è®¡ç®—å…¬å¼å¯ä»¥è°ƒæ•´ä¸º:\n\\[\n\\mathcal{L}_{smooth} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c}^{smooth} \\log(\\hat{y}_{i,c})\n\\tag{35}\\] å…¶ä¸­ï¼Œ\\(y_{i,c}^{smooth}\\) æ˜¯ç»è¿‡Label Smoothingå¤„ç†åçš„ç›®æ ‡æ ‡ç­¾ã€‚\ndef cross_entropy_loss(logits, labels, ignore_index=0, label_smoothing=0.0):\n    # Create mask for ignore_index\n    mask = labels != ignore_index\n    num_classes = logits.size(-1)\n\n    if label_smoothing &gt; 0.0:\n        smooth_labels = F.one_hot(labels, num_classes).float()\n        smooth_labels = smooth_labels * (1 - label_smoothing) + label_smoothing / num_classes\n    else:\n        smooth_labels = F.one_hot(labels, num_classes).float()\n\n    log_probs = F.log_softmax(logits, dim=-1)\n    loss = -torch.sum(smooth_labels * log_probs, dim=-1)\n    loss = loss * mask.float()\n    loss = loss.sum() / mask.sum()\n\n    return loss",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#evaluation-metric",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#evaluation-metric",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.5 Evaluation Metric",
    "text": "3.5 Evaluation Metric\n\n3.5.1 BLUE\nåœ¨è¯„ä¼°Transformeræ¨¡å‹çš„æ€§èƒ½æ—¶ï¼Œé€šå¸¸ä½¿ç”¨BLEUï¼ˆBilingual Evaluation Understudyï¼‰åˆ†æ•°ä½œä¸ºä¸»è¦çš„è¯„ä»·æŒ‡æ ‡ã€‚BLEUåˆ†æ•°æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°æœºå™¨ç¿»è¯‘è´¨é‡çš„è‡ªåŠ¨åŒ–æŒ‡æ ‡ï¼Œé€šè¿‡æ¯”è¾ƒæœºå™¨ç”Ÿæˆçš„ç¿»è¯‘ä¸ä¸€ä¸ªæˆ–å¤šä¸ªå‚è€ƒç¿»è¯‘ä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥è¡¡é‡ç¿»è¯‘çš„å‡†ç¡®æ€§ã€‚BLEUåˆ†æ•°çš„è®¡ç®—è¿‡ç¨‹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤:\n\nN-gramåŒ¹é…: è®¡ç®—æœºå™¨ç¿»è¯‘è¾“å‡ºä¸å‚è€ƒç¿»è¯‘ä¹‹é—´çš„n-gramåŒ¹é…æ•°é‡ï¼Œé€šå¸¸è€ƒè™‘1-gramåˆ°4-gramã€‚\nç²¾ç¡®ç‡è®¡ç®—: å¯¹æ¯ä¸ªn-gramï¼Œè®¡ç®—åŒ¹é…çš„n-gramæ•°é‡ä¸æœºå™¨ç¿»è¯‘è¾“å‡ºä¸­n-gramæ€»æ•°çš„æ¯”å€¼ï¼Œå¾—åˆ°ç²¾ç¡®ç‡ã€‚\nå‡ ä½•å¹³å‡: å°†å„ä¸ªn-gramçš„ç²¾ç¡®ç‡è¿›è¡Œå‡ ä½•å¹³å‡ï¼Œä»¥ç»¼åˆè€ƒè™‘ä¸åŒé•¿åº¦çš„n-gramåŒ¹é…æƒ…å†µã€‚\né•¿åº¦æƒ©ç½š: ä¸ºäº†é˜²æ­¢æœºå™¨ç¿»è¯‘è¾“å‡ºè¿‡çŸ­ï¼ŒBLEUåˆ†æ•°å¼•å…¥äº†é•¿åº¦æƒ©ç½šé¡¹ï¼Œæ ¹æ®æœºå™¨ç¿»è¯‘è¾“å‡ºçš„é•¿åº¦ä¸å‚è€ƒç¿»è¯‘çš„é•¿åº¦è¿›è¡Œè°ƒæ•´ã€‚\næœ€ç»ˆè®¡ç®—: å°†å‡ ä½•å¹³å‡çš„ç²¾ç¡®ç‡ä¸é•¿åº¦æƒ©ç½šç›¸ä¹˜ï¼Œå¾—åˆ°æœ€ç»ˆçš„BLEUåˆ†æ•°ï¼ŒèŒƒå›´åœ¨0åˆ°1ä¹‹é—´ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºç™¾åˆ†æ¯”å½¢å¼ã€‚\n\nè®¡ç®—BLEUåˆ†æ•°çš„å…¬å¼å¦‚ä¸‹: \\[\n\\text{BLEU} = \\text{BP} \\cdot \\exp\\left(\\sum_{n=1}^{N} w_n \\log p_n\\right)\n\\tag{36}\\]\nå…¶ä¸­ï¼Œ\\(\\text{BP}\\) æ˜¯é•¿åº¦æƒ©ç½šé¡¹ï¼Œ\\(p_n\\) æ˜¯n-gramçš„ç²¾ç¡®ç‡ï¼Œ\\(w_n\\) æ˜¯n-gramçš„æƒé‡ï¼Œé€šå¸¸å‡åŒ€åˆ†é…ã€‚\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\ndef compute_bleu(reference, candidate):\n    reference_tokens = [reference.split()]\n    candidate_tokens = candidate.split()\n    smoothing_function = SmoothingFunction().method1\n    bleu_score = sentence_bleu(reference_tokens, candidate_tokens,\n                               weights=(0.25, 0.25, 0.25, 0.25),\n                               smoothing_function=smoothing_function)\n    return bleu_score * 100  # Convert to percentage\n\n\n3.5.2 Perplexity\nå›°æƒ‘åº¦ï¼ˆPerplexityï¼‰æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹æ€§èƒ½çš„å¸¸ç”¨æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡æ¨¡å‹å¯¹ç»™å®šæ–‡æœ¬åºåˆ—çš„é¢„æµ‹èƒ½åŠ›ã€‚å›°æƒ‘åº¦çš„å®šä¹‰æ˜¯è¯­è¨€æ¨¡å‹å¯¹æµ‹è¯•é›†ä¸Šæ¯ä¸ªè¯çš„å¹³å‡ä¸ç¡®å®šæ€§ï¼Œæ•°å€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹å¯¹æ–‡æœ¬çš„é¢„æµ‹è¶Šå‡†ç¡®ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªæµ‹è¯•é›† \\(W = w_1, w_2, \\ldots, w_N\\)ï¼Œè¯­è¨€æ¨¡å‹è®¡ç®—è¯¥åºåˆ—çš„æ¦‚ç‡ \\(P(W)\\)ï¼Œå›°æƒ‘åº¦çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:\n\\[\n\\text{Perplexity}(W) = P(W)^{-\\frac{1}{N}} = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i | w_1, w_2, \\ldots, w_{i-1})\\right)\n\\tag{37}\\]\nå…¶ä¸­ï¼Œ\\(N\\) æ˜¯æµ‹è¯•é›†ä¸­çš„è¯æ•°ï¼Œ\\(P(w_i | w_1, w_2, \\ldots, w_{i-1})\\) æ˜¯è¯­è¨€æ¨¡å‹é¢„æµ‹ç¬¬ \\(i\\) ä¸ªè¯çš„æ¡ä»¶æ¦‚ç‡ã€‚å›°æƒ‘åº¦å¯ä»¥ç†è§£ä¸ºæ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ—¶é¢ä¸´çš„é€‰æ‹©æ•°é‡çš„æŒ‡æ•°çº§å¢é•¿ã€‚\nåœ¨å®é™…è®¡ç®—ä¸­ï¼Œå›°æƒ‘åº¦é€šå¸¸é€šè¿‡äº¤å‰ç†µæŸå¤±æ¥é—´æ¥è®¡ç®—: \\[\n\\text{Perplexity}(W) = \\exp(\\text{CrossEntropyLoss})\n\\tag{38}\\]\nåœ¨ä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰æåˆ°Label Smoothing, å®ƒä¼šå½±å“å›°æƒ‘åº¦çš„è®¡ç®—ï¼Œå› ä¸ºLabel Smoothingä¼šæ”¹å˜ç›®æ ‡åˆ†å¸ƒï¼Œä»è€Œå½±å“äº¤å‰ç†µæŸå¤±çš„è®¡ç®—ï¼Œè¿›è€Œå½±å“å›°æƒ‘åº¦çš„æ•°å€¼ã€‚å› æ­¤ï¼Œåœ¨ä½¿ç”¨Label Smoothingæ—¶ï¼Œå›°æƒ‘åº¦çš„æ•°å€¼å¯èƒ½ä¼šæœ‰æ‰€åå·®ï¼Œéœ€è¦è°¨æ…è§£é‡Šã€‚\n\n\n\n\n\n\nFigureÂ 10: ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œéšç€ \\(\\epsilon\\) çš„å¢åŠ ï¼ŒPerplexity ä¹Ÿåœ¨å¢åŠ ã€‚è¿™æ˜¯å› ä¸º Label Smoothing å¼•å…¥äº†å™ªå£°ï¼Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´éš¾ä»¥å‡†ç¡®é¢„æµ‹ç›®æ ‡è¯ï¼Œä»è€Œå¯¼è‡´äº¤å‰ç†µæŸå¤±å¢åŠ ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#training",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#training",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.6 Training",
    "text": "3.6 Training\nåœ¨è®­ç»ƒTransformeræ¨¡å‹ï¼Œæˆ‘ä»¬è®¾ç½®äº†ä»¥ä¸‹è¶…å‚æ•°:\n@dataclass\nclass ModelConfig:\n    vocab_size: int = VOCAB_SIZE\n    max_seq_len: int = 128\n\n    d_model: int = 512\n    d_ff: int = 2048\n    num_heads: int = 8\n    num_layers: int = 6\n    dropout: float = 0.1\n\n@dataclass\nclass TrainConfig:\n    batch_size: int = 256\n    gradient_steps: int = 8\n    total_steps: int = 10_000  # set to 0 for automatic calculation\n    warmup_steps: int = 1000  # will be set by total_steps // 10\n\n    lr: float = 5e-3\n    min_lr: float = 1e-5\n    betas: tuple[float, float] = field(default_factory=lambda: (0.9, 0.98))\n    weight_decay: float = 0.01\n    optim_eps: float = 1e-9\n\n    label_smoothing: float = 0.1\n\n    debug: bool = False\n    device = get_device()\n    mixed_precision: bool = True\n    eval_steps: int = 100\nåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†Mixed Precision Trainingæ¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹å¹¶å‡å°‘æ˜¾å­˜å ç”¨ã€‚æ··åˆç²¾åº¦è®­ç»ƒé€šè¿‡åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ä½¿ç”¨16ä½æµ®ç‚¹æ•°ï¼ˆFP16ï¼‰å’Œ32ä½æµ®ç‚¹æ•°ï¼ˆFP32ï¼‰çš„ç»„åˆï¼Œæ—¢ä¿æŒäº†æ¨¡å‹çš„ç²¾åº¦ï¼Œåˆæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚å…·ä½“æ¥è¯´ï¼Œæ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä¸»è¦ä½¿ç”¨FP16è¿›è¡Œè®¡ç®—ï¼Œè€Œå…³é”®çš„å‚æ•°æ›´æ–°å’Œæ¢¯åº¦ç´¯ç§¯åˆ™ä½¿ç”¨FP32ï¼Œä»¥ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ã€‚\nåŒæ—¶ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨äº†Gradient AccumulationæŠ€æœ¯ï¼Œä»¥ä¾¿åœ¨æ˜¾å­˜æœ‰é™çš„æƒ…å†µä¸‹ä½¿ç”¨è¾ƒå¤§çš„æœ‰æ•ˆæ‰¹é‡å¤§å°è¿›è¡Œè®­ç»ƒã€‚æ¢¯åº¦ç´¯ç§¯çš„åŸºæœ¬æ€æƒ³æ˜¯å°†å¤šä¸ªå°æ‰¹é‡çš„æ¢¯åº¦ç´¯ç§¯èµ·æ¥ï¼Œç„¶åå†è¿›è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°ã€‚å…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ä¸€ä¸ªè¾ƒå¤§çš„æ‰¹é‡å¤§å° \\(B\\) è¿›è¡Œè®­ç»ƒï¼Œä½†ç”±äºæ˜¾å­˜é™åˆ¶ï¼Œæˆ‘ä»¬åªèƒ½ä½¿ç”¨ä¸€ä¸ªè¾ƒå°çš„æ‰¹é‡å¤§å° \\(b\\)ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°† \\(B/b\\) ä¸ªå°æ‰¹é‡çš„æ¢¯åº¦ç´¯ç§¯èµ·æ¥ï¼Œç„¶åå†è¿›è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°ã€‚\nç®€å•æ¥çœ‹ï¼Œæˆ‘ä»¬çš„è®­ç»ƒå¾ªç¯å¦‚ä¸‹:\nfor batch in dataloader:\n    optimizer.zero_grad()\n    for micro_step in range(gradient_steps):\n        with torch.autocast(\n            device_type=train_config.device.type, enabled=train_config.mixed_precision, dtype=torch.bfloat16\n        ):\n            logits = model(**batch)\n            loss = cross_entropy_loss(\n                logits,\n                labels,\n                ignore_index=translation_dataset.pad_id,\n                label_smoothing=train_config.label_smoothing,\n            )\n            loss /= train_config.gradient_steps\n        loss.backward()\n    \n    optimizer.update_lr()\n    optimizer.step()\n\n\nNOTE: OOM Error\n\n\nå¦‚æœå¤§å®¶åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œé‡åˆ°äº†OOM Errorï¼Œæˆ‘ä»¬å¯ä»¥è°ƒå°æˆ‘ä»¬çš„Batch Sizeï¼ŒåŒæ—¶å¢å¤§æˆ‘ä»¬çš„Gradient Stepsï¼Œè¿™æ ·å¯ä»¥ä¿æŒæœ€ç»ˆçš„Batch Sizeä¸å˜ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/01-transformer/Transformer.html#results",
    "href": "posts/100-AI-Papers/01-transformer/Transformer.html#results",
    "title": "01: Attention is All You Need (Transformer)",
    "section": "3.7 Results",
    "text": "3.7 Results\n\n\n\n\n\n\nFigureÂ 11: The Loss Curve of Transformer training for 10,000 steps\n\n\n\næœ‰ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡å°±æ˜¯ï¼ŒLossçš„ä¸‹é™å‘ˆç° zig-zag patternï¼Œè¿™ä¸ªç°è±¡åœ¨å¾ˆå¤šNLPæ¨¡å‹çš„è®­ç»ƒä¸­éƒ½ä¼šå‡ºç°ï¼Œä½†æ˜¯æˆ‘è¿˜æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªå¾ˆå¥½çš„è§£é‡Šï¼Œå¯èƒ½æ˜¯Learning Rate è°ƒèŠ‚çš„åŸå› ï¼Œä¹Ÿå¯èƒ½æ˜¯Dataloaderçš„é—®é¢˜ï¼Œæœ‰æ—¶é—´æˆ‘å°±æ¢ç´¢è¿™ä¸ªé—®é¢˜çš„ã€‚æ¬¢è¿å¤§å®¶åœ¨è¯„è®ºåŒºç•™è¨€è®¨è®ºï¼\nä¸‹é¢æ˜¯è®­ç»ƒå®Œ10,000æ­¥åä¸€ä¸ªç¿»è¯‘çš„ä¾‹å­:\nEnglish Input: Several years ago here at TED, Peter Skillman  introduced a design challenge  called the marshmallow\nchallenge.\nModel Output: &lt;s&gt; å‡ å¹´å‰,åœ¨TED, Peter Skillmanä»‹ç»äº†ä¸€ä¸ªè®¾è®¡æŒ‘æˆ˜  å«åšæ¨é¥¼å¹²çš„æŒ‘æˆ˜-- &lt;/s&gt;\nReference: å‡ å¹´å‰ï¼Œåœ¨è¿™é‡Œçš„ TED ä¸Šï¼ŒPeter Skillman æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œæ£‰èŠ±ç³–æŒ‘æˆ˜â€çš„è®¾è®¡æŒ‘æˆ˜ã€‚\nä¸€äº›ç®€å•çš„ä¾‹å­\nEnglish Input: Who are you?\nModel Output: &lt;s&gt; ä½ æ˜¯è°?&lt;/s&gt;\nEnglish Input: What is your name?\nModel Output: &lt;s&gt; ä½ å«ä»€ä¹ˆ?&lt;/s&gt;\nEnglish Input: I love Artificial Intelligence.\nModel Output: &lt;s&gt; æˆ‘å–œæ¬¢é­…åŠ›ã€‚&lt;/s&gt;\nå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å·²ç»èƒ½å¤Ÿè¿›è¡Œç®€å•çš„è‹±æ–‡åˆ°ä¸­æ–‡çš„ç¿»è¯‘äº†ï¼Œå½“ç„¶è·ç¦»å®é™…åº”ç”¨è¿˜æœ‰å¾ˆå¤§çš„å·®è·ï¼Œæ¯”å¦‚ç¿»è¯‘çš„æµç•…åº¦å’Œå‡†ç¡®åº¦è¿˜éœ€è¦æå‡ï¼Œæ¨¡å‹çš„è§„æ¨¡ä¹Ÿéœ€è¦æ›´å¤§ï¼Œè®­ç»ƒçš„æ•°æ®ä¹Ÿéœ€è¦æ›´å¤šç­‰ç­‰ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "001: Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/06-clip/CLIP.html",
    "href": "posts/100-AI-Papers/06-clip/CLIP.html",
    "title": "06: Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
    "section": "",
    "text": "1 Preliminary\n\n\n2 CLIP\n\n\n3 Summary\n\n\n4 Key Concepts\n\n\n5 Q & A\n\n\n6 Related resource & Further Reading\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/100-AI-Papers/16-dit/DiT.html",
    "href": "posts/100-AI-Papers/16-dit/DiT.html",
    "title": "16: Scalable Diffusion Models with Transformers (DiT)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/16-dit/DiT.html#experiment",
    "href": "posts/100-AI-Papers/16-dit/DiT.html#experiment",
    "title": "16: Scalable Diffusion Models with Transformers (DiT)",
    "section": "3.1 Experiment",
    "text": "3.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "",
    "text": "åœ¨é˜…è¯»æœ¬ç« ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆäº†è§£ä¸€ä¸‹ä»€ä¹ˆæ˜¯Transformer(Vaswani et al. 2023)ã€‚ å¦‚æœæœ‰ä¸ç†Ÿæ‚‰çš„åŒå­¦ï¼Œæ¬¢è¿é˜…è¯»æˆ‘ä»¬ 100 Paper with Code ç³»åˆ—çš„ç¬¬ä¸€ç¯‡:01: Attention is all you need (Transformer)ï¼Œæˆ‘ä»¬åœ¨é‚£ç¯‡æ–‡ç« ä¸­ï¼Œè¯¦ç»†çš„ä»‹ç»äº†Transformerçš„æ¶æ„ä»¥åŠå·¥ä½œæµç¨‹ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#patch-embedding",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#patch-embedding",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.1 Patch Embedding",
    "text": "2.1 Patch Embedding\nåœ¨Transformerè¿™ä¸€ç¯‡ï¼Œæˆ‘ä»¬äº†è§£åˆ°ï¼Œå®ƒæ˜¯ä½œç”¨äºSequence Modelingçš„, textå°±æ˜¯å¾ˆè‡ªç„¶çš„Sequence Modelï¼Œå¾ˆæ˜¾ç„¶ï¼ŒImageä¸æ˜¯ Sequenceçš„, å®ƒæœ‰é•¿(\\(H\\))å’Œå®½(\\(W\\))ã€‚å¾ˆç›´è§‚çš„ç¬¬ä¸€ç§æƒ³æ³•å°±æ˜¯ï¼Œå°†å›¾ç‰‡ç›´æ¥å±•å¼€ï¼Œä»äºŒç»´ \\((3, H, W)\\) å±•å¼€æˆä¸€ç»´çš„ \\((3 \\times H \\times W)\\). è¿™æ ·æˆ‘ä»¬å°±å¾—åˆ°çš„å›¾ç‰‡çš„ Sequence Modelã€‚å¦‚ä¸‹å›¾ FigureÂ 2 æ‰€ç¤º\n\n\n\n\n\n\nFigureÂ 2: Illustration of flattening an image into a sequence (Image Source: iGPT)\n\n\n\nè¿™ç§æ–¹æ³•æœ‰ä¸€ç§æ˜æ˜¾çš„é—®é¢˜å°±æ˜¯:Sequenceçš„é•¿åº¦å¤ªé•¿ã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œå¯¹äº \\(3\\times 256 \\times 256\\) çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬æœ‰ \\(256 \\times 256 = 65,336\\) ä¸ªtokensï¼Œé€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæ‰€éœ€è¦çš„è®­ç»ƒæ—¶é•¿å¾ˆé•¿ (åœ¨Transformer è¿™ä¸€èŠ‚ï¼Œæˆ‘ä»¬äº†è§£è¿‡ï¼ŒAttentionçš„æ—¶é—´å¤æ‚åº¦æ˜¯ \\(\\mathcal{O}(n^{2}d)\\))ã€‚\nå¦ä¸€ä¸ªé—®é¢˜æ˜¯:å®ƒæ²¡æœ‰ç”¨åˆ°å›¾ç‰‡çš„ç‰¹æ€§: ç›¸é‚»çš„pixel ä¹‹é—´ï¼Œæ˜¯æœ‰å¾ˆé«˜çš„correlationã€‚\næ‰€ä»¥æˆ‘ä»¬å¾ˆè‡ªç„¶çš„æƒ³åˆ°:å¦‚æœæŠŠç›¸é‚»çš„pixelså’Œåœ¨ä¸€ç»„ï¼Œç»„æˆä¸€ä¸ªpatchï¼Œè¿™æ ·ä¸å°±æ—¢å‡å°‘äº†tokensçš„æ•°é‡ï¼Œåˆç”¨åˆ°äº†pixelä¹‹é—´çš„correlationã€‚è¿™å°±æ˜¯Vision Transformerçš„Patch Embeddingã€‚\n\nThe standard Transformer receives as input a 1D sequence of token embeddings. To handle 2D images, we reshape the image \\(x \\in \\mathbb{R}^{H \\times W \\times C}\\) into a sequence of flattened 2D patches\\(x \\in \\mathbb{R}^{N \\times (P^{2} \\times C)}\\), where (\\(H, W\\)) is the resolution of the original image, \\(C\\) is the number of channels, (\\(P, P\\)) is the resolution of each image patch, and \\(N = HW/P^{2}\\) is the resulting number of patches, which also serves as the effective input sequence length for the Transformer. The Transformer uses constant latent vector size \\(D\\) through all of its layers, so we flatten the patches and map to \\(D\\) dimensions with a trainable linear projection. We refer to the output of this projection as the patch embeddings.  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.3 \n\næœ‰äº†Patchä¹‹åï¼Œæˆ‘ä»¬å°±å°†å›¾ç‰‡ä» \\((H, W, C)\\) å˜æˆäº† \\((N, P, P, C)\\)ï¼Œ å…¶ä¸­ \\(N = \\frac{H \\times W}{P^{2}}\\)ã€‚ æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç æ€ä¹ˆå®ç°:\n# Load Image and resize it to certain size\nimage_path = IMAGE_PATH\nimg_bgr = cv2.imread(image_path)\nimg_resized = cv2.resize(img_bgr, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)\nimg = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB) \n\n# Patchify \npatches = einops.rearrange( \n     img, \"(h ph) (w pw) c -&gt; (h w) ph pw c\", ph=PATCH_SIZE, pw=PATCH_SIZE \n) \né€šè¿‡è¿™ä¸ªPatchifyä¹‹åï¼Œæˆ‘ä»¬å°†å›¾ç‰‡åˆ†æˆäº† \\(\\left( \\frac{H}{P} \\times \\frac{W}{P}, P, P, C \\right)\\) ä¸ªPatches\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 3: Illustration of Patchify\n\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªPatch å±•å¼€æˆä¸€ä¸ªå‘é‡ï¼Œå˜æˆ \\((N, P^{2} \\times C)\\)ï¼Œç„¶åä¼ å…¥ä¸€ä¸ªLinear Layerï¼Œå°†å…¶æ˜ å°„åˆ°ä¸€ä¸ªéšè—ç©ºé—´ï¼Œå˜æˆ \\((N, d_{model})\\)ã€‚ è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†Transformerå¯ä»¥æ¥å—çš„è¾“å…¥ã€‚\nflat_patch = einops.rearrange( patches, \"n ph pw c -&gt; n (ph pw c)\") \n\nmlp = nn.Linear(PATCH_SIZE * PATCH_SIZE * 3, d_model)\npatch_embedding = mlp(flat_patch)\né€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†Transformerå¯ä»¥æ¥å—çš„ä»»æ„é•¿åº¦çš„è¾“å…¥ã€‚ä¸è¿‡åœ¨å®é™…æ“ä½œä¸­ï¼Œæˆ‘ä»¬å¹¶ä¸ä¼šç”¨ä»¥ä¸Šçš„æ–¹å¼ï¼Œè€Œæ˜¯ç”¨ä¸€ä¸ªå·ç§¯å±‚æ¥å®ç°è¿™ä¸ªPatch Embeddingçš„è¿‡ç¨‹ã€‚åŸå› æœ‰äºŒ:\n\næ•ˆç‡æ›´é«˜: å°†Patchify + Flatten + Linear åˆæˆä¸€ä¸ªå·ç§¯å±‚ï¼Œå¯ä»¥å‡å°‘ä¸­é—´çš„å†…å­˜è¯»å†™ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚\nä»£ç æ›´ç®€æ´: ç”¨ä¸€ä¸ªå·ç§¯å±‚å°±å¯ä»¥å®ç°æ‰€æœ‰çš„åŠŸèƒ½ï¼Œä»£ç é‡æ›´å°‘ï¼Œæ›´æ˜“è¯»æ‡‚ã€‚\n\nå¦‚æœæˆ‘ä»¬ç”¨ä¸€ä¸ª å·ç§¯å±‚ï¼Œå‚æ•°è®¾ç½®ä¸º:\n\nkernel_size = PATCH_SIZE ï¼ˆå·ç§¯æ ¸è¦†ç›–ä¸€ä¸ª patchï¼‰\nstride = PATCH_SIZE ï¼ˆä¸é‡å åœ°ç§»åŠ¨ï¼Œç›¸å½“äºåˆ‡ patchï¼‰\nin_channels = 3ï¼ˆRGB å›¾ç‰‡çš„é€šé“æ•°ï¼‰\nout_channels = d_model\n\né‚£ä¹ˆå·ç§¯ä¼š:\n\næŠŠè¾“å…¥å›¾ç‰‡åˆ†æˆ PATCH_SIZE x PATCH_SIZE çš„ä¸é‡å å—ï¼ˆå› ä¸º stride = kernel_sizeï¼‰ã€‚\nå¯¹æ¯ä¸ª patch åšä¸€æ¬¡çº¿æ€§æ˜ å°„ï¼ˆå› ä¸ºå·ç§¯æœ¬è´¨ä¸Šå°±æ˜¯å¯¹å±€éƒ¨åŒºåŸŸåšåŠ æƒæ±‚å’Œï¼Œç›¸å½“äº Linearï¼‰ã€‚\nè¾“å‡ºçš„ shape è‡ªåŠ¨å°±æ˜¯ (batch, num_patches, d_model)ã€‚\n\nè¿™æ­£å¥½ç­‰ä»·äº åˆ‡ patch + flatten + Linear çš„ç»„åˆ.\nä»£ç å¦‚ä¸‹:\nclass PatchEmbedder(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n        self.config = config\n        self.num_patches_per_side = config.image_size // config.patch_size\n        self.num_patches = self.num_patches_per_side**2\n\n        self.proj = nn.Conv2d( \n            in_channels=config.num_channels, \n            out_channels=config.d_model, \n            kernel_size=config.patch_size, \n            stride=config.patch_size, \n        ) \n\n    def forward(self, x: torch.Tensor):\n        # x: (B, C, H, W)\n        x = self.proj(x)  # (B, D, H/P, W/P)\n        x = x.flatten(2)  # (B, D, N)\n        x = x.transpose(1, 2)  # (B, N, D)\n        return x\nç”¨å·ç§¯çš„å¥½å¤„ï¼Œé™¤äº†å¯ä»¥æ›´é«˜æ•ˆçš„å®ç°Patch Embeddingï¼Œä»£ç æ›´åŠ ç®€æ´ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æ”¹å˜ stride æ¥ä½¿ä¸€äº›Patch Overlappingï¼Œè·å¾—ä¸€ä¸ªå¤šå°ºåº¦çš„ç»“æ„ã€‚ï¼ˆå°½ç®¡è¿™ä¸ªåœ¨ViTä¸­æ²¡æœ‰æåˆ°ï¼Œä½†æ˜¯æˆ‘è§‰å¾—æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼‰\n\n\nNOTE: å…³äºPatch Embedding\n\n\nå¯ä»¥è¡¥ä¸€å¥ç‚¹æ˜:â€œViT åŸç‰ˆç”¨ non-overlap patchï¼Œåç»­å¾ˆå¤šå·¥ä½œä¼šç”¨ overlap/conv stem æ¥è¡¥ inductive biasâ€ã€‚ æˆ‘ä»¬ä¹‹åä¼šäº†è§£è¿™ä¸€ç±»å˜ä½“ã€‚\n\n\næˆ‘ä»¬è®¡ç®—ä¸€ä¸‹ï¼Œé€šè¿‡è¿™ç§æ–¹æ³•ï¼Œå¯ä»¥å‡å°‘å¤šå°‘Tokensçš„æ•°é‡:\n\\[\n\\text{Number of Tokens} = \\frac{H \\times W}{P^{2}}\n\\tag{1}\\]\n\n\n\n\n\n\n\n\n\n\n\nMethod\nNumber of Tokens\nAttention Complexity\n\n\n\n\nFlatten Image\n\\(224 \\times 224 = 50,176\\)\n\\(\\mathcal{O}(n^{2}d) = \\mathcal{O}(50,176^{2}d)\\)\n\n\nPatchify (\\(P=8\\))\n\\(\\frac{224 \\times 224}{8^{2}} = 784\\)\n\\(\\mathcal{O}(n^{2}d) = \\mathcal{O}(784^{2}d)\\)\n\n\nPatchify (\\(P=16\\))\n\\(\\frac{224 \\times 224}{16^{2}} = 196\\)\n\\(\\mathcal{O}(n^{2}d) = \\mathcal{O}(196^{2}d)\\)\n\n\nPatchify (\\(P=32\\))\n\\(\\frac{224 \\times 224}{32^{2}} = 49\\)\n\\(\\mathcal{O}(n^{2}d) = \\mathcal{O}(49^{2}d)\\)\n\n\n\n\n\nTableÂ 1: æ¯”è¾ƒä¸åŒè·å¾—Visual Tokençš„æ–¹æ³•, ä»¥ \\(224 \\times 224\\) çš„å›¾ç‰‡ä¸ºä¾‹\n\n\n\nä» TableÂ 1 å¯ä»¥çœ‹å‡ºï¼Œé€šè¿‡Patchifyï¼Œæˆ‘ä»¬å¯ä»¥å¤§å¤§å‡å°‘Tokensçš„æ•°é‡ï¼Œä»è€Œé™ä½Attentionçš„è®¡ç®—å¤æ‚åº¦ã€‚è¿™ä¹Ÿæ˜¯ViTèƒ½å¤Ÿåœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­å–å¾—æˆåŠŸçš„ä¸€ä¸ªé‡è¦åŸå› ã€‚ä¸è¿‡ï¼ŒPatch Sizeçš„é€‰æ‹©ä¹Ÿæ˜¯ä¸€ä¸ªtrade-offï¼Œè¿‡å¤§å¯èƒ½ä¼šä¸¢å¤±ç»†èŠ‚ä¿¡æ¯ï¼Œè¿‡å°åˆ™ä¼šå¢åŠ è®¡ç®—é‡ã€‚ViTåŸç‰ˆä½¿ç”¨çš„æ˜¯ \\(P=16\\)ï¼Œå³æ¯ä¸ªpatchåŒ…å« \\(16 \\times 16\\) çš„åƒç´ ã€‚\n\n\nTL;DR\n\n\nViT çš„æ ¸å¿ƒæ”¹åŠ¨åªæœ‰ä¸¤æ­¥:patchifyï¼ˆåˆ‡å—ï¼‰+ embeddingï¼ˆçº¿æ€§æŠ•å½±ï¼‰ï¼Œå…¶ä½™å‡ ä¹å°±æ˜¯åŸå°ä¸åŠ¨çš„ Transformer Encoder",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#position-encoding",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#position-encoding",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.2 Position Encoding",
    "text": "2.2 Position Encoding\nå°†å›¾ç‰‡è½¬åŒ–ä¸º Transformer çš„è¾“å…¥ä¹‹åï¼Œæ¥ä¸‹æ¥Transformerä¸­çš„å¦ä¸€ä¸ªç»„ä»¶å°±æ˜¯ä¼ å…¥ Position Informationã€‚ æˆ‘ä»¬çŸ¥é“åœ¨ä¸­ï¼Œä»–ä»¬ç”¨çš„æ˜¯ Sine-cosine position embeddingï¼Œåœ¨é‚£ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿæåˆ°äº†ï¼Œè¿˜å­˜åœ¨å…¶ä»–ä¸åŒçš„Position Encodingçš„åŠæ³•ï¼ŒViTç”¨çš„å°±æ˜¯å¦ä¸€ç§åŠæ³•ï¼ŒLearned Position Embeddingã€‚Learned Position Embeddingçš„æ–¹æ³•å¾ˆç®€å•ï¼Œä¹Ÿå¾ˆå¥½ç†è§£ï¼Œå¯¹äºæ¯ä¸€ä¸ªä½ç½®ï¼Œæˆ‘ä»¬ç»™ä»–ä¸€ä¸ªindexï¼Œå°†è¿™ä¸ªindexä¼ å…¥ä¸€ä¸ª Embedding Matrixï¼Œ æˆ‘ä»¬å°±å¾—åˆ°ä¸€ä¸ªPosition Embeddingã€‚ä¸è¿‡ä¸Token Embeddingä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä¼šç”¨åˆ°æ‰€æœ‰çš„Positionï¼Œä¹Ÿæ•´ä¸ªmatrixï¼Œ æ‰€ä»¥æˆ‘ä»¬ä¸ç”¨å®šindexï¼Œç›´æ¥å®šä¹‰æ•´ä¸ªEmbeddingï¼Œç„¶åå°†å®ƒä¼ å…¥Transformerä¸­ã€‚\nclass PosEmbedder(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n\n        self.position_embeddings = nn.Parameter( \n            torch.randn(1, (config.image_size // config.patch_size) ** 2 + 1, config.d_model) \n        ) # +1 for cls token \n\n        self.cls_token = nn.Parameter(torch.randn(1, 1, config.d_model))\n\n    def forward(self, x: torch.Tensor):\n        B = x.shape[0]\n        cls_tokens = self.cls_token.expand(B, 1, -1)\n        x = torch.cat((cls_tokens, x), dim=1)\n\n        x = x + self.position_embeddings\n        return x\n\n\nQuestion: ä¸ºä»€ä¹ˆViTè¦ç”¨Learned Position Embeddingï¼Ÿ\n\n\nä¸ºä»€ä¹ˆViTè¦ç”¨Learned Position Embeddingå‘¢ï¼Ÿåœ¨ViTè¿™ç¯‡æ–‡ç« ä¸­ï¼Œä»–ä»¬å°è¯•è¿‡ä¸åŒçš„Position Embeddingï¼Œæ¯”å¦‚:\n\nNo Positional Information\n1-dimensional Positional Embedding\n2-dimensional Positional Embedding\nRelative Positional Embedding\n\nå‘ç°ï¼Œé™¤äº†No Positional Informationä¹‹å¤–ï¼Œå…¶ä½™3ç§åœ¨Image Classificationä¸­çš„è¡¨ç°ï¼Œéƒ½æ˜¯å·®ä¸å¤šçš„ã€‚\n\nè®ºæ–‡ä¸­è¡¨ç¤ºï¼Œå¯èƒ½æ˜¯å› ä¸ºæ‰€éœ€è¦çš„Positionçš„ä¿¡æ¯è¾ƒå°ï¼Œå¯¹äºä¸åŒç§ç±»çš„Position Embeddingçš„æ–¹æ³•ï¼Œå­¦ä¹ è¿™ä¸ªPosition Informationçš„èƒ½åŠ›ï¼Œéƒ½æ˜¯å·®ä¸å¤šçš„ã€‚\n\nWe speculate that since our Transformer encoder operates on patch-level inputs, as opposed to pixel-level, the differences in how to encode spatial information is less important. More precisely, in patch-level inputs, the spatial dimensions are much smaller than the original pixel-level inputs, e.g., \\(14 \\times 14\\) as opposed to \\(224 \\times 224\\), and learning to represent the spatial relations in this resolution is equally easy for these different positional encoding strategies.  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.18 \n\nä¸è¿‡ï¼Œå°½ç®¡Positionçš„æ–¹æ³•ä¸é‡è¦ï¼Œä½†æ˜¯ä¸åŒçš„è®­ç»ƒå‚æ•°ï¼Œè¿˜æ˜¯ä¼šå½±å“åˆ°å­¦ä¹ åˆ°çš„Position Information, ä¸‹å›¾æ‰€ç¤º:\n\nä»å›¾ä¸­çœ‹åˆ°ï¼Œä¸åŒçš„è®­ç»ƒå‚æ•°ï¼Œå­¦ä¹ åˆ°çš„Position Informationæ˜¯ä¸åŒçš„ã€‚\n\n\n\n2.2.1 Position Interpolation\nå½“æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªPre-Trainingçš„æ¨¡å‹ï¼Œæˆ‘ä»¬æƒ³ç”¨å®ƒFine-Tuningåˆ°ä¸€ä¸ªä¸åŒå›¾ç‰‡å¤§å°çš„æ•°æ®åº“ï¼Œæˆ‘ä»¬æ”¹æ€ä¹ˆåšå‘¢?\nç¬¬ä¸€ä¸ªæ–¹æ³•å½“ç„¶æ˜¯ï¼ŒResize æˆ‘ä»¬çš„å›¾ç‰‡ï¼Œåˆ°ViT Pre-trainingçš„å›¾ç‰‡å¤§å°ï¼Œä½†æ˜¯ï¼Œè¿™ä¸ªèƒ½å¯¼è‡´è¾ƒå¤§çš„å›¾ç‰‡ï¼Œå¤±å»å¾ˆå¤šç»†èŠ‚ã€‚å¦‚æœæˆ‘ä»¬æƒ³ä¿æŒå›¾ç‰‡çš„å¤§å°ä¸å˜ï¼ŒåŒæ—¶è®©æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬å°±éœ€è¦Extend Position Encodingï¼Œå› ä¸ºå½“Patch Sizeä¸å˜ï¼Œå›¾ç‰‡å¤§å°å˜äº†çš„è¯ï¼Œäº§ç”Ÿçš„Number of Patches ä¹Ÿæ˜¯ä¼šæ”¹å˜çš„ï¼Œæˆ‘ä»¬éœ€è¦åšçš„æ˜¯: æ‰¾åˆ°ä¸€ç§æ–¹æ³•ï¼Œå¢å¤§æˆ–è€…å‡å°Positionçš„æ•°é‡ã€‚ è¿™å°±æ˜¯æ‰€è°“çš„Position Interpolationã€‚\n\nThe Vision Transformer can handle arbitrary sequence lengths (up to memory constraints), however, the pre-trained position embeddings may no longer be meaningful. We therefore perform 2D interpolation of the pre-trained position embeddings, according to their location in the original image  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.4 \n\næˆ‘ä»¬å¯ä»¥æŠŠPosition Embeddingçœ‹æˆæ˜¯\\(\\sqrt{Number of Patches} \\times \\sqrt{Number of Patches} \\times dim\\)çš„ä¸€å¼ å›¾åƒï¼Œé‚£ä¹ˆå½“æˆ‘ä»¬æ”¹å˜å›¾ç‰‡çš„å¤§å°ï¼Œäº§ç”Ÿçš„patchæ•°é‡ä¹Ÿæ”¹å˜äº†ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡å¯¹Position Embeddingè¿›è¡ŒäºŒç»´æ’å€¼ï¼ˆ2D Interpolationï¼‰ï¼Œæ¥å¾—åˆ°æ–°çš„Position Embeddingã€‚\næˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç æ˜¯æ€ä¹ˆå®ç°Position Interpolationçš„:\ndef interpolate_pos_encoding(self, x, w, h):\n    npatch = x.shape[1] - 1\n    N = self.pos_embed.shape[1] - 1\n    if npatch == N and w == h:\n        return self.pos_embed\n    class_pos_embed = self.pos_embed[:, 0]\n    patch_pos_embed = self.pos_embed[:, 1:]\n    dim = x.shape[-1]\n    w0 = w // self.patch_embed.patch_size\n    h0 = h // self.patch_embed.patch_size\n    \n    patch_pos_embed = F.interpolate(\n        patch_pos_embed.reshape(\n            1, \n            int(math.sqrt(N)), \n            int(math.sqrt(N)), \n            dim\n        ).permute(0, 3, 1, 2),\n        scale_factor=(w0 / math.sqrt(N), h0 / math.sqrt(N)),\n        mode='bicubic',\n    )\n    patch_pos_embed = patch_pos_embed.permute(0, 2, 3, 1).view(1, -1, dim)\n    return torch.cat((class_pos_embed.unsqueeze(0), patch_pos_embed), dim=1)\néœ€è¦æ³¨æ„çš„æ˜¯ä»£ç çš„ç¬¬6è¡Œå’Œè¿”å›å€¼ï¼Œæˆ‘ä»¬éœ€è¦å°†ä½ç½®ç¼–ç åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ˜¯ [CLS] token çš„ä½ç½®ç¼–ç ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯patchçš„ä½ç½®ä¿¡æ¯ã€‚æˆ‘ä»¬åªå¯¹patchçš„ä½ç½®ä¿¡æ¯è¿›è¡Œæ’å€¼ï¼Œæœ€åå†å°† [CLS] token çš„ä½ç½®ç¼–ç å’Œæ–°çš„patchä½ç½®ç¼–ç æ‹¼æ¥èµ·æ¥ã€‚\n\n\nTL;DR: 2D interpolation of the pre-trained position embeddings\n\n\nViT åœ¨é¢„è®­ç»ƒæ—¶ï¼Œé€šå¸¸ç”¨å›ºå®šè¾“å…¥åˆ†è¾¨ç‡ï¼ˆæ¯”å¦‚ 224Ã—224ï¼‰ â†’ ç”Ÿæˆå›ºå®šæ•°é‡çš„ patchï¼ˆæ¯”å¦‚ 16Ã—16 patch â†’ 196 ä¸ª patchï¼‰ã€‚ä½†åœ¨ fine-tuning æ—¶ï¼Œè¾“å…¥å›¾ç‰‡å¯èƒ½å¤§å°ä¸ä¸€æ ·ï¼Œæ¯”å¦‚ 384Ã—384ï¼Œè¿™æ—¶ patch æ•°é‡å°±å˜äº†ã€‚è¿™ä¼šå¯¼è‡´åŸæœ¬çš„ ä½ç½®ç¼–ç  (position embeddings) å’Œæ–°çš„ patch æ•°é‡å¯¹ä¸ä¸Šã€‚è§£å†³åŠæ³•:å¯¹é¢„è®­ç»ƒå¥½çš„ä½ç½®ç¼–ç åš äºŒç»´æ’å€¼ (2D interpolation)ï¼Œæ ¹æ® patch åœ¨åŸå›¾ä¸­çš„ç©ºé—´ä½ç½®ï¼ŒæŠŠä½ç½®ç¼–ç æ‹‰ä¼¸/ç¼©æ”¾åˆ°æ–°çš„åˆ†è¾¨ç‡ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#cls-tokens-mlp-head",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#cls-tokens-mlp-head",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.3 [CLS] Tokens & MLP Head",
    "text": "2.3 [CLS] Tokens & MLP Head\nåœ¨Transformerä¸­ï¼Œæˆ‘ä»¬äº†è§£åˆ°:æ¯è¾“å…¥ä¸€ä¸ªtokenï¼ŒTransformerä¼šè¾“å‡ºå¯¹åº”çš„tokenã€‚è¿™å°±æ˜¯è¯´ï¼Œå¯¹äºæ¯ä¸ªpatchï¼ŒTransformerä¼šè¾“å‡ºå¯¹åº”çš„Tokensï¼Œé‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªä¸€ä¸ªtokenä½œä¸ºæˆ‘ä»¬å›¾ç‰‡çš„è¡¨ç¤ºå‘¢ã€‚ BERT (Devlin et al. 2019)ï¼Œ ç”¨äº†ä¸€ä¸ª [CLS], æ¥è¡¨ç¤ºä¸€ä¸ªå¥å­ã€‚åŒç†ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ·»åŠ ä¸€ä¸ª [CLS] token, æ¥è¡¨ç¤ºä¸€å¼ å›¾ç‰‡ã€‚åŒæ—¶ï¼Œå¯¹äº [CLS] token, æˆ‘ä»¬ä¹Ÿè¦åœ¨ç»™ä»–ä¸€ä¸ªè¡¨ç¤ºä½ç½®çš„ä¿¡æ¯ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨Position Encodingä¸Šï¼Œæˆ‘ä»¬æœ‰ (config.image_size // config.patch_size) ** 2 + 1, ä½ç½®ä¿¡æ¯ï¼Œå…¶ä¸­ +1 å°±æ˜¯ [CLS] çš„ä½ç½®ä¿¡æ¯ã€‚\n\n\nTL;DR: [CLS] Token\n\n\n[CLS] token çš„ä½œç”¨å°±æ˜¯ç”¨æ¥èšåˆæ‰€æœ‰çš„Patchçš„æ¶ˆæ¯ï¼Œç„¶åç”¨æ¥Image çš„Representationã€‚\n\n\næˆ‘ä»¬æƒ³ä¸€ä¸‹ï¼Œé™¤äº†åŠ ä¸€ä¸ª [CLS] tokenï¼Œä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æœ‰å…¶ä»–åŠæ³•æ¥è¡¨ç¤ºå›¾ç‰‡å—ã€‚æœ‰ä¸€ç§å¾ˆè‡ªç„¶çš„æ–¹æ³•å°±æ˜¯ï¼Œå°†æ‰€æœ‰çš„patchçš„æ¶ˆæ¯æ”¶é›†èµ·æ¥ï¼Œç„¶åå»ä¸€ä¸ªå¹³å‡å€¼æ¥è¡¨ç¤ºè¿™ä¸ªå›¾ç‰‡ã€‚ç±»ä¼¼äºä¼ ç»Ÿçš„ConvNetæˆ‘ä»¬å¯ä»¥é€šè¿‡ AvgPooling æ¥å®ç°ã€‚ ä¸è¿‡è®ºæ–‡ä¸­æåˆ°ï¼Œ å¯¹äºä¸¤ç§ä¸åŒçš„Image Representationï¼Œéœ€è¦æœ‰ä¸åŒçš„Learning Rate æ¥è®­ç»ƒè¿™ä¸ªç½‘ç»œã€‚ é€šè¿‡ä¸‹å›¾ï¼Œæˆ‘ä»¬çœ‹åˆ°ï¼Œä¸ç”¨çš„æ”¶é›†ä¿¡æ¯çš„æ–¹æ³•ï¼Œéœ€è¦ä¸åŒçš„learning rate\n\n\n\n\n\n\nFigureÂ 4: Different learning rates are required to train the model when using global average pooling (GAP) vs.Â a [CLS] token for image representation\n\n\n\nç»“æ„ä¸ŠäºŒè€…éƒ½å¯è¡Œï¼Œä½†éœ€è¦ä¸åŒ LR / recipeã€‚ å®è·µé‡Œå¾ˆå¤šå®ç°é»˜è®¤ç”¨ CLSï¼ˆä¸ BERT å¯¹é½ã€ä¸‹æ¸¸æ›´ç»Ÿä¸€ï¼‰ï¼Œä¹Ÿæœ‰ç”¨ GAP çš„å˜ä½“æ¯”å¦‚æˆ‘ä»¬æ¥ä¸‹æ¥è¦å­¦çš„ Swin Transformer (Liu et al. 2021)\n\nAn initial attempt at using only image-patch embeddings, globally average-pooling (GAP) them, followed by a linear classifierâ€”just like ResNetâ€™s final feature mapâ€”performed very poorly. However, we found that this is neither due to the extra token, nor to the GAP operation. Instead, the difference in performance is fully explained by the requirement for a different learning-rate,  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.17 \n\næœ‰äº†Image Representä¹‹åï¼Œæˆ‘ä»¬åªéœ€è¦å°†è¿™ä¸ªRepresentationä¼ å…¥ä¸€ä¸ªç®€å•çš„MLPï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°ä¸€ä¸ªClassifierã€‚MLPçš„è¾“å…¥æ˜¯hidden dimï¼Œè¾“å‡ºåˆ™æ˜¯æˆ‘ä»¬Number of Classesã€‚ä¸åŒçš„Index è¡¨ç¤ºä¸åŒçš„Classsesã€‚\n\nBoth during pre-training and fine-tuning, a classification head is attached to \\(\\mathrm{z}_{L}^{0}\\). The classification head is implemented by a MLP with one hidden layer at pre-training time and by a single linear layer at fine-tuning time.  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.3 \n\nclass MLPHead(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n        self.fc1 = nn.Linear(config.d_model, config.d_model)\n        self.fc2 = nn.Linear(config.d_model, config.num_classes)\n        self.dropout = nn.Dropout(config.dropout_rate)\n\n    def forward(self, x: torch.Tensor):\n        cls = x[:, 0, :]\n        cls = self.dropout(F.relu(self.fc1(cls)))\n        cls = self.fc2(cls)\n\n        return cls",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#transformer-encoder-block",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#transformer-encoder-block",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.4 Transformer Encoder Block",
    "text": "2.4 Transformer Encoder Block\nè‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»è®²å®Œäº†ViT, ä¸Transformerçš„ä¸»è¦ä¸åŒä¹‹å¤„ã€‚æ¥ä¸‹æ¥ï¼Œå°±æ˜¯Transformerçš„Encoderã€‚\n\n\n\n\n\n\nFigureÂ 5: The Transformer Encoder in ViT.\n\n\n\nè¿™éƒ¨åˆ†ï¼Œå’ŒTransformeråŸæœ¬çš„Encoderå¾ˆç±»ä¼¼ï¼Œåªä¸è¿‡æœ‰å‡ å¤„ä¸åŒ:\n\nPre-Norm: åœ¨ViTåŒï¼Œè¾“å…¥å…ˆè¿›è¡Œä¸€ä¸ªLayerNormï¼Œç„¶ååœ¨ä¼ å…¥MHAæˆ–è€…MLPä¸­ï¼Œåè§‚åœ¨TransformeråŸæœ¬çš„Encoderä¸­ï¼Œæˆ‘ä»¬æ˜¯å…ˆå°†MHAæˆ–è€…MLPçš„è¾“å‡ºä¸è¾“å…¥åŠ åœ¨ä¸€èµ·ï¼Œä¹‹åå†è¿›è¡Œä¸€ä¸ªNormalizationã€‚è¿™å«åšPost-Norm,\n\n\\[\n\\begin{split}\n\\text{Post-Norm:} \\quad x_{l} &= \\mathrm{Norm}(x_{l-1} + \\mathrm{MHA}(x_{l-1})) \\\\\n\\text{Pre-Norm:} \\quad x_{l} &= x_{l-1} + \\mathrm{MHA}(\\mathrm{Norm}(x_{l-1}))\n\\end{split}\n\\tag{2}\\]\nPre-Normçš„å¥½å¤„æ˜¯ï¼ŒGradientå¯ä»¥ä¸å—å¹²æ‰°çš„ç›´æ¥æµè¿‡æ®‹å·®è¿æ¥ï¼ˆresidual connectionï¼‰ï¼Œè€ŒPost-Normåˆ™ä¼šæœ‰ä¸€äº›å¹²æ‰°ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚ViTä½¿ç”¨Pre-Normæ¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§ã€‚\n\nMLPçš„å®ç°:åœ¨Transformer Encoderä¸­ï¼Œç”¨çš„æ˜¯ ReLU, è€Œåœ¨ViTä¸­ï¼Œç”¨çš„æ˜¯ GELU\n\né™¤æ­¤ä¹‹å¤–ï¼Œå…¶ä»–éƒ¨åˆ†éƒ½æ˜¯ä¸€æ ·çš„ã€‚ä¸€ä¸‹æ˜¯ViT Encoderçš„å®ç°:\nclass EncoderBlock(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n        self.mha = MHA(config)\n        self.ffn = FFN(config)\n        self.norm1 = LayerNorm(config.d_model)\n        self.norm2 = LayerNorm(config.d_model)\n\n    def forward(self, x: torch.Tensor):\n        attn, _ = self.mha(self.norm1(x))\n        x = x + attn\n        x = x + self.ffn(self.norm2(x))\n\n        return x\n\n2.4.1 Multi-Heads Attention\nè¿˜æœ‰ä¸€ä¸ªå°±æ˜¯Attentionæ¨¡å—ï¼ŒAttentionæ¨¡å—ä¸Transformerçš„æ˜¯ä¸€æ¨¡ä¸€æ ·ï¼Œåœ¨è¿™é‡Œå°±ä¸è¿‡å¤šçš„èµ˜è¿°äº†ã€‚\nclass MHA(nn.Module):\n    def __init__(self, config: ModelConfig):\n        super().__init__()\n        self.num_heads = config.num_heads\n        self.d_model = config.d_model\n        assert config.d_model % config.num_heads == 0, \"d_model must be divisible by num_heads\"\n        self.d_k = config.d_model // config.num_heads\n\n        self.qkv_linear = nn.Linear(config.d_model, config.d_model * 3)\n        self.out_linear = nn.Linear(config.d_model, config.d_model)\n\n        self.attention_dropout = nn.Dropout(config.attention_dropout_rate)\n\n    def forward(self, x: torch.Tensor):\n        B, N, C = x.shape  # Batch size, Number of tokens, Embedding dimension\n\n        q, k, v = (\n            self.qkv_linear(x).reshape(B, N, 3, self.num_heads, self.d_k).permute(2, 0, 3, 1, 4).unbind(0)\n        )\n\n        scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(\n            torch.tensor(self.d_k, dtype=torch.float32)\n        )  # (B, num_heads, N, N)\n        attn_weight = torch.softmax(scores, dim=-1)  # (B, num_heads, N, N)\n        attn = self.attention_dropout(attn_weight)\n\n        context = torch.matmul(attn, v)  # (B, num_heads, N, d_k)\n        context = context.transpose(1, 2).reshape(B, N, C)  # (B, N, d_model)\n\n        out = self.out_linear(context)  # (B, N, d_model)\n\n        return out, attn_weight",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#cnn-vs.-vit-inductive-bias",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#cnn-vs.-vit-inductive-bias",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.5 CNN vs.Â ViT: Inductive bias",
    "text": "2.5 CNN vs.Â ViT: Inductive bias\nè‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»å®Œäº†Vision Transformerï¼Œæˆ‘ä»¬æ¥ä»Inductive Biasçš„æ–¹é¢ï¼Œçœ‹çœ‹ CNN å’Œ ViT æœ‰ä»€ä¹ˆä¸åŒ\n\n\nNOTE: Inductive Bias\n\n\nåœ¨æ·±åº¦å­¦ä¹ é‡Œï¼ŒInductive Biasï¼ˆå½’çº³åç½®ï¼‰æ˜¯æŒ‡æ¨¡å‹åœ¨å­¦ä¹ ä¹‹å‰ï¼Œå› ç»“æ„æˆ–è®¾è®¡è€Œè‡ªå¸¦çš„å‡è®¾æˆ–å…ˆéªŒ ï¼Œæ¯”å¦‚ Convolution Layer, å®ƒå°±æ˜¯å‡è®¾ç›¸é‚»çš„pixelä¹‹é—´ï¼Œæ˜¯æœ‰ä¸€å®šè”ç³»çš„ï¼Œå› æ­¤å¯ä»¥ç”¨ä¸€ä¸ªKernelæ¥å°†å­¦ä¹ è¿™äº›å…³ç³»ã€‚\n\n\nå¯¹äºå›¾åƒæ¥è¯´ï¼Œå¸¸è§çš„å…ˆéªŒå°±æ˜¯:\n\nå±€éƒ¨åƒç´ æ˜¯ç›¸å…³çš„ï¼ˆlocalityï¼‰\nç›¸é‚»åŒºåŸŸçš„æ¨¡å¼æœ‰è§„å¾‹ï¼ˆ2D neighborhoodï¼‰\nç‰©ä½“æ— è®ºå‡ºç°åœ¨å›¾åƒå“ªé‡Œï¼Œè¯†åˆ«æ–¹å¼åº”è¯¥ä¸€æ ·ï¼ˆTranslation Equivarianceï¼‰\n\né‚£ä¹ˆï¼ŒCNN çš„ç»“æ„æ€ä¹ˆä½“ç°è¿™äº›åç½®ï¼Ÿ\n\nå±€éƒ¨æ€§ (Locality):\n\nå·ç§¯æ ¸ï¼ˆä¾‹å¦‚ \\(3 \\times 3\\)ï¼‰åªå’Œå±€éƒ¨åƒç´ æ‰“äº¤é“ï¼Œè€Œä¸æ˜¯å…¨å›¾ã€‚\nè¿™æ„å‘³ç€æ¨¡å‹â€œç›¸ä¿¡â€å›¾åƒçš„é‡è¦ç‰¹å¾æ¥è‡ªå±€éƒ¨é‚»åŸŸï¼Œè€Œä¸æ˜¯é¥è¿œåŒºåŸŸã€‚\n\näºŒç»´é‚»åŸŸç»“æ„ (2D structure):\n\nå·ç§¯æ“ä½œæ˜¯æ²¿ç€ å›¾åƒçš„äºŒç»´ç½‘æ ¼è¿›è¡Œçš„ï¼Œå¤©ç„¶åˆ©ç”¨äº†å›¾åƒçš„è¡Œåˆ—ç»“æ„ã€‚\nè¿™å’Œæ–‡æœ¬ï¼ˆåºåˆ— 1Dï¼‰ä¸ä¸€æ ·ï¼ŒCNN æ˜ç¡®çŸ¥é“è¾“å…¥æ˜¯ 2D æ’åˆ—çš„ã€‚\n\nå¹³ç§»ç­‰å˜æ€§ (Translation equivariance):\n\nå·ç§¯æ ¸çš„å‚æ•°åœ¨æ•´å¼ å›¾å…±äº«ã€‚\næ‰€ä»¥çŒ«åœ¨å·¦ä¸Šè§’è¿˜æ˜¯å³ä¸‹è§’ï¼Œå·ç§¯æ ¸éƒ½èƒ½æ£€æµ‹åˆ°â€œçŒ«è€³æœµâ€ã€‚\nè¿™è®© CNN è‡ªåŠ¨å…·æœ‰â€œè¯†åˆ«ä½ç½®æ— å…³â€çš„èƒ½åŠ›ã€‚\n\n\nè¿™äº›æ€§è´¨ä¸æ˜¯æ¨¡å‹é€šè¿‡è®­ç»ƒå­¦å‡ºæ¥çš„ï¼Œè€Œæ˜¯å› ä¸ºå·ç§¯æ“ä½œæœ¬èº«çš„æ•°å­¦ç»“æ„å°±å¸¦æ¥çš„ï¼ˆä¹Ÿæ˜¯æˆ‘ä»¬äººä¸ºè®¾è®¡çš„ï¼‰:\n\nkernel çš„å±€éƒ¨è¿æ¥ â†’ å±€éƒ¨æ€§\nkernel æ»‘åŠ¨è¦†ç›–å…¨å›¾ â†’ å¹³ç§»ç­‰å˜æ€§\næ“ä½œåœ¨äºŒç»´ç©ºé—´å®šä¹‰ â†’ é‚»åŸŸç»“æ„\n\næ‰€ä»¥ï¼Œå“ªæ€•æˆ‘ä»¬ä¸ç»™ CNN å–‚å¤ªå¤šæ•°æ®ï¼Œå®ƒä¹Ÿä¼šåˆ©ç”¨è¿™äº›åç½®å»å­¦ä¹ ç‰¹å¾ã€‚\nè€Œå¯¹äº ViT æ¥è¯´ï¼Œå…¶å½’çº³åç½®éå¸¸å¼±ï¼Œå‡ ä¹å®Œå…¨ä¾èµ–æ•°æ®å’Œè®­ç»ƒæ¥å­¦ä¹ ï¼Œä¸è¿‡å®ƒä¹Ÿæœ‰åˆ©ç”¨äº†ä¸€äº›å›¾ç‰‡çš„Inductive Bias:\n\nPatch åˆ‡åˆ† (Patchification)\n\nViT å”¯ä¸€çš„â€œå›¾åƒå…ˆéªŒâ€ä¹‹ä¸€å°±æ˜¯æŠŠè¾“å…¥å›¾ç‰‡åˆ‡æˆ patch\nè¿™ä¸€æ“ä½œéšå«äº†:å›¾åƒæ˜¯ä¸€ä¸ªäºŒç»´ç»“æ„ï¼Œå¯ä»¥è¢«åˆ†å—å¤„ç†ã€‚\n\nä½ç½®ç¼–ç  (Positional Embeddings)\n\nTransformer æœ¬èº«åªå¤„ç†åºåˆ—ï¼Œæ²¡æœ‰ç©ºé—´ç»“æ„çš„æ¦‚å¿µã€‚\nViT é€šè¿‡åŠ ä½ç½®ç¼–ç å‘Šè¯‰æ¨¡å‹ patch åœ¨å›¾åƒä¸­çš„ç›¸å¯¹ä½ç½®ã€‚\nåœ¨è¾“å…¥åˆ†è¾¨ç‡å˜åŒ–æ—¶ï¼Œä¼šåš äºŒç»´æ’å€¼ (2D interpolation) æ¥é€‚é…ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§äººå·¥å¼•å…¥çš„ 2D å…ˆéªŒã€‚\n\nå…¶ä»–éƒ¨åˆ†\n\né™¤äº†ä»¥ä¸Šä¸¤ç‚¹ï¼ŒViT çš„æ³¨æ„åŠ›æœºåˆ¶æ˜¯ å…¨å±€çš„ (global)ï¼Œæ²¡æœ‰å±€éƒ¨æ€§çº¦æŸã€‚\næ²¡æœ‰åƒ CNN é‚£æ ·å†…ç½®çš„å¹³ç§»ç­‰å˜æ€§æˆ–å±€éƒ¨é‚»åŸŸç»“æ„ã€‚\n\n\nè¿™æ ·å°±æ˜¯ä¸ºä»€ä¹ˆViTéœ€è¦æ›´å¤šæ•°æ®å’Œè®¡ç®—æ‰èƒ½å­¦åˆ°åŒæ ·çš„ç©ºé—´å½’çº³è§„å¾‹ã€‚\n\nViT is Data-Hungry because it has very weak inductive bias, relying on the data to learn spatial relationships, while CNNs have strong built-in biases that help them learn from less data.",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#vit-model-variants",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#vit-model-variants",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.6 ViT Model Variants",
    "text": "2.6 ViT Model Variants\nViT æœ‰3ç§ä¸åŒçš„åŸºæœ¬å˜å½¢ï¼Œ å¦‚ä¸‹è¡¨ï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariant\n#Layers\nHidden Dim (d_model)\nMLP Dim (d_ff)\n#Heads\n#Params\n\n\n\n\nViT-Base (ViT-B/16)\n12\n768\n3072\n12\n86M\n\n\nViT-Large (ViT-L/16)\n24\n1024\n4096\n16\n307M\n\n\nViT-Huge (ViT-H/14)\n32\n1280\n5120\n16\n632M\n\n\n\n\n\nTableÂ 2: ViTçš„ä¸åŒå˜ä½“\n\n\n\nViTçš„åå­—é€šå¸¸è¡¨ç¤ºä¸º: ViT-L/16: æ„æ€æ˜¯ï¼ŒViT-Largeï¼Œç„¶åç”¨çš„16 Patch Sizeã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒPatch Sizeè¶Šå¤§ï¼Œæˆ‘ä»¬å¾—åˆ°çš„tokenså°±è¶Šå°‘ï¼Œä¹Ÿå°±æ˜¯éœ€è¦æ›´å°‘çš„è®­ç»ƒæ—¶å®ç°, ä½†é€šå¸¸éœ€è¦æ›´å¤§çš„å›¾ç‰‡æ¥è®­ç»ƒã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#experiment",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#experiment",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "2.7 Experiment",
    "text": "2.7 Experiment\næˆ‘ä»¬å…ˆæ¥çœ‹çœ‹åŸè®ºæ–‡æ˜¯å¦‚ä½•è®­ç»ƒçš„:\n\né¢„è®­ç»ƒï¼ˆæ‰€æœ‰æ¨¡å‹ï¼ŒåŒ…æ‹¬ ResNetï¼‰:ä½œè€…ç»Ÿä¸€ä½¿ç”¨ Adamï¼ˆ\\(\\beta_{1} = 0.9, \\beta_{2}=0.999\\)ï¼‰ï¼Œbatch size = 4096ï¼Œå¹¶ä½¿ç”¨è¾ƒå¤§çš„ weight decay = 0.1ã€‚ä½œè€…æŒ‡å‡ºè¿™å¯¹æ‰€æœ‰æ¨¡å‹çš„è¿ç§»è¡¨ç°éƒ½æœ‰å¸®åŠ©\nå­¦ä¹ ç‡ç­–ç•¥:é‡‡ç”¨çº¿æ€§ warmup + çº¿æ€§ decayï¼ˆç»†èŠ‚è§ Appendix B.1ï¼‰ã€‚\nå¾®è°ƒï¼ˆfine-tuningï¼‰:å¯¹æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€æ”¹ç”¨å¸¦ momentum çš„ SGDï¼Œbatch size 512.\næƒé‡å¹³å‡:åŒæ—¶ä½¿ç”¨ Polyak averagingï¼ˆæŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼Œç³»æ•° 0.9999ï¼‰ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥è®­ç»ƒæˆ‘ä»¬å®šä¹‰çš„ViTã€‚å…·ä½“çš„ä»£ç å¯ä»¥åœ¨ è¿™é‡Œ æŸ¥çœ‹ã€‚\n\n2.7.1 Dataset\næˆ‘ä»¬ç”¨CIFAT-10çš„è®­ç»ƒé›†æ¥è®­ç»ƒViTã€‚\n\n\nWARNING: Limited of Dataset\n\n\næˆ‘ä»¬ä¹‹å‰æåˆ°äº†ViTè¦åœ¨å¤§è§„æ¨¡çš„æ•°æ®é›†ä¸Šæ‰å¯ä»¥å‘æŒ¥å®ƒçš„èƒ½åŠ›ï¼Œç”±äºèµ„æºæœ‰é™ï¼Œæˆ‘ä»¬åªåœ¨è¿™å±•ç¤ºViTçš„è®­ç»ƒæµç¨‹ï¼Œåœ¨äº†è§£äº†è¿™ä¸ªè®­ç»ƒæµç¨‹ä¹‹åï¼Œå¾ˆå®¹æ˜“æ‹“å±•åˆ°å…¶ä»–çš„å¤§æ•°æ®é›†ã€‚\n\n\nIMG_MEAN = [0.4914, 0.4822, 0.4465]\nIMG_STD = [0.2470, 0.2435, 0.2616]\nIMG_SIZE = 32\n\n\ndata_transform = transforms.Compose(\n    [\n        transforms.Resize(\n            (IMG_SIZE, IMG_SIZE),\n            interpolation=transforms.InterpolationMode.BILINEAR,\n        ),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(IMG_MEAN, IMG_STD),\n    ]\n)\n\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=train_config.data_dir, download=True, train=True, transform=data_transform\n)\nif train_config.debug:\n    train_dataset = torch.utils.data.Subset(train_dataset, range(1000))\n\n\ndataloader = DataLoader(\n    train_dataset,\n    batch_size=train_config.batch_size,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True if train_config.device.type == \"cuda\" else False,\n)\n\n\n2.7.2 Optimizer & Loss Function\nè®ºæ–‡ä¸­åº”ç”¨äº† Adam Optimizerï¼Œæˆ‘ä»¬åœ¨æ­¤ä¹Ÿç”¨Adamã€‚å› ä¸ºæˆ‘ä»¬è®­ç»ƒçš„æ˜¯Image Classification Taskï¼Œæ‰€ä»¥æŸå¤±å‡½æ•°æ˜¯æ˜¯Cross Entropy Loss:\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=train_config.lr,\n    betas=train_config.betas,\n    weight_decay=train_config.weight_decay,\n)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, train_config.num_epochs, eta_min=train_config.min_lr\n)\n\n\n2.7.3 Result\n\n\næˆ‘ä»¬æ¥çœ‹çœ‹ï¼Œè¿™ä¸ªToy ViT ç©¶ç«Ÿè®­ç»ƒçš„æ€ä¹ˆæ ·:\nN_ROWS = 4\nN_COLS = 8\nN_IMGS = N_ROWS * N_COLS\ntest_dataset = torchvision.datasets.CIFAR10(\n    root=train_config.data_dir,\n    download=True,\n    train=False,\n)\nIDX_TO_CLASS = {v: k for k, v in test_dataset.class_to_idx.items()}\n\norg_imgs, true_labels = test_dataset.data[:N_IMGS], test_dataset.targets[:N_IMGS]\ntransformed_imgs = torch.stack([data_transform(Image.fromarray(img)) for img in org_imgs])\npred_labels = model(tensor_to_device(transformed_imgs, device=train_config.device)).argmax(dim=1).cpu()\n\n\nfig, axes = plt.subplots(N_ROWS, N_COLS, figsize=(N_COLS * 2, N_ROWS * 2))\nfor i in range(N_ROWS):\n    for j in range(N_COLS):\n        idx = i * N_COLS + j\n        axes[i, j].imshow(org_imgs[idx])\n        axes[i, j].axis(\"off\")\n        if true_labels[idx] == pred_labels[idx].item():\n            axes[i, j].set_title(\n                f\"{IDX_TO_CLASS[true_labels[idx]]} (Pred: {IDX_TO_CLASS[pred_labels[idx].item()]})\",\n                fontsize=10,\n                color=\"green\",\n            )\n        else:\n            axes[i, j].set_title(\n                f\"{IDX_TO_CLASS[true_labels[idx]]} (Pred: {IDX_TO_CLASS[pred_labels[idx].item()]})\",\n                fontsize=10,\n                color=\"red\",\n            )\nplt.tight_layout()\nplt.show()\n\næˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹çœ‹Attention Mapçš„\nN_ROWS = 4\nN_COLS = 8\nN_IMGS = N_ROWS * N_COLS\ntest_dataset = torchvision.datasets.CIFAR10(\n    root=train_config.data_dir,\n    download=True,\n    train=False,\n)\nIDX_TO_CLASS = {v: k for k, v in test_dataset.class_to_idx.items()}\n\norg_imgs, true_labels = test_dataset.data[:N_IMGS], test_dataset.targets[:N_IMGS]\ntransformed_imgs = torch.stack([data_transform(Image.fromarray(img)) for img in org_imgs]).to(\n    train_config.device\n)\n\n# pred_labels = model(tensor_to_device(transformed_imgs, device=train_config.device)).argmax(dim=1).cpu()\nTARGET_LAYER = 5  # 0-based index\nHEAD = 2\nGAMMA = 0.7\nFLOOR = 0.15\n\n\ndef to_vit_attention_vis(img_uint8, attn_map, gamma=0.7, floor=0.15):\n    \"\"\"\n    gamma:     &gt;0, smaller -&gt; sharper spotlight\n    floor:     how visible the dark region is (0 = pure black background)\n    \"\"\"\n    img = img_uint8.astype(np.float32) / 255.0\n\n    # normalize attention to [0,1]\n    a = attn_map.astype(np.float32)\n    a = a - a.min()\n    a = a / (a.max() + 1e-6)\n\n    # make it more \"spotlight-like\"\n    a = a**gamma  # sharpen\n    a = floor + (1 - floor) * a  # keep some visibility outside\n    a = np.clip(a, 0, 1)\n\n    return img * a[..., None]  # darken outside attention\n\n\nmodel.eval()\nx = model.backbone.patch_embedder(transformed_imgs)\nx = model.backbone.pos_embedder(x)\nfor i in range(TARGET_LAYER):\n    x = model.backbone.encoder_layers[i](x)\n\n_, attn_weights = model.backbone.encoder_layers[TARGET_LAYER].mha(\n    model.backbone.encoder_layers[TARGET_LAYER].norm1(x)\n)\nif HEAD &gt;= 0:\n    attn_weights = attn_weights[:, HEAD, 0, 1:]  # (B, N)\nelse:\n    attn_weights = attn_weights.mean(dim=1)[:, 0, 1:]  # (B, N)\n\n# Reshape attention weights to (B, H, W)\nnum_patches_per_side = model_config.image_size // model_config.patch_size\nattn_maps = attn_weights.reshape(-1, num_patches_per_side, num_patches_per_side)  # (B, H, W)\n\n# Upsample attention maps to image size\nattn_maps_upsampled = F.interpolate(\n    attn_maps.unsqueeze(1),\n    size=(model_config.image_size, model_config.image_size),\n    mode=\"bilinear\",\n    align_corners=False,\n).squeeze(1)  # (B, H, W)\n\n# Move attention map to CPU for visualization\nattn_maps_upsampled = attn_maps_upsampled.cpu().detach().numpy()\n\n# Visualize Overlaid Attention Maps\nfig, axes = plt.subplots(N_ROWS, N_COLS, figsize=(N_COLS * 2, N_ROWS * 2))\nfor i in range(N_ROWS):\n    for j in range(N_COLS):\n        idx = i * N_COLS + j\n        vis = to_vit_attention_vis(\n            org_imgs[idx],\n            attn_maps_upsampled[idx],\n            gamma=GAMMA,\n            floor=FLOOR,\n        )\n\n        axes[i, j].imshow(vis)\n        axes[i, j].axis(\"off\")\n        if true_labels[idx] == pred_labels[idx].item():\n            axes[i, j].set_title(\n                f\"{IDX_TO_CLASS[true_labels[idx]]} (Pred: {IDX_TO_CLASS[pred_labels[idx].item()]})\",\n                fontsize=10,\n                color=\"green\",\n            )\n        else:\n            axes[i, j].set_title(\n                f\"{IDX_TO_CLASS[true_labels[idx]]} (Pred: {IDX_TO_CLASS[pred_labels[idx].item()]})\",\n                fontsize=10,\n                color=\"red\",\n            )\nplt.tight_layout()\nplt.suptitle(\n    f\"Attention Maps Over Images On Layer {TARGET_LAYER}  {'Head ' + str(HEAD) if HEAD &gt;= 0 else 'Avg Head'}\",\n    y=1.02,\n)\nplt.show()\n\n\n\n2.7.4 Training Recipe\næ¥ä¸‹æ¥æˆ‘æä¾›å‡ ä¸ªå¯èƒ½çš„æå‡Accuracyçš„æ–¹æ³•ï¼ˆç”±äºæ—¶é—´ç°å®ï¼Œæš‚æ—¶æ²¡æœ‰èƒ½å®ç°ï¼Œæœ‰å…´è¶£çš„è¯»è€…æ¬¢è¿è‡ªè¡Œå°è¯•ï¼‰:\n\nä¼˜åŒ–å™¨:AdamWï¼ˆè€Œé Adamï¼‰+ weight decay\nå­¦ä¹ ç‡ç­–ç•¥:warmup + cosineï¼Œbatch size å¯¹ LR çš„çº¿æ€§ç¼©æ”¾è§„åˆ™\nå¢å¼º:RandAugment / Mixup / CutMix\næ­£åˆ™:DropPathï¼ˆstochastic depthï¼‰ã€Label smoothing\n\n\n\nTIP: ViT è®­ç»ƒå¸¸è§ç»„åˆ\n\n\nAdamW + cosine + warmup + strong augï¼ˆRA/Mixup/CutMixï¼‰+ DropPath + label smoothing\n\n\n\n\n2.7.5 Training Summary\nä»å®éªŒç»“æœæ¥çœ‹ï¼Œè¿™ä¸ª toy ViT çš„è¡¨ç°ç¡®å®ä¸ç®—ç†æƒ³ï¼Œç”šè‡³ä¸å¦‚ä¸€ä¸ªç®€å•çš„å·ç§¯ç½‘ç»œã€‚è¿™å…¶å®åœ¨é¢„æœŸä¹‹å†…:ViT çš„å½’çº³åç½®æ›´å¼±ï¼ˆç¼ºå°‘å·ç§¯çš„å±€éƒ¨æ€§ä¸å¹³ç§»ç­‰å˜æ€§ï¼‰ï¼Œåœ¨æ•°æ®é‡è¾ƒå°ã€è®­ç»ƒ recipe ä¸å¤Ÿå¼ºçš„æƒ…å†µä¸‹æ›´å®¹æ˜“æ¬ æ‹Ÿåˆæˆ–æ³›åŒ–ä¸è¶³ï¼Œå› æ­¤å¾ˆéš¾åœ¨ CIFAR-10 è¿™ç±»å°è§„æ¨¡æ•°æ®ä¸Šå åˆ°ä¾¿å®œã€‚\næ¯”è¾ƒâ€œåç›´è§‰â€çš„æ˜¯ï¼Œæˆ‘ä»¬å¯è§†åŒ–å¾—åˆ°çš„ Attention Map å‡ ä¹æ¥è¿‘å‡åŒ€åˆ†å¸ƒï¼Œè€Œä¸æ˜¯åƒåŸè®ºæ–‡é‚£æ ·å‘ˆç°å‡ºæ›´æ¸…æ™°çš„è¯­ä¹‰èšç„¦ï¼ˆä¾‹å¦‚å¯¹ç‰©ä½“åŒºåŸŸçš„æ³¨æ„åŠ›æ›´å¼ºï¼‰:\n\nä¸€ç§åˆç†çš„è§£é‡Šæ˜¯:æˆ‘ä»¬çš„è¾“å…¥åˆ†è¾¨ç‡åªæœ‰ (\\(32\\times32\\))ï¼Œåœ¨å¸¸è§ patch è®¾ç½®ä¸‹ token æ•°é‡éå¸¸æœ‰é™ï¼ˆä¾‹å¦‚ (\\(P=4\\)) æ—¶ä¹Ÿåªæœ‰ (\\(8\\times8=64\\)) ä¸ª patchï¼‰ã€‚åœ¨è¿™ç§ä½åˆ†è¾¨ç‡ã€ä½ token æ•°çš„è®¾å®šé‡Œï¼Œæ¯ä¸ª token è¦†ç›–çš„åŒºåŸŸç›¸å¯¹â€œç²—â€ï¼Œå¹¶ä¸”æ—©æœŸè®­ç»ƒé˜¶æ®µæ¨¡å‹å¾€å¾€æ›´å€¾å‘äºå­¦ä¹ å…¨å±€å¹³å‡çš„ç›¸å…³æ€§æ¥æœ€å°åŒ–æŸå¤±ï¼Œå¯¼è‡´æ³¨æ„åŠ›æƒé‡çœ‹èµ·æ¥æ›´å¹³å‡ã€‚å¦ä¸€ä¸ªæ³¨æ„çš„ç‚¹å°±æ˜¯:å•å±‚æ³¨æ„åŠ›æƒé‡æœ¬èº«æœªå¿…ç­‰ä»·äºâ€œå¯è§£é‡Šæ€§â€ï¼Œå³ä½¿æ¨¡å‹åœ¨åšå‡ºæ­£ç¡®å†³ç­–ï¼Œä¹Ÿå¯èƒ½å‡ºç°æ³¨æ„åŠ›å›¾ä¸å¤Ÿå°–é”çš„ç°è±¡ã€‚\nå¦‚æœå¸Œæœ›å¾—åˆ°æ›´æœ‰ä¿¡æ¯é‡çš„å¯è§£é‡Šç»“æœï¼Œé€šå¸¸æœ‰ä¸¤æ¡æ›´ç¨³å¦¥çš„è·¯å¾„:\n\nä½¿ç”¨æ›´å¯é çš„å¯è§£é‡Šæ–¹æ³•ï¼Œä¾‹å¦‚ Grad-CAM (Selvaraju et al. 2020)ï¼Œæˆ–è€…ç»“åˆå¤šå±‚æ³¨æ„åŠ›çš„ Attention Rollout (Abnar and Zuidema 2020)ï¼Œè€Œä¸æ˜¯åªè§‚å¯ŸæŸä¸€å±‚/æŸä¸€å¤´çš„ attentionã€‚\næé«˜è¾“å…¥åˆ†è¾¨ç‡ä¸è®­ç»ƒè§„æ¨¡ï¼ˆä¾‹å¦‚åœ¨ ImageNet æˆ–æ›´å¤§æ•°æ®ä¸Šè®­ç»ƒ/é¢„è®­ç»ƒåå†è¿ç§»ï¼‰ï¼Œè®©æ¨¡å‹æœ‰æœºä¼šå­¦ä¹ åˆ°æ›´ç»†ç²’åº¦çš„ç©ºé—´ç»“æ„ä¸æ›´ç¨³å®šçš„è¯­ä¹‰å¯¹é½ã€‚\n\nè¿™é‡Œå°±ä¸å±•å¼€å®ç°ç»†èŠ‚äº†ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥æ ¹æ®ä¸Šè¿°è®ºæ–‡è¿›ä¸€æ­¥å°è¯•ä¸å¯¹æ¯”ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#self-supervised-pre-training",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#self-supervised-pre-training",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "3.1 Self-Supervised Pre-Training",
    "text": "3.1 Self-Supervised Pre-Training\né™¤äº†åš Image Classificationï¼ŒViT å›¢é˜Ÿä¹Ÿå°è¯•äº†è‡ªç›‘ç£é¢„è®­ç»ƒï¼ˆSelf-Supervised Pre-Trainingï¼‰ã€‚ä»–ä»¬é‡‡ç”¨äº†ä¸€ç§éå¸¸â€œç±»ä¼¼äºBERT(Devlin et al. 2019)â€çš„æ€è·¯:Masked Patch Predictionâ€”â€”å…ˆæŠŠå›¾åƒåˆ‡æˆ patch tokensï¼Œç„¶åéšæœºâ€œè…èš€ï¼ˆcorruptï¼‰â€ä¸€éƒ¨åˆ† tokenï¼Œè®©æ¨¡å‹å»é¢„æµ‹è¢«è…èš€éƒ¨åˆ†çš„å†…å®¹ã€‚\n\næ ¸å¿ƒæ˜¯æŠŠ ViT å½“æˆâ€œè§†è§‰ç‰ˆ BERTâ€:éšæœºé®ä½ï¼ˆæˆ–æ›¿æ¢ï¼‰ä¸€éƒ¨åˆ† patch tokenï¼Œå†é¢„æµ‹è¢«é®ä½ patch çš„ç›®æ ‡ï¼ˆè¿™é‡Œç”¨ç¦»æ•£é¢œè‰²ä½œä¸ºé¢„æµ‹æ ‡ç­¾ï¼‰ã€‚\n\n\nä»–ä»¬å¯¹ 50% çš„ patch embedding åš corruptionï¼Œå¹¶é‡‡ç”¨ä¸ BERT ç±»ä¼¼çš„ 80/10/10 ç­–ç•¥: - 80%:ç”¨ä¸€ä¸ªå¯å­¦ä¹ çš„ [mask] embedding æ›¿æ¢ - 10%:æ›¿æ¢æˆå¦ä¸€å—éšæœº patch çš„ embedding - 10%:ä¿æŒä¸å˜ï¼ˆä½†ä»ç„¶ä½œä¸ºé¢„æµ‹ç›®æ ‡ï¼‰\nè¿™ç§è®¾è®¡çš„ç›´è§‰æ˜¯:æ—¢è¦è®©æ¨¡å‹å­¦ä¼šâ€œæ ¹æ®ä¸Šä¸‹æ–‡è¡¥å…¨ç¼ºå¤±ä¿¡æ¯â€ï¼Œåˆè¦é¿å…æ¨¡å‹è¿‡åº¦ä¾èµ–æŸä¸€ç§å›ºå®šçš„ mask æ¨¡å¼ã€‚\nä»–ä»¬æœ€ç»ˆé€‰æ‹©äº†ä¸€ä¸ªéå¸¸è½»é‡ä½†æœ‰æ•ˆçš„é¢„æµ‹ç›®æ ‡:\nå¯¹æ¯ä¸ªè¢«è…èš€ patchï¼Œé¢„æµ‹å…¶ 3-bit mean colorï¼ˆä¸€å…± \\(2^9 = 512\\) ç§é¢œè‰²ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ª 512-way åˆ†ç±»é—®é¢˜ï¼‰ã€‚\nåŒæ—¶ä»–ä»¬ä¹Ÿå¯¹æ¯”è¿‡å‡ ç§ç›®æ ‡è®¾å®š: 1) åªé¢„æµ‹ä¸€ä¸ª mean 3-bit colorï¼ˆ512 åˆ†ç±»ï¼Œ1 ä¸ªé¢„æµ‹ï¼‰\n2) æŠŠ 16Ã—16 patch ä¸‹é‡‡æ ·æˆ 4Ã—4ï¼Œå†å¯¹æ¯ä¸ªå°æ ¼é¢„æµ‹ 3-bit colorï¼ˆ512 åˆ†ç±»ï¼Œ16 ä¸ªå¹¶è¡Œé¢„æµ‹ï¼‰\n3) ç›´æ¥å¯¹å®Œæ•´ patch åšåƒç´ çº§ L2 å›å½’ï¼ˆRGB é€šé“ä¸Šçš„å¯†é›†å›å½’ï¼‰\nç»“æœæ¯”è¾ƒæœ‰æ„æ€:ä¸‰ç§æ–¹å¼éƒ½èƒ½å¸¦æ¥ä¸é”™æ•ˆæœï¼Œä½† åƒç´  L2 å›å½’ç•¥å·®.\n\nWe employ the masked patch prediction objective for preliminary self-supervision experiments. To do so we corrupt 50% of patch embeddings by either replacing their embeddings with a learnable [mask] embedding (80%), a random other patch embedding (10%) or just keeping them as is (10%). This setup is very similar to the one used for language by BERT. Finally, we predict the 3-bit, mean color (i.e., 512 colors in total) of every corrupted patch using their respective patch representations  An Image is Worth 16x16 Words- Transformers for Image Recognition at Scale, p.14 \n\nåç»­çš„å·¥ä½œä¹Ÿè¯´æ˜äº†è¿™ç§æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œæ¯”å¦‚SiMIM (Xie et al. 2022)",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-1",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-1",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.1 Question 1",
    "text": "5.1 Question 1\n\nQuestion 1: ä¸ºä»€ä¹ˆ Vision Transformer éœ€è¦å¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®ï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nå› ä¸º ViT ç¼ºä¹å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„å½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼Œä¾‹å¦‚å±€éƒ¨æ€§ï¼ˆlocalityï¼‰å’Œå¹³ç§»ä¸å˜æ€§ï¼ˆtranslation equivarianceï¼‰ï¼Œè¿™äº›èƒ½åŠ›éœ€è¦é€šè¿‡å¤§é‡æ•°æ®æ¥å­¦ä¹ ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-2",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-2",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.2 Question 2",
    "text": "5.2 Question 2\n\nQuestion 2:Eq.(1) é‡Œä¸ºä»€ä¹ˆè¦åŠ  [CLS] tokenï¼Œå®ƒå’Œå…¨å±€å¹³å‡æ± åŒ–æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\n[CLS] token ç»™æ¨¡å‹ä¸€ä¸ªâ€œä¸“é—¨èšåˆä¿¡æ¯çš„æ§½ä½â€ï¼Œé€šè¿‡æ³¨æ„åŠ›ä¸»åŠ¨ä»æ‰€æœ‰ patch æ‹‰å–ä¿¡æ¯ï¼›è€Œ GAP æ˜¯è¢«åŠ¨å¹³å‡ã€‚è®ºæ–‡åœ¨é™„å½•å¯¹æ¯”è¿‡ä¸¤è€…è¡¨ç°æ¥è¿‘ï¼Œä½†å­¦ä¹ ç‡ç­‰é…æ–¹å¯èƒ½éœ€è¦ä¸åŒè°ƒæ•´ã€‚arXiv+1",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-3",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-3",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.3 Question 3",
    "text": "5.3 Question 3\n\nQuestion 3:ViT ç”¨ 1D position embedding ä¸ä¼šä¸¢æ‰ 2D ç»“æ„å—ï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nä¸¢æ‰äº†â€œæ˜¾å¼ 2D å½’çº³åç½®â€ï¼Œä½†ä½œè€…å‘ç°æ›´å¤æ‚çš„ 2D-aware ä½ç½®ç¼–ç å¹¶æ²¡æœ‰å¸¦æ¥æ˜¾è‘—æ”¶ç›Šï¼›ViT ä¾é æ•°æ®ä¸è®­ç»ƒä»å¤´å­¦ä¹ ç©ºé—´å…³ç³»ã€‚çœŸæ­£éœ€è¦ 2D çš„åœ°æ–¹ä¸»è¦åœ¨åˆ†è¾¨ç‡è¿ç§»æ—¶çš„ä½ç½®ç¼–ç æ’å€¼ã€‚arXiv+1",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-4",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-4",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.4 Question 4",
    "text": "5.4 Question 4\n\nQuestion 4:ä¸ºä»€ä¹ˆè®ºæ–‡å¼ºè°ƒâ€œè§„æ¨¡è®­ç»ƒèƒœè¿‡å½’çº³åç½®â€ï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nè®ºæ–‡å®éªŒæ˜¾ç¤º:å°æ•°æ®é¢„è®­ç»ƒæ—¶å¼º CNNï¼ˆå¦‚ BiT ResNetï¼‰æ›´ç¨³ï¼›éšç€é¢„è®­ç»ƒæ•°æ®ä» ImageNet â†’ ImageNet-21k â†’ JFT-300M å¢å¤§ï¼ŒViT å¤§æ¨¡å‹çš„è¿ç§»æ€§èƒ½æ˜¾è‘—æå‡å¹¶åè¶… CNNï¼Œè¯´æ˜å¯¹ ViT è€Œè¨€æ•°æ®è§„æ¨¡æ˜¯å…³é”®ç“¶é¢ˆã€‚UofT Computer Science+1",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-5",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-5",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.5 Question 5",
    "text": "5.5 Question 5\n\nQuestion 5:patch size é€‰ 16 è¿˜æ˜¯ 32 çš„ä¸»è¦æƒè¡¡æ˜¯ä»€ä¹ˆï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\npatch è¶Šå°ï¼ˆå¦‚ 16ï¼‰â†’ token æ•° NNN è¶Šå¤§ â†’ æ³¨æ„åŠ›æ›´è´µä½†ç»†ç²’åº¦æ›´å¼ºï¼›patch è¶Šå¤§ï¼ˆå¦‚ 32ï¼‰â†’ æ›´çœç®—åŠ›ä½†å¯èƒ½æŸå¤±ç»†èŠ‚ã€‚è®ºæ–‡ä¹Ÿæ˜ç¡®æŒ‡å‡ºåºåˆ—é•¿åº¦ä¸ P2P^2P2 æˆåæ¯”ï¼Œå› æ­¤å° patch æ›´æ˜‚è´µã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-6",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-6",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.6 Question 6",
    "text": "5.6 Question 6\n\nQuestion 6:ä¸ºä»€ä¹ˆ ViT åœ¨å°æ•°æ®é›†ä¸Šé€šå¸¸ä¸å¦‚ CNNï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nå› ä¸º CNN é€šè¿‡å·ç§¯å’Œæƒé‡å…±äº«å†…ç½®äº†å¼ºå…ˆéªŒï¼Œè€Œ ViT éœ€è¦ä»æ•°æ®ä¸­å­¦ä¹ è¿™äº›å…ˆéªŒï¼Œåœ¨å°æ•°æ®æ¡ä»¶ä¸‹ä¸å¤Ÿé«˜æ•ˆã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-7",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-7",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.7 Question 7",
    "text": "5.7 Question 7\n\nQuestion 7:åˆ†è¾¨ç‡å¾®è°ƒæ—¶ä¸ºä»€ä¹ˆè¦å¯¹ä½ç½®ç¼–ç åš 2D æ’å€¼ï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nå› ä¸º token ç½‘æ ¼å¤§å°å˜äº†ï¼ˆNNN å˜äº†ï¼‰ï¼Œé¢„è®­ç»ƒçš„ EposE_{pos}Eposâ€‹ ä¸èƒ½ç›´æ¥å¯¹é½æ–°ä½ç½®ï¼›2D æ’å€¼è®©ä½ç½®ç¼–ç åœ¨ç©ºé—´ä¸Šâ€œå¹³æ»‘ä¼¸ç¼©â€ï¼Œä»è€Œå¤ç”¨é¢„è®­ç»ƒçŸ¥è¯†ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-8",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#question-8",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "5.8 Question 8",
    "text": "5.8 Question 8\n\nQuestion 8:ä¸ºä»€ä¹ˆ ViT éœ€è¦æŠŠå›¾åƒåˆ‡æˆ patchï¼Œè€Œä¸æ˜¯ç›´æ¥æŠŠæ¯ä¸ªåƒç´ å½“ tokenï¼Ÿ\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\nåƒç´ çº§ token ä¼šè®©åºåˆ—é•¿åº¦å˜æˆ \\(H \\times W\\)ï¼Œè‡ªæ³¨æ„åŠ›å¤æ‚åº¦ \\(\\mathcal{O}(n^{2})\\) ç›´æ¥çˆ†ç‚¸ï¼›patchify æŠŠ NNN é™åˆ° \\(\\frac{HW}{P^2}\\)â€‹ï¼Œè®©æ ‡å‡†å…¨å±€æ³¨æ„åŠ›åœ¨å¯æ¥å—çš„ç®—åŠ›ä¸‹è¿è¡Œï¼ŒåŒæ—¶ä¿ç•™ç«¯åˆ°ç«¯å­¦ä¹ ç©ºé—´ç»“æ„çš„èƒ½åŠ›ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#å‡å°‘tokensçš„æŠ€å·§",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#å‡å°‘tokensçš„æŠ€å·§",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "6.1 å‡å°‘Tokensçš„æŠ€å·§",
    "text": "6.1 å‡å°‘Tokensçš„æŠ€å·§\n\n6.1.1 Patch Merge\nç±»ä¼¼äº Swin Transformer(Liu et al. 2021) çš„åšæ³•:åœ¨ä¸åŒå±‚å°†ç›¸é‚» patch åˆå¹¶ï¼ˆä¾‹å¦‚ 2Ã—2 â†’ 1ï¼‰ï¼Œå‡å°‘ token æ•°ï¼Œä½¿æ¨¡å‹å±‚çº§åŒ–ã€‚\n\n\n6.1.2 Pixel Shuffle",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#vision-language-model",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#vision-language-model",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "6.2 Vision Language Model",
    "text": "6.2 Vision Language Model\næˆ‘ä»¬ä»¥åŠå­¦ä¹ äº†ViT for computer Visionï¼Œ Transformer for NLPï¼Œ æ¥ä¸‹æ¥æœ‰ä»€ä¹ˆåŠæ³•è®©è¿™ä¸¤ç§æ¨¡å‹ç»“åˆèµ·æ¥å‘¢ï¼Ÿ CLIP (Radford et al. 2021): å°† ViT èåˆåˆ° vision-language é¢„è®­ç»ƒä¸­ã€‚æˆ‘ä»¬ä¹‹åä¼šå­¦ä¹ è¿™ç¯‡æ–‡ç« ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#video-transformer",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#video-transformer",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "6.3 Video Transformer",
    "text": "6.3 Video Transformer\nåœ¨å­¦ä¹ äº†å¦‚ä½•å°†Transformeråº”ç”¨åˆ°Imageä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ›´è¿‘ä¸€æ­¥ï¼Œçœ‹çœ‹å¦‚ä½•å°†Transformeråº”ç”¨åˆ°Video æ¨¡æ€ä¸­ã€‚ViViT(Arnab et al. 2021) çš„æå‡ºï¼Œå°±æ˜¯å°†Transformeråº”ç”¨åˆ°Videoã€‚ä¸­ï¼Œæˆ‘ä»¬ä¹‹åä¼šå­¦ä¹ åˆ°è¿™ä¸€ç¯‡ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#native-resolution",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#native-resolution",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "6.4 Native Resolution",
    "text": "6.4 Native Resolution\nåœ¨ViT ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†å›¾ç‰‡Resizeåˆ°ç›¸åŒå¤§å°çš„å›¾ç‰‡ï¼Œé‚£æˆ‘ä»¬å°±æƒ³ä¸Resizeï¼Œèƒ½ä¸èƒ½ç›´æ¥è®­â€œä¸åŒå¤§å°/ä¸åŒé•¿å®½æ¯”â€çš„å›¾ï¼Ÿ NaViT (Dehghani et al. 2023)æå‡ºæ¯å¼ å›¾åœ¨â€œåŸå§‹åˆ†è¾¨ç‡/åŸå§‹é•¿å®½æ¯”â€ä¸‹åˆ‡æˆ patch token åºåˆ—ï¼Œç„¶åæŠŠå¤šå¼ å›¾çš„ token åºåˆ—â€œæ‰“åŒ…ï¼ˆpackingï¼‰â€åˆ°åŒä¸€æ¡å›ºå®šé•¿åº¦åºåˆ—é‡Œè®­ç»ƒï¼Œç”¨ attention mask ä¿è¯ä¸åŒå›¾ç‰‡ä¹‹é—´äº’ä¸â€œä¸²é—¨â€ã€‚\n\n\nPatch nâ€™ Pack:æŠŠå¤šå¼ ä¸åŒåˆ†è¾¨ç‡å›¾ç‰‡çš„ patch token åºåˆ—æ‹¼æˆä¸€ä¸ªå®šé•¿ packed sequenceï¼Œä»¥å‡å°‘ padding/resize æµªè´¹\n\nAttention Mask:ä½¿ç”¨ block-diagonal maskï¼Œè®©åŒä¸€å¼ å›¾çš„ token æ‰èƒ½äº’ç›¸ attentionï¼Œä¸åŒå›¾ä¹‹é—´å®Œå…¨éš”ç¦»\nä½ç½®ç¼–ç :é‡‡ç”¨ factorizedï¼ˆx/y åˆ†è§£ï¼‰ä½ç½®ç¼–ç ï¼Œå¹¶å¯ç”¨ fractional åæ ‡æå‡å¯¹æœªè§åˆ†è¾¨ç‡çš„æ³›åŒ–",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#axial-attentionè½´å‘æ³¨æ„åŠ›",
    "href": "posts/100-AI-Papers/02-vision-transformer/Vision-Transformer.html#axial-attentionè½´å‘æ³¨æ„åŠ›",
    "title": "02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)",
    "section": "9.1 Axial Attentionï¼ˆè½´å‘æ³¨æ„åŠ›ï¼‰",
    "text": "9.1 Axial Attentionï¼ˆè½´å‘æ³¨æ„åŠ›ï¼‰\nåœ¨å¤„ç† å›¾åƒæˆ–è§†é¢‘ è¿™ç±»é«˜ç»´è¾“å…¥æ—¶ï¼Œå¦‚æœç›´æ¥å¯¹æ‰€æœ‰åƒç´ åš å…¨å±€ self-attentionï¼Œå¤æ‚åº¦æ˜¯ \\(\\mathcal{O}(H^2 W^2)\\)å½“å›¾åƒå¾ˆå¤§æ—¶ï¼Œè¿™ä¸ªä»£ä»·å¤ªé«˜ã€‚ æ ¸å¿ƒæƒ³æ³•:æŠŠäºŒç»´ attention æ‹†æˆä¸¤æ¬¡ä¸€ç»´ attentionï¼ˆæ²¿ç€å›¾åƒçš„ä¸¤ä¸ªâ€œè½´â€åˆ†åˆ«åšï¼‰ã€‚ 1. Row-wise Attentionï¼ˆè¡Œæ³¨æ„åŠ›ï¼‰ â€¢ æ²¿ç€æ°´å¹³æ–¹å‘ï¼ˆå®½åº¦è½´ Wï¼‰åšæ³¨æ„åŠ›ï¼Œæ¯ä¸€è¡Œçš„åƒç´ äº’ç›¸å…³æ³¨ã€‚ â€¢ å¤æ‚åº¦:\\(\\mathcal{O}(H \\cdot W^2)\\)ã€‚ 2. Column-wise Attentionï¼ˆåˆ—æ³¨æ„åŠ›ï¼‰ â€¢ æ²¿ç€å‚ç›´æ–¹å‘ï¼ˆé«˜åº¦è½´ Hï¼‰åšæ³¨æ„åŠ›ï¼Œæ¯ä¸€åˆ—çš„åƒç´ äº’ç›¸å…³æ³¨ã€‚ â€¢ å¤æ‚åº¦: \\(\\mathcal{O}(W \\cdot H^2)\\)ã€‚\nç»„åˆèµ·æ¥ï¼Œç›¸å½“äºåœ¨ H å’Œ W ä¸¤ä¸ªè½´ä¸Šéƒ½åšäº†å…¨å±€ä¾èµ–å»ºæ¨¡ã€‚",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "02: Vision Transformer"
    ]
  },
  {
    "objectID": "posts/100-AI-Papers/10-pixel-gated-cnn/Pixel Gated CNN.html",
    "href": "posts/100-AI-Papers/10-pixel-gated-cnn/Pixel Gated CNN.html",
    "title": "10: Conditional Image Generation with PixelCNN Decoders (Pixel Gated CNN)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/10-pixel-gated-cnn/Pixel Gated CNN.html#experiment",
    "href": "posts/100-AI-Papers/10-pixel-gated-cnn/Pixel Gated CNN.html#experiment",
    "title": "10: Conditional Image Generation with PixelCNN Decoders (Pixel Gated CNN)",
    "section": "1.1 Experiment",
    "text": "1.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/100_Papers_index.html",
    "href": "posts/100-AI-Papers/100_Papers_index.html",
    "title": "100 Papers with Code",
    "section": "",
    "text": "01: Attention is All You Need (Transformer)\n\n\n\nNLP\n\nArchitecture\n\nTransformer\n\nâ­ï¸â­ï¸â­ï¸â­ï¸â­ï¸\n\n\n\nTransformer æ˜¯ä¸€ç§åŸºäº è‡ªæ³¨æ„åŠ›æœºåˆ¶ çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œèƒ½å¤Ÿå¹¶è¡Œå¤„ç†åºåˆ—ï¼Œåœ¨è¯­è¨€ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼›å¹¶ä¸”ä½œä¸º GPTã€BERT ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ ¸å¿ƒåŸºç¡€ï¼Œæ¨åŠ¨äº†å½“ä»Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•ã€‚åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ Transformer çš„åŸºæœ¬åŸç†ï¼Œä»¥åŠå…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬ **Wordâ€¦\n\n\n\n\n\nYY Zhang\n\n\n60 mins\n\n\n\n\n\n\n\n\n\n\n\n\n02: An Image is Worth \\(16 \\times 16\\) Words: Transformers for Image Recognition at Scale (Vision-Transformer)\n\n\n\nComputer Vision\n\nTransformer\n\n\n\nVision Transformer (ViT) é€šè¿‡å°†å›¾åƒåˆ‡åˆ†ä¸º Patch å¹¶ç›´æ¥åº”ç”¨æ ‡å‡† Transformer æ¶æ„ï¼Œå®ç°äº†å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æœ¬æ–‡ä»‹ç»äº† ViT çš„æ ¸å¿ƒç»„ä»¶ï¼ŒåŒ…æ‹¬ Patch Embeddingã€Position Embeddingã€[CLS] Token ä»¥åŠ Transformer ç¼–ç å™¨å—ï¼Œæ¢è®¨äº† ViTâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03: Training data-efficient image transformers & distillation through attention (DeiT)\n\n\n\nComputer Vision\n\nTransformer\n\nKnowledge Distillation\n\n\n\nTraining data-efficient image transformers & distillation through attentionï¼ˆDeiTï¼‰æå‡ºäº†ä¸€ç§é€šè¿‡çŸ¥è¯†è’¸é¦ï¼ˆdistillation token ä¸ attention-based distillationï¼‰æ˜¾è‘—æå‡ Vision Transformerâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)\n\n\n\nComputer Vision\n\nAttention\n\nTransformer\n\n\n\nSwin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05: ViViT: A Video Vision Transformer(ViViT)\n\n\n\nComputer Vision\n\nTransformer\n\n\n\nViViT: A Video Vision Transformeræå‡ºå°† Vision Transformer ç³»ç»Ÿæ€§æ‰©å±•åˆ°è§†é¢‘å»ºæ¨¡ï¼Œé€šè¿‡æ—¶ç©ºåˆ†è§£ä¸é«˜æ•ˆæ³¨æ„åŠ›è®¾è®¡ç›´æ¥å¯¹è§†é¢‘åºåˆ—è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨è§†é¢‘åˆ†ç±»ç­‰ä»»åŠ¡ä¸Šå–å¾—å¼ºæ€§èƒ½ä¸è‰¯å¥½å¯æ‰©å±•æ€§ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n06: Learning Transferable Visual Models From Natural Language Supervision (CLIP)\n\n\n\nMulti Modality\n\nRepresentation Learning\n\n\n\nä¸€ç§é€šè¿‡å¯¹é½å›¾åƒä¸è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œåœ¨æµ·é‡å›¾æ–‡å¯¹ä¸Šè®­ç»ƒç»Ÿä¸€è¡¨ç¤ºï¼Œä»è€Œè·å¾—å¼ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›çš„è§†è§‰æ¨¡å‹ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07: Emerging Properties in Self-Supervised Vision Transformers (DINO)\n\n\n\nSelf Supervised Learning\n\nRepresentation Learning\n\n\n\nä¸€ç§æ— éœ€æ ‡ç­¾çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æ•™å¸ˆâ€“å­¦ç”Ÿè‡ªè’¸é¦è®­ç»ƒ Vision Transformerï¼Œè‡ªå‘æ¶Œç°å‡ºè¯­ä¹‰ä¸€è‡´çš„å…¨å±€è¡¨ç¤ºä¸æ¸…æ™°çš„æ³¨æ„åŠ›åˆ†å‰²èƒ½åŠ›ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n08: Auto-Encoding Variational Bayes (VAE)\n\n\n\nSelf Supervised Learning\n\nGenerative Model\n\nRepresentation Learning\n\n\n\nVAEï¼ˆå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼‰æ˜¯ä¸€ç±»ç»“åˆæ¦‚ç‡å›¾æ¨¡å‹ä¸ç¥ç»ç½‘ç»œçš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡å¼•å…¥å¯å‚æ•°åŒ–çš„è¿‘ä¼¼åéªŒ \\(q_\\phi(z|x)\\) æ¥æ‘Šé”€æ¨æ–­æˆæœ¬ï¼Œå¹¶ç”¨æœ€å¤§åŒ– ELBO çš„æ–¹å¼åŒæ—¶å­¦ä¹ æ•°æ®çš„æ½œåœ¨è¡¨ç¤ºä¸ç”Ÿæˆè¿‡ç¨‹ï¼šå…¶ä¸­é‡å»ºé¡¹ç¡®ä¿æ¨¡å‹èƒ½ä»æ½œå˜é‡è¿˜åŸæ•°æ®ï¼ŒKL é¡¹åˆ™å°†æ½œç©ºé—´çº¦æŸä¸ºæ¥è¿‘å…ˆéªŒçš„è¿ç»­ç»“æ„ã€‚å€ŸåŠ©é‡å‚æ•°åŒ–æŠ€å·§ï¼ŒVAEâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n09: Masked Autoencoders Are Scalable Vision Learners(MAE)\n\n\n\nSelf Supervised Learning\n\nRepresentation Learning\n\nAutoEncoder\n\n\n\nä¸€ç§é€šè¿‡éšæœºé®æŒ¡å¤§æ¯”ä¾‹å›¾åƒ patch å¹¶é‡å»ºç¼ºå¤±å†…å®¹è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿ Vision Transformer èƒ½ä»¥æ›´é«˜æ•ˆç‡å’Œæ›´å¥½å¯æ‰©å±•æ€§å­¦ä¹ é€šç”¨è§†è§‰è¡¨ç¤ºã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10: Conditional Image Generation with PixelCNN Decoders (Pixel Gated CNN)\n\n\n\nGenerative Model\n\n\n\nä¸€ç§åŸºäºåƒç´ çº§è‡ªå›å½’å»ºæ¨¡çš„æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é—¨æ§å·ç§¯ï¼ˆGated CNNï¼‰åœ¨ç»™å®šæ¡ä»¶ï¼ˆå¦‚ç±»åˆ«æˆ–ä¸Šä¸‹æ–‡ï¼‰ä¸‹é€åƒç´ ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11: Neural Discrete Representation Learning (VQ_VAE)\n\n\n\nRepresentation Learning\n\nSelf Supervised Learning\n\n\n\nä¸€ç§é€šè¿‡ç¦»æ•£åŒ–æ½œåœ¨è¡¨ç¤ºå¹¶ä½¿ç”¨ç æœ¬è¿›è¡Œé‡æ„çš„ç”Ÿæˆæ¨¡å‹ï¼Œå°†è¿ç»­è¡¨ç¤ºè½¬ä¸ºç¦»æ•£ç¬¦å·ï¼Œä»è€Œå­¦ä¹ é«˜è´¨é‡ã€å¯ç»„åˆçš„è§†è§‰è¡¨ç¤ºå¹¶æ”¯æŒé«˜æ•ˆç”Ÿæˆã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15: High-Resolution Image Synthesis with Latent Diffusion Models (Latent Diffusion Model)\n\n\n\nGenerative Model\n\n\n\nä¸€ç§åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£å»ºæ¨¡çš„ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ã€é«˜è´¨é‡çš„å›¾åƒç”Ÿæˆã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16: Scalable Diffusion Models with Transformers (DiT)\n\n\n\nGenerative Model\n\nDiffusion Model\n\n\n\nä¸€ç§å°† Transformer æ¶æ„å¼•å…¥æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡åºåˆ—åŒ–å»ºæ¨¡ä¸è§„æ¨¡åŒ–è®­ç»ƒï¼Œåœ¨å¤§æ¨¡å‹ä¸å¤§æ•°æ®è®¾ç½®ä¸‹å®ç°æ›´å¼ºçš„ç”Ÿæˆè´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)\n\n\n\nTransformer\n\n\n\nFlashAttention æ˜¯ä¸€IO-awareçš„exact Attention å®ç°ï¼šå®ƒæŠŠ QKáµ€ å’Œ softmax çš„è®¡ç®—æŒ‰å—ï¼ˆtilingï¼‰æ¬è¿›ç‰‡ä¸Š SRAM/å…±äº«å†…å­˜ï¼Œç”¨**åœ¨çº¿ softmaxï¼ˆç»´æŠ¤ running max ä¸ sum çš„ log-sum-expâ€¦\n\n\n\n\n\n\n\n\nNo matching items\n\n  \n\n Back to top",
    "crumbs": [
      "ğŸ“ 100 AI Papers with Code",
      "About this series"
    ]
  },
  {
    "objectID": "posts/LLM-Series/index.html",
    "href": "posts/LLM-Series/index.html",
    "title": "LLM Model Series Learning Notes",
    "section": "",
    "text": "Qwen Model Series\n\n\nåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ä¸€ç³»åˆ—çš„Qwenæ¨¡å‹ï¼Œæ²¿ç€Qwenæ¨¡å‹çš„å‘å±•æ—¶ï¼Œæ¥çœ‹çœ‹ä¸åŒæ—¶æœŸçš„Qwenæ¨¡å‹è¿ç”¨äº†æ€ä¹ˆæ ·çš„ä¸åŒçš„æŠ€æœ¯\n\n\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html",
    "href": "posts/DLFaC/Chapter01/Chapter01.html",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "",
    "text": "Chapter 01ä¸»è¦ä»‹ç»äº†ä»€ä¹ˆæ˜¯Deep Learningï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å­¦ä¹ Deep Learning çš„åŸå› ã€‚é€šè¿‡å‡ ä¸ªå®é™…çš„ä¾‹å­ï¼Œè¯´æ˜äº†Deep Learning åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ã€‚æœ€åé€šè¿‡ä¸€ä¸ªç®€å•çš„Polynomial Regression ä¾‹å­ï¼Œä»‹ç»äº†Deep Learning æ¨¡å‹è®­ç»ƒçš„åŸºæœ¬æµç¨‹ä»¥åŠç›¸å…³çš„æ¦‚å¿µã€‚ æ¥ä¸‹æ¥è®©æˆ‘ä»¬å…·ä½“çœ‹ä¸€ä¸‹æœ¬ç« çš„å†…å®¹ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#applications-of-deep-learning",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#applications-of-deep-learning",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "1.1 Applications of Deep Learning",
    "text": "1.1 Applications of Deep Learning\næ·±åº¦å­¦ä¹ å·²ç»åœ¨å¤šä¸ªé¢†åŸŸå±•ç°å‡ºäº†å¼ºå¤§çš„èƒ½åŠ›ï¼Œä¹¦ä¸­ä¸¾äº†4ä¸ªç»å…¸çš„ä¾‹å­ï¼š\n\nMedical diagnosisï¼š é€šè¿‡è®­ç»ƒä¸€ä¸ªNeural Networkæ¨¡å‹æ¥åˆ†æåŒ»å­¦å½±åƒæ•°æ®ï¼Œä»è€Œå®ç°å¯¹ç–¾ç—…çš„è‡ªåŠ¨è¯Šæ–­å’Œé¢„æµ‹ã€‚\nProtein structureï¼š é€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥é¢„æµ‹è›‹ç™½è´¨çš„ä¸‰ç»´ç»“æ„ï¼Œä»è€ŒåŠ é€Ÿæ–°è¯çš„ç ”å‘å’Œç”Ÿç‰©å­¦ç ”ç©¶ã€‚\nImage synthesisï¼š é€šè¿‡æ·±åº¦å­¦ä¹ æŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œç”¨äºè‰ºæœ¯åˆ›ä½œã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚\nLarge language modelsï¼ˆLLMï¼‰ï¼š é€šè¿‡è®­ç»ƒå¤§è§„æ¨¡çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå®ç°å¯¹è‡ªç„¶è¯­è¨€çš„ç†è§£å’Œç”Ÿæˆï¼Œç°åœ¨çš„ChatGPTå°±æ˜¯åŸºäºLLMï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå…¶ä»–è®­ç»ƒå¾—åˆ°çš„ã€‚\n\nå…·ä½“çš„ä¾‹å­å†…å®¹åœ¨è¿™é‡Œå°±ä¸å±•å¼€äº†ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒä¹¦ä¸­çš„å†…å®¹ã€‚åœ¨è¿™é‡Œæ•´ç†ä¸€ä¸‹è¿™äº›ä¾‹å­çš„ç›¸åŒç‚¹ä¸ä¸åŒç‚¹ï¼Œå¹¶ä¸”ç”±æ­¤æ€»ç»“ä¸€ä¸‹å¸¸è§çš„æ·±åº¦å­¦ä¹ çš„ä»»åŠ¡ç±»å‹ï¼š\n\n1.1.1 Classification vs.Â Regression\nä¸Šé¢æåˆ°çš„Medical diagnosiså’ŒLarge language modelséƒ½æ˜¯å±äºClassificationä»»åŠ¡ï¼š ç»™å®šè¾“å…¥æ•°æ®ï¼Œæ¨¡å‹éœ€è¦é¢„æµ‹å…¶æ‰€å±çš„ç±»åˆ«æ ‡ç­¾ã€‚ä¾‹å¦‚ï¼ŒMedical diagnosisä¸­æ¨¡å‹éœ€è¦åˆ¤æ–­æ‚£è€…æ˜¯å¦æ‚£æœ‰æŸç§ç–¾ç—…ï¼ŒLarge language modelsä¸­æ¨¡å‹éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„ç±»åˆ«ã€‚ä¸å…¶ç›¸å¯¹çš„ï¼ŒRegressionä»»åŠ¡åˆ™æ˜¯é¢„æµ‹ä¸€ä¸ªè¿ç»­çš„æ•°å€¼ã€‚ä¾‹å¦‚ï¼Œé¢„æµ‹æˆ¿ä»·ã€è‚¡ç¥¨ä»·æ ¼ç­‰ã€‚\nClassificationå’ŒRegressionæ˜¯ç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰ä¸­æœ€å¸¸è§çš„ä¸¤ç§ä»»åŠ¡ç±»å‹ã€‚è€Œç›‘ç£å­¦ä¹ æ˜¯æŒ‡æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦ä½¿ç”¨å¸¦æœ‰æ ‡ç­¾çš„æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚æ¯”å¦‚å¯¹äºMedical diagnosisä»»åŠ¡ï¼Œè®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªåŒ»å­¦å½±åƒéƒ½å¯¹åº”ä¸€ä¸ªç–¾ç—…æ ‡ç­¾ï¼Œæˆ‘ä»¬æœ‰è®­ç»ƒæ•°æ® \\(\\mathcal{D}\\{(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\ldots, (\\mathbf{x}_n, y_n)\\}\\) æ¨¡å‹é€šè¿‡å­¦ä¹ è¿™äº›æ ‡ç­¾æ¥è¿›è¡Œé¢„æµ‹ã€‚ä¸è¿‡ï¼Œä¸Medical diagnosisä¸åŒï¼ŒLarge language modelsçš„è®­ç»ƒæ•°æ®é€šå¸¸æ˜¯æ— æ ‡ç­¾çš„æ–‡æœ¬æ•°æ®ï¼ˆåªæ˜¯ä¸€æ®µæ®µæ–‡å­—ï¼‰ï¼Œä¸è¿‡æˆ‘ä»¬å®é™…æ˜¯æœ‰æ ‡ç­¾çš„ï¼ˆä¸‹ä¸€ä¸ªå•è¯æ˜¯ä»€ä¹ˆï¼‰ï¼Œåªä¸è¿‡æ²¡æœ‰æ˜¾å¼çš„è¡¨ç°å‡ºæ¥ã€‚è¿™ç§é€šè¿‡æ„é€ ä¸€ç§ä»»åŠ¡ï¼ˆPre-text taskï¼‰æ¥è¿›è¡Œè®­ç»ƒçš„æ–¹å¼ï¼Œç§°ä¸ºè‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰ï¼Œä¹Ÿæ˜¯ç›‘ç£å­¦ä¹ çš„ä¸€ç§å½¢å¼ã€‚\n\n\n1.1.2 Generative vs.Â Discriminative Models\nè¦è®ºç°åœ¨æœ€ç«çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œéç”Ÿæˆå¼AIï¼ˆGenerative AIï¼‰è«å±ã€‚ChatGPTã€Midjourneyç­‰éƒ½æ˜¯ç”Ÿæˆå¼æ¨¡å‹çš„å…¸å‹ä»£è¡¨ã€‚ç”Ÿæˆå¼æ¨¡å‹çš„ç›®æ ‡æ˜¯å­¦ä¹ æ•°æ®çš„åˆ†å¸ƒï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆä¸è®­ç»ƒæ•°æ®ç›¸ä¼¼çš„æ–°æ•°æ®ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œç”Ÿæˆå¼è¯­è¨€æ¨¡å‹å¯ä»¥ç”Ÿæˆä¸ä¹‹ç›¸å…³çš„æ–‡æœ¬å†…å®¹ï¼›ç»™å®šä¸€å¼ å›¾åƒï¼Œç”Ÿæˆå¼å›¾åƒæ¨¡å‹å¯ä»¥ç”Ÿæˆä¸ä¹‹ç›¸ä¼¼çš„å›¾åƒã€‚ä¸ä¹‹ç›¸å¯¹çš„ï¼Œåˆ¤åˆ«å¼æ¨¡å‹ï¼ˆDiscriminative Modelsï¼‰åˆ™æ˜¯ç›´æ¥å­¦ä¹ è¾“å…¥æ•°æ®ä¸æ ‡ç­¾ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œä»è€Œè¿›è¡Œåˆ†ç±»æˆ–å›å½’ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼ŒMedical diagnosis, Protein structureç­‰ä»»åŠ¡é€šå¸¸ä½¿ç”¨åˆ¤åˆ«å¼æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚\n\n\n1.1.3 Learning vs.Â Inference\næ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹é€šå¸¸åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå­¦ä¹ ï¼ˆLearningï¼‰å’Œæ¨æ–­ï¼ˆInferenceï¼‰ã€‚å­¦ä¹ é˜¶æ®µæ˜¯æŒ‡æ¨¡å‹é€šè¿‡è®­ç»ƒæ•°æ®è¿›è¡Œå‚æ•°ä¼˜åŒ–ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆæ•°æ®åˆ†å¸ƒã€‚æ¨æ–­é˜¶æ®µåˆ™æ˜¯æŒ‡æ¨¡å‹åœ¨è®­ç»ƒå®Œæˆåï¼Œå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–ç”Ÿæˆçš„è¿‡ç¨‹ã€‚å­¦ä¹ é˜¶æ®µé€šå¸¸éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œè€Œæ¨æ–­é˜¶æ®µåˆ™ç›¸å¯¹è¾ƒå¿«ï¼Œé€‚åˆå®æ—¶åº”ç”¨ã€‚è¿™æœ¬ä¹¦çš„åç»­ç« èŠ‚ä¸»è¦ä»‹ç»å­¦ä¹ é˜¶æ®µçš„å†…å®¹ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„æ„å»ºã€æŸå¤±å‡½æ•°çš„è®¾è®¡ã€ä¼˜åŒ–ç®—æ³•ç­‰ã€‚è€Œæ¨æ–­é˜¶æ®µåˆ™ç›¸å¯¹ç®€å•ï¼Œä¸»è¦æ¶‰åŠæ¨¡å‹çš„éƒ¨ç½²å’Œåº”ç”¨ã€‚\n\n\n1.1.4 Fine-tuning vs.Â From Scratch\nåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒé€šå¸¸æœ‰ä¸¤ç§æ–¹å¼ï¼šä»å¤´å¼€å§‹è®­ç»ƒï¼ˆFrom Scratchï¼‰å’Œå¾®è°ƒï¼ˆFine-tuningï¼‰ã€‚ä»å¤´å¼€å§‹è®­ç»ƒæ˜¯æŒ‡æ¨¡å‹çš„å‚æ•°å…¨éƒ¨éšæœºåˆå§‹åŒ–ï¼Œç„¶åé€šè¿‡è®­ç»ƒæ•°æ®è¿›è¡Œä¼˜åŒ–ã€‚è¿™ç§æ–¹å¼é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚å¾®è°ƒåˆ™æ˜¯æŒ‡åœ¨ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„è®­ç»ƒï¼Œä»è€Œä½¿æ¨¡å‹æ›´å¥½åœ°é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚å¾®è°ƒé€šå¸¸èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒæ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ã€‚å…¶ä¸­ï¼ŒTransfer Learningï¼ˆè¿ç§»å­¦ä¹ ï¼‰æ˜¯ä¸€ç§å¸¸è§çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡å°†é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°æ–°ä»»åŠ¡ä¸­ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#summary-of-deep-learning-applications",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#summary-of-deep-learning-applications",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "1.2 Summary of Deep Learning Applications",
    "text": "1.2 Summary of Deep Learning Applications\né€šè¿‡ä¸Šé¢çš„å‡ ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬åˆæ­¥äº†è§£äº†æ·±åº¦å­¦ä¹ åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ï¼Œä»¥åŠå¸¸è§çš„ä»»åŠ¡ç±»å‹å’Œè®­ç»ƒæ–¹å¼ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºä¸€ç§å¼ºå¤§çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå·²ç»åœ¨åŒ»ç–—è¯Šæ–­ã€è›‹ç™½è´¨ç»“æ„é¢„æµ‹ã€å›¾åƒåˆæˆå’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰å¤šä¸ªé¢†åŸŸå±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚éšç€è®¡ç®—èµ„æºçš„æå‡å’Œæ•°æ®é‡çš„å¢åŠ ï¼Œæ·±åº¦å­¦ä¹ æœ‰æœ›åœ¨æœªæ¥ç»§ç»­æ¨åŠ¨äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œå¸¦æ¥æ›´å¤šåˆ›æ–°å’Œå˜é©ã€‚ä¸ç†è§£è¿™äº›çš„åŒå­¦ä¹Ÿä¸ç”¨æ‹…å¿ƒï¼Œç­‰å¾…åç»­ç« èŠ‚çš„å­¦ä¹ ï¼Œä½ ä¼šå¯¹è¿™äº›æ¦‚å¿µæœ‰æ›´æ·±å…¥çš„ç†è§£ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#datasets",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#datasets",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "2.1 Datasets",
    "text": "2.1 Datasets\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„åˆæˆæ•°æ®é›†ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥å˜é‡ \\(x\\)ï¼Œå…¶å–å€¼èŒƒå›´ä¸º \\([0, 1]\\)ï¼Œè¾“å‡ºå˜é‡ \\(t\\) ä¸è¾“å…¥å˜é‡ä¹‹é—´çš„å…³ç³»ä¸ºä¸€ä¸ªäºŒæ¬¡å¤šé¡¹å¼å‡½æ•°ï¼Œå¹¶ä¸”æ·»åŠ äº†ä¸€äº›éšæœºå™ªå£°ã€‚å…·ä½“æ¥è¯´ï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬ \\((x_i, t_i)\\) æ»¡è¶³ä»¥ä¸‹å…³ç³»ï¼š\n\\[\nt_i= \\sin(2 \\pi x_i) + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, 0.1)\n\\]\nå…¶ä¸­ï¼Œ\\(\\epsilon_i\\) æ˜¯æœä»å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º0.1çš„é«˜æ–¯å™ªå£°ã€‚æˆ‘ä»¬ç”Ÿæˆäº†100ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒæ•°æ®é›†ï¼Œå¦å¤–ç”Ÿæˆäº†50ä¸ªæ ·æœ¬ä½œä¸ºæµ‹è¯•æ•°æ®é›†ã€‚\nä»è¿™ä¸ªæ„é€ çš„è®­ç»ƒæ•°æ®ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°å®ä¸–ç•Œä¸­çš„è®­ç»ƒæ•°æ®çš„æ„å»ºï¼š\n\næ•°æ®é€šå¸¸æ˜¯å¸¦æœ‰å™ªå£°çš„ï¼Œæ¨¡å‹éœ€è¦å­¦ä¼šä»å™ªå£°ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯ã€‚\næˆ‘ä»¬çš„è®­ç»ƒç›®æ ‡æ˜¯å¸Œæœ›æ¨¡å‹å¯ä»¥åœ¨æ²¡æœ‰è§è¿‡çš„æµ‹è¯•æ•°æ®ä¸Šä¹Ÿæœ‰è‰¯å¥½çš„è¡¨ç°ã€‚è¿™å°±æ˜¯æ‰€è°“çš„æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰ã€‚\n\nä»è€Œæˆ‘ä»¬æ„å»ºå‡ºäº†è®­ç»ƒæ•°æ®é›† \\(\\mathcal{D}_{train}=\\{(x_1, t_1), (x_2, t_2), \\ldots, (x_{10}, t_{10})\\}\\) å’Œæµ‹è¯•æ•°æ®é›† \\(\\mathcal{D}_{test}=\\{(x_1, t_1), (x_2, t_2), \\ldots, (x_{50}, t_{50})\\}\\)ã€‚\n\n\n\n\n\n\nFigureÂ 2: 10 ä¸ªè®­ç»ƒæ•°æ®ç‚¹çš„åˆ†å¸ƒæƒ…å†µï¼Œå¯ä»¥çœ‹åˆ°æ•°æ®ç‚¹å¤§è‡´åˆ†å¸ƒåœ¨ \\(\\sin(2 \\pi x)\\) æ›²çº¿é™„è¿‘ï¼Œä½†ç”±äºå™ªå£°çš„å­˜åœ¨ï¼Œæ•°æ®ç‚¹å¹¶ä¸å®Œå…¨åœ¨æ›²çº¿ä¸Šã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#model",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#model",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "2.2 Model",
    "text": "2.2 Model\næœ‰äº†æ•°æ®é›†\\(\\mathcal{D}_{train}\\)ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æ¨¡å‹æ˜¯è®¸å¤šç ”ç©¶çš„æ ¸å¿ƒå†…å®¹ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„Linear Modelæ¥è¿›è¡ŒPolynomial Regressionã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªäºŒæ¬¡å¤šé¡¹å¼æ¨¡å‹æ¥æ‹Ÿåˆæ•°æ®ï¼š\n\\[\ny(x, \\mathbf{w}) = w_0 + w_1 x + w_2 x^2 + \\ldots + w_M x^M = \\sum_{j=0}^{M} w_j x^j\n\\]\nå…¶ä¸­ï¼Œ\\(\\mathbf{w} = [w_0, w_1, \\ldots, w_M]^T\\) æ˜¯æ¨¡å‹çš„å‚æ•°å‘é‡ï¼Œ\\(M\\) æ˜¯å¤šé¡¹å¼çš„é˜¶æ•°ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹© \\(M=9\\)ï¼Œå³ä½¿ç”¨ä¸€ä¸ª9æ¬¡å¤šé¡¹å¼æ¨¡å‹æ¥æ‹Ÿåˆæ•°æ®ã€‚\n\n\n\n\n\n\nWhy called Linear Model?\n\n\n\nè™½ç„¶è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªå¤šé¡¹å¼æ¨¡å‹ï¼Œä½†å®ƒä»ç„¶è¢«ç§°ä¸ºçº¿æ€§æ¨¡å‹ï¼ˆLinear Modelï¼‰ï¼Œå› ä¸ºå®ƒåœ¨å‚æ•° \\(\\mathbf{w}\\) ä¸Šæ˜¯çº¿æ€§çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹çš„è¾“å‡º \\(y(x, \\mathbf{w})\\) æ˜¯å‚æ•° \\(\\mathbf{w}\\) çš„çº¿æ€§ç»„åˆï¼Œè€Œä¸æ˜¯è¾“å…¥å˜é‡ \\(x\\) çš„çº¿æ€§ç»„åˆã€‚è¿™ç§çº¿æ€§æ€§è´¨ä½¿å¾—æ¨¡å‹çš„è®­ç»ƒå’Œä¼˜åŒ–æ›´åŠ ç®€å•å’Œé«˜æ•ˆã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#loss-function-optimization",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#loss-function-optimization",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "2.3 Loss Function & Optimization",
    "text": "2.3 Loss Function & Optimization\næœ‰äº†æ¨¡å‹ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰æ¥è¡¡é‡æ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨Sum of Squared Errors (SSE) ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š\n\\[\nE(\\mathbf{w}) = \\frac{1}{2} \\sum_{i=1}^{N} (y(x_i, \\mathbf{w}) - t_i)^2\n\\]\nå…¶ä¸­ï¼Œ\\(N\\) æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ï¼Œ\\(y(x_i, \\mathbf{w})\\) æ˜¯æ¨¡å‹å¯¹è¾“å…¥ \\(x_i\\) çš„é¢„æµ‹ç»“æœï¼Œ\\(t_i\\) æ˜¯å¯¹åº”çš„çœŸå®æ ‡ç­¾ã€‚æŸå¤±å‡½æ•° \\(E(\\mathbf{w})\\) è¡¡é‡äº†æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œç›®æ ‡æ˜¯é€šè¿‡è°ƒæ•´å‚æ•° \\(\\mathbf{w}\\) æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆæ•°æ®ã€‚\\(\\frac{1}{2}\\) æ˜¯ä¸ºäº†åœ¨åç»­è®¡ç®—æ¢¯åº¦æ—¶æ›´åŠ æ–¹ä¾¿ã€‚\næˆ‘ä»¬å¸Œæœ›é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•° \\(E(\\mathbf{w})\\)ï¼Œä½¿å¾—æ¨¡å‹çš„é¢„æµ‹ç»“æœå°½å¯èƒ½æ¥è¿‘çœŸå®æ ‡ç­¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çŸ¥é“ \\(E(\\mathbf{w})\\) æ˜¯ \\(\\mathbf{w}\\) çš„å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼˜åŒ–ç®—æ³•æ¥è°ƒæ•´å‚æ•° \\(\\mathbf{w}\\)ï¼Œä½¿å¾—æŸå¤±å‡½æ•°è¾¾åˆ°æœ€å°å€¼ã€‚åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è§£æè§£ï¼ˆAnalytical Solutionï¼‰æ¥ç›´æ¥è®¡ç®—å‡ºæœ€ä¼˜å‚æ•° \\(\\mathbf{w}^*\\)ï¼Œå› ä¸ºæŸå¤±å‡½æ•°æ˜¯ä¸€ä¸ªå…³äº \\(\\mathbf{w}\\) çš„äºŒæ¬¡å‡½æ•°ï¼Œå…·æœ‰å”¯ä¸€çš„å…¨å±€æœ€å°å€¼ï¼ˆé«˜ä¸­çŸ¥è¯†ï¼Œ äºŒæ¬¡å‡½æ•°çš„å›¾åƒæ˜¯ä¸€ä¸ªæŠ›ç‰©çº¿ï¼Œå–å…¶å¯¼æ•°ä¸º0çš„ç‚¹ ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæœ€ä¼˜å‚æ•° \\(\\mathbf{w}^*\\) å¯ä»¥é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—å¾—åˆ°ï¼š \\[\n\\mathbf{w}^* = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf{t}\n\\]\nï¼Œ ä½†åœ¨ç°å®ä¸­ é€šå¸¸ä¼šä½¿ç”¨æ•°å€¼ä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æ¥è¿›è¡Œå‚æ•°ä¼˜åŒ–ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#model-complexity-model-selection",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#model-complexity-model-selection",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "2.4 Model Complexity & Model Selection",
    "text": "2.4 Model Complexity & Model Selection\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ¨¡å‹åœ¨æµ‹è¯•é›† \\(\\mathcal{D}_{test}\\) ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬å¯ä»¥è®¡ç®—æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡æ–¹è¯¯å·®ï¼ˆMean Squared Error, MSEï¼‰æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼š \\[\n\\text{MSE} = \\frac{1}{N_{test}} \\sum_{i=1}^{N_{test}} (y(x_i, \\mathbf{w}^*) - t_i)^2\n\\] å…¶ä¸­ï¼Œ\\(N_{test}\\) æ˜¯æµ‹è¯•æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ï¼Œ\\(y(x_i, \\mathbf{w}^*)\\) æ˜¯æ¨¡å‹å¯¹è¾“å…¥ \\(x_i\\) çš„é¢„æµ‹ç»“æœï¼Œ\\(t_i\\) æ˜¯å¯¹åº”çš„çœŸå®æ ‡ç­¾ã€‚é€šè¿‡è®¡ç®—MSEï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„è¡¨ç°ï¼Œä»è€Œåˆ¤æ–­æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\nMake accurate predictions on previously unseen inputs is a key goal in machine learning and is known as generalization.  Deep Learning Foundations and Concepts, p.6 \n\nTrain Set:\n  SSE of Train Set: 0.0000\n  RMSE of Train Set: 0.0000\nTest Set:  \n  SSE of Test Set: 9.0839  \n  RMSE of Test Set: 0.4262  \n\n\n\n\n\n\nFigureÂ 3\n\n\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°éå¸¸å¥½ï¼Œå‡ ä¹æ²¡æœ‰è¯¯å·®ï¼ˆSSEå’ŒRMSEéƒ½æ¥è¿‘äº0ï¼‰ã€‚ä½†æ˜¯åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å°±å·®å¾ˆå¤šäº†ï¼ŒSSEè¾¾åˆ°äº†9.0839ï¼ŒRMSEä¹Ÿè¾¾åˆ°äº†0.4262ã€‚è¿™è¯´æ˜æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆï¼ˆOverfittingï¼‰äº†ï¼Œæ— æ³•å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„æ•°æ®ä¸Šã€‚è¿™å°±æ˜¯æ¨¡å‹å¤æ‚åº¦ï¼ˆModel Complexityï¼‰å’Œæ¨¡å‹é€‰æ‹©ï¼ˆModel Selectionï¼‰çš„é—®é¢˜ã€‚\næˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªæ¨¡å‹å¯¹äºæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®æ¥è¯´ï¼Œè¿‡äºçš„å¤æ‚ï¼Œå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°å¾ˆå·®ã€‚å¯¹äºå¤æ‚çš„æ¨¡å‹ï¼Œå…¶ä¸­ä¸€ä¸ªæ–¹æ³•å°±æ˜¯å¢åŠ è®­ç»ƒæ•°æ®çš„æ•°é‡\n\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ª9æ¬¡å¤šé¡¹å¼æ¨¡å‹æ¥æ‹Ÿåˆæ•°æ®ï¼Œè¿™ä¸ªæ¨¡å‹çš„å¤æ‚åº¦è¾ƒé«˜ï¼Œå®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚ä¸ºäº†æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹ï¼ˆå¦‚ä½é˜¶å¤šé¡¹å¼ï¼‰æˆ–è€…å¼•å…¥æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰æ¥æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ã€‚\n\n2.4.1 Regularization\næˆ‘ä»¬å¯ä»¥çœ‹çœ‹ \\(\\mathbf{w}\\) çš„å€¼ï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nw0\nw1\nw2\nw3\nw4\nw5\nw6\nw7\nw8\nw9\n\n\n\n\n0.113824\n4.405167\n94.162776\n-1514.731222\n9498.903764\n-31346.008432\n58321.808397\n-61525.006624\n34368.919801\n-7902.500007\n\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹çš„å‚æ•°å˜åŒ–éå¸¸å¤§ï¼Œè¿™ä¹Ÿæ˜¯è¿‡æ‹Ÿåˆçš„ä¸€ä¸ªè¡¨ç°ã€‚æ¨¡å‹ç›¸å½“äºâ€œå®šåˆ¶â€äº†è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°ï¼Œä»è€Œå¯¼è‡´åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°å¾ˆå·®ã€‚ä¸ºäº†ç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥æ­£åˆ™åŒ–é¡¹ï¼ˆRegularization Termï¼‰æ¥æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ã€‚å¸¸è§çš„æ­£åˆ™åŒ–æ–¹æ³•æœ‰L2æ­£åˆ™åŒ–ï¼ˆRidge Regressionï¼‰å’ŒL1æ­£åˆ™åŒ–ï¼ˆLasso Regressionï¼‰ã€‚ä»¥L2æ­£åˆ™åŒ–ä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æŸå¤±å‡½æ•°ä¿®æ”¹ä¸ºï¼š \\[\nE_{reg}(\\mathbf{w}) = \\frac{1}{2} \\sum_{i=1}^{N} (y(x_i, \\mathbf{w}) - t_i)^2 + \\frac{\\lambda}{2} \\sum_{j=0}^{M} w_j^2\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nw0\nw1\nw2\nw3\nw4\nw5\nw6\nw7\nw8\nw9\n\n\n\n\n0.607766\n3.463379\n-11.168293\n-1.675222\n3.747767\n4.911149\n3.725974\n1.447197\n-1.24926\n-4.015138\n\n\n\n\nå¯ä»¥çœ‹åˆ°ï¼Œå¼•å…¥æ­£åˆ™åŒ–é¡¹åï¼Œæ¨¡å‹çš„å‚æ•°å˜å¾—æ›´åŠ å¹³æ»‘ï¼Œå˜åŒ–èŒƒå›´ä¹Ÿå˜å°äº†ã€‚è¿™æœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘è¿‡æ‹Ÿåˆçš„é£é™©ã€‚\n\n\n\n\n\n\nFigureÂ 4\n\n\n\nä½†æ˜¯è¦é€‰æ‹©åˆé€‚çš„æ­£åˆ™åŒ–å‚æ•° \\(\\lambda\\) ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è¿‡å¤§çš„ \\(\\lambda\\) ä¼šå¯¼è‡´æ¨¡å‹æ¬ æ‹Ÿåˆï¼ˆUnderfittingï¼‰ï¼Œè€Œè¿‡å°çš„ \\(\\lambda\\) åˆ™æ— æ³•æœ‰æ•ˆåœ°æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡äº¤å‰éªŒè¯ï¼ˆCross Validationï¼‰ç­‰æ–¹æ³•æ¥é€‰æ‹©åˆé€‚çš„æ­£åˆ™åŒ–å‚æ•°ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\nå½“æˆ‘ä»¬å–çš„åˆ°åˆé€‚çš„æ­£åˆ™åŒ–å‚æ•° \\(\\lambda\\) åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°æœ‰äº†æ˜¾è‘—çš„æå‡ï¼š\n\n\n\n\n\n\nFigureÂ 5\n\n\n\n\n\n2.4.2 Cross Validation\næƒ³è¿™ç§é€‰æ‹© \\(M\\) å’Œ \\(\\lambda\\) çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºæ¨¡å‹é€‰æ‹©ï¼ˆModel Selectionï¼‰ã€‚æ¨¡å‹é€‰æ‹©çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªæ—¢èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œåˆèƒ½åœ¨æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½çš„æ¨¡å‹ã€‚å¸¸è§çš„æ¨¡å‹é€‰æ‹©æ–¹æ³•æœ‰äº¤å‰éªŒè¯ï¼ˆCross Validationï¼‰ã€ä¿¡æ¯å‡†åˆ™ï¼ˆInformation Criteriaï¼‰ç­‰ã€‚\nåœ¨è¿™é‡Œæˆ‘ä»¬ä»‹ç»æœ€å¸¸è§çš„Cross Validationã€‚Cross Validationæ˜¯ä¸€ç§è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æ–¹æ³•ï¼Œé€šè¿‡å°†è®­ç»ƒæ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªå­é›†ï¼Œä¾æ¬¡ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªå­é›†ä½œä¸ºéªŒè¯é›†ï¼Œå…¶ä»–å­é›†ä½œä¸ºè®­ç»ƒé›†ï¼Œæ¥è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡å¤šæ¬¡é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¨¡å‹åœ¨ä¸åŒéªŒè¯é›†ä¸Šçš„å¹³å‡è¡¨ç°ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n\n\n\n\n\nFigureÂ 6\n\n\n\n\n\n\n\n\n\nFigureÂ 7\n\n\n\n\n\n\n\n\n\nFigureÂ 8\n\n\n\næ˜¾ç„¶ï¼ŒCross Validation å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°é€‰æ‹©æ¨¡å‹çš„å¤æ‚åº¦å‚æ•° \\(M\\) å’Œæ­£åˆ™åŒ–å‚æ•° \\(\\lambda\\)ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å½“å®ƒä¹Ÿå­˜åœ¨ä¸€ä¸ªæ˜æ˜¾çš„ç¼ºç‚¹ï¼Œå°±æ˜¯è®¡ç®—å¼€é”€è¾ƒå¤§ï¼šå¯¹äºæ¯ä¸€ç»„å‚æ•°ç»„åˆï¼Œæˆ‘ä»¬éƒ½éœ€è¦è¿›è¡Œå¤šæ¬¡è®­ç»ƒå’Œè¯„ä¼°ï¼Œè¿™å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†å’Œå¤æ‚æ¨¡å‹æ¥è¯´ï¼Œå¯èƒ½ä¼šéå¸¸è€—æ—¶ã€‚å› æ­¤åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æ ¹æ®ç»éªŒå’Œå…ˆéªŒçŸ¥è¯†æ¥ç¼©å°å‚æ•°æœç´¢ç©ºé—´ï¼Œä»è€Œå‡å°‘è®¡ç®—å¼€é”€ã€‚\n\n\n\n\n\n\nNote\n\n\n\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆï¼Œå¥½å¤šäººç§°æ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªå®éªŒæ€§å¾ˆå¼ºçš„é¢†åŸŸã€‚å› ä¸ºå¾ˆå¤šæ¨¡å‹çš„è¶…å‚æ•°ï¼ˆHyper-parametersï¼‰æ˜¯éœ€è¦é€šè¿‡å®éªŒæ¥è°ƒä¼˜çš„ã€‚å¤§å®¶éƒ½æŠŠè¿™ä¸ªè¿‡ç¨‹å«åšç‚¼ä¸¹ï¼Œå› ä¸ºè¿™ä¸ªè¿‡ç¨‹å°±åƒç‚¼ä¸¹ä¸€æ ·ï¼Œéœ€è¦ä¸æ–­åœ°è¯•éªŒå’Œè°ƒæ•´ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€ä¼˜çš„é…æ–¹ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#model-training-summary",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#model-training-summary",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "2.5 Model Training Summary",
    "text": "2.5 Model Training Summary\né€šè¿‡è¿™ä¸ªç®€å•çš„Polynomial Regressionä¾‹å­ï¼Œæˆ‘ä»¬äº†è§£äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ•´ä¸ªè¿‡ç¨‹ï¼š\n\næ„å»ºæ•°æ®é›†ï¼šæ”¶é›†å’Œå‡†å¤‡è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ã€‚\nå®šä¹‰æ¨¡å‹ï¼šé€‰æ‹©åˆé€‚çš„æ¨¡å‹ç»“æ„å’Œå‚æ•°ã€‚åˆé€‚çš„æ¨¡å‹ç»“æ„èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰æ•°æ®çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„è¡¨ç°ã€‚\nå®šä¹‰æŸå¤±å‡½æ•°ï¼šé€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°æ¥è¡¡é‡æ¨¡å‹çš„è¡¨ç°ã€‚\nä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼šä½¿ç”¨ä¼˜åŒ–ç®—æ³•æ¥è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–ã€‚\nè¯„ä¼°æ¨¡å‹è¡¨ç°ï¼šä½¿ç”¨æµ‹è¯•æ•°æ®æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\nä¸‡å˜ä¸ç¦»å…¶å®—ï¼Œæ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒå°±æ˜¯é€šè¿‡æ„å»ºåˆé€‚çš„æ¨¡å‹å’Œä¼˜åŒ–ç®—æ³•ï¼Œä»æ•°æ®ä¸­å­¦ä¹ æœ‰ç”¨çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œå®ç°å¯¹å¤æ‚ä»»åŠ¡çš„è§£å†³ã€‚å“ªæ€•æ˜¯ç°åœ¨çš„LLMæ¨¡å‹ï¼Œå…¶å®ä¹Ÿæ˜¯éµå¾ªè¿™ä¸ªåŸºæœ¬æµç¨‹ï¼Œåªä¸è¿‡æ¨¡å‹ç»“æ„æ›´åŠ å¤æ‚ï¼Œä¼˜åŒ–ç®—æ³•æ›´åŠ å…ˆè¿›ï¼Œæ•°æ®é‡ä¹Ÿæ›´åŠ åºå¤§ç½¢äº†ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#preceptron",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#preceptron",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "3.1 Preceptron",
    "text": "3.1 Preceptron\næ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰æ˜¯ç”±Frank Rosenblattåœ¨1958å¹´æå‡ºçš„ä¸€ç§ç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å®ƒæ˜¯æœ€æ—©çš„ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œä¸»è¦ç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ã€‚æ„ŸçŸ¥æœºçš„åŸºæœ¬ç»“æ„åŒ…æ‹¬è¾“å…¥å±‚ã€æƒé‡ã€åç½®å’Œæ¿€æ´»å‡½æ•°ã€‚å…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š\n\nè¾“å…¥å±‚ï¼šæ„ŸçŸ¥æœºæ¥æ”¶å¤šä¸ªè¾“å…¥ä¿¡å·ï¼Œæ¯ä¸ªè¾“å…¥ä¿¡å·å¯¹åº”ä¸€ä¸ªæƒé‡ã€‚\næƒé‡å’Œåç½®ï¼šæ¯ä¸ªè¾“å…¥ä¿¡å·ä¹˜ä»¥å¯¹åº”çš„æƒé‡ï¼Œç„¶åå°†æ‰€æœ‰åŠ æƒè¾“å…¥ä¿¡å·ç›¸åŠ ï¼Œå†åŠ ä¸Šä¸€ä¸ªåç½®é¡¹ã€‚\næ¿€æ´»å‡½æ•°ï¼šå°†åŠ æƒå’Œé€šè¿‡ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆé€šå¸¸æ˜¯é˜¶è·ƒå‡½æ•°ï¼‰ï¼Œå¦‚æœç»“æœå¤§äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™è¾“å‡º1ï¼Œå¦åˆ™è¾“å‡º0ã€‚\nå­¦ä¹ è¿‡ç¨‹ï¼šæ„ŸçŸ¥æœºé€šè¿‡è°ƒæ•´æƒé‡å’Œåç½®æ¥æœ€å°åŒ–é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„è¯¯å·®ï¼Œä»è€Œå­¦ä¹ è¾“å…¥æ•°æ®ä¸è¾“å‡ºæ ‡ç­¾ä¹‹é—´çš„å…³ç³»ã€‚\n\nå…¶ä¸­æ¿€æ´»å‡½æ•°é€šå¸¸ä½¿ç”¨é˜¶è·ƒå‡½æ•°ï¼ˆStep Functionï¼‰ï¼š \\[\nf(z) = \\begin{cases}\n1, & \\text{if } z \\geq 0 \\\\\n0, & \\text{if } z &lt; 0\n\\end{cases}\n\\]\næ„ŸçŸ¥æœºçš„æå‡ºå±•ç¤ºäº†ç¥ç»ç½‘ç»œåœ¨æ¨¡å¼è¯†åˆ«ä¸­çš„æ½œåŠ›ï¼Œç„¶è€Œå®ƒä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚ä¾‹å¦‚ï¼Œå•å±‚æ„ŸçŸ¥æœºåªèƒ½è§£å†³çº¿æ€§å¯åˆ†çš„é—®é¢˜ï¼Œæ— æ³•å¤„ç†éçº¿æ€§é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶äººå‘˜å¼•å…¥äº†å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMulti-Layer Perceptron, MLPï¼‰ï¼Œé€šè¿‡å¢åŠ éšè—å±‚æ¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#feed-forward-neural-networks",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#feed-forward-neural-networks",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "3.2 Feed Forward Neural Networks",
    "text": "3.2 Feed Forward Neural Networks\nPreceptronçš„å±€é™æ€§ä¿ƒä½¿ç ”ç©¶äººå‘˜æ¢ç´¢æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œç»“æ„ã€‚1986å¹´ï¼ŒRumelhartç­‰äººæå‡ºäº†åå‘ä¼ æ’­ç®—æ³•ï¼ˆBackpropagationï¼‰ï¼Œä½¿å¾—å¤šå±‚ç¥ç»ç½‘ç»œçš„è®­ç»ƒæˆä¸ºå¯èƒ½ã€‚ä¸»è¦çš„å˜åŒ–åŒ…æ‹¬ï¼š\n\nå¼•å…¥Differential Calculusï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥è®¡ç®—æŸå¤±å‡½æ•°å¯¹äºæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚\nåº”ç”¨äº†Gradient-Based Optimization æ–¹æ³•ï¼ˆå¦‚ Stochastic Gradient Descent, SGDï¼‰ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»è€Œæœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚\nä½¿ç”¨äº†éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå¦‚Sigmoid, ReLUï¼‰ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ•æ‰å¤æ‚çš„éçº¿æ€§å…³ç³»ã€‚\n\nè¿™äº›æ”¹è¿›ä½¿å¾—å¤šå±‚ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆå¤æ‚çš„æ•°æ®åˆ†å¸ƒï¼Œæ¨åŠ¨äº†ç¥ç»ç½‘ç»œç ”ç©¶çš„å‘å±•ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter01/Chapter01.html#deep-neural-networks",
    "href": "posts/DLFaC/Chapter01/Chapter01.html#deep-neural-networks",
    "title": "Chapter 01: Introduction to the Deep Learning",
    "section": "3.3 Deep Neural Networks",
    "text": "3.3 Deep Neural Networks\néšç€è®¡ç®—èƒ½åŠ›çš„æå‡å’Œå¤§è§„æ¨¡æ•°æ®é›†çš„å‡ºç°ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDeep Neural Networks, DNNsï¼‰åœ¨21ä¸–çºªåˆå¾—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚2006å¹´ï¼ŒHintonç­‰äººæå‡ºäº†æ·±åº¦ç½®ä¿¡ç½‘ç»œï¼ˆDeep Belief Networks, DBNsï¼‰ï¼Œé€šè¿‡æ— ç›‘ç£é¢„è®­ç»ƒæ¥åˆå§‹åŒ–æ·±åº¦ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œä»è€Œç¼“è§£äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚éšåï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networks, CNNsï¼‰åœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œç‰¹åˆ«æ˜¯2012å¹´AlexNetåœ¨ImageNetç«èµ›ä¸­çš„èƒœåˆ©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ çš„å´›èµ·ã€‚å…¶åŸºæœ¬çš„æ¦‚å¿µä¸FFNNç±»ä¼¼ï¼Œåªä¸è¿‡å¼•å…¥äº†å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰å’Œæ± åŒ–å±‚ï¼ˆPooling Layerï¼‰ï¼Œä»è€Œæ›´å¥½åœ°å¤„ç†å›¾åƒæ•°æ®ã€‚\néšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼Œä¸åŒçš„æŠ€æœ¯çš„æå‡ºï¼Œæ¯”å¦‚Auto-Differentiation ç­‰ï¼Œä½¿å¾—è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œå˜å¾—æ›´åŠ é«˜æ•ˆå’Œä¾¿æ·ã€‚ç”±æ­¤ä¹Ÿå‚¬ç”Ÿå‡ºäº†è®¸å¤šä¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œå¦‚å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networks, RNNsï¼‰ï¼ŒTransformeräºå¤„ç†åºåˆ—æ•°æ®ï¼Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGenerative Adversarial Networks, GANsï¼‰ç”¨äºç”Ÿæˆä»»åŠ¡ç­‰ã€‚\nå¯ä»¥çœ‹åˆ°ï¼Œäººå·¥æ™ºèƒ½çš„æˆåŠŸä¸æ˜¯ä¸€è¹´è€Œå°±çš„ï¼Œè€Œæ˜¯ç»å†äº†å¤šä¸ªé˜¶æ®µçš„å‘å±•å’Œç§¯ç´¯ã€‚æ¯ä¸€ä¸ªé‡è¦çš„çªç ´éƒ½ç¦»ä¸å¼€å‰äººçš„åŠªåŠ›å’Œåˆ›æ–°ã€‚é€šè¿‡äº†è§£æ·±åº¦å­¦ä¹ çš„å‘å±•å†å²ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ç†è§£å…¶ç°çŠ¶å’Œæœªæ¥è¶‹åŠ¿ï¼Œä¸ºè¿›ä¸€æ­¥çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 01: Introduction"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter02/Chapter02.html",
    "href": "posts/DLFaC/Chapter02/Chapter02.html",
    "title": "Chapter 02: Probabilities & Information Theory",
    "section": "",
    "text": "åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šé‡åˆ°ä¸ç¡®å®šæ€§çš„é—®é¢˜ã€‚æ¦‚ç‡è®ºä¸ºæˆ‘ä»¬æä¾›äº†ä¸€å¥—å·¥å…·ï¼Œç”¨äºé‡åŒ–å’Œå¤„ç†è¿™ç§ä¸ç¡®å®šæ€§ã€‚ä¿¡æ¯è®ºåˆ™å¸®åŠ©æˆ‘ä»¬ç†è§£ä¿¡æ¯çš„ä¼ é€’å’Œå­˜å‚¨æ–¹å¼ã€‚åœ¨æœ¬ç« ä¸­ä»‹ç»äº†è¿™äº›åŸºæœ¬æ¦‚å¿µï¼Œä¸ºåç»­ç« èŠ‚çš„å­¦ä¹ æ‰“ä¸‹äº†åšå®çš„åŸºç¡€ã€‚å…¶ä¸­ï¼Œä¸ç¡®å®šå¯ä»¥å¤§è‡´åˆ†ä¸ºä¸¤ç±»ï¼š\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¦‚ç‡è®ºå’Œä¿¡æ¯è®ºçš„å·¥å…·æ¥é‡åŒ–å’Œå¤„ç†è¿™äº›ä¸ç¡®å®šæ€§ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚é¦–å…ˆæˆ‘ä»¬å¦‚ä½•å®šä¹‰ Probability å‘¢ï¼Ÿä»é¢‘ç‡å­¦æ´¾ï¼ˆFrequentist Viewï¼‰çš„è§’åº¦æ¥çœ‹ï¼Œæ¦‚ç‡å¯ä»¥è¢«å®šä¹‰ä¸ºåœ¨å¤§é‡é‡å¤å®éªŒä¸­æŸä¸€äº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéšæœºå˜é‡ \\(X\\)ï¼Œå®ƒå¯ä»¥å–å€¼ \\(x_1, x_2, \\ldots, x_n\\)ï¼Œé‚£ä¹ˆäº‹ä»¶ \\(X = x_i\\) çš„æ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºï¼š\\[\nP(X = x_i) = \\lim_{N \\to \\infty} \\frac{N_i}{N}\n\\]å…¶ä¸­ï¼Œ\\(N\\) æ˜¯å®éªŒçš„æ€»æ¬¡æ•°ï¼Œ\\(N_i\\) æ˜¯äº‹ä»¶ \\(X = x_i\\) å‘ç”Ÿçš„æ¬¡æ•°ã€‚ è¿™ç§å®šä¹‰å¼ºè°ƒäº†æ¦‚ç‡çš„å®¢è§‚æ€§ï¼Œå³æ¦‚ç‡æ˜¯é€šè¿‡å®é™…è§‚å¯Ÿå’Œå®éªŒå¾—å‡ºçš„ã€‚ç„¶è€Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€æ— æ³•è¿›è¡Œæ— é™æ¬¡çš„å®éªŒï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•æ¥ä¼°è®¡æ¦‚ç‡åˆ†å¸ƒã€‚ å¦ä¸€æ–¹é¢ï¼Œè´å¶æ–¯å­¦æ´¾ï¼ˆBayesian Viewï¼‰åˆ™å°†æ¦‚ç‡è§†ä¸ºå¯¹äº‹ä»¶å‘ç”Ÿçš„ä¸ç¡®å®šæ€§çš„ä¸»è§‚åº¦é‡ã€‚æ ¹æ®è´å¶æ–¯è§‚ç‚¹ï¼Œæ¦‚ç‡åæ˜ äº†æˆ‘ä»¬å¯¹æŸä¸€äº‹ä»¶å‘ç”Ÿçš„ä¿¡å¿µç¨‹åº¦ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºé¢‘ç‡ã€‚è´å¶æ–¯å®šç†æ˜¯è´å¶æ–¯å­¦æ´¾çš„æ ¸å¿ƒï¼Œå®ƒæè¿°äº†å¦‚ä½•æ ¹æ®æ–°çš„è¯æ®æ›´æ–°æˆ‘ä»¬çš„ä¿¡å¿µã€‚è´å¶æ–¯å®šç†å¯ä»¥è¡¨ç¤ºä¸ºï¼š\\[\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]å…¶ä¸­ï¼Œ\\(P(A|B)\\) æ˜¯åœ¨äº‹ä»¶ \\(B\\) å‘ç”Ÿçš„æ¡ä»¶ä¸‹äº‹ä»¶ \\(A\\) å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\\(P(B|A)\\) æ˜¯åœ¨äº‹ä»¶ \\(A\\) å‘ç”Ÿçš„æ¡ä»¶ä¸‹äº‹ä»¶ \\(B\\) å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\\(P(A)\\) æ˜¯äº‹ä»¶ \\(A\\) çš„å…ˆéªŒæ¦‚ç‡ï¼Œ\\(P(B)\\) æ˜¯äº‹ä»¶ \\(B\\) çš„è¾¹é™…æ¦‚ç‡ã€‚ è´å¶æ–¯æ–¹æ³•å…è®¸æˆ‘ä»¬ç»“åˆå…ˆéªŒçŸ¥è¯†å’Œè§‚å¯Ÿæ•°æ®ï¼Œä»è€Œæ›´çµæ´»åœ°å¤„ç†ä¸ç¡®å®šæ€§é—®é¢˜ã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œè´å¶æ–¯æ–¹æ³•è¢«å¹¿æ³›åº”ç”¨äºæ¨¡å‹é€‰æ‹©ã€å‚æ•°ä¼°è®¡å’Œä¸ç¡®å®šæ€§é‡åŒ–ç­‰æ–¹é¢ã€‚\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å…·ä½“æ¥çœ‹ä¸€ä¸‹æ¦‚ç‡è®º",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 02: Probability and Information Theory"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter02/Chapter02.html#sum-rule",
    "href": "posts/DLFaC/Chapter02/Chapter02.html#sum-rule",
    "title": "Chapter 02: Probabilities & Information Theory",
    "section": "1.1 Sum Rule",
    "text": "1.1 Sum Rule\nSum Rule ç”¨äºè®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­çš„è¾¹é™…æ¦‚ç‡ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªéšæœºå˜é‡ \\(X\\) å’Œ \\(Y\\)ï¼Œå®ƒä»¬çš„è”åˆæ¦‚ç‡åˆ†å¸ƒä¸º \\(P(X, Y)\\)ã€‚æ ¹æ® Sum Ruleï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹å¦ä¸€ä¸ªå˜é‡è¿›è¡Œæ±‚å’Œæ¥è®¡ç®—è¾¹é™…æ¦‚ç‡ï¼š \\[\nP(X) = \\sum_{y} P(X, Y = y)\n\\]\nå¯¹äºè¿ç»­éšæœºå˜é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨ç§¯åˆ†æ¥ä»£æ›¿æ±‚å’Œï¼š\n\\[\nP(X) = \\int P(X, Y = y) dy\n\\]\nSum Rule çš„ç›´è§‚ç†è§£æ˜¯ï¼Œé€šè¿‡è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„ \\(Y\\) çš„å–å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ° \\(X\\) çš„æ€»æ¦‚ç‡ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 02: Probability and Information Theory"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter02/Chapter02.html#product-rule",
    "href": "posts/DLFaC/Chapter02/Chapter02.html#product-rule",
    "title": "Chapter 02: Probabilities & Information Theory",
    "section": "1.2 Product Rule",
    "text": "1.2 Product Rule\nProduct Rule ç”¨äºè®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­çš„æ¡ä»¶æ¦‚ç‡ã€‚æ ¹æ® Product Ruleï¼Œè”åˆæ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºæ¡ä»¶æ¦‚ç‡å’Œè¾¹é™…æ¦‚ç‡çš„ä¹˜ç§¯ï¼š \\[\nP(X, Y) = P(X|Y) \\cdot P(Y)\n\\] åŒæ ·åœ°ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥äº¤æ¢ \\(X\\) å’Œ \\(Y\\) çš„ä½ç½®ï¼š \\[\nP(X, Y) = P(Y|X) \\cdot P(X)\n\\]\nProduct Rule çš„ç›´è§‚ç†è§£æ˜¯ï¼Œè”åˆäº‹ä»¶ \\(X\\) å’Œ \\(Y\\) çš„æ¦‚ç‡å¯ä»¥é€šè¿‡å…ˆè®¡ç®— \\(Y\\) å‘ç”Ÿçš„æ¦‚ç‡ï¼Œç„¶ååœ¨ \\(Y\\) å·²ç»å‘ç”Ÿçš„æ¡ä»¶ä¸‹è®¡ç®— \\(X\\) å‘ç”Ÿçš„æ¦‚ç‡æ¥å¾—åˆ°ã€‚\nå½“ç„¶ï¼Œç»“åˆ Sum Rule å’Œ Product Ruleï¼Œæˆ‘ä»¬å¯ä»¥æ¨å¯¼å‡ºæ›´å¤šå¤æ‚çš„æ¦‚ç‡å…³ç³»ï¼Œä¾‹å¦‚è´å¶æ–¯å®šç†ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 02: Probability and Information Theory"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter02/Chapter02.html#bayes-theorem",
    "href": "posts/DLFaC/Chapter02/Chapter02.html#bayes-theorem",
    "title": "Chapter 02: Probabilities & Information Theory",
    "section": "1.3 Bayesâ€™ Theorem",
    "text": "1.3 Bayesâ€™ Theorem\nè´å¶æ–¯å®šç†æ˜¯æ¦‚ç‡è®ºä¸­çš„ä¸€ä¸ªé‡è¦å®šç†ï¼Œå®ƒæè¿°äº†å¦‚ä½•æ ¹æ®æ–°çš„è¯æ®æ›´æ–°æˆ‘ä»¬çš„ä¿¡å¿µã€‚è´å¶æ–¯å®šç†å¯ä»¥è¡¨ç¤ºä¸ºï¼š \\[\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\] å…¶ä¸­ï¼Œ\\(P(A|B)\\) æ˜¯åœ¨äº‹ä»¶ \\(B\\) å‘ç”Ÿçš„æ¡ä»¶ä¸‹äº‹ä»¶ \\(A\\) å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\\(P(B|A)\\) æ˜¯åœ¨äº‹ä»¶ $A å‘ç”Ÿçš„æ¡ä»¶ä¸‹äº‹ä»¶ \\(B\\) å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\\(P(A)\\) æ˜¯äº‹ä»¶ \\(A\\) çš„å…ˆéªŒæ¦‚ç‡ï¼Œ\\(P(B)\\) æ˜¯äº‹ä»¶ \\(B\\) çš„è¾¹é™…æ¦‚ç‡ã€‚ è´å¶æ–¯å®šç†å…è®¸æˆ‘ä»¬ç»“åˆå…ˆéªŒçŸ¥è¯†å’Œè§‚å¯Ÿæ•°æ®ï¼Œä»è€Œæ›´çµæ´»åœ°å¤„ç†ä¸ç¡®å®šæ€§é—®é¢˜ã€‚\nå¥½çš„ï¼Œè¿™ç§æ¦‚å¿µå¾ˆæŠ½è±¡ï¼Œæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥ç†è§£è´å¶æ–¯å®šç†çš„åº”ç”¨ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 02: Probability and Information Theory"
    ]
  },
  {
    "objectID": "posts/DLFaC/Chapter02/Chapter02.html#medical-screening-example",
    "href": "posts/DLFaC/Chapter02/Chapter02.html#medical-screening-example",
    "title": "Chapter 02: Probabilities & Information Theory",
    "section": "1.4 Medical Screening Example",
    "text": "1.4 Medical Screening Example\nå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ»ç–—æµ‹è¯•ï¼Œç”¨äºæ£€æµ‹æŸç§ç–¾ç—…ã€‚è®¾äº‹ä»¶ \\(D\\) è¡¨ç¤ºâ€œæ‚£æœ‰ç–¾ç—…â€ï¼Œäº‹ä»¶ \\(T\\) è¡¨ç¤ºâ€œæµ‹è¯•ç»“æœä¸ºé˜³æ€§â€ã€‚å·²çŸ¥ä»¥ä¸‹ä¿¡æ¯ï¼š\n\nè¯¥ç–¾ç—…åœ¨æ€»ä½“ä¸­çš„æ‚£ç—…ç‡ä¸º \\(P(D) = 0.01\\)ï¼ˆå³ 1% çš„äººæ‚£æœ‰è¯¥ç–¾ç—…ï¼‰ã€‚\næµ‹è¯•çš„çµæ•åº¦ï¼ˆå³æ‚£ç—…è€…æµ‹è¯•ä¸ºé˜³æ€§çš„æ¦‚ç‡ï¼‰ä¸º \\(P(T|D) = 0.99\\)ã€‚\næµ‹è¯•çš„ç‰¹å¼‚åº¦ï¼ˆå³æœªæ‚£ç—…è€…æµ‹è¯•ä¸ºé˜´æ€§çš„æ¦‚ç‡ï¼‰ä¸º \\(P(T^c|D^c) = 0.95\\)ï¼Œå…¶ä¸­ \\(T^c\\) è¡¨ç¤ºæµ‹è¯•ç»“æœä¸ºé˜´æ€§ï¼Œ\\(D^c\\) è¡¨ç¤ºæœªæ‚£ç—…ã€‚\nå› æ­¤ï¼Œæœªæ‚£ç—…è€…æµ‹è¯•ä¸ºé˜³æ€§çš„æ¦‚ç‡ä¸º \\(P(T|D^c) = 1 - P(T^c|D^c) = 0.05\\)ã€‚",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "Chapter 02: Probability and Information Theory"
    ]
  },
  {
    "objectID": "posts/DLFaC/index.html",
    "href": "posts/DLFaC/index.html",
    "title": "Deep Learning Foundation and Concepts(DLFaC) Learning Notes",
    "section": "",
    "text": "Note\n\n\n\n Due to the time constraint, these notes may contain errors or omissions. And to speed up the writing process, I only wrote the notes in CHINESES. If you are interested in collaborating to improve these notes,or transalting to different languages, please feel free to contact me. \n\n\nRelated Resources:\n\nBook Website: Deep Learning Foundations and Concepts\nMy GitHub Repo: GitHub\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChapter 01: Introduction to the Deep Learning\n\n\nChapter 01 ä¸»è¦ä»‹ç»äº†ä»€ä¹ˆDeep Learning ä¸å…¶çš„åº”ç”¨ï¼Œå¹¶ä¸”é€šè¿‡ä¸€ä¸ªç®€å•çš„ Polynomial Regression ä¾‹å­æ¥è¯´æ˜ Deep Learning æ¨¡å‹è®­ç»ƒçš„åŸºæœ¬æµç¨‹ã€‚é€šè¿‡Chapter 01çš„å­¦ä¹ ï¼Œè¯»è€…å¯ä»¥åˆæ­¥äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€åº”ç”¨é¢†åŸŸä»¥åŠæ¨¡å‹è®­ç»ƒçš„åŸºæœ¬æ­¥éª¤ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChapter 02: Probabilities & Information Theory\n\n\nChapter 02 ä»‹ç»äº†æ¦‚ç‡è®ºå’Œä¿¡æ¯è®ºçš„åŸºæœ¬æ¦‚å¿µï¼ŒåŒ…æ‹¬éšæœºå˜é‡ã€æ¦‚ç‡åˆ†å¸ƒã€æ¡ä»¶æ¦‚ç‡ã€ç†µç­‰å†…å®¹ã€‚è¿™äº›æ¦‚å¿µåœ¨æ·±åº¦å­¦ä¹ ä¸­å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºå®ƒä»¬å¸®åŠ©æˆ‘ä»¬ç†è§£æ¨¡å‹å¦‚ä½•å¤„ç†ä¸ç¡®å®šæ€§å’Œä¿¡æ¯ã€‚\n\n\n\n\n\n\n\n\nNo matching items\n Back to top",
    "crumbs": [
      "ğŸ“– Deep Learning Foundation & Concepts",
      "About this book"
    ]
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html",
    "href": "posts/LLM-Series/Qwen/Qwen.html",
    "title": "Qwen Model Series",
    "section": "",
    "text": "åœ¨äº†è§£ Qwen ç­‰LLM æ¨¡å‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆäº†è§£ä»€ä¹ˆæ˜¯ Transformer, åœ¨è¿™é‡Œå°±ä¸å…·ä½“å±•å¼€äº†ï¼Œæœ‰å…´è¶£çš„åŒå­¦å‰å»æŸ¥çœ‹ è¿™ç¯‡æ–‡ç« ã€‚ å¯¹äºMulti-Modalityçš„Qwenï¼Œæˆ‘ä»¬éœ€è¦å…·å¤‡çš„æ˜¯ Vision-Transformer çš„çŸ¥è¯†ã€‚\nå‰ç½®çŸ¥è¯†ï¼š\n\nTransformer\nVision-Transformer\n\nQwenï¼ˆé€šä¹‰åƒé—®ï¼‰ æ˜¯é˜¿é‡Œäº‘æ——ä¸‹è¾¾æ‘©é™¢æ¨å‡ºçš„ä¸€ç³»åˆ—å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM) ä¸å¤šæ¨¡æ€æ¨¡å‹ï¼ˆM-LLMï¼‰ã€‚å®ƒç±»ä¼¼ OpenAI çš„ GPT ç³»åˆ—ï¼Œæ˜¯é˜¿é‡Œæ‰“é€ çš„å…¨æ ˆå¼ç»Ÿä¸€LLMä½“ç³»ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥æ²¿ç€Qwenæ¨¡å‹å‘å±•çš„æ—¶é—´çº¿ï¼Œæ¥æ„Ÿå—ä¸€ä¸‹LLMå‘å±•çš„è¿‡ç¨‹ã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#tokenization",
    "href": "posts/LLM-Series/Qwen/Qwen.html#tokenization",
    "title": "Qwen Model Series",
    "section": "2.1 Tokenization",
    "text": "2.1 Tokenization\nQwen ç”¨byte pair encoding (BPE)çš„Tokenizationçš„æ–¹æ³•ï¼Œè¿™ä¸GPT-3.5ï¼ŒGPT-4ç³»åˆ—æ˜¯ä¸€æ ·çš„ã€‚åœ¨è®­ç»ƒTokenizationä¹‹åï¼Œæœ€åçš„Vocabulary Size ç”±152Kã€‚ Qwençš„Tokenizationçš„æ–¹æ³•ï¼Œå®ç°äº†è¾ƒä½çš„Compression Ratioã€‚ä½Compression Ratioè¯´æ˜äº†Qwenåœ¨è¿™äº›è¯­è¨€çš„Training å’Œ Inference ä¸­ä¼šæ¯”è¾ƒé«˜æ•ˆã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#architecture",
    "href": "posts/LLM-Series/Qwen/Qwen.html#architecture",
    "title": "Qwen Model Series",
    "section": "2.2 Architecture",
    "text": "2.2 Architecture\nQwen-1 çš„æ¨¡å‹å€Ÿé‰´äº†LLaMAæ¨¡å‹ï¼Œä¹Ÿæ˜¯Decoder-Only çš„ Transformer (Vaswani et al. 2023) æ¨¡å‹ï¼Œåªä¸è¿‡æœ‰ç€ä»¥ä¸‹å‡ ç‚¹çš„æ”¹å˜ï¼š\n\nEmbedding and output projection: LLaMAå’ŒTransformer éƒ½ç”¨äº†Weight Tyingçš„æŠ€æœ¯ï¼Œè¿™ç§æ–¹å¼å¯ä»¥å‡å°‘æ¨¡å‹çš„å‚æ•°ï¼Œæé«˜è®­ç»ƒçš„æ•ˆç‡ã€‚ä¸è¿‡Qwenæ²¡æœ‰æ²¿ç”¨è¿™ç§æ–¹å¼ï¼Œè€Œæ˜¯è®©è¿™ä¸¤ä¸ªæœ‰å„è‡ªçš„parametersã€‚\nPositional Embeddingï¼š Qwenç”¨äº† RoPE (Su et al. 2023) æ¥Encoding Positionæ¶ˆæ¯ï¼ŒåŒæ—¶è¿ç”¨äº† FP32 çš„ç²¾åº¦ï¼Œæ¥ inverse frequency matrix.\nBias: å¯¹äºè®¸å¤šçš„Layerï¼Œç§»é™¤äº†biasçš„termï¼Œä¸è¿‡å¯¹äºQKV Layersï¼Œè¿˜æ˜¯åŠ äº†Biasã€‚\nPre-Norm & RMSNormï¼šQwen æ¨¡å‹ç”¨äº† Pre-Norm å’ŒRMSNormæ¥å½“ä½œNormalization çš„æ–¹æ³•\nActivation Function: ç”¨äº†SwiGLUå½“ä½œActivation Function, ä¸ºäº†ä¿æŒæ¨¡å‹å‚æ•°çš„ä¸å˜ï¼Œå‡å°‘äº†d_ffåˆ° \\(\\frac{8}{3}\\)"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#pre-training",
    "href": "posts/LLM-Series/Qwen/Qwen.html#pre-training",
    "title": "Qwen Model Series",
    "section": "2.3 Pre-Training",
    "text": "2.3 Pre-Training\nPre-Training éµå¾ªäº†æ ‡å‡†çš„Auto-Regressive LMçš„è®­ç»ƒç›®æ ‡ï¼ŒContext Lengthè®¾ä¸º2048ï¼Œ è¿ç”¨äº†Flash-Attentionã€‚ åˆ©ç”¨AdamW çš„optimizerã€‚ å’Œ Cosine Learning Rate schedule. å¹¶ä¸”è¿ç”¨äº† Mixed Precision Training ä¸ºäº†æé«˜æ¨¡å‹çš„Stability å’Œ è®­ç»ƒé€Ÿåº¦ã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#extend-context-length",
    "href": "posts/LLM-Series/Qwen/Qwen.html#extend-context-length",
    "title": "Qwen Model Series",
    "section": "2.4 Extend Context Length",
    "text": "2.4 Extend Context Length\næ¨¡å‹åœ¨è®­ç»ƒæ—¶çš„Context Lengthè®¾ä¸ºäº†2048ï¼Œä¸è¿‡è¿™åœ¨Inferenceæ—¶ï¼Œæ˜¯ä¸å¤Ÿçš„ã€‚äºæ˜¯Qwenåˆ©ç”¨äº†ä¸€ç§training-free techniques çš„æ–¹æ³•ï¼Œ NTK-aware interpolation\n\n2.4.1 NTK-aware Interpolation\nNTK-aware Interpolation ä¸æ™®é€šçš„Position Interpolationä¸åŒï¼ŒNTK-aware Interpolation adjust the base of RoPEã€‚ Qwençš„å›¢é˜Ÿåœ¨NTK-awareçš„åŸºç¡€ä¸Šï¼Œä¸ºäº†æ›´å¥½çš„å‹æ¦¨å‡ºNTKçš„æ€§èƒ½ï¼Œå®ç°äº†ä¸€ä¸ªNTKçš„extensionï¼Œå«åš dynamic NTK-aware interpolationã€‚\n\n\n2.4.2 Attention\né™¤äº†Position Encodingï¼Œattentionçš„è®¡ç®—æ•ˆç‡ä¹Ÿæ˜¯é˜»ç¢Context lengthçš„åŸå› ä¹‹ä¸€ã€‚ Qwençš„å›¢é˜Ÿç”¨äº†ä¸¤ä¸ªAttentionçš„æŠ€å·§ï¼š - LogN-Scaling - Layer-wise Window Attention: ä¸åŒçš„Layer æœ‰ä¸åŒçš„Window Size\n\nWe also observed that the long-context modeling ability of our model varies across layers, with lower layers being more sensitive in context length extension compared to the higher layers. To leverage this observation, we assign different window sizes to each layer, using shorter windows for lower layers and longer windows for higher layers.  QWEN TECHNICAL REPORT, p.8 \n\nè¿ç”¨äº†ä»¥ä¸Šå‡ ä¸ªæŠ€å·§ä¹‹åï¼ŒQwen æ¨¡å‹å°†context length ä»2048æå‡åˆ°äº†8192ï¼Œ åœ¨æ²¡æœ‰æŸå®³æ¨¡å‹èƒ½åŠ›çš„å‰æä¸‹ã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#alignment",
    "href": "posts/LLM-Series/Qwen/Qwen.html#alignment",
    "title": "Qwen Model Series",
    "section": "2.5 Alignment",
    "text": "2.5 Alignment\nåœ¨Pre-train Qwenä¹‹åï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥ä½¿ç”¨ï¼Œ\n\n2.5.1 Supervised Fine-Tuning\nSFTçš„è®­ç»ƒï¼Œå¯ä»¥è®©Qwenæ¨¡å‹éµå¾ªChatç±»å‹çš„å›ç­”ã€‚\n\n2.5.1.1 Data\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful, harmless and honest assistant.\"},\n    {\"role\": \"user\", \"content\": \"å¸®æˆ‘å†™ä¸€æ®µå…³äºQwenæ¨¡å‹çš„ç®€ä»‹ã€‚\"},\n    {\"role\": \"assistant\", \"content\": \"Qwen æ˜¯é˜¿é‡Œäº‘æ¨å‡ºçš„ä¸€ç³»åˆ—å¤§è¯­è¨€æ¨¡å‹...\"}\n  ]\n}\n\n\n2.5.1.2 Training\nä¸Pre-Trainingç±»ä¼¼ï¼ŒSFT ç”¨äº†ç›¸åŒçš„è®­ç»ƒç›®æ ‡ Next-Token Predictionï¼Œä¸è¿‡ä¸Pre-Trainingä¸åŒçš„æ˜¯ï¼ŒSFTç”¨äº†ä¸€ä¸ªLoss Maskæ¥maskæ‰system å’Œ user inputsã€‚\nåŒæ ·è¿ç”¨äº† AdamW optimizer\n\n\n\n2.5.2 RLHF\nåœ¨SFTä¹‹åï¼Œæ¨¡å‹å¯èƒ½overfittingï¼Œå¹¶ä¸”ç¼ºå°‘generalization å’Œ creativityã€‚ ä¸ºäº†è®©æ¨¡å‹è·å¾—è¿™äº›èƒ½åŠ›ï¼Œåœ¨SFTä¹‹åï¼Œæˆ‘ä»¬éœ€è¦RLHFï¼Œè¿™ä¸ªè¿‡ç¨‹æ¶‰åŠåˆ°ä¸¤ä¸ªæ­¥éª¤ï¼š 1. Reward Model Training 2. Policy Training\n\n2.5.2.1 Reward Model Training\nReward Model Training ä¹Ÿå«åš Preference Model Pretraining (PMP)ï¼Œ è¿™ä¸ªåŒæ ·éœ€è¦pre- training ç„¶åFine-Tuniningã€‚ PMP çš„è®­ç»ƒæ•°æ®, ä¹Ÿæ˜¯ç”±ä¸€ç³»åˆ—çš„comparison data ç»„æˆã€‚\n{\n  \"prompt\": \"Explain why the Earth has seasons.\",\n  \"chosen\": \"The Earth has seasons because its axis is tilted about 23.5 degrees. As the planet orbits the Sun, this tilt causes different hemispheres to receive more or less direct sunlight throughout the year, creating seasonal temperature and daylight changes.\",\n  \"rejected\": \"The Earth has seasons because sometimes it randomly moves closer to the Sun and sometimes farther away.\"\n}\nè®­ç»ƒè¿™ä¸ªReward Modelã€‚ Qwençš„å›¢é˜Ÿç”¨äº†Pre-trained Language Model ä¹Ÿå°±æ˜¯Qwenï¼Œ æ¥å½“ä½œInitiate æƒé‡ã€‚ åœ¨è¿™ä¸ªQwenæ¨¡å‹ä¹‹ä¸Šï¼ŒåŠ ä¸Šäº†ä¸€å±‚Pooling Layeræ¥æå–å‡º Reward ï¼ˆä¸€ä¸ªScalar Valueï¼‰ #### Policy Training\nåœ¨è®­ç»ƒå®ŒReward Modelä¹‹åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯è¿ç”¨Reinforcementçš„ç®—æ³•æ¥è®­ç»ƒLLMã€‚Qwençš„å›¢é˜Ÿè¿ç”¨äº†PPOçš„ç®—æ³•ï¼Œæ¥è®­ç»ƒï¼Œè¿™ä¸ªç®—æ³•ç”±4ä¸ªéƒ¨åˆ†ï¼š - Policy Model - Value Model - Reference Model - Reward Model\nè‡³æ­¤ï¼ŒQwençš„Foundation Modelï¼Œä»¥åŠè®­ç»ƒç»“æŸäº†ã€‚æ¥ä¸‹æ¥å¯ä»¥é€šè¿‡ä¸åŒçš„è®­ç»ƒæ•°æ®ï¼Œè®©Qwen è·å¾—ä¸åŒçš„èƒ½åŠ›ï¼Œæ¯”å¦‚Code-Qwenï¼Œä»¥åŠMath-Qwen"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#code-qwen",
    "href": "posts/LLM-Series/Qwen/Qwen.html#code-qwen",
    "title": "Qwen Model Series",
    "section": "2.6 Code Qwen",
    "text": "2.6 Code Qwen"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#math-qwen",
    "href": "posts/LLM-Series/Qwen/Qwen.html#math-qwen",
    "title": "Qwen Model Series",
    "section": "2.7 Math Qwen",
    "text": "2.7 Math Qwen"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#qwen-1-summary",
    "href": "posts/LLM-Series/Qwen/Qwen.html#qwen-1-summary",
    "title": "Qwen Model Series",
    "section": "2.8 Qwen 1 Summary",
    "text": "2.8 Qwen 1 Summary"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#model-architecture",
    "href": "posts/LLM-Series/Qwen/Qwen.html#model-architecture",
    "title": "Qwen Model Series",
    "section": "3.1 Model Architecture",
    "text": "3.1 Model Architecture\nQwen-VLçš„æ¨¡å‹ä¸»è¦åŒ…å«äº†ä»¥ä¸‹å‡ ä¸ªç»„ä»¶ï¼š - Large Language Modelï¼š Qwen-VLæ˜¯åŸºäºä¹‹å‰çš„ Qwen-7Bæ¥å½“ä½œå¤§è¯­è¨€ç»„ä»¶ - Visual Encoderï¼š Visual Encoderçš„ç»“æ„æ˜¯ï¼Œä¸ Vision-Transformer (Dosovitskiy et al. 2021) çš„ç»“æ„æ˜¯ä¸€æ ·çš„ã€‚é€šè¿‡åŠ è½½ OpenCLIPçš„æƒé‡, æ¥åˆå§‹åŒ–ViT - Position-aware Vision-Language Adapter: ä¸ºäº†å‡å°‘ image featureçš„é•¿åº¦ï¼ŒQwen-VL åˆ©ç”¨äº† Vision Language Adapter. è¿™ä¸ªæ˜¯ä¸€ç»„Cross-Attention Module éšæœºåˆå§‹åŒ–ï¼Œè¿™ç§æ–¹æ³•å°†Visual Featureçš„é•¿åº¦ï¼Œå‹ç¼©åˆ°äº†256. åœ¨è¿™ä¸ªAdapter ä¸­ï¼Œ2D absolute positional encoding ä¹Ÿæ·»åŠ äº†è¿›æ¥ï¼Œç”¨æ¥å‡å°‘å¯èƒ½æ¶ˆæ¯çš„ä¸¢å¤±ã€‚\n ## Inputs and Outputs æ·»åŠ äº†Visual Tokensä¹‹åï¼Œæ¨¡å‹éœ€è¦ä¸€ç§æ–¹æ³•ï¼Œæ¥è¾¨åˆ«å‡ºå“ªäº›æ˜¯Visual Tokens, å“ªäº›æ˜¯Text Tokens\n\nImages are processed through the visual encoder and adapter, yielding fixed-length sequences of image features. To differentiate between image feature input and text feature input, two special tokens ( and ) are appended to the beginning and end of the image feature sequence respectively, signifying the start and end of image content  Qwen-VL- A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond, p.4 \n\nå¯¹äºä¸åŒçš„è¾“å…¥å’Œè¦æ±‚ï¼Œæ¨¡å‹çš„è¾“å‡ºçš„å†…å®¹æ˜¯ä¸ä¸€æ ·çš„ã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#training-1",
    "href": "posts/LLM-Series/Qwen/Qwen.html#training-1",
    "title": "Qwen Model Series",
    "section": "3.2 Training",
    "text": "3.2 Training\nQwen-VL çš„è®­ç»ƒåˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n\n\n3.2.0.1 Pre-Training\nåœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ¨¡å‹è®­ç»ƒå‡ºè®¤è¯†å›¾ç‰‡çš„èƒ½åŠ›ï¼Œå†»ç»“äº†LLMï¼Œè®­ç»ƒViTå’ŒVL adapterã€‚\n\n\n3.2.0.2 Multi-Task Pre-Training\nåœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ¨¡å‹å·²ç»æœ‰äº†å¯¹Imageçš„åŸºæœ¬è®¤çŸ¥ï¼Œæ¥ä¸‹æ¥å°±æ˜¯è®­ç»ƒæ¨¡å‹å¯¹äºä¸åŒè¦æ±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„Multi-Taskã€‚ åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ‰€æœ‰çš„æƒé‡ï¼Œéƒ½è¿›è¡Œå¾®è°ƒã€‚é€šè¿‡è¿™ä¸ªè®­ç»ƒï¼Œæ¨¡å‹è·å¾—äº†å®Œæˆä¸åŒä»»åŠ¡çš„èƒ½åŠ›ã€‚\n\n\n3.2.0.3 Supervised Finetuning\nåœ¨è¿™ä¸ªé˜¶æ®µä¸‹ï¼ŒQwenå›¢é˜Ÿè®­ç»ƒäº†Qwen-VLï¼Œä½¿å®ƒè·å¾—Instruction- Followingçš„èƒ½åŠ›ã€‚ ä¹Ÿå°±æ˜¯Qwen-VL-Chat Modelï¼Œ\nSupervised Finetuning çš„æ•°æ®å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š \nè‡³æ­¤ï¼ŒQwen-VLçš„è®­ç»ƒå·²ç»ç»“æŸäº†ï¼Œ"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#qwen1-vl-sumary",
    "href": "posts/LLM-Series/Qwen/Qwen.html#qwen1-vl-sumary",
    "title": "Qwen Model Series",
    "section": "3.3 Qwen1-VL Sumary",
    "text": "3.3 Qwen1-VL Sumary"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#tokenizer",
    "href": "posts/LLM-Series/Qwen/Qwen.html#tokenizer",
    "title": "Qwen Model Series",
    "section": "5.1 Tokenizer",
    "text": "5.1 Tokenizer\nQwen2 çš„Tokenizationçš„æ–¹æ³•ï¼Œä¸Qwen1 æ˜¯ä¸€æ ·çš„ï¼Œéƒ½é‡‡ç”¨äº†BPE Tokenization Algorithmsã€‚Vocabulary Size æœ‰151,643 Regular tokenså’Œ3 ä¸ªcontrol tokensã€‚"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#architecture-1",
    "href": "posts/LLM-Series/Qwen/Qwen.html#architecture-1",
    "title": "Qwen Model Series",
    "section": "5.2 Architecture",
    "text": "5.2 Architecture\nä¸Qwen1 ç›¸æ¯”ï¼ŒQwen2 çš„æ¨¡å‹æ”¹åŠ¨å¹¶æ²¡æœ‰å¾ˆå¤§ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢\n\n5.2.1 Dense Model\n\n5.2.1.1 Gouged Query Attention\nè¿ç”¨äº†Grouped Query Attention, è¿™ç§æ–¹å¼å¯ä»¥ä¼˜åŒ–KV Cache\n\n\n5.2.1.2 Dual Chunk Attention with YARN\nè¿ç”¨äº†Dual Chunk Attention å’Œ YARN æ¥æé«˜Context çš„é•¿åº¦ã€‚\n\n\n\n5.2.2 Mixture-Of-Expert Model"
  },
  {
    "objectID": "posts/LLM-Series/Qwen/Qwen.html#architecture-2",
    "href": "posts/LLM-Series/Qwen/Qwen.html#architecture-2",
    "title": "Qwen Model Series",
    "section": "6.1 Architecture",
    "text": "6.1 Architecture\n\n\n6.1.1 Naive Dynamic Resolution\nNaive Dynamic Resolution åœ¨ NaViT (Dehghani et al. 2023) ä¸­æå‡ºï¼Œå®ƒå¯ä»¥è®©Vision Transformer åœ¨ä¸åŒé•¿åº¦çš„å›¾ç‰‡ä¸­è®­ç»ƒã€‚\né™¤æ­¤ä¹‹å¤–ï¼ŒQwen2-VL æ‘’å¼ƒäº†Absolute Position Embeddingï¼Œè½¬ç”¨2D-RoPE (Su et al. 2023), é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨ViT ç”ŸæˆRepresentationä¹‹åï¼ŒQwen2-VL è¿˜åœ¨ä¹‹åæ·»åŠ äº†ä¸€å±‚MLPLayerï¼Œå®ƒçš„ä½œç”¨æ˜¯å‡å°‘Tokensçš„æ•°é‡ï¼Œé€šè¿‡ä¸´è¿‘çš„ \\(2\\times 2\\) çš„tokensï¼ŒMLPè®²è¿™äº›tokens mergeåœ¨ä¸€èµ·ï¼Œå°†Tokensçš„æ•°é‡å‡å°‘äº† 4 å€ã€‚æ¯”å¦‚ä¸€å¼  \\(224 \\times 224\\) çš„å›¾ç‰‡, åˆ†æˆå¤§å°ä¸º14çš„patchesï¼Œå¾—åˆ°äº†256 ä¸ªtokensï¼Œå°†è¿™äº›tokens mergeåœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº† 64 ä¸ªtokensã€‚\n\n\n6.1.2 Multi-Modal Rotary Position Embedding (M-RoPE)\nQwen2-VL åˆ©ç”¨M-RoPEæ¥æå–å‡ºä¸åŒModalityä¹‹é—´çš„position çš„ä¿¡æ¯ã€‚ é€šè¿‡å°†Rotary Embedding åˆ†è§£æˆï¼š - Temporal - Height - Width ä¸‰ä¸ªéƒ¨åˆ†ã€‚ å¯¹äºText çš„éƒ¨åˆ†ï¼Œè¿™å‡ ä¸ªéƒ¨åˆ†ä¼šå¾—åˆ°ç›¸åŒçš„IDsï¼Œè¿™ä½¿å¾—å®ƒå¯ä»¥ç±»ä¼¼äº1D-RoPEçš„ä½œç”¨ã€‚å¯¹äºå›¾ç‰‡çš„è¾“å…¥ï¼ŒTemporal éƒ¨åˆ†çš„IDä¿æŒä¸å˜ï¼ŒHeight å’Œ Widthçš„éƒ¨åˆ†ï¼Œä¼šå¾—åˆ°ä¸åŒçš„IDsã€‚ å¯¹äºè§†é¢‘çš„è¾“å…¥ï¼ŒTemporalï¼ŒHeightï¼ŒWidthéƒ½ä¼šæ”¹å˜ã€‚\n\nM-RoPE not only enhances the modeling of positional information but also reduces the value of position IDs for images and videos, enabling the model to extrapolate to longer sequences during inference.  Qwen -VL- Enhancing Vision-Language Modelâ€™s Perception of the World at Any Resolution, p.5 \n\n\nFor text, these three use identical position IDs â†’ equivalent to standard 1D RoPE.\nFor images, temporal ID is constant; height & width IDs encode patch position.\nFor videos, temporal ID increases per frame; height & width same as image."
  },
  {
    "objectID": "posts/100-AI-Papers/15-stable-diffusion/Latent Diffusion Model.html",
    "href": "posts/100-AI-Papers/15-stable-diffusion/Latent Diffusion Model.html",
    "title": "15: High-Resolution Image Synthesis with Latent Diffusion Models (Latent Diffusion Model)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/15-stable-diffusion/Latent Diffusion Model.html#experiment",
    "href": "posts/100-AI-Papers/15-stable-diffusion/Latent Diffusion Model.html#experiment",
    "title": "15: High-Resolution Image Synthesis with Latent Diffusion Models (Latent Diffusion Model)",
    "section": "1.1 Experiment",
    "text": "1.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/03-deit/DeiT.html#experiment",
    "href": "posts/100-AI-Papers/03-deit/DeiT.html#experiment",
    "title": "03: Training data-efficient image transformers & distillation through attention (DeiT)",
    "section": "2.1 Experiment",
    "text": "2.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#online-softmax",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#online-softmax",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "1.1 Online Softmax",
    "text": "1.1 Online Softmax\nOnline Softmaxï¼ˆä¹Ÿå« streaming softmax / one-pass softmax statisticsï¼‰æŒ‡çš„æ˜¯ï¼šä½ ä¸éœ€è¦å…ˆæŠŠæ•´è¡Œ logits \\(s_1,\\dots,s_D\\) å…¨éƒ¨å­˜ä¸‹æ¥å†åš softmaxï¼Œè€Œæ˜¯ä¸€è¾¹è¯»å…¥ï¼ˆæˆ–ä¸€è¾¹è®¡ç®—ï¼‰logitsï¼Œä¸€è¾¹æ›´æ–°å¿…è¦çš„ç»Ÿè®¡é‡ï¼Œæœ€åå¾—åˆ° softmax çš„å½’ä¸€åŒ–å› å­ï¼›åœ¨éœ€è¦è¾“å‡ºæ¦‚ç‡æ—¶å†ç”¨è¿™äº›ç»Ÿè®¡é‡æŠŠæ¯ä¸ª logit å˜æˆæ¦‚ç‡ã€‚\næˆ‘ä»¬çŸ¥é“ï¼Œå¯¹äºä¸€è¡Œå‘é‡ \\(s \\in \\mathbb{R}^{D}\\), å¯¹äºæ•°å€¼ç¨³å®šçš„Softmaxï¼Œæˆ‘ä»¬è¦å…ˆå‡å»å®ƒçš„ max valueï¼Œè¿™å°±å¯¼è‡´äº†ï¼Œå¯¹äºè®¡ç®—softmaxå€¼ï¼Œæˆ‘ä»¬éœ€è¦éå†3æ¬¡è¿™ä¸ªæ•°ç»„ã€‚è€ŒOnline Softmaxåˆ™åœ¨ä¿æŒåŸæ¥çš„éå†ä¸¤æ­¥çš„åŸºç¡€ä¸Šï¼ŒåŒæ—¶ä¿æŒMax Softmaxçš„ç‰¹æ€§ã€‚\nè¦å®ç°è¿™ä¸ªæ¦‚å¿µçš„æ ¸å¿ƒåšæ³•å°±ï¼šåœ¨éå†è¿‡ç¨‹ä¸­ï¼Œç»´æŠ¤ä¸¤ä¸ªå˜é‡ï¼š - mï¼šå½“å‰éå†è¿‡çš„logitsçš„æœ€å¤§å€¼ - lï¼šå½“å‰éå†è¿‡çš„logitsçš„å½’ä¸€åŒ–å› å­ï¼ˆå³ \\(\\sum_{j=1}^{i} \\exp(s_j - m)\\)ï¼‰\nå…·ä½“çš„æ›´æ–°å…¬å¼å¦‚ä¸‹ï¼š\n\\[\n\\begin{split}\nm_{new} & = \\max(m, s_i) \\\\\nl & = l \\cdot \\exp(m - m_{new}) + \\exp(s_i - m_{new}) \\\\\nm & = m_{new}\n\\end{split}\n\\]\nä¸‹é¢æ˜¯Pythonçš„å®ç°ä»£ç ï¼š\ndef online_softmax(x):\n    m, l = float(\"-inf\"), 0.0\n\n    for i in range(len(x)):\n        m_new = max(m, x[i])\n        l = l * math.exp(m - m_new) + math.exp(x[i] - m_new)\n        m = m_new\n\n    softmax_values = [0.0] * len(x)\n    for i in range(len(x)):\n        softmax_values[i] = math.exp(x[i] - m) / l\n    return softmax_values\n\nè‡³äºä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ³•æ˜¯æ­£ç¡®çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ•°å­¦å½’çº³æ³•æ¥è¯æ˜ï¼š - Base Case: å½“åªéå†äº†ç¬¬ä¸€ä¸ªå…ƒç´  \\(s_1\\) æ—¶ï¼Œæ˜¾ç„¶ \\(m = s_1\\)ï¼Œ\\(l = \\exp(s_1 - s_1) = 1\\)ï¼Œæ­¤æ—¶ softmax è®¡ç®—æ­£ç¡®ã€‚ - Inductive Step: å‡è®¾åœ¨éå†åˆ°ç¬¬ \\(i-1\\) ä¸ªå…ƒç´ æ—¶ï¼Œ\\(m\\) å’Œ \\(l\\) å·²ç»æ­£ç¡®åœ°åæ˜ äº†å‰ \\(i-1\\) ä¸ªå…ƒç´ çš„æœ€å¤§å€¼å’Œå½’ä¸€åŒ–å› å­ã€‚ç°åœ¨è€ƒè™‘ç¬¬ \\(i\\) ä¸ªå…ƒç´  \\(s_i\\)ï¼š - å¦‚æœ \\(s_i &gt; m\\)ï¼Œåˆ™æ–°çš„æœ€å¤§å€¼ \\(m_{new} = s_i\\)ï¼Œå½’ä¸€åŒ–å› å­æ›´æ–°ä¸ºï¼š \\[\n      l_{new} = l \\cdot \\exp(m - s_i) + \\exp(s_i - s_i) = l \\cdot \\exp(m - s_i) + 1\n      \\] - å¦‚æœ \\(s_i \\leq m\\)ï¼Œåˆ™æœ€å¤§å€¼ä¿æŒä¸å˜ \\(m_{new} = m\\)ï¼Œå½’ä¸€åŒ–å› å­æ›´æ–°ä¸ºï¼š \\[\n     l_{new} = l \\cdot \\exp(m - m) + \\exp(s_i - m) = l + \\exp(s_i - m)\n     \\] æˆ‘ä»¬çŸ¥é“ \\(\\ell\\) åˆ°é‡åˆ°ç¬¬ \\(i\\) ä¸ªå…ƒç´ æ—¶ï¼Œåœ¨åŠ ä¸Šç¬¬ \\(i\\) ä¸ªå…ƒç´ çš„è´¡çŒ®ä¹‹å‰ï¼Œè¦æ ¹æ®å½“å‰çš„æœ€å¤§å€¼è¿›è¡Œè°ƒæ•´ï¼Œé‡æ–°ç¼©æ”¾ä¹‹å‰çš„å’Œï¼Œä»¥ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ã€‚\n\nåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæ›´æ–°åçš„ \\(m_{new}\\) å’Œ \\(l_{new}\\) ä»ç„¶æ­£ç¡®åœ°åæ˜ äº†å‰ \\(i\\) ä¸ªå…ƒç´ çš„æœ€å¤§å€¼å’Œå½’ä¸€åŒ–å› å­ã€‚å› æ­¤ï¼Œé€šè¿‡æ•°å­¦å½’çº³æ³•ï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥åœ¨çº¿ç®—æ³•åœ¨éå†å®Œæ•´ä¸ªæ•°ç»„åï¼Œèƒ½å¤Ÿæ­£ç¡®è®¡ç®—å‡º softmax çš„å½’ä¸€åŒ–å› å­ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#recomputing",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#recomputing",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "1.2 Recomputing",
    "text": "1.2 Recomputing\nRecomputing æ˜¯ä¸€ç§ä»¥è®¡ç®—æ¢å†…å­˜çš„æŠ€æœ¯ï¼Œå®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨å‰å‘ä¼ æ’­æ—¶ï¼Œä¸ä¿å­˜æŸäº›ä¸­é—´ç»“æœï¼Œè€Œæ˜¯åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—è¿™äº›ç»“æœï¼Œä»è€ŒèŠ‚çœå†…å­˜ç©ºé—´ã€‚\næˆ‘ä»¬çŸ¥é“ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œéœ€è¦ç”¨åˆ°å‰å‘ä¼ æ’­ä¸­çš„ä¸€äº›ä¸­é—´ç»“æœæ¥è®¡ç®—æ¢¯åº¦ã€‚å¦‚æœæˆ‘ä»¬åœ¨å‰å‘ä¼ æ’­æ—¶ä¿å­˜äº†æ‰€æœ‰çš„ä¸­é—´ç»“æœï¼Œé‚£ä¹ˆä¼šå ç”¨å¤§é‡çš„å†…å­˜ç©ºé—´ã€‚é€šè¿‡ Recomputingï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©æ€§åœ°ä¸ä¿å­˜æŸäº›ä¸­é—´ç»“æœï¼Œè€Œæ˜¯åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—å®ƒä»¬ã€‚ä¸¾ä¸ªä¾‹å­ï¼šå‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªMLPå±‚\\(y=W_2\\cdot \\sigma(W_1 \\cdot x)\\)ï¼Œå¸¸è§„çš„åšæ³•æ˜¯ï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ï¼Œä¿å­˜ \\(h=W_1 \\cdot x\\) å’Œ \\(a=\\sigma(W_1 \\cdot x)\\) çš„ç»“æœï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æ—¶è®¡ç®—æ¢¯åº¦ï¼š\\(\\frac{\\partial L}{\\partial W_2} = d y \\, a^\\top\\) å’Œ \\(\\frac{\\partial L}{\\partial W_1} = (W_2^\\top d y) \\odot \\sigma'(a) \\, x^\\top\\)ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ Recomputingï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸ä¿å­˜ \\(a = W_1 \\cdot x\\) å’Œ \\(\\sigma(a)\\)ï¼Œè€Œæ˜¯åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—å®ƒä»¬ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±èŠ‚çœäº†å†…å­˜ç©ºé—´ï¼Œä½†éœ€è¦é¢å¤–çš„è®¡ç®—æ—¶é—´æ¥é‡æ–°è®¡ç®—è¿™äº›ä¸­é—´ç»“æœã€‚\nè¿™ç§æŠ€æœ¯çš„å¥½å¤„å°±æ˜¯ï¼Œå‡å°‘äº†å†…å­˜çš„ä½¿ç”¨ï¼ŒåŒæ—¶é™ä½äº†è¯»å†™å†…å­˜çš„å¸¦å®½éœ€æ±‚ï¼Œä»è€Œæå‡äº†æ•´ä½“çš„è®¡ç®—æ•ˆç‡ã€‚\né€šè¿‡PyTorch çš„ torch.autograd.Functionï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å®ç° Recomputingã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#gpus-memory-model",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#gpus-memory-model",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "1.3 GPUâ€™s Memory Model",
    "text": "1.3 GPUâ€™s Memory Model\nåœ¨ç†è§£ Flash Attention ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆäº†è§£ä¸€ä¸‹ GPU çš„å†…å­˜æ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œä¸»è¦ä»‹ç»ä¸€ä¸‹ GPU çš„å‡ ç§ä¸»è¦å†…å­˜ç±»å‹ï¼š\n\nHigh Bandwidth Memory (HBM): è¿™æ˜¯ GPU ä¸Šçš„ä¸»è¦å†…å­˜ç±»å‹ï¼Œå…·æœ‰é«˜å¸¦å®½å’Œè¾ƒä½çš„å»¶è¿Ÿã€‚HBM é€šå¸¸ç”¨äºå­˜å‚¨å¤§è§„æ¨¡çš„æ•°æ®ï¼Œå¦‚æ¨¡å‹å‚æ•°å’Œè¾“å…¥æ•°æ®ã€‚\nSRAM: è¿™æ˜¯ GPU ä¸Šçš„ç‰‡ä¸Šå†…å­˜ï¼Œå…·æœ‰éå¸¸é«˜çš„å¸¦å®½å’Œä½å»¶è¿Ÿã€‚SRAM é€šå¸¸ç”¨äºå­˜å‚¨ä¸´æ—¶æ•°æ®ï¼Œå¦‚ä¸­é—´è®¡ç®—ç»“æœã€‚(SRAM è¿˜å¯ä»¥ç»†åˆ†æˆ L1 Cache å’Œ L2 Cacheï¼Œ Registerï¼Œ Shared Memory ç­‰åœ¨è¿™é‡Œæˆ‘ä»¬ç»Ÿç§°ä¸º SRAM)\n\nå› æ­¤æˆ‘ä»¬å¸Œæœ›ï¼Œå°½å¯èƒ½å¤šçš„è®¡ç®—åœ¨ SRAM ä¸Šå®Œæˆï¼Œå‡å°‘å¯¹ HBM çš„è¯»å†™ï¼Œä»è€Œæå‡æ•´ä½“çš„è®¡ç®—æ•ˆç‡ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#tiling",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#tiling",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "1.4 Tiling",
    "text": "1.4 Tiling"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#matrix-calculus-cheatsheet",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#matrix-calculus-cheatsheet",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "1.5 Matrix Calculus Cheatsheet",
    "text": "1.5 Matrix Calculus Cheatsheet\nåœ¨è¿™é‡Œä»‹ç»ä¸€äº›å¸¸ç”¨çš„çŸ©é˜µå¾®ç§¯åˆ†å…¬å¼ï¼Œä»¥ä¾¿æˆ‘ä»¬åœ¨åç»­çš„æ¨å¯¼ä¸­ä½¿ç”¨ï¼š\n\n\n\n\n\n\n\\(O=PV, \\text{where } O \\in \\mathbb{R}^{m \\times n}, P \\in \\mathbb{R}^{m \\times k},  V \\in \\mathbb{R}^{k \\times n}\\)\n\n\n\\[\n\\frac{\\partial L}{\\partial P} = \\frac{\\partial L}{\\partial O} V^\\top, \\quad \\frac{\\partial L}{\\partial V} = P^\\top \\frac{\\partial L}{\\partial O}\n\\]\n\n\n\n\\(P = \\text{softmax}(S), \\text{where } P \\in \\mathbb{R}^{m \\times n}, S \\in \\mathbb{R}^{m \\times n}\\)\n\\[\n\\frac{\\partial L}{\\partial S} = P \\odot \\left( \\frac{\\partial L}{\\partial P} - \\text{row\\_sum}\\left(P \\odot \\frac{\\partial L}{\\partial P}\\right) \\right)\n\\]\nå…¶ä¸­ï¼š\\(\\odot\\) è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ï¼Œ\\(\\text{row\\_sum}(\\cdot)\\) è¡¨ç¤ºå¯¹æ¯ä¸€è¡Œæ±‚å’Œå¹¶å¹¿æ’­ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#experiment",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#experiment",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "2.1 Experiment",
    "text": "2.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#tiling-qk-v",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#tiling-qk-v",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "6.1 Tiling Qï¼ŒKï¼Œ V",
    "text": "6.1 Tiling Qï¼ŒKï¼Œ V\nFlash Attention é¦–å…ˆå°† Qï¼ŒKï¼ŒV æŒ‰å—ï¼ˆtilingï¼‰åŠ è½½åˆ°ç‰‡ä¸Šå†…å­˜ï¼ˆSRAM/Shared Memoryï¼‰ä¸­è¿›è¡Œè®¡ç®—ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ³¨æ„åŠ›çŸ©é˜µ \\(A = \\text{softmax}(QK^\\top)V\\)ï¼Œå…¶ä¸­ \\(Q \\in \\mathbb{R}^{N \\times D}\\)ï¼Œ\\(K \\in \\mathbb{R}^{M \\times D}\\)ï¼Œ\\(V \\in \\mathbb{R}^{M \\times D}\\)ã€‚æˆ‘ä»¬å¯ä»¥å°† \\(Q\\) åˆ†æˆ \\(N_b\\) ä¸ªå—ï¼Œæ¯ä¸ªå—å¤§å°ä¸º \\(B_n \\times D\\)ï¼Œå°† \\(K\\) å’Œ \\(V\\) åˆ†æˆ \\(M_b\\) ä¸ªå—ï¼Œæ¯ä¸ªå—å¤§å°ä¸º \\(B_m \\times D\\)ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ³¨æ„åŠ›çŸ©é˜µçš„è®¡ç®—åˆ†è§£ä¸ºå¤šä¸ªå°å—çš„è®¡ç®—ï¼Œä»è€Œå‡å°‘å¯¹ HBM çš„è¯»å†™ã€‚\nä¸è¿‡ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯softmaxçš„è®¡ç®—ï¼šå®ƒéœ€è¦ä¸€æ•´è¡Œçš„logitsæ‰èƒ½è®¡ç®—å‡ºå½’ä¸€åŒ–å› å­ï¼Œè€ŒFlash Attentionæ˜¯æŒ‰å—è®¡ç®—çš„ï¼Œæ²¡æ³•ä¸€æ¬¡æ€§æ‹¿åˆ°æ•´è¡Œlogitsã€‚é‚£ä¹ˆFlash Attentionæ˜¯å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜çš„å‘¢ï¼Ÿç­”æ¡ˆå°±æ˜¯ï¼šOnline Softmaxã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#online-softmax-for-attention",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#online-softmax-for-attention",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "6.2 Online Softmax for Attention",
    "text": "6.2 Online Softmax for Attention\nFlash Attention ä½¿ç”¨ Online Softmax æ¥è®¡ç®—æ³¨æ„åŠ›çŸ©é˜µçš„ softmax éƒ¨åˆ†ã€‚å…·ä½“æ¥è¯´ï¼ŒFlash Attention åœ¨è®¡ç®—æ¯ä¸ªå—çš„æ³¨æ„åŠ›æ—¶ï¼Œç»´æŠ¤ä¸¤ä¸ªå˜é‡ï¼šm å’Œ lï¼Œåˆ†åˆ«è¡¨ç¤ºå½“å‰å—çš„æœ€å¤§å€¼å’Œå½’ä¸€åŒ–å› å­ã€‚åœ¨è®¡ç®—æ¯ä¸ªå—çš„æ³¨æ„åŠ›æ—¶ï¼ŒFlash Attention ä¼šæ›´æ–° m å’Œ lï¼Œä»è€Œå®ç°åœ¨çº¿è®¡ç®— softmax çš„å½’ä¸€åŒ–å› å­ã€‚\nå…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æ­£åœ¨è®¡ç®—ç¬¬ \\(i\\) ä¸ªå—çš„æ³¨æ„åŠ›ï¼Œæˆ‘ä»¬æœ‰ï¼š\n\\[\nS_{i,j} = Q_i K_j^\\top\n\\]\nç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ Online Softmax çš„æ›´æ–°å…¬å¼æ¥æ›´æ–° m å’Œ lï¼š\n\\[\n\\begin{split}\nm_{new} & = \\max(m, \\max(S_{i,j})) \\\\\nl & = l \\cdot \\exp(m - m_{new}) + \\sum_{k} \\exp(S_{i,j,k} - m_{new}) \\\\\nm & = m_{new}\n\\end{split}\n\\]\né€šè¿‡è¿™ç§æ–¹å¼ï¼ŒFlash Attention å¯ä»¥åœ¨ä¸ä¿å­˜å®Œæ•´æ³¨æ„åŠ›çŸ©é˜µçš„æƒ…å†µä¸‹ï¼Œè®¡ç®—å‡ºæ­£ç¡®çš„ softmax å½’ä¸€åŒ–å› å­ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#recomputing-for-backward-pass",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#recomputing-for-backward-pass",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "6.3 Recomputing for Backward Pass",
    "text": "6.3 Recomputing for Backward Pass\næˆ‘ä»¬çŸ¥é“ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œéœ€è¦ç”¨åˆ°å‰å‘ä¼ æ’­ä¸­çš„ä¸€äº›ä¸­é—´ç»“æœæ¥è®¡ç®—æ¢¯åº¦ã€‚å¦‚æœæˆ‘ä»¬åœ¨å‰å‘ä¼ æ’­æ—¶ä¿å­˜äº†æ‰€æœ‰çš„ä¸­é—´ç»“æœï¼Œé‚£ä¹ˆä¼šå ç”¨å¤§é‡çš„å†…å­˜ç©ºé—´ã€‚Flash Attention é€šè¿‡ Recomputing æŠ€æœ¯ï¼Œé€‰æ‹©æ€§åœ°ä¸ä¿å­˜æŸäº›ä¸­é—´ç»“æœï¼Œè€Œæ˜¯åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—å®ƒä»¬ï¼Œä»è€ŒèŠ‚çœå†…å­˜ç©ºé—´ã€‚å…·ä½“æ¥è¯´ï¼ŒFlash Attention åœ¨å‰å‘ä¼ æ’­æ—¶ï¼Œä¸ä¿å­˜å®Œæ•´çš„æ³¨æ„åŠ›çŸ©é˜µ \\(S\\) å’Œ softmax çŸ©é˜µ \\(P\\)ï¼Œè€Œæ˜¯åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—å®ƒä»¬ã€‚è¿™æ ·ï¼ŒFlash Attention å°±èŠ‚çœäº†å¤§é‡çš„å†…å­˜ç©ºé—´ï¼ŒåŒæ—¶é™ä½äº†è¯»å†™å†…å­˜çš„å¸¦å®½éœ€æ±‚ï¼Œä»è€Œæå‡äº†æ•´ä½“çš„è®¡ç®—æ•ˆç‡ã€‚\nå…·ä½“æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ³¨æ„åŠ›çŸ©é˜µ \\(A = PV\\)ï¼Œå…¶ä¸­ \\(P = \\text{softmax}(S)\\)ã€‚åœ¨åå‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®— \\(\\frac{\\partial L}{\\partial Q}\\)ï¼Œ\\(\\frac{\\partial L}{\\partial K}\\) å’Œ \\(\\frac{\\partial L}{\\partial V}\\)ã€‚Flash Attention é€šè¿‡é‡æ–°è®¡ç®— \\(S\\) å’Œ \\(P\\) æ¥å®ç°è¿™ä¸€ç‚¹ï¼š\n\\[\n\\begin{split}\n\\frac{\\partial L}{\\partial V} & = P^\\top \\frac{\\partial L}{\\partial A} \\\\\n\\frac{\\partial L}{\\partial P} & = \\frac{\\partial L}{\\partial A} V^\\top \\\\\n\\frac{\\partial L}{\\partial S} & = P \\odot \\left( \\frac{\\partial L}{\\partial P} - \\text{row\\_sum}\\left(P \\odot \\frac{\\partial L}{\\partial P}\\right) \\right) \\\\\n\\frac{\\partial L}{\\partial Q} & = \\frac{\\partial L}{\\partial S} K \\\\\n\\frac{\\partial L}{\\partial K} & = Q^\\top \\frac{\\partial L}{\\partial S}\n\\end{split}\n\\]\né€šè¿‡è¿™ç§æ–¹å¼ï¼ŒFlash Attention åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—äº†å¿…è¦çš„ä¸­é—´ç»“æœï¼Œä»è€ŒèŠ‚çœäº†å†…å­˜ç©ºé—´ï¼ŒåŒæ—¶é™ä½äº†è¯»å†™å†…å­˜çš„å¸¦å®½éœ€æ±‚ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#kernel-fusion",
    "href": "posts/100-AI-Papers/17-flash-attention/Flash Attention.html#kernel-fusion",
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness(Flash Attention)",
    "section": "6.4 Kernel-Fusion",
    "text": "6.4 Kernel-Fusion\nFlash Attention é€šè¿‡å°†å¤šä¸ªè®¡ç®—æ­¥éª¤èåˆåˆ°ä¸€ä¸ª GPU kernel ä¸­ï¼Œå‡å°‘äº†å†…å­˜è¯»å†™çš„å¼€é”€ï¼Œä»è€Œæå‡äº†æ•´ä½“çš„è®¡ç®—æ•ˆç‡ã€‚å…·ä½“æ¥è¯´ï¼ŒFlash Attention å°† QKáµ€ çš„è®¡ç®—ã€softmax çš„è®¡ç®—å’Œä¸ V çš„ä¹˜æ³•è®¡ç®—èåˆåˆ°ä¸€ä¸ª kernel ä¸­ï¼Œä»è€Œå‡å°‘äº†ä¸­é—´ç»“æœçš„å­˜å‚¨å’Œè¯»å–ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒFlash Attention å¯ä»¥åœ¨ä¸€ä¸ª kernel ä¸­å®Œæˆæ‰€æœ‰çš„è®¡ç®—ï¼Œä»è€Œå‡å°‘äº†å†…å­˜è¯»å†™çš„å¼€é”€ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/07-dino/DINO.html",
    "href": "posts/100-AI-Papers/07-dino/DINO.html",
    "title": "07: Emerging Properties in Self-Supervised Vision Transformers (DINO)",
    "section": "",
    "text": "1 Preliminary\n\n\n2 DINO\n\n\n3 Summary\n\n\n4 Key Concepts\n\n\n5 Q & A\n\n\n6 Related resource & Further Reading\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/100-AI-Papers/09-mae/MAE.html",
    "href": "posts/100-AI-Papers/09-mae/MAE.html",
    "title": "09: Masked Autoencoders Are Scalable Vision Learners(MAE)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/09-mae/MAE.html#experiment",
    "href": "posts/100-AI-Papers/09-mae/MAE.html#experiment",
    "title": "09: Masked Autoencoders Are Scalable Vision Learners(MAE)",
    "section": "1.1 Experiment",
    "text": "1.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html",
    "href": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html",
    "title": "11: Neural Discrete Representation Learning (VQ_VAE)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#experiment",
    "href": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#experiment",
    "title": "11: Neural Discrete Representation Learning (VQ_VAE)",
    "section": "1.1 Experiment",
    "text": "1.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#experiment-1",
    "href": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#experiment-1",
    "title": "11: Neural Discrete Representation Learning (VQ_VAE)",
    "section": "7.1 Experiment",
    "text": "7.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#vector-quantization",
    "href": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#vector-quantization",
    "title": "11: Neural Discrete Representation Learning (VQ_VAE)",
    "section": "12.1 Vector Quantization",
    "text": "12.1 Vector Quantization\nå‘é‡é‡åŒ–ï¼ˆVector Quantizationï¼‰æ˜¯ä¸€ç§æŠŠè¿ç»­çš„å‘é‡è½¬æ¢ä¸ºç¦»æ•£çš„â€œç´¢å¼•â€ çš„æ–¹æ³•ã€‚é€šè¿‡è¿™ä¸ªç´¢å¼•ï¼Œåœ¨å­—å…¸ï¼ˆcodebookï¼‰ä¸­æ‰¾åˆ°ä¸€ä¸ªä¸å…¶æœ€ç›¸è¿‘çš„ä¸€ä¸ªå‘é‡ï¼Œè¿™ä¸ªå­—å…¸ä¹Ÿå«åšï¼š - CodeBook - Embedding Table - Centroids è¿™æ—¶ï¼Œæ¯ä¸ªå‘é‡å°±å˜æˆäº†ä¸€ä¸ªç¦»æ•£çš„ç¼–å·ï¼ˆIndexï¼‰ ç”¨æ•°å­¦è¡¨è¾¾å°±æ˜¯ï¼š æˆ‘ä»¬æœ‰: - A vector \\(z \\in \\mathbb{R}^{d}\\) - A codebook \\(E \\in \\mathbb{R}^{K \\times d}\\), å…¶ä¸­ æœ‰ \\(K\\) ä¸ªç´¢å¼•\næˆ‘ä»¬é€šè¿‡æ¯”è¾ƒ \\(z\\) å’Œ \\(K\\) ä¸ªå‘é‡ä¸­ï¼Œæ‰¾åˆ°æœ€è¿‘çš„ä¸€ä¸ªå‘é‡\n\\[\n\\text{quantized}(z) = e_{k} \\quad \\text{where}\\ k = \\underset{j}{\\operatorname{arg\\min}}   \\|z - e_{j} \\|^{2}\n\\]\nimport torch\n\ndef quantize(embedding_table: torch.Tensor, z: torch.Tensor):\n    \"\"\"\n    embedding_table: (K, D)\n    z: (B, D)\n    \"\"\"\n    # (B, 1, D) - (1, K, D) â†’ (B, K, D)\n    diff = z.unsqueeze(1) - embedding_table.unsqueeze(0)\n\n    # (B, K, D) -&gt; (B, K)\n    distances = torch.linalg.norm(diff, dim=2)\n\n    #  (B, K) -&gt; (B,)\n    indices = distances.argmin(dim=1)\n\n    # Gather quantized embeddings â†’ (B, D)\n    q = embedding_table[indices]\n\n    return q, indices\n\n\nK, D = 512, 64\nB = 8\n\ncodebook = torch.randn(K, D)\nz = torch.randn(B, D)\n\nq, idx = quantize(codebook, z)\nassert q.shape == (B, D)\nassert idx.shape == (B,)"
  },
  {
    "objectID": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#straight-through-estimator",
    "href": "posts/100-AI-Papers/11-vq-vae/VQ_VAE.html#straight-through-estimator",
    "title": "11: Neural Discrete Representation Learning (VQ_VAE)",
    "section": "12.2 Straight Through Estimator",
    "text": "12.2 Straight Through Estimator\nK, D = 512, 64\nB = 8\n\nembedding_table = torch.randn(K, D)\nz_enc = torch.randn(B, D, requires_grad=True)\nassert z_enc.grad is None\n\nz_k, _ = quantize(embedding_table, z_enc)\n\n# STE\nz_k = z_enc + (z_k - z_enc).detach()\nz_k.retain_grad()\n\nloss = (z_k**2).mean()\nloss.backward()\n\nassert z_k.grad is not None\nassert z_enc.grad is not None\nassert torch.allclose(z_enc.grad, z_k.grad)"
  },
  {
    "objectID": "posts/100-AI-Papers/05-vivit/ViViT.html#experiment",
    "href": "posts/100-AI-Papers/05-vivit/ViViT.html#experiment",
    "title": "05: ViViT: A Video Vision Transformer(ViViT)",
    "section": "2.1 Experiment",
    "text": "2.1 Experiment"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "",
    "text": "# Preliminary"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#window-multi-head-attention-w-mha",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#window-multi-head-attention-w-mha",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.1 Window Multi-Head-Attention (W-MHA)",
    "text": "1.1 Window Multi-Head-Attention (W-MHA)\nW-MHA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š\n\næŠŠå›¾åƒåˆ’åˆ†æˆå›ºå®šå¤§å°çš„çª—å£ï¼ˆwindowï¼‰ï¼Œæ¯”å¦‚ 7Ã—7 patch çš„çª—å£ã€‚\nåœ¨çª—å£å†…çš„ token ä¹‹é—´åšå±€éƒ¨è‡ªæ³¨æ„åŠ›ï¼Œè€Œä¸æ˜¯åœ¨æ•´å¼ å›¾åƒçš„æ‰€æœ‰ token ä¹‹é—´åšå…¨å±€æ³¨æ„åŠ›ã€‚\næ¯ä¸ªçª—å£ç‹¬ç«‹è®¡ç®— Multi-Head Attention â†’ é™ä½è®¡ç®—é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥å¹¶è¡Œçš„è®¡ç®—\n\nè¿™æ ·ä¸€æ¥ï¼š\n\nå•ä¸ªçª—å£ token æ•°é‡å›ºå®š = \\(M^{2}\\)ï¼ˆå¦‚ 7Ã—7=49ï¼‰ã€‚\næ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦ä» \\(\\mathcal{O}((hw)^{2}C)\\) é™ä½ä¸º \\(\\mathcal{O}(M^{2}hwC)\\)ï¼Œå…¶ä¸­ \\(M \\ll \\sqrt{ N }\\)ã€‚\n\né™¤äº†é™ä½è®¡ç®—å¤æ‚åº¦ä¹‹å¤–ï¼ŒW-MHAï¼Œè¿˜æœ‰ä¿ç•™CNN åœ¨å›¾åƒå¤„ç†ä¸­å¼ºå¤§çš„ä¸€ç‚¹æ˜¯ å±€éƒ¨æ„Ÿå—é‡ å’Œ å¹³ç§»ä¸å˜æ€§ã€‚\n\nW-MHA é€šè¿‡çª—å£é™åˆ¶ï¼Œä½¿å¾—æ³¨æ„åŠ›æœºåˆ¶ä¹Ÿå…·å¤‡ç±»ä¼¼çš„å±€éƒ¨å½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼Œé€‚åˆå›¾åƒå»ºæ¨¡ã€‚\n\n\nFor efficient modeling, we propose to compute self-attention within local windows. The windows are arranged to evenly partition the image in a non-overlapping manner.  Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#shifted-window-multi-head-attention-sw-mha",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#shifted-window-multi-head-attention-sw-mha",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.2 Shifted Window Multi-Head-Attention (SW-MHA)",
    "text": "1.2 Shifted Window Multi-Head-Attention (SW-MHA)\nW-MHA å¾ˆå¥½ï¼Œä½†æ˜¯å®ƒå­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼š\n\nçª—å£ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œç¼ºå°‘è·¨çª—å£çš„ä¿¡æ¯äº¤æµã€‚è¿™ä¼šå¯¼è‡´ï¼Œæ¨¡å‹åªèƒ½çœ‹è§å±€éƒ¨ï¼Œä¸èƒ½è·å¾—å…¨å±€çš„ä¿¡æ¯ã€‚\n\n\nThe window-based self-attention module lacks connections across windows, which limits its modeling power. To introduce cross-window connections while maintaining the efficient computation of non-overlapping windows, we propose a shifted window partitioning approach which alternates between two partitioning configurations in consecutive Swin Transformer blocks.  Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4 \n\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒSwin- Transformeræå‡ºæ¥ Shifted Window Mulit-Head-Attention (SW-MHA) çª—å£ä½ç½®ç›¸å¯¹å‰ä¸€å±‚å¹³ç§»ï¼Œæ¯”å¦‚ 7Ã—7 çª—å£ â†’ å¹³ç§» 3 ä¸ª patchã€‚ è¿™æ ·ï¼Œæ–°çš„çª—å£ä¼šè·¨è¶ŠåŸæ¥çš„è¾¹ç•Œï¼Œtoken ä¼šå’Œç›¸é‚»çª—å£çš„ token ä¸€èµ·è®¡ç®—æ³¨æ„åŠ›ã€‚ ç›¸å½“äºå¼ºåˆ¶è·¨çª—å£äº¤äº’ï¼Œè®©ä¿¡æ¯å¯ä»¥åœ¨ä¸åŒåŒºåŸŸä¹‹é—´æµåŠ¨ã€‚\n å¦‚ä¸Šå¦‚æ‰€ç¤ºï¼Œæˆ‘ä»¬å°†Windowé€šè¿‡å‘å·¦ä¸Šè§’ç§»åŠ¨ï¼Œé€šè¿‡ç»™å›¾ç‰‡å¢åŠ Paddingæ¥ï¼Œä½†æ˜¯è¿™ç§åŠæ³•æ˜¾ç„¶ä¼šå¢åŠ è®¡ç®—çš„å¤æ‚åº¦ã€‚Swin Transformerç”¨äº†ä¸€ç§å¾ˆèªæ˜çš„åŠæ³•ï¼Œå«åš Cycling Shiftï¼Œè¿™ç§æ–¹æ³•å°±æ˜¯å°†å°†ä¸€ä¸ªå¼ é‡æˆ–å›¾åƒåœ¨æŸä¸ªç»´åº¦ä¸Šåš å¹³ç§»ï¼Œä½†ä¸æ˜¯æŠŠç§»å‡ºå»çš„éƒ¨åˆ†ä¸¢æ‰ï¼Œè€Œæ˜¯ é‡æ–°ä»å¦ä¸€è¾¹è¡¥å›æ¥ã€‚å°±åƒâ€œç¯å½¢é˜Ÿåˆ—â€æˆ–â€œé’Ÿè¡¨èµ°ä¸€åœˆåˆå›åˆ°èµ·ç‚¹â€ã€‚ å¦‚ä¸‹å›¾æ‰€ç¤º \nå¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡Cycling Shiftï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ¯ä¸ªwindowçš„å†…å®¹ï¼Œå’Œä¹‹å‰æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯æ‰€éœ€è¦çš„Windowçš„æ•°é‡ï¼Œå°äº†å¾ˆå¤šï¼Œè¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œæ‰€éœ€è¦çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¹Ÿå°äº†å¾ˆå¤šã€‚\n\nä¸è¿‡Cycling Shiftä¹Ÿæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åŒä¸€ä¸ªçª—å£é‡Œé¢ï¼Œå¯èƒ½æœ‰æ¥è‡ªä¸åŒå›¾ç‰‡çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯åœ¨åŸå›¾ç‰‡ä¸Šä¸æ˜¯ç›¸é‚»çš„ï¼Œè‡ªç„¶ä¸åº”è¯¥ç›¸äº’äº¤æµä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥å°†å›¾ç‰‡ï¼ŒæŠ½è±¡æˆä¸‹å›¾çš„å½¢å¼ã€‚ç»„ç»‡Attentionäº¤æµï¼Œå¾ˆè‡ªç„¶çš„ä¸€ç§æ–¹æ³•æ˜¯åˆ©ç”¨Maskï¼Œå°±åƒTransformeré‡Œçš„Causal Maskä¸€æ ·ã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªMaské•¿ä»€ä¹ˆæ ·å­å‘¢\n\næˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹Maskï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ‰é¢œè‰²çš„åŒºåŸŸè¡¨ç¤ºMask == 1ï¼Œ åœ¨æ­¤ä¸ºäº†æ›´å¥½çš„"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#consecutive-swin-transformer-block",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#consecutive-swin-transformer-block",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.3 Consecutive Swin Transformer Block",
    "text": "1.3 Consecutive Swin Transformer Block\n\nSwin Transformer is built by replacing the standard multi-head self attention (MSA) module in a Transformer block by a module based on shifted windows (described in Section 3.2), with other layers kept the same. As illustrated in Figure 3(b), a Swin Transformer block consists of a shifted window based MSA module, followed by a 2-layer MLP with GELU nonlinearity in between. A LayerNorm (LN) layer is applied before each MSA module and each MLP, and a residual connection is applied after each module  Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4 \n\n\n\\[\n\\begin{split}\n\\hat{z}^l &= \\text{W-MSA} \\left( \\text{LN} \\left( z^{l-1} \\right) \\right) + z^{l-1} \\\\\nz^l &= \\text{MLP} \\left( \\text{LN} \\left( \\hat{z}^l \\right) \\right) + \\hat{z}^l \\\\\n\\hat{z}^{l+1} &= \\text{SW-MSA} \\left( \\text{LN} \\left( z^l \\right) \\right) + z^l \\\\\nz^{l+1} &= \\text{MLP} \\left( \\text{LN} \\left( \\hat{z}^{l+1} \\right) \\right) + \\hat{z}^{l+1}\n\\end{split}\n\\]\nå°†W-MSA å’Œ SW-MSAå åœ¨ä¸€èµ·ï¼Œå°±å¾—åˆ°äº†Transformer Blockï¼Œå½“ç„¶ï¼Œè¿˜æœ‰ä¸€ä¸ªMLPï¼ŒLayer Normalizationï¼Œåœ¨æ­¤å°±ä¸èµ˜è¿°äº†ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#patch-merge",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#patch-merge",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.4 Patch Merge",
    "text": "1.4 Patch Merge\nè®²å®Œäº†W-MHAï¼Œå’ŒSW-MHAï¼Œæˆ‘ä»¬å°±ç†è§£äº†Swin- Transformerä¸­æœ€éš¾ç†è§£ï¼Œä¹Ÿæ˜¯æœ€ç»ˆçš„éƒ¨åˆ†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å…¶ä»–ç®€å•çš„éƒ¨åˆ†ã€‚ Patch Merge , å›¾ä¸­ç»¿è‰²çš„éƒ¨åˆ†ï¼Œé€æ­¥é™ä½ token æ•°é‡ï¼ˆé™é‡‡æ ·ï¼‰ï¼ŒåŒæ—¶å¢åŠ ç‰¹å¾ç»´åº¦çš„æ“ä½œã€‚è¿™ç±»ä¼¼äºCNNä¸­çš„æ“ä½œï¼Œéšç€å±‚æ•°çš„å¢åŠ ï¼Œåˆ†è¾¨ç‡é€æ­¥é™ä½ã€é€šé“æ•°é€æ­¥å¢åŠ ï¼Œè¿™æ ·æ—¢å‡å°‘äº†è®¡ç®—é‡ï¼Œåˆèƒ½æå–å±‚çº§ç‰¹å¾ã€‚å…·ä½“çš„å®ç°ï¼š\n\nåˆ†ç»„ï¼šå°†ç›¸é‚»çš„ 2Ã—2 patch åˆå¹¶æˆä¸€ä¸ªæ–°çš„ patchã€‚\n\nå‡è®¾è¾“å…¥ç‰¹å¾å¤§å°ä¸º (H, W, C)ã€‚\næ¯ 2Ã—2 çš„ patch â†’ åˆå¹¶ä¸º 1 ä¸ªæ–° tokenã€‚\næ–°ç‰¹å¾å›¾å¤§å°å˜ä¸º (H/2, W/2, 4C)ã€‚\n\nçº¿æ€§å˜æ¢:\n\nå°†åˆå¹¶åçš„ 4C ç»´ç‰¹å¾é€šè¿‡ä¸€ä¸ª çº¿æ€§å±‚ (Linear Projection)ï¼Œé™åˆ° 2C ç»´ã€‚\nè¾“å‡ºç»´åº¦ç¿»å€ï¼ˆ2Cï¼‰ï¼Œä»¥è¡¥å¿åˆ†è¾¨ç‡å‡åŠå¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚ ğŸ”¹ ä¸ºä»€ä¹ˆæå‡º Patch Merging\n\n\nåˆ†å±‚è¡¨ç¤º (Hierarchical Representation) â€¢ æ¨¡ä»¿ CNN çš„é‡‘å­—å¡”ç»“æ„ï¼Œä»å±€éƒ¨ç»†èŠ‚é€æ­¥èšåˆåˆ°å…¨å±€è¯­ä¹‰ã€‚ â€¢ æœ‰åˆ©äºä¸‹æ¸¸ä»»åŠ¡ï¼ˆæ£€æµ‹ã€åˆ†å‰²ï¼‰ä¸­ä¸åŒå°ºåº¦çš„ç›®æ ‡å»ºæ¨¡ã€‚\nè®¡ç®—æ•ˆç‡ â€¢ token æ•°é‡é€å±‚å‡å°‘ â†’ Attention çš„å¤æ‚åº¦å¤§å¹…ä¸‹é™ã€‚ â€¢ ä¿è¯æ¨¡å‹å¯æ‰©å±•åˆ°å¤§åˆ†è¾¨ç‡å›¾åƒã€‚\nè¯­ä¹‰ä¿¡æ¯èšåˆ â€¢ é€šè¿‡åˆå¹¶ç›¸é‚» patchï¼Œæ¨¡å‹èƒ½æŠŠæ›´å¤§æ„Ÿå—é‡çš„ä¿¡æ¯æ•´åˆåˆ°æ–°çš„ token ä¸­ã€‚\n\n\nx = x.view(B, H, W, C)\n\nx0 = x[:, 0::2, 0::2, :]  # (B, H/2, W/2, C)\nx1 = x[:, 1::2, 0::2, :]  # (B, H/2, W/2, C)\nx2 = x[:, 0::2, 1::2, :]  # (B, H/2, W/2, C)\nx3 = x[:, 1::2, 1::2, :]  # (B, H/2, W/2, C)\n\nx = torch.cat([x0, x1, x2, x3], -1)  # (B, H/2, W/2, 4*C)\nx = x.view(B, -1, 4 * C)  # (B, H/2*W/2, 4*C)\n\nx = self.reduction(x)  # (B, H/2*W/2, 2*C)"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#relative-position-encoding",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#relative-position-encoding",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.5 Relative Position Encoding",
    "text": "1.5 Relative Position Encoding\nä¸Transformer å’Œ Vision-Transformer ä¸­ä¸åŒçš„æ˜¯ï¼ŒSwin Transformeråˆ©ç”¨çš„æ˜¯Relative Position Encodingã€‚\n\\[\n\\text{Attention}(Q, K, V) = \\text{Softmax}\\left( \\frac{QK^{T}}{\\sqrt{ d }} +B\\right) V\n\\]\n1.  å®šä¹‰åç½®è¡¨ (relative_position_bias_table)\nâ€¢   å¤§å°æ˜¯ (2*Wh-1) * (2*Ww-1, num_heads)\nâ€¢   æ„å‘³ç€çª—å£å†…çš„ä»»æ„ä¸¤ä¸ª token çš„ç›¸å¯¹ä½ç½® (dx, dy)ï¼Œéƒ½æœ‰ä¸€ä¸ªå¯å­¦ä¹ çš„åç½®å€¼ï¼ˆæ¯ä¸ª head ä¸€ä»½ï¼‰ã€‚\nâ€¢   ä¾‹å¦‚çª—å£æ˜¯ 7Ã—7 â†’ ç›¸å¯¹ä½ç½®èŒƒå›´æ˜¯ [-6,6]ï¼Œæ‰€ä»¥è¡¨å¤§å°æ˜¯ 13Ã—13=169ï¼Œæ¯ä¸ªä½ç½®å­˜ä¸€ç»„åç½®\n\n\n2.  è®¡ç®—ç›¸å¯¹ä½ç½®ç´¢å¼• (relative_position_index)\nâ€¢   é¦–å…ˆç”Ÿæˆçª—å£å†…æ¯ä¸ª token çš„åæ ‡ã€‚\nâ€¢   ç„¶ååšå·®ï¼Œå¾—åˆ°ä»»æ„ä¸¤ä¸ª token çš„ç›¸å¯¹åæ ‡ (dx, dy)ã€‚\nâ€¢   å†æ˜ å°„æˆè¡¨çš„ç´¢å¼•ï¼ˆé€šè¿‡ç§»ä½å’Œå“ˆå¸Œæˆä¸€ä¸ªæ•´æ•° indexï¼‰ã€‚\nâ€¢   ç»“æœæ˜¯ä¸€ä¸ª (Wh*Ww, Wh*Ww) çš„çŸ©é˜µï¼Œæ¯ä¸ªå…ƒç´ å­˜ä¸¤ä¸ª token ä¹‹é—´åœ¨ bias è¡¨é‡Œçš„ç´¢å¼•ã€‚\n\n\nâ€¢   åœ¨å›¾åƒé‡Œï¼Œç›¸å¯¹ä½ç½®æ¯”ç»å¯¹ä½ç½®æ›´é‡è¦ï¼š\nâ€¢   æ¯”å¦‚ä¸€ä¸ªåƒç´ çš„å·¦é‚»å’Œå³é‚»å¾ˆç›¸ä¼¼ï¼Œæ— è®ºè¿™ä¸ªåƒç´ åœ¨å›¾åƒçš„å“ªä¸ªåœ°æ–¹ã€‚\n\\[\n\\begin{tabular}\n\\Xhline{1.0pt}\n& \\multicolumn{2}{c|}{ImageNet} & \\multicolumn{2}{c|}{COCO} & \\multicolumn{1}{c}{ADE20k} \\\\\n& top-1 & top-5  & AP$^\\text{box}$ & AP$^\\text{mask}$ & mIoU \\\\\n\\hline\nno pos. & 80.1 & 94.9 & 49.2 & 42.6  & 43.8 \\\\\nabs. pos. & 80.5 & 95.2 & 49.0 & 42.4  & 43.2 \\\\\nabs.+rel. pos. & 81.3 & 95.6 & 50.2 & 43.4 & 44.0\\\\\nrel. pos. w/o app. & 79.3 & 94.7 & 48.2 & 41.9 & 44.1 \\\\\nrel. pos. & \\textbf{81.3} & \\textbf{95.6} & \\textbf{50.5} & \\textbf{43.7} & \\textbf{46.1} \\\\\n\\Xhline{1.0pt}\n\\end{tabular}\n\\]\n\n1.5.1 Fine-Tuning in different image size\nå’Œ Vision-Transformer ä¸€æ ·ï¼Œå½“è¾“å…¥çš„å›¾ç‰‡å’Œè®­ç»ƒæ—¶ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ bi-cubic interpolation æ¥å¢å¤§Relative Position\n\nThe learnt relative position bias in pre-training can be also used to initialize a model for fine-tuning with a different window size through bi-cubic interpolation  Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.5 \n\n\\[\n\\begin{table}\n    \\centering\n\\small\n\\addtolength{\\tabcolsep}{-4.0pt}\n\\begin{tabular}\n\\Xhline{1.0pt}\n\\multirow{2}{*}{method} & \\multicolumn{4}{c|}{MSA in a stage (ms)} & \\multicolumn{3}{c}{Arch. (FPS)} \\\\\n& S1 & S2 & S3 & S4 & T & S & B \\\\\n\\hline\nsliding window (naive) & 122.5 & 38.3 & 12.1 & 7.6 & 183 & 109 & 77 \\\\\nsliding window (kernel)  & 7.6 & 4.7 & 2.7 & 1.8 & 488 & 283 & 187 \\\\\n\\hline\nPerformer~\\cite{choromanski2020performer} & 4.8 & 2.8 & 1.8 & 1.5 & 638 & 370 & 241 \\\\\n\\hline\nwindow (w/o shifting) & 2.8 & 1.7 & 1.2 & 0.9 & 770 & 444 & 280 \\\\\n\\hline\nshifted window (padding) & 3.3 & 2.3 & 1.9 & 2.2 & 670 & 371 & 236 \\\\\nshifted window (cyclic)  & 3.0 & 1.9 & 1.3 & 1.0 & 755 & 437 & 278 \\\\\n\\Xhline{1.0pt}\n\\end{tabular}\n    \\caption{Real speed of different self-attention computation methods and implementations on a V100 GPU. }\n    \\label{tab:ablation-selfatt-efficient}\n\\normalsize\n\\end{table}\n\\]"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#others",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#others",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.6 Others",
    "text": "1.6 Others\né™¤äº†ä»¥ä¸Šå‡ ä¸ªï¼ŒSwin Transformer ä¸­è¿˜æœ‰å…¶ä»–Componentï¼Œæ¯”å¦‚ ï¼š\n\nPatch Embedding\nLinear Projection\nFeedForward\nLayer Normalization åœ¨æ­¤ï¼Œå°±ä¸èµ˜è¿°äº†ï¼Œæœ‰éœ€è¦çš„åŒå­¦ï¼Œè¯·å‚è€ƒå‰ä¸€ç¯‡ Vision-Transformerï¼Œ æˆ–è€… Transformer"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#downstream-tasks",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#downstream-tasks",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.7 Downstream Tasks",
    "text": "1.7 Downstream Tasks\nå½“ä¸€åœºå›¾ç‰‡ä¼ å…¥Swin Transformerï¼Œ å®ƒå¯ä»¥æå–å‡ºå›¾ç‰‡çš„ç‰¹å¾ã€‚ \\[\n\\mathrm{z} = f_{\\theta}(\\mathrm{x}), \\quad \\text{where}\\ \\mathrm{x} \\in \\mathbb{R}^{3\\times H \\times W}, \\mathrm{z} \\in \\mathbb{R}^{H'W' \\times C}\n\\]\nä¸€å¼ å›¾ç‰‡è½¬åŒ–æˆäº† \\(H'W'\\) ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾çš„å¤§å°ä¸º $Cã€‚\nSwin Transformer å¯ä»¥æœ‰å½“ä½œåŸºæœ¬çš„backboneï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ä¸‹æ¸¸è¿›è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼š\n\nImage Classification\nObject Detection\nSemantic segmentation\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¦‚ä½•ç”¨Swin Transformeråœ¨ä¸åŒçš„ä»»åŠ¡ä¸­\n\n\n1.7.1 Image Classification\nå¯¹äº \\(\\mathrm{z}\\) çš„ hidden statesï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€ä¸ªAverage Poolingï¼Œå¯¹äºæ¯ä¸€ä¸ªç‰¹å¾æ±‚å‡å€¼ï¼Œç„¶åå†å°†è¿™ä¸ªä¼ å…¥ä¸€ä¸ªåˆ†ç±»å¤´ï¼Œå°±å¯ä»¥å¾—åˆ°æˆ‘ä»¬Classificationäº†ã€‚ä¸ Vision-Transformer ä¸åŒçš„æ˜¯ï¼ŒSwin Transformer æ²¡æœ‰ [CLS] token æ¥å½“æ”¶é›†å…¨éƒ¨çš„ä¿¡æ¯ã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#object-detection-semantic-segmentation",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#object-detection-semantic-segmentation",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.8 Object Detection & Semantic segmentation",
    "text": "1.8 Object Detection & Semantic segmentation\nBackbone (Swin Transformer)ï¼š\n\nStage 1: [N, C1, H/4, W/4]\nStage 2: [N, C2, H/8, W/8]\nStage 3: [N, C3, H/16, W/16]\nStage 4: [N, C4, H/32, W/32]\n\nå¯ä»¥å¾—åˆ° FPN(Lin et al. 2017) to create a pyramid of feature maps suitable for detection.\n{P2: [N, C, H/4, W/4], \n P3: [N, C, H/8, W/8], \n P4: [N, C, H/16, W/16], \n P5: [N, C, H/32, W/32]}\næœ‰äº†è¿™äº›FPN ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆä¸åŒçš„ç®—æ³•ï¼Œæ¥è¿›è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œæ¯”å¦‚\nä¾‹å­ 1ï¼šç›®æ ‡æ£€æµ‹ (Object Detection)\nä»¥ Swin Transformer + Faster R-CNN (Ren et al. 2016) ä¸ºä¾‹ï¼š 1. è¾“å…¥å›¾åƒï¼šä¸€å¼  800Ã—1333 çš„ COCO æ•°æ®é›†å›¾ç‰‡ã€‚\n3.  FPN (ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ)ï¼šå°†å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œå½¢æˆç»Ÿä¸€çš„é‡‘å­—å¡”ç‰¹å¾ã€‚\n4.  RPN (Region Proposal Network)ï¼šåœ¨ç‰¹å¾å›¾ä¸Šç”Ÿæˆå€™é€‰åŒºåŸŸã€‚\n5.  RoI Headï¼šå¯¹å€™é€‰åŒºåŸŸè¿›è¡Œåˆ†ç±» (è½¦ã€äººã€ç‹—â€¦) å’Œè¾¹æ¡†å›å½’ã€‚\n6.  è¾“å‡ºï¼šé¢„æµ‹ç»“æœï¼Œä¾‹å¦‚ï¼š\nâ€¢   â€œä¸€è¾†è½¦â€ â†’ è¾¹æ¡† (x1,y1,x2,y2) + ç±»åˆ« â€œcarâ€\nâ€¢   â€œä¸€ä¸ªäººâ€ â†’ è¾¹æ¡† + ç±»åˆ« â€œpersonâ€\n ğŸ‘‰ åœ¨ COCO æ•°æ®é›†ä¸Šï¼ŒSwin-T + Faster R-CNNæ¯” ResNet-50 + Faster R-CNN çš„ mAP æé«˜çº¦ 5~6 ä¸ªç‚¹ã€‚\nè¯­ä¹‰åˆ†å‰² (Semantic Segmentation)  ä»¥ Swin Transformer + UPerNet(Xiao et al. 2018)ä¸ºä¾‹ï¼š 1. è¾“å…¥å›¾åƒï¼šä¸€å¼  512Ã—512 çš„ ADE20K æ•°æ®é›†å›¾ç‰‡ã€‚ 2. Backbone (Swin Transformer)ï¼šåŒæ ·è¾“å‡º 1/4, 1/8, 1/16, 1/32 å››ä¸ªå°ºåº¦ç‰¹å¾ã€‚ 3. FPN/UPerNet Headï¼š â€¢ å°†å¤šå±‚ç‰¹å¾èåˆï¼Œå¯¹åº”ä¸åŒè¯­ä¹‰å±‚çº§ã€‚ â€¢ åˆ©ç”¨èåˆåçš„ç‰¹å¾ç”Ÿæˆåƒç´ çº§é¢„æµ‹ã€‚ 4. é¢„æµ‹å›¾ (segmentation map)ï¼šå¤§å° 512Ã—512ï¼Œæ¯ä¸ªåƒç´ å±äºä¸€ä¸ªç±»åˆ«ã€‚ â€¢ [0,0] åƒç´  â†’ â€œskyâ€ â€¢ [100,150] åƒç´  â†’ â€œbuildingâ€ â€¢ [200,300] åƒç´  â†’ â€œroadâ€ 5. è¾“å‡ºï¼šå®Œæ•´çš„è¯­ä¹‰åˆ†å‰²å›¾ï¼Œæ¯ä¸ªåƒç´ éƒ½æœ‰ç±»åˆ«æ ‡ç­¾ã€‚\nğŸ‘‰ åœ¨ ADE20K ä¸Šï¼ŒSwin-L + UPerNet çš„ mIoU è¾¾åˆ° 53.5+ï¼Œæ¯”ä¼ ç»Ÿ CNN backbone æå‡æ˜¾è‘—ã€‚ å…·ä½“çš„å®ç°ç»†èŠ‚ï¼Œç­‰åˆ°ä»¥åæˆ‘ä»¬é˜…è¯»åˆ°å…³äºSegmentationçš„å†…å®¹åœ¨ï¼Œå†æ¥å®ç°"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#training-details",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#training-details",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.9 Training Details",
    "text": "1.9 Training Details\n\nWe employ an AdamW optimizer for 300 epochs using a cosine decay learning rate scheduler and 20 epochs of linear warm-up. A batch size of 1024, an initial learning rate of 0.001, and a weight decay of 0.05 are used. We include most of the augmentation and regularization strategies of in training, except for repeated augmentation and EMA, which do not enhance performance.  Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.5 \n\n\n1.9.1 DropPath\nè®ºæ–‡ä¸­è¿˜ç”¨åˆ°äº† DropPath æ¥å½“ä½œä¸€ç§ Regularizationã€‚ DropPath ä¹Ÿç§°ä¹‹ä¸º Stochastic Depth (Huang et al. 2016) , å®ƒæ˜¯ä¸€ç§åº”ç”¨åœ¨Residual Networkï¼Œ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºä¸¢å¼ƒæ•´ä¸ª æ®‹å·®åˆ†æ”¯ (residual branch) æˆ– æ•´ä¸ªè·¯å¾„ (path)ã€‚å‡å°‘è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶è®©æ¨¡å‹å­¦ä¼šä¾èµ–ä¸åŒæ·±åº¦çš„è·¯å¾„ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚ \nä¸Dropout ä¸åŒçš„æ˜¯ï¼Œ Dropout ä¸¢å¼ƒçš„æ˜¯å•ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼Œ è€ŒDropPath ä¸¢å¼ƒçš„æ˜¯æ•´ä¸ªæ®‹å·®åˆ†æ”¯ / æ•´å±‚ Block\n\n\n\n\n\n\n\n\nç‰¹æ€§\nDropout (ç»å…¸)\nDropPath (Stochastic Depth)\n\n\n\n\nä¸¢å¼ƒå¯¹è±¡\nå•ä¸ªç¥ç»å…ƒçš„è¾“å‡º\næ•´ä¸ªæ®‹å·®åˆ†æ”¯ / æ•´å±‚ Block\n\n\nåº”ç”¨ç²’åº¦\né€å…ƒç´  (element-wise)\nå±‚çº§ (layer-wise)\n\n\nä½¿ç”¨åœºæ™¯\nå…¨è¿æ¥å±‚ã€CNNã€RNN ç­‰\næ®‹å·®ç½‘ç»œã€Transformer ç­‰\n\n\næ¨ç†é˜¶æ®µæ•ˆæœ\nä¸ä¸¢å¼ƒï¼Œä½¿ç”¨ç¼©æ”¾è¡¥å¿\nä¸ä¸¢å¼ƒï¼Œä¿ç•™å®Œæ•´è·¯å¾„\n\n\nä½œç”¨\nå‡å°‘ç¥ç»å…ƒè¿‡æ‹Ÿåˆ\né˜²æ­¢æ·±å±‚ç½‘ç»œè¿‡æ‹Ÿåˆã€æå‡ç¨³å®šæ€§\n\n\n\ndef drop_path(x, drop_prob: float = 0.0, training: bool = False):\n    if drop_prob == 0.0 or not training:\n        return x\n    keep_prob = 1 - drop_prob\n    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n    random_tensor.floor_()  # binarize\n    output = x.div(keep_prob) * random_tensor\n    return output\n\n\nclass DropPath(nn.Module):\n    def __init__(self, drop_prob=None):\n        super().__init__()\n        self.drop_prob = drop_prob\n\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training)\n        \n\nclass SwinTransformerBlock(nn.Module):\n    def __init__(self):\n        ...\n        self.drop_path = DropPath(drop_path) if drop_path &gt; 0.0 else nn.Identity()\n        \n    \n    def forward(self, x):\n        shortcut = x \n        ... # Attention \n        x = shortcut + self.drop_path(x)\n        \n        shortcut = x \n        ... # FFN\n        x = shortcut + self.drop_path(x)\n        \n        ...\n        \n        return x \n\nğŸ“ TAKEAWAY DropPathï¼ˆä¹Ÿå« Stochastic Depthï¼‰æ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå®ƒåœ¨è®­ç»ƒæ—¶éšæœºè·³è¿‡ï¼ˆä¸¢å¼ƒï¼‰æ•´ä¸ªç½‘ç»œå±‚æˆ–åˆ†æ”¯çš„è®¡ç®—ï¼Œä»¥å‡å°‘è¿‡æ‹Ÿåˆå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n\n\n1.9.2 Gradient Checkpoint\nåœ¨æ­¤ï¼Œæˆ‘ä»¬åœ¨ä»‹ç»ä¸€ä¸ªè®­ç»ƒæ–¹æ³•ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒï¼Œå«åšGradient Checkpointåˆå«åšActivation Checkpointï¼Œ ç”¨PyTorhå®ç°ï¼Œæ˜¯å¾ˆå®¹æ˜“çš„ çš„ï¼Œæˆ‘ä»¬åªéœ€è¦call utils.checkpoint\næ­£å¸¸è®­ç»ƒæµç¨‹ï¼š åœ¨å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰æ—¶ï¼Œæ¯ä¸€å±‚çš„ä¸­é—´æ¿€æ´»å€¼ï¼ˆactivationï¼‰éƒ½ä¼šä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿åå‘ä¼ æ’­ï¼ˆbackwardï¼‰æ—¶ç”¨æ¥è®¡ç®—æ¢¯åº¦ã€‚ é—®é¢˜æ˜¯ï¼šä¿å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»å€¼ä¼šæ¶ˆè€—å¤§é‡æ˜¾å­˜ï¼ˆGPU memoryï¼‰ã€‚ â€¢ Gradient Checkpoint çš„æ€è·¯ï¼š å¹¶ä¸æ˜¯ä¿å­˜æ‰€æœ‰æ¿€æ´»å€¼ï¼Œè€Œæ˜¯åªåœ¨éƒ¨åˆ†å…³é”®èŠ‚ç‚¹ï¼ˆcheckpointï¼‰ä¿å­˜æ¿€æ´»ã€‚ å¯¹äºæœªä¿å­˜çš„æ¿€æ´»å€¼ï¼Œåœ¨åå‘ä¼ æ’­æ—¶é‡æ–°å†è·‘ä¸€æ¬¡å‰å‘è®¡ç®—æ¥å¾—åˆ°å®ƒä»¬ï¼Œä»è€ŒèŠ‚çœæ˜¾å­˜ã€‚\næ¢å¥è¯è¯´ï¼šç”¨è®¡ç®—æ¢æ˜¾å­˜ã€‚\nğŸ”¹ å·¥ä½œæœºåˆ¶ 1. åœ¨å‰å‘ä¼ æ’­æ—¶ï¼š â€¢ æ¨¡å‹è¢«åˆ‡åˆ†æˆè‹¥å¹²å—ï¼ˆsegmentsï¼‰ã€‚ â€¢ åªä¿å­˜æ¯ä¸€å—çš„è¾“å…¥ï¼Œä¸¢å¼ƒä¸­é—´çš„æ¿€æ´»ã€‚ 2. åœ¨åå‘ä¼ æ’­æ—¶ï¼š â€¢ éœ€è¦ç”¨åˆ°æ¢¯åº¦æ—¶ï¼Œé‡æ–°å¯¹é‚£ä¸€å—åšä¸€æ¬¡ forward æ¥æ¢å¤æ¿€æ´»ã€‚ â€¢ ç„¶åæ­£å¸¸è®¡ç®—æ¢¯åº¦ã€‚\nâ€¢   å¢åŠ è®¡ç®—å¼€é”€ï¼šå› ä¸ºè¦åœ¨ backward æ—¶é‡æ–°åšä¸€æ¬¡ forwardã€‚\nâ€¢   ä¸€èˆ¬ä¼šå¸¦æ¥ 20%ï½30% é¢å¤–çš„è®­ç»ƒæ—¶é—´ã€‚\nimport torch\nfrom torch import nn\nfrom torch.utils.checkpoint import checkpoint\n\nclass MyModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(1024, 1024)\n        self.layer2 = nn.Linear(1024, 1024)\n\n    def forward(self, x):\n        def custom_forward(*inputs):\n            return self.layer2(self.layer1(*inputs))\n        \n        # å¯¹è¿™éƒ¨åˆ†ä½¿ç”¨ checkpoint\n        x = checkpoint(custom_forward, x)\n        return x\n\nğŸ“ TAKEAWAY Gradient Checkpointing æ˜¯ä¸€ç§ ç”¨é¢å¤–è®¡ç®—æ¢æ˜¾å­˜ çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨å‰å‘ä¼ æ’­æ—¶å°‘å­˜æ¿€æ´»ï¼Œåå‘ä¼ æ’­æ—¶é‡ç®—ï¼Œèƒ½è®©å¤§æ¨¡å‹åœ¨æœ‰é™æ˜¾å­˜ä¸‹å®Œæˆè®­ç»ƒã€‚"
  },
  {
    "objectID": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#swin-v2",
    "href": "posts/100-AI-Papers/04-swin-transformer/Swin-Transformer.html#swin-v2",
    "title": "04: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Swin-Transformer)",
    "section": "1.10 Swin V2",
    "text": "1.10 Swin V2\nâ€œSwin V2â€ (Liu et al. 2022) æ˜¯åœ¨åŸå§‹ Swin Transformer çš„åŸºç¡€ä¸Šï¼Œä¸ºäº†æ›´å¥½åœ° æ‰©å±•æ¨¡å‹å®¹é‡ï¼ˆæ›´å¤šå‚æ•°ï¼‰ã€å¤„ç†é«˜åˆ†è¾¨ç‡è¾“å…¥ ä»¥åŠ æé«˜è®­ç»ƒç¨³å®šæ€§ æ‰€åšçš„ä¸€ç³»åˆ—æ”¹è¿›ã€‚ åœ¨è§†è§‰ä»»åŠ¡ä¸­ï¼ŒTransformer æ¨¡å‹è‹¥è¦å˜å¾—æ›´å¼ºï¼ˆæ›´å¤šå‚æ•°ã€æ›´é«˜åˆ†è¾¨ç‡è¾“å…¥ã€æ›´å¤šå±‚æ•°ï¼‰å°±ä¼šé‡åˆ°å‡ ä¸ªæŒ‘æˆ˜ï¼š 1. è®­ç»ƒä¸ç¨³å®šï¼šéšç€æ¨¡å‹å˜æ·±ã€é€šé“å˜å®½ï¼Œå†…éƒ¨æ¿€æ´»çš„å¹…åº¦å¯èƒ½æ€¥å‰§å¢é•¿ï¼Œå¯¼è‡´æ¢¯åº¦ã€æ•°å€¼ä¸ç¨³å®šã€‚ 2. åˆ†è¾¨ç‡è¿ç§»é—®é¢˜ï¼šæ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡ä¸‹é¢„è®­ç»ƒï¼ˆä¾‹å¦‚ 224Ã—224ï¼‰åï¼Œç”¨åœ¨é«˜åˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚ 1,536Ã—1,536ï¼‰æˆ–ä¸åŒçª—å£å°ºå¯¸æ—¶è¡¨ç°ä¼šä¸‹é™ã€‚ 3. å¯¹æ ‡æ³¨æ•°æ®çš„è¿‡åº¦ä¾èµ–ï¼šå¤§æ¨¡å‹éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®æ‰èƒ½è®­ç»ƒå¾—å¥½ã€‚\nSwin V2 å°±æ˜¯ä¸ºäº†å…‹æœè¿™äº›éšœç¢ï¼Œæ”¯æŒè®­ç»ƒè¶…å¤§æ¨¡å‹ï¼ˆå¦‚ 30 äº¿å‚æ•°çº§åˆ«ï¼‰ï¼ŒåŒæ—¶èƒ½å¤„ç†å¤§å°ºå¯¸è¾“å…¥ \n\n1.10.1 Post normalization\nclass SwinTransformerBlock(nn.Module):\n    def __init__(self):\n        ...\n        self.drop_path = DropPath(drop_path) if drop_path &gt; 0.0 else nn.Identity()\n        \n    \n    def forward(self, x):\n        shortcut = x \n        ... # Attention \n        x = shortcut + self.drop_path(self.norm1(x))\n        \n        shortcut = x \n        ... # FFN\n        x = x + self.drop_path(self.norm2(self.mlp(x)))\n        \n        ...\n        \n        return x \n\n\n1.10.2 Scaled cosine attention\nclass WindowAttention:\n    def __init__(self,):\n    \n        ...\n        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))), requires_grad=True)\n        ...\n    \n    \n    def forward(self, x):\n        attn = (F.normalize(q, dim=-1) @ F.normalize(k, dim=-1).transpose(-2, -1))\n        logit_scale = torch.clamp(self.logit_scale, max=torch.log(torch.tensor(1. / 0.01))).exp()\n        attn = attn * logit_scale\n\n\n1.10.3 Log-spaced Continuous Position Bias(Log-CPB)\nlog-spaced continuous position bias approach to address the issue in transferring across window resolutions\n\\[\n\\begin{split}\n\\widehat{\\Delta x} &= \\operatorname{sign}(x) \\cdot \\log(1 + |\\Delta x|) \\\\\n\\widehat{\\Delta y} &= \\operatorname{sign}(y) \\cdot \\log(1 + |\\Delta y|)\n\\end{split}\n\\]\nself.cpb_mlp = nn.Sequential(nn.Linear(2, 512, bias=True),\n                             nn.ReLU(inplace=True),\n                             nn.Linear(512, num_heads, bias=False))\n                             \ndef forward(self, x):\n    relative_position_bias_table = self.cpb_mlp(self.relative_coords_table).view(-1, self.num_heads)"
  },
  {
    "objectID": "posts/CS336/Lecture04/lec04.html",
    "href": "posts/CS336/Lecture04/lec04.html",
    "title": "Lecture 04: Introduction to MoE",
    "section": "",
    "text": "éšç€2025å¹´æ˜¥èŠ‚DeepSeek-R1 çš„å‘å¸ƒï¼ŒMixture of Experts (MoE) æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸé‡æ–°å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚è¿™èŠ‚è¯¾æˆ‘ä»¬å°†ä¼šå­¦ä¹ ä»€ä¹ˆçš„MoE Layerã€‚å®ƒçš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿä»¥åŠå®ƒä¸ºä»€ä¹ˆèƒ½å¤Ÿæå‡æ¨¡å‹çš„æ€§èƒ½ã€‚\næˆ‘ä»¬é¦–å…ˆæ¥äº†è§£ä¸€ä¸‹ï¼Œä»€ä¹ˆæ˜¯Mixture of Experts (MoE) æ¨¡å‹ï¼Œå¹¶ä¸”ä¸ºä»€ä¹ˆå®ƒå—åˆ°äº†å¦‚æ­¤å¤šçš„å…³æ³¨ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 04: MoE Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture04/lec04.html#routing-function",
    "href": "posts/CS336/Lecture04/lec04.html#routing-function",
    "title": "Lecture 04: Introduction to MoE",
    "section": "2.1 Routing Function",
    "text": "2.1 Routing Function\nMoE çš„æ ¸å¿ƒä¸æ˜¯â€œæœ‰å¾ˆå¤šä¸“å®¶â€ï¼Œè€Œæ˜¯æ¯ä¸ª token è¯¥å»å“ªäº›ä¸“å®¶ã€‚è¿™ä¸ªå†³ç­–ç”± Routerï¼ˆè·¯ç”±å™¨ï¼‰å®Œæˆã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒç†è§£æˆä¸€ä¸ªâ€œè½»é‡çš„åˆ†ç±»å™¨/æ‰“åˆ†å™¨â€ï¼šè¾“å…¥æ˜¯æ¯ä¸ª token çš„ hidden stateï¼Œè¾“å‡ºæ˜¯å¯¹æ‰€æœ‰ä¸“å®¶çš„åå¥½åˆ†æ•°ï¼Œç„¶åé€‰å‡º top-K ä¸ªä¸“å®¶æ‰§è¡Œã€‚æœ‰ä¸€ç‚¹å¾ˆé‡è¦çš„æ˜¯ï¼š\n\nRouter æ˜¯å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒä¼šæ ¹æ® token çš„å†…å®¹åŠ¨æ€å†³å®šè·¯ç”±ç»“æœï¼Œä¹Ÿå°±æ˜¯è¯´åŒä¸€ä¸ª token åœ¨ä¸åŒè¯­å¢ƒä¸‹å¯ä»¥è¢«é€å»ä¸åŒä¸“å®¶ã€‚\n\nRouterå®ç°å¤§æ¦‚æœ‰3ç§æ€è·¯ï¼š\n\nToken-choiceï¼ˆtoken é€‰ä¸“å®¶ï¼‰ï¼š æ¯ä¸ª token ç»™æ‰€æœ‰ä¸“å®¶æ‰“åˆ†ï¼Œé€‰æ‹© top-K ä¸“å®¶å¤„ç†å®ƒï¼ˆç°ä»£ä¸»æµï¼‰\nExpert-choiceï¼ˆä¸“å®¶é€‰ tokenï¼‰ï¼š æ¯ä¸ªä¸“å®¶ä»ä¸€æ‰¹ token é‡ŒæŒ‘ top-K ä¸ªæ¥å¤„ç†ï¼ˆå¤©ç„¶æ›´å‡è¡¡ï¼‰\nGlobal assignmentï¼ˆå…¨å±€åˆ†é…ï¼‰ï¼šæŠŠ tokenâ€“expert åŒ¹é…è§†ä½œä¼˜åŒ–é—®é¢˜ï¼ˆå¦‚çº¿æ€§åˆ†é…/æœ€ä¼˜ä¼ è¾“ï¼‰ï¼Œè¿½æ±‚æ›´å‡è¡¡æˆ–æ›´ä½é€šä¿¡æˆæœ¬\n\n\n\n\n\n\n\nFigureÂ 5: ä¸åŒçš„Routerè®¾è®¡æ€è·¯æ¯”è¾ƒã€‚\n\n\n\nåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒToken-choice æ˜¯ç›®å‰æœ€ä¸»æµçš„è®¾è®¡æ€è·¯ï¼Œå› ä¸ºå®ƒå®ç°ç®€å•ä¸”æ˜“äºæ‰©å±•ã€‚ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Token-choice Routerçš„å…·ä½“å®ç°ã€‚\n\n2.1.1 Token-choice Router\nToken-choice Router, é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯æ¯ä¸ª token ç»™æ‰€æœ‰ä¸“å®¶æ‰“åˆ†ï¼Œé€‰æ‹© top-K ä¸“å®¶å¤„ç†å®ƒã€‚å½“ç„¶ï¼Œè¿™ä¸ªâ€œæ‰“åˆ†â€è¿‡ç¨‹ï¼ˆRoutingï¼‰å¯ä»¥æœ‰å¾ˆå¤šç§å®ç°æ–¹å¼ï¼Œæ¯”å¦‚ï¼š\n\nTop-K Gatingï¼šä½¿ç”¨ä¸€ä¸ªçº¿æ€§å±‚å¯¹ token çš„ hidden state è¿›è¡ŒæŠ•å½±ï¼Œå¾—åˆ°æ¯ä¸ªä¸“å®¶çš„åˆ†æ•°ï¼Œç„¶åé€‰æ‹© top-K ä¸ªä¸“å®¶ã€‚\nHashing-based Routingï¼šä½¿ç”¨å“ˆå¸Œå‡½æ•°å°† token æ˜ å°„åˆ°ä¸“å®¶ï¼Œä»è€Œå®ç°è·¯ç”±ï¼ˆé€šå¸¸ä½œä¸ºBaselineï¼‰ã€‚\nRL to learn Routingï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥å­¦ä¹ è·¯ç”±ç­–ç•¥ã€‚\nSolve a Optimization Problemï¼šå°†è·¯ç”±é—®é¢˜è§†ä½œä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œé€šè¿‡æ±‚è§£è¯¥é—®é¢˜æ¥ç¡®å®šè·¯ç”±ç»“æœã€‚\n\nä¸‹å›¾å±•ç¤ºäº†ä¸åŒçš„Token-choice Routerå®ç°æ–¹å¼ã€‚\n\n\n\n\n\n\n\n\n\n\n\n(a) Top-K routing choice\n\n\n\n\n\n\n\n\n\n\n\n(b) Hashing-based routingï¼ˆé€šå¸¸ä½œä¸ºBaselineï¼‰\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) RL-Based Routing\n\n\n\n\n\n\n\n\n\n\n\n(d) Solve a Optimization Problem\n\n\n\n\n\n\n\nFigureÂ 6\n\n\n\nåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒTop-K Gating æ˜¯ç›®å‰æœ€å¸¸ç”¨çš„ Token-choice Router å®ç°æ–¹å¼ï¼Œå› ä¸ºå®ƒç®€å•ä¸”é«˜æ•ˆã€‚ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ Top-K Gating çš„å…·ä½“å®ç°ç»†èŠ‚ã€‚\n\n2.1.1.1 Top-K Gating\nTop-K Gating çš„å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š\n\nScore Calculationï¼šå¯¹äºæ¯ä¸ª token çš„ hidden state \\(h_i\\)ï¼Œé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚è®¡ç®—æ¯ä¸ªä¸“å®¶çš„åˆ†æ•°ï¼š \\[\ns_{i,j} = W_g h_i + b_g\n\\tag{1}\\] å…¶ä¸­ï¼Œ\\(W_g\\) å’Œ \\(b_g\\) æ˜¯è·¯ç”±å™¨çš„å‚æ•°ï¼Œ\\(s_{i,j}\\) æ˜¯ token \\(i\\) å¯¹ä¸“å®¶ \\(j\\) çš„åˆ†æ•°ã€‚\n\næœ‰äº†scoreä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦é€‰æ‹© top-K ä¸ªä¸“å®¶ï¼Œä¸è¿‡åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¯¹scoreè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ¯”è¾ƒä¸åŒä¸“å®¶çš„åˆ†æ•°ã€‚å¸¸ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨softmaxå‡½æ•°ï¼š \\[\np_{i,j} = \\frac{exp(s_{i,j})}{\\sum_{k} exp(s_{i,k})}\n\\tag{2}\\] å…¶ä¸­ï¼Œ\\(p_{i,j}\\) æ˜¯ token \\(i\\) å¯¹ä¸“å®¶ \\(j\\) çš„å½’ä¸€åŒ–åˆ†æ•°ã€‚\n\nTop-K Selectionï¼šå¯¹äºæ¯ä¸ª tokenï¼Œé€‰æ‹©åˆ†æ•°æœ€é«˜çš„ K ä¸ªä¸“å®¶ï¼š \\[\ng_{i, j} = \\begin{cases}\ns_{i, j}, \\quad s_{i, j} \\in \\text{Top-K}(s_i) \\\\\n0, \\quad \\text{otherwise}\n\\end{cases}\n\\tag{3}\\] å…¶ä¸­ï¼Œ\\(g_{i,j}\\) æ˜¯ token \\(i\\) å¯¹ä¸“å®¶ \\(j\\) çš„é€‰æ‹©ç»“æœã€‚\nPassing to Expertsï¼šå°† token é€å…¥é€‰æ‹©çš„ä¸“å®¶è¿›è¡Œå¤„ç†ã€‚æ¯ä¸ªä¸“å®¶åªå¤„ç†è¢«é€‰ä¸­çš„ tokenï¼Œå…¶ä½™ token è¢«å¿½ç•¥ã€‚\nCombining Outputsï¼šå°†ä¸“å®¶çš„è¾“å‡ºè¿›è¡Œåˆå¹¶ï¼Œå¾—åˆ°æœ€ç»ˆçš„ token è¡¨ç¤ºã€‚é€šå¸¸ä½¿ç”¨åŠ æƒå¹³å‡çš„æ–¹å¼ï¼š \\[\nh_i' = \\sum_{j} g_{i,j} \\text{Expert}_j(h_i) + h_i\n\\tag{4}\\] å…¶ä¸­ï¼Œ\\(h_i'\\) æ˜¯ token \\(i\\) çš„æœ€ç»ˆè¡¨ç¤ºï¼Œ\\(\\text{Expert}_j(h_i)\\) æ˜¯ä¸“å®¶ \\(j\\) å¯¹ token \\(i\\) çš„å¤„ç†ç»“æœ, \\(h_i\\) æ˜¯ token \\(i\\) çš„åŸå§‹è¡¨ç¤º(Residual Connection), \\(g_{i,j}\\) æ˜¯ token \\(i\\) å¯¹ä¸“å®¶ \\(j\\) çš„é€‰æ‹©ç»“æœã€‚\n\né€šè¿‡ä»¥ä¸Šæ­¥éª¤ï¼ŒTop-K Gating å®ç°äº†å¯¹ token çš„åŠ¨æ€è·¯ç”±ï¼Œä½¿å¾—æ¯ä¸ª token åªç»è¿‡å°‘æ•°å‡ ä¸ªä¸“å®¶ï¼Œä»è€Œå®ç°äº† MoE çš„é«˜æ•ˆè®¡ç®—ã€‚\n\n\n2.1.1.2 Top-K Variants\nåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒTop-K Gating æœ‰ä¸€äº›å˜ä½“ï¼Œå…¶ä¸­æ¯”è¾ƒå¸¸è§çš„æ˜¯DeepSeekæå‡ºçš„Top-Kå˜å½¢(Dai et al. 2024), å®ƒæå‡ºï¼Œåœ¨é€‰æ‹©Top-Kä¸“å®¶çš„åŸºç¡€ä¸Šï¼Œæ¯ä¸ªtokenè¿˜ä¼šå›ºå®šä¼ å…¥ä¸€ä¸ªShared Expertã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥ç¡®ä¿æ¯ä¸ªtokenè‡³å°‘æœ‰ä¸€ä¸ªä¸“å®¶èƒ½å¤Ÿå¤„ç†å®ƒã€‚ å¹¶ä¸”Expertçš„å¤§å°å˜å°ï¼Œä½†æ˜¯æ•°é‡å˜å¤šï¼ˆfine-grained Expertsï¼‰ï¼Œä»è€Œæå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\n\n\n\n\n\n\nFigureÂ 7: DeepSeekæå‡ºçš„Top-Kå˜å½¢ï¼Œæ¯ä¸ªtokené™¤äº†é€‰æ‹©Top-Kä¸“å®¶å¤–ï¼Œè¿˜ä¼šå›ºå®šä¼ å…¥ä¸€ä¸ªShared Expertã€‚\n\n\n\nè¿™ç§æ–¹å¼ï¼Œåœ¨ä¹‹åçš„å®éªŒä¸­ä¹Ÿè¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ã€‚ Qwen3æ¨¡å‹(Yang et al. 2025) ä¹Ÿé‡‡ç”¨äº†ç±»ä¼¼çš„è®¾è®¡ã€‚\n\n\n\n\n\n\nFigureÂ 8: ä»è¿™ç§æ¶ˆèå®éªŒä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨expertså˜å¤šçš„æƒ…å†µä¸‹ï¼ŒåŠ å…¥Shared Expertèƒ½å¤Ÿæå‡æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n\n\n\n\n2.1.1.3 Choice of K\næˆ‘ä»¬äº†è§£äº†Top-K Gatingçš„å®ç°ç»†èŠ‚ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Kå€¼çš„é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ Kå€¼çš„é€‰æ‹©å¯¹MoEæ¨¡å‹çš„æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè¾ƒå°çš„Kå€¼å¯ä»¥å‡å°‘è®¡ç®—é‡ï¼Œä½†å¯èƒ½ä¼šé™åˆ¶æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼›è€Œè¾ƒå¤§çš„Kå€¼åˆ™å¯ä»¥æå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä½†ä¼šå¢åŠ è®¡ç®—é‡ã€‚å› æ­¤ï¼Œåœ¨å®é™…çš„åº”ç”¨ä¸­ï¼Œé€šå¸¸ä½¿ç”¨ K=1 æˆ– K=2 ä½œä¸ºé»˜è®¤é€‰æ‹©ã€‚\n\n\n\n\n\n\nK &gt; 1\n\n\n\nè¯¾å ‚ä¸­æœ‰æåˆ°ï¼ŒK &gt; 1 æ—¶ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆBanditçš„é—®é¢˜ï¼ˆç†Ÿæ‚‰Reinforcement Learningçš„åŒå­¦åº”è¯¥äº†è§£ï¼‰ã€‚æ¯ä¸ªtokenåœ¨é€‰æ‹©ä¸“å®¶æ—¶ï¼Œå°±åƒæ˜¯åœ¨ç©ä¸€ä¸ªå¤šè‡‚è€è™æœºï¼ˆMulti-armed Banditï¼‰ï¼Œæ¯æ¬¡é€‰æ‹©Kä¸ªä¸“å®¶è¿›è¡Œå°è¯•ï¼Œä»è€Œè·å¾—æ›´å¥½çš„å¥–åŠ±ï¼ˆæ¨¡å‹æ€§èƒ½ï¼‰ã€‚è¿™ä¹Ÿæ˜¯RLä¸­æ¢ç´¢ä¸åˆ©ç”¨ï¼ˆExploration vs.Â Exploitationï¼‰é—®é¢˜çš„ä¸€ä¸ªä½“ç°ã€‚\n\n\n\n\n2.1.1.4 Is Top-K Gating Optimal?\næˆ‘ä»¬äº†è§£äº†Top-K Gatingçš„å®ç°ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸æ˜¯æœ€ä¼˜çš„å‘¢ï¼Ÿå…¶å®ä¹Ÿä¸å°½ç„¶ã€‚Lectureä¸­æœ‰æåˆ°ä¸€ä¸ªæ¯”è¾ƒæœ‰è¶£çš„è§‚å¯Ÿï¼šå³ä½¿ router å¾ˆå¼±ï¼ˆæ¯”å¦‚åŸºäº hashing çš„ç¡®å®šæ€§æ˜ å°„ï¼‰ï¼Œå¾ˆå¤šæ—¶å€™ä¹Ÿèƒ½æ¯” dense æ›´å¼ºã€‚æœ‰ä¸€ç§åˆç†çš„è§£é‡Šæ˜¯ï¼šåªè¦æ˜ å°„æ˜¯ç¡®å®šæ€§çš„ï¼Œæ¯ä¸ªä¸“å®¶ä»ä¼šé•¿æœŸçœ‹åˆ°æŸä¸ªå­åˆ†å¸ƒï¼Œä»è€Œå½¢æˆæŸç§â€œä¸“é—¨åŒ–â€ï¼ˆä¸ä¸€å®šæ˜¯ä½ ä»¥ä¸ºçš„è¯­ä¹‰ä¸“é—¨åŒ–ï¼Œå¯èƒ½æ˜¯é¢‘ç‡/æ¨¡å¼ä¸Šçš„ä¸“é—¨åŒ–ï¼‰ã€‚å› æ­¤ï¼ŒRouterå¹¶ä¸ä¸€å®šè¦è®¾è®¡çš„å¾ˆå¤æ‚ï¼Œç®€å•æœ‰æ•ˆå³å¯ï¼Œè¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆTop-K Gatingèƒ½è¿™ä¹ˆå—æ¬¢è¿çš„åŸå› ä¹‹ä¸€ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 04: MoE Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture04/lec04.html#experts",
    "href": "posts/CS336/Lecture04/lec04.html#experts",
    "title": "Lecture 04: Introduction to MoE",
    "section": "2.2 Experts",
    "text": "2.2 Experts\nåœ¨MoEæ¨¡å‹ä¸­ï¼ŒExpertsæ˜¯å¤šä¸ªç‹¬ç«‹çš„FFN Layerï¼Œæ¯ä¸ªExpertè´Ÿè´£å¤„ç†ä¸€éƒ¨åˆ†tokenã€‚æ¯ä¸ªExperté€šå¸¸ç”±ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeed-Forward Neural Network, FFNï¼‰ç»„æˆï¼Œç»“æ„ä¸ä¼ ç»Ÿçš„Transformerä¸­çš„FFNç±»ä¼¼ï¼Œä½†å‚æ•°æ˜¯ç‹¬ç«‹çš„ã€‚é‚£ä¹ˆï¼ŒExpertsçš„ä¸­é—´å±‚çš„ç»´åº¦åº”è¯¥å¦‚ä½•é€‰æ‹©å‘¢ï¼Ÿ ä¸€èˆ¬æ¥è¯´ï¼ŒExpertsçš„ä¸­é—´å±‚ç»´åº¦é€šå¸¸è®¾ç½®ä¸ºè¾“å…¥ç»´åº¦çš„4å€ï¼ˆå³\\(4d_{model}\\)ï¼‰ï¼Œå’Œä¼ ç»Ÿçš„FFN Layerä¿æŒä¸€è‡´ã€‚è¿™æ˜¯å› ä¸ºè¾ƒå¤§çš„ä¸­é—´å±‚ç»´åº¦å¯ä»¥æå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½ã€‚ ä½†æ˜¯ï¼Œåœ¨FigureÂ 7ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°DeepSeekä»‹ç»äº†Fine-Grained Expertsçš„æ¦‚å¿µï¼Œå³é€šè¿‡å¢åŠ Expertsçš„æ•°é‡ï¼ŒåŒæ—¶å‡å°‘æ¯ä¸ªExpertçš„ä¸­é—´å±‚ç»´åº¦ï¼Œä»è€Œæå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚åœ¨DeepSeek MoE ä¸­(Dai et al. 2024), æ¯ä¸ªExpertçš„ä¸­é—´å±‚ç»´åº¦è¢«è®¾ç½®ä¸º\\(\\frac{1}{4}d_{ff}\\). è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥è®©æ¨¡å‹æ‹¥æœ‰æ›´å¤šçš„ä¸“å®¶ï¼Œä»è€Œæå‡æ¨¡å‹çš„å¤šæ ·æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚\n\nDeepSeekMoE has 1 shared expert and 63 routed experts, where each expert is 0.25 times the size of a standard FFN. DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, p.9",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 04: MoE Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture04/lec04.html#training-objectives",
    "href": "posts/CS336/Lecture04/lec04.html#training-objectives",
    "title": "Lecture 04: Introduction to MoE",
    "section": "2.3 Training Objectives",
    "text": "2.3 Training Objectives\nå¦‚æœè¯´ Routing Function è§£å†³çš„æ˜¯â€œæ¯ä¸ª token å»å“ªäº›ä¸“å®¶â€ï¼Œé‚£ Training Objectives è§£å†³çš„æ˜¯æ›´ç°å®çš„é—®é¢˜ï¼šâ€œæ¯ä¸ªä¸“å®¶åˆ°åº•å­¦ä»€ä¹ˆâ€ã€‚åœ¨ MoE é‡Œï¼Œå•çº¯é ä¸»ä»»åŠ¡ loss(Next token Prediction Loss) å¾€å¾€ä¸å¤Ÿ.å¦‚æœä½ åªç”¨è¯­è¨€æ¨¡å‹çš„ä¸»æŸå¤±ï¼ˆnext-token lossï¼‰å»è®­ MoEï¼Œrouter å¾ˆå®¹æ˜“æŠŠæ‰€æœ‰ token éƒ½é€å»åŒä¸€ä¸ªä¸“å®¶ã€‚ç»“æœæ˜¯ï¼šä¸€ä¸ªä¸“å®¶å˜æˆâ€œä¸‡èƒ½ä¸“å®¶â€ï¼Œå…¶å®ƒä¸“å®¶å‡ ä¹ä»ä¸è¢«æ¿€æ´»ï¼ˆdead expertsï¼‰ï¼Œä½ ç™½ç™½å­˜äº†ä¸€å †å‚æ•°ï¼Œæ€§èƒ½ä¹Ÿä¼šå˜å·®ã€‚\nå› æ­¤ï¼Œè¯¾å ‚ä¸Šä¹Ÿåœ¨åå¤å¼ºè°ƒçš„ä¸€ç‚¹æ˜¯ï¼š\n\n\n\n\n\n\nImportant\n\n\n\nMoE çš„ forward å¾ˆç®€å•ï¼Œéš¾ç‚¹åœ¨äºè®­ç»ƒæ—¶å¦‚ä½•é¿å… expert collapseï¼Œå¹¶è®©ä¸“å®¶ä½¿ç”¨æ›´å‡åŒ€ã€æ›´æœ‰æ•ˆç‡ã€‚\n\n\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªè®­ç»ƒé—®é¢˜éš¾åœ¨å“ªé‡Œï¼Œä»¥åŠæœ‰å“ªäº›å¸¸ç”¨çš„è§£å†³æ–¹æ³•ã€‚\n\n2.3.1 The Challenge of MoE Training\nMoE çš„ä¼˜åŠ¿åœ¨äºï¼Œåœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦æ ¹æ®Routeræ¥é€‰æ‹©æ¿€æ´»éƒ¨åˆ†ï¼ˆTop-kï¼‰ä¸“å®¶è¿›è¡Œè®¡ç®—ï¼Œè€Œä¸æ˜¯æ‰€æœ‰ä¸“å®¶éƒ½å‚ä¸è®¡ç®—ã€‚è¿™ç§ç¨€ç–æ¿€æ´»çš„æ–¹å¼ï¼Œå¯ä»¥å¤§å¹…å‡å°‘æ¯ä¸€æ­¥çš„è®¡ç®—é‡ï¼ˆFLOPsï¼‰ï¼Œä»è€Œæå‡è®­ç»ƒæ•ˆç‡ã€‚ä½†æ˜¯ï¼Œè¿™ç§ç¨€ç–æ¿€æ´»çš„æ–¹å¼ä¹Ÿå¸¦æ¥çš„æŒ‘æˆ˜æ˜¯ï¼šTop-Kæ˜¯ä¸å¯å¾®çš„ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬æ— æ³•ç›´æ¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€‚å› æ­¤ï¼Œç ”ç©¶å‘˜ä»¬æå‡ºäº†å‡ ç§æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n\n2.3.1.1 RL Based Optimization\nä¸€ç§æ€è·¯æ˜¯ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰çš„æ–¹æ³•æ¥ä¼˜åŒ–è·¯ç”±å™¨çš„å‚æ•°ã€‚\n\n\n\n\n\n\nRL 101\n\n\n\nå¯¹äºä¸ç†Ÿæ‚‰å¼ºåŒ–å­¦ä¹ çš„åŒå­¦ï¼Œç®€å•ä»‹ç»ä¸€ä¸‹ã€‚å¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå®ƒé€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“ï¼ˆAgentï¼‰é€šè¿‡è§‚å¯Ÿç¯å¢ƒçŠ¶æ€ï¼ˆStateï¼‰ï¼Œé€‰æ‹©åŠ¨ä½œï¼ˆActionï¼‰ï¼Œå¹¶æ ¹æ®ç¯å¢ƒåé¦ˆçš„å¥–åŠ±ï¼ˆRewardï¼‰æ¥è°ƒæ•´ç­–ç•¥ï¼Œä»è€Œæœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚ åœ¨äº¤äº’çš„è¿‡ç¨‹ä¸­ï¼ŒAgentæ‰€äº§ç”Ÿçš„åŠ¨ä½œé€šå¸¸æ˜¯ç¦»æ•£çš„ï¼ˆDiscrete Actionï¼‰ï¼Œè¿™å°±å¯¼è‡´äº†å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨ç¦»æ•£åŠ¨ä½œç©ºé—´ä¸­è¿›è¡Œæœ‰æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ã€‚å¸¸ç”¨çš„æ–¹æ³•åŒ…æ‹¬ç­–ç•¥æ¢¯åº¦ï¼ˆPolicy Gradientï¼‰å’ŒQ-learningç­‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†MoEçš„è·¯ç”±é—®é¢˜è§†ä½œä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œé€šè¿‡è®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œæ¥å¼•å¯¼è·¯ç”±å™¨å­¦ä¹ æ›´ä¼˜çš„è·¯ç”±ç­–ç•¥ã€‚\n\n\nä½†æ˜¯ï¼Œå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•é€šå¸¸æ¯”è¾ƒå¤æ‚ï¼Œä¸”è®­ç»ƒè¿‡ç¨‹ä¸ç¨³å®šï¼ˆGradient Estimation Varianceè¾ƒå¤§ï¼‰ï¼Œå› æ­¤åœ¨å®é™…åº”ç”¨ä¸­å¹¶ä¸å¸¸ç”¨ã€‚\n\n\n2.3.1.2 Stochastic Approximation\nå¦ä¸€ç§æ€è·¯æ˜¯ä½¿ç”¨éšæœºè¿‘ä¼¼ï¼ˆStochastic Approximationï¼‰çš„æ–¹æ³•æ¥ä¼˜åŒ–è·¯ç”±å™¨çš„å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨ router æ‰“åˆ†ï¼ˆlogitsï¼‰é‡Œæ³¨å…¥å™ªå£°/æ‰°åŠ¨ï¼Œè®© top-K çš„é€‰æ‹©åœ¨è®­ç»ƒæ—©æœŸâ€œå¶å°”æ¢è·¯â€ï¼Œä»è€Œæ›´åƒ bandit çš„æ¢ç´¢ç­–ç•¥ã€‚å…¶ä¸­ä¸€ä¸ªç»å…¸çš„ä¾‹å­å°±æ˜¯ Stochastic Jittering. å®ƒé€šè¿‡åœ¨è·¯ç”±å™¨çš„æ‰“åˆ†ä¸­æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œä»è€Œå®ç°å¯¹ä¸“å®¶çš„éšæœºé€‰æ‹©ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Stochastic Jitteringçš„å…·ä½“å®ç°ç»†èŠ‚ã€‚\n\n2.3.1.2.1 Stochastic Jittering\nStochastic Jittering çš„å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š\n\nRouter è®¡ç®—ï¼šå¯¹äºæ¯ä¸ª token çš„ hidden state \\(h_i\\)ï¼Œé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚è®¡ç®—æ¯ä¸ªä¸“å®¶çš„åˆ†æ•°ï¼š \\[\ns_{i,j} = W_g h_i + b_g\n\\tag{5}\\]\næ·»åŠ å™ªå£°ï¼šåœ¨æ¯ä¸ªä¸“å®¶çš„åˆ†æ•°ä¸­æ·»åŠ é«˜æ–¯å™ªå£°ï¼š \\[\n\\tilde{s}_{i,j} = s_{i,j} + \\epsilon_{i,j}, \\quad \\epsilon_{i,j} \\sim \\mathcal{N}(0, \\sigma(x_i)^2)\n\\tag{6}\\]\nTop-K é€‰æ‹©ï¼šå¯¹äºæ¯ä¸ª tokenï¼Œé€‰æ‹©æ·»åŠ å™ªå£°åçš„åˆ†æ•°æœ€é«˜çš„ K ä¸ªä¸“å®¶ï¼š \\[\ng_{i, j} = \\begin{cases}\n\\tilde{s}_{i, j}, \\quad \\tilde{s}_{i, j} \\in \\text{Top-K}(\\tilde{s}_i) \\\\\n0, \\quad \\text{otherwise}\n\\end{cases}\n\\tag{7}\\]\n\nå…¶ä¸­ï¼Œ\\(\\sigma(x_i)\\) æ˜¯å™ªå£°çš„æ ‡å‡†å·®, å®ƒæ˜¯ä¸€ä¸ªå¯å­¦ä¹ çš„å‡½æ•°ï¼Œé€šå¸¸é€šè¿‡ä¸€ä¸ªå°çš„ç¥ç»ç½‘ç»œæ¥å®ç°ã€‚é€šè¿‡è°ƒæ•´å™ªå£°çš„å¤§å°ï¼Œå¯ä»¥æ§åˆ¶è·¯ç”±å™¨çš„æ¢ç´¢ç¨‹åº¦ï¼Œä»è€Œæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚\né‚£ä¹ˆè¿™ä¸ªStochastic Jitteringè§£å†³äº†ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿ å®ƒå…¶å®è§£å†³äº†ç±»ä¼¼äºâ€œæ¢ç´¢ä¸åˆ©ç”¨â€ï¼ˆExploration vs.Â Exploitationï¼‰çš„é—®é¢˜ã€‚åœ¨MoEçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›è·¯ç”±å™¨èƒ½å¤Ÿæ—¢èƒ½åˆ©ç”¨å½“å‰çš„çŸ¥è¯†ï¼ˆé€‰æ‹©è¡¨ç°å¥½çš„ä¸“å®¶ï¼‰ï¼Œåˆèƒ½æ¢ç´¢æ–°çš„å¯èƒ½æ€§ï¼ˆå°è¯•å…¶ä»–ä¸“å®¶ï¼‰ã€‚è¿™äº \\(\\epsilon_{i,j} \\sim \\mathcal{N}(0, \\sigma(x_i)^2)\\) ä¸­çš„å™ªå£°æ³¨å…¥æœºåˆ¶ç›¸å‘¼åº”ï¼Œé€šè¿‡åœ¨è·¯ç”±å™¨çš„æ‰“åˆ†ä¸­æ·»åŠ å™ªå£°ï¼Œå¯ä»¥è®©è·¯ç”±å™¨åœ¨è®­ç»ƒæ—©æœŸâ€œå¶å°”æ¢è·¯â€ï¼Œä»è€Œæ›´åƒ bandit çš„æ¢ç´¢ç­–ç•¥ã€‚\nä½†æ˜¯ï¼Œå®ƒæ˜¾ç„¶æ²¡æœ‰è§£å†³Top-Ké€‰æ‹©çš„ä¸å¯å¾®é—®é¢˜ï¼Œå¹¶ä¸”ï¼Œå™ªå£°çš„å¼•å…¥ä¹Ÿå¯èƒ½å¯¼è‡´è®­ç»ƒè¿‡ç¨‹çš„ä¸ç¨³å®šï¼š\n\nå™ªå£°è¿‡å¤§ï¼šå¯èƒ½å¯¼è‡´è·¯ç”±å™¨é€‰æ‹©çš„ä¸“å®¶è¿‡äºéšæœºï¼Œæ¯ä¸ªä¸“å®¶ä¸å¤Ÿä¸“é—¨åŒ–ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ã€‚\nå™ªå£°è¿‡å°ï¼šå¯èƒ½æ— æ³•æœ‰æ•ˆä¿ƒè¿›æ¢ç´¢ï¼Œè·¯ç”±å™¨ä»ç„¶å€¾å‘äºé€‰æ‹©å°‘æ•°å‡ ä¸ªä¸“å®¶ï¼Œå¯¼è‡´ä¸“å®¶å´©æºƒï¼ˆExpert Collapseï¼‰ã€‚\n\n\n\n\n\n\n\nNote\n\n\n\nè¯¾ä¸Šè¿˜æåˆ°å¯¹ logitsåšä¹˜æ³•å™ªå£°ï¼ˆMultiplicative Perturbationï¼‰ï¼Œä¹Ÿæ˜¯ç±»ä¼¼çš„æ€è·¯ï¼Œä½†æ˜¯ä¹Ÿæœ‰ç±»ä¼¼çš„é—®é¢˜ã€‚\n\n\n\n\n\n2.3.1.3 Auxiliary / Heuristic Balancing Losses\næ—¢ç„¶MoEè®­ç»ƒçš„éš¾ç‚¹åœ¨äºé¿å…ä¸“å®¶å´©æºƒï¼ˆExpert Collapseï¼‰ï¼Œé‚£ä¹ˆä¸€ä¸ªç›´æ¥çš„æ€è·¯å°±æ˜¯åœ¨ä¸»ä»»åŠ¡æŸå¤±ï¼ˆCross Entropy Lossï¼‰ä¹‹å¤–ï¼Œæ·»åŠ ä¸€äº›è¾…åŠ©æŸå¤±ï¼ˆAuxiliary Lossesï¼‰æ¥é¼“åŠ±ä¸“å®¶çš„å‡è¡¡ä½¿ç”¨ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥ç›´æ¥å¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´å‡è¡¡çš„ä¸“å®¶ä½¿ç”¨ç­–ç•¥ï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»ä¸¤ç§å¸¸ç”¨çš„è¾…åŠ©æŸå¤±ï¼šLoad Balancing Loss å’Œ Z-Lossã€‚\n\n2.3.1.3.1 Load Balancing Loss\nLoad Balancing Loss æ˜¯Switch Transformer(Fedus, Zoph, and Shazeer 2022)ä¸­æå‡ºçš„ä¸€ç§è¾…åŠ©æŸå¤±ï¼Œæ—¨åœ¨é¼“åŠ±è·¯ç”±å™¨å‡è¡¡åœ°ä½¿ç”¨æ‰€æœ‰ä¸“å®¶ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé€šè¿‡è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰æ‹©çš„é¢‘ç‡ï¼Œå¹¶ä¸ç†æƒ³çš„å‡è¡¡åˆ†å¸ƒè¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œè®¡ç®—å‡ºè´Ÿè½½å‡è¡¡æŸå¤±ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š $$\nL_{} = N _{i=1}^{N} f_i P_i $${#eq-load-balancing-loss}\nå…¶ä¸­ï¼š\n\n\\(f_i\\) æ˜¯ä¸“å®¶ \\(i\\) è¢«é€‰æ‹©çš„é¢‘ç‡, å®šä¹‰ä¸ºï¼š \\[\nf_i = \\frac{1}{T} \\sum_{x \\in \\mathcal{B}} \\mathbb{1} \\{\\text{argmax } p(x) = i\\}\n\\tag{8}\\] \\(\\mathcal{B}\\) æ˜¯å½“å‰æ‰¹æ¬¡çš„æ ·æœ¬é›†åˆï¼Œ\\(T\\) æ˜¯token çš„æ•°é‡ï¼Œ\\(\\mathbb{1}\\) æ˜¯æŒ‡ç¤ºå‡½æ•°ï¼Œå½“ä¸“å®¶ \\(i\\) è¢«é€‰æ‹©æ—¶å–å€¼ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚ç›´è§‚æ¥è¯´ï¼šexpert i å®é™…ä¸Šâ€œæ‰¿æ‹…â€äº†å¤šå°‘è´Ÿè½½ã€‚\n\\(P_i\\) æ˜¯ä¸“å®¶ \\(i\\) çš„å¹³å‡è·¯ç”±æ¦‚ç‡ï¼Œå®šä¹‰ä¸ºï¼š \\[\nP_i = \\frac{1}{T} \\sum_{x \\in \\mathcal{B}} p_i(x)\n\\tag{9}\\] å…¶ä¸­ï¼Œ\\(p_i(x)\\) æ˜¯è·¯ç”±å™¨å¯¹ä¸“å®¶ \\(i\\) çš„è¾“å‡ºåˆ†æ•°ã€‚ç›´è§‚æ¥è¯´ï¼šrouter â€œæœ¬æ¥å€¾å‘â€æŠŠå¤šå°‘æ¦‚ç‡åˆ†ç»™ expert iã€‚\n\nç›´è§‚æ¥çœ‹ï¼šå¦‚æœæŸä¸ª expert å®é™…æ‹¿äº†å¾ˆå¤š tokens (\\(f_i\\) å¾ˆå¤§ï¼‰ï¼ŒåŒæ—¶ router è¿˜ç»§ç»­ç»™å®ƒå¾ˆé«˜æ¦‚ç‡ï¼ˆ\\(P_i\\) å¾ˆå¤§ï¼‰ï¼Œé‚£ä¹ˆå®ƒçš„è´Ÿè½½å‡è¡¡æŸå¤±å°±ä¼šå¾ˆå¤§ï¼Œä»è€Œä¿ƒä½¿è·¯ç”±å™¨å‡å°‘å¯¹è¯¥ä¸“å®¶çš„é€‰æ‹©ã€‚åä¹‹äº¦ç„¶ã€‚\né€šè¿‡æœ€å°åŒ–è´Ÿè½½å‡è¡¡æŸå¤±ï¼Œå¯ä»¥é¼“åŠ±è·¯ç”±å™¨å‡è¡¡åœ°ä½¿ç”¨æ‰€æœ‰ä¸“å®¶ï¼Œä»è€Œæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚å…·ä½“æ¥è¯´ï¼š - å¦‚æœæŸä¸ªä¸“å®¶è¢«é€‰æ‹©çš„æ¬¡æ•°è¿œé«˜äºå¹³å‡æ°´å¹³ï¼Œé‚£ä¹ˆå®ƒçš„è´Ÿè½½å‡è¡¡æŸå¤±å°±ä¼šå¾ˆå¤§ï¼Œä»è€Œä¿ƒä½¿è·¯ç”±å™¨å‡å°‘å¯¹è¯¥ä¸“å®¶çš„é€‰æ‹©ã€‚ - åä¹‹ï¼Œå¦‚æœæŸä¸ªä¸“å®¶è¢«é€‰æ‹©çš„æ¬¡æ•°è¿œä½äºå¹³å‡æ°´å¹³ï¼Œé‚£ä¹ˆå®ƒçš„è´Ÿè½½å‡è¡¡æŸå¤±ä¹Ÿä¼šå¾ˆå¤§ï¼Œä»è€Œä¿ƒä½¿è·¯ç”±å™¨å¢åŠ å¯¹è¯¥ä¸“å®¶çš„é€‰æ‹©ã€‚\n\n\n\n\n\n\nDeepseek æ ¹æ®ä¸Šé¢çš„ Load Balancing Loss è®¾è®¡äº†ä¸€ä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚å®ƒä»¬æå‡ºï¼š\n\n\n- Per-expert Balancing Lossï¼šå°†ä¸Šè¿°çš„è´Ÿè½½å‡è¡¡æŸå¤±ï¼Œæ‹“å±•ä¸ºTop-Kä¸“å®¶çš„æƒ…å†µã€‚ - Per-Device Balancing Lossï¼šåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œè€ƒè™‘æ¯ä¸ªè®¡ç®—è®¾å¤‡ä¸Šçš„ä¸“å®¶è´Ÿè½½å‡è¡¡ã€‚\n\n\næˆ‘ä»¬æ¥çœ‹çœ‹Per-Device Balancing Lossåšçš„æ˜¯ä»€ä¹ˆã€‚ æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œä¸åŒçš„è®¡ç®—è®¾å¤‡ä¸Šå¯èƒ½ä¼šæœ‰ä¸åŒæ•°é‡çš„ä¸“å®¶ã€‚å¦‚æœæŸä¸ªè®¾å¤‡ä¸Šçš„ä¸“å®¶è¢«é€‰æ‹©çš„æ¬¡æ•°è¿œé«˜äºå¹³å‡æ°´å¹³ï¼Œé‚£ä¹ˆè¿™ä¸ªGPUå¾ˆå¯èƒ½è¿‡è½½ï¼Œç”šè‡³æŸåï¼Œä»è€Œå½±å“æ•´ä½“è®­ç»ƒæ•ˆç‡ã€‚è€Œæœ‰äº›è®¾å¤‡ä¸Šçš„ä¸“å®¶å¯èƒ½å‡ ä¹æ²¡æœ‰è¢«é€‰æ‹©ï¼Œå¯¼è‡´èµ„æºæµªè´¹ã€‚å› æ­¤ï¼ŒDeepSeekæå‡ºäº†Per-Device Balancing Lossï¼Œæ—¨åœ¨é¼“åŠ±æ¯ä¸ªè®¡ç®—è®¾å¤‡ä¸Šçš„ä¸“å®¶å‡è¡¡ä½¿ç”¨ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š \\[\nL_{\\text{device}} = \\beta \\cdot D \\cdot \\sum_{d=1}^{D} f_d P_d\n\\tag{10}\\]\n\n\nå…¶ä¸­ï¼š - \\(D\\) æ˜¯è®¡ç®—è®¾å¤‡çš„æ•°é‡ã€‚ - \\(f_d\\) æ˜¯è®¾å¤‡ \\(d\\) ä¸Šçš„ä¸“å®¶è¢«é€‰æ‹©çš„é¢‘ç‡ï¼Œ - \\(P_d\\) æ˜¯è®¾å¤‡ \\(d\\) ä¸Šçš„ä¸“å®¶çš„å¹³å‡è·¯ç”±æ¦‚ç‡ã€‚\n\n\n&gt;Per-expert ä¿è¯â€œä¸“å®¶åˆ«æ­»â€ï¼ŒPer-device ä¿è¯â€œGPU åˆ«çˆ†â€ã€‚\n\n\n\nDeepSeek V3 è¿˜æå‡ºäº†å¦ä¸€ç§æ”¹è¿›ç‰ˆæœ¬ï¼Œå®ƒä»¬ç§°ä½œAuxiliary Loss Free Balancingï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šä¸å†ä¸»è¦ä¾èµ– \\(\\mathcal{L}_{\\text{ExpBal}}\\) æ¥åšè´Ÿè½½å‡è¡¡ï¼Œè€Œæ˜¯é€šè¿‡è°ƒæ•´è·¯ç”±å™¨çš„åç½®é¡¹ï¼ˆBiasï¼‰æ¥å®ç°å‡è¡¡ä½¿ç”¨ä¸“å®¶ã€‚å…·ä½“æ¥è¯´ï¼š\n\\[\ng_{i,j} = \\being{cases}\ns_{i,j} + b_j, \\quad s_{i,j} \\in \\text{Top-K}(s_i) \\\\\n0, \\quad \\text{otherwise}\n\\end{cases}\n\\tag{11}\\]\nç›´è§‚æ¥çœ‹ï¼š\n\nå¦‚æœ expert i æœ€è¿‘æ‹¿åˆ° token å¤ªå° â†’ å¢å¤§\\(b_i\\) â†’ å®ƒæ›´å®¹æ˜“è¿›å…¥ top-K\nå¦‚æœ expert i æ‹¿åˆ°çš„ token å¤ªå¤š â†’ å‡å° \\(b_i\\) â†’ å®ƒæ›´ä¸å®¹æ˜“è¢«é€‰ä¸­\n\nè¿™æ˜¯ä¸€ç§åœ¨çº¿æ§åˆ¶/åœ¨çº¿å­¦ä¹ å¼çš„è´Ÿè½½å‡è¡¡ï¼šç”¨è§„åˆ™æ›´æ–° \\(b_i\\)ï¼Œ è€Œä¸æ˜¯â€‹é€šè¿‡æ¢¯åº¦ä¸‹é™å»å­¦ä¹  \\(P_i\\) â€‹\n\n\n\n\n\n\nFigureÂ 9: æˆ‘ä»¬çœ‹åˆ°ï¼Œä¸åŠ è´Ÿè½½å‡è¡¡æŸå¤±æ—¶ï¼ŒæŸäº›ä¸“å®¶å‡ ä¹æ²¡æœ‰è¢«é€‰æ‹©ï¼ˆDead Expertsï¼‰ã€‚è€ŒåŠ å…¥è´Ÿè½½å‡è¡¡æŸå¤±åï¼Œä¸“å®¶çš„ä½¿ç”¨æ›´åŠ å‡è¡¡ã€‚\n\n\n\n\n\n2.3.1.3.2 Z-Loss\nZ-Loss æ˜¯å¦ä¸€ç§å¸¸ç”¨çš„è¾…åŠ©æŸå¤±ï¼Œæ—¨åœ¨é¼“åŠ±è·¯ç”±å™¨çš„è¾“å‡ºåˆ†å¸ƒæ›´åŠ å‡åŒ€ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š \\[\nL_{z} = \\sum_{i} \\left( \\frac{p_i}{\\sum_{j} p_j} - \\frac{1}{E} \\right)^2\n\\tag{12}\\] å…¶ä¸­ï¼Œ\\(p_i\\) æ˜¯è·¯ç”±å™¨å¯¹ä¸“å®¶ \\(i\\) çš„è¾“å‡ºåˆ†æ•°ï¼Œ\\(E\\) æ˜¯ä¸“å®¶çš„æ€»æ•°ã€‚é€šè¿‡æœ€å°åŒ–è¿™ä¸ªæŸå¤±ï¼Œå¯ä»¥é¼“åŠ±è·¯ç”±å™¨çš„è¾“å‡ºåˆ†å¸ƒæ›´åŠ å‡åŒ€ï¼Œä»è€Œæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚\n\n\n\n2.3.1.4 Loss Combination\nåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒMoEæ¨¡å‹çš„æ€»æŸå¤±é€šå¸¸ç”±ä¸»ä»»åŠ¡æŸå¤±ï¼ˆCross Entropy Lossï¼‰å’Œè¾…åŠ©æŸå¤±ï¼ˆLoad Balancing Loss å’Œ Z-Lossï¼‰ç»„æˆï¼š \\[\nL_{total} = L_{CE} + \\lambda_{load} L_{load} + \\lambda_{z} L_{z}\n\\tag{13}\\] å…¶ä¸­ï¼Œ\\(L_{CE}\\) æ˜¯ä¸»ä»»åŠ¡æŸå¤±ï¼Œ\\(L_{load}\\) æ˜¯è´Ÿè½½å‡è¡¡æŸå¤±ï¼Œ\\(L_{z}\\) æ˜¯Z-Lossï¼Œ\\(\\lambda_{load}\\) å’Œ \\(\\lambda_{z}\\)\n\n\n\n2.3.2 System Side\nåœ¨MoEæ¨¡å‹çš„å®ç°ä¸­ï¼Œç³»ç»Ÿå±‚é¢çš„ä¼˜åŒ–ä¹Ÿæ˜¯éå¸¸é‡è¦çš„ã€‚ç”±äºMoEæ¨¡å‹é€šå¸¸åŒ…å«å¤§é‡çš„ä¸“å®¶ï¼Œå› æ­¤åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œéœ€è¦è€ƒè™‘å¦‚ä½•é«˜æ•ˆåœ°ç®¡ç†å’Œè°ƒåº¦è¿™äº›ä¸“å®¶ï¼Œä»¥æå‡è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚ä½†æ˜¯ï¼Œå®ƒä»¬ä¹Ÿå¸¦æ¥äº†ç³»ç»Ÿå®ç°ä¸Šçš„æŒ‘æˆ˜ï¼Œæ¯”å¦‚ï¼š\n\næ¯ä¸ª token åªæ¿€æ´»å°‘æ•°ä¸“å®¶ï¼ˆtop-Kï¼‰æ‰èƒ½çœ FLOPsï¼Œä½†ä¸“å®¶å¾€å¾€åˆ†æ•£åœ¨ä¸åŒ GPU/èŠ‚ç‚¹ä¸Šï¼Œäºæ˜¯è®­ç»ƒè¦é¢‘ç¹åš all-to-all dispatch + all-to-all gatherï¼ˆæŠŠ token å‘ç»™å¯¹åº”ä¸“å®¶ç®—ï¼Œå†æ”¶å›æ¥åˆå¹¶ï¼‰ã€‚è¿™ç±»é€šä¿¡æ˜¯å¦åˆ’ç®—å–å†³äºä¸“å®¶ FFN è®¡ç®—æ˜¯å¦â€œå¤Ÿå¤§å¤Ÿé‡â€ï¼Œèƒ½å¦ amortize é€šä¿¡æˆæœ¬ã€‚\n\n\n\n2.3.3 Fine-tuning MoE\nMoE fine-tune æ›´éš¾ï¼šæ›´å®¹æ˜“ä¸ç¨³å®šï¼ˆblow upï¼‰+ æ›´å®¹æ˜“è¿‡æ‹Ÿåˆï¼ˆtrainâ€“val gap å¤§ï¼‰ã€‚\n\n\n2.3.4 Upcycling\nMoE çš„å¦ä¸€ä¸ªæœ‰è¶£åº”ç”¨æ˜¯â€œUpcyclingâ€ï¼ˆå›æ”¶åˆ©ç”¨ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œå…ˆè®­ç»ƒå¥½ä¸€ä¸ª dense Transformerï¼Œå†æŠŠå…¶ä¸­çš„ FFN/MLP å¤åˆ¶æˆå¤šä»½ä¸“å®¶ï¼ˆexpertsï¼‰ï¼ŒåŠ ä¸Šä¸€ä¸ª routerï¼Œè®©æ¨¡å‹ä»è¿™ä¸€åˆ»èµ·å˜æˆ MoEï¼›ç»§ç»­è®­ç»ƒä¸€æ®µæ—¶é—´ï¼Œå°±èƒ½ç”¨è¾ƒä½æˆæœ¬å¾—åˆ°â€œæ€»å‚æ•°æ›´å¤§ã€æ¨ç†ä»ç¨€ç–æ¿€æ´»â€çš„ MoEã€‚å®ƒè§£å†³äº†â€œä»é›¶è®­ç»ƒ MoE å¤ªæ…¢å¤ªéš¾â€çš„é—®é¢˜ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 04: MoE Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html",
    "href": "posts/CS336/Lecture03/lec03.html",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "",
    "text": "Lecture 03 ä»‹ç»äº†ç°ä»£å¤§æ¨¡å‹çš„æ ¸å¿ƒæ¶æ„ä¸ä¸åŒçš„è¶…å‚æ•°è®¾è®¡ã€‚è¿™èŠ‚è¯¾æ˜¯ç†è§£å¤§æ¨¡å‹çš„åŸºç¡€ï¼Œå†…å®¹æ¯”è¾ƒå¤šï¼Œå»ºè®®å¤šçœ‹å‡ éã€‚ æœ¬èŠ‚è¯¾çš„ç›®æ ‡æ˜¯äº†è§£ä¸‹å›¾ä¸­çš„å†…å®¹:",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#normalization",
    "href": "posts/CS336/Lecture03/lec03.html#normalization",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "2.1 Normalization",
    "text": "2.1 Normalization\n\nä¸ºä»€ä¹ˆéœ€è¦ Normalizationï¼Ÿ\nNormalization æŠ€æœ¯åœ¨æ·±åº¦å­¦ä¹ ä¸­èµ·åˆ°äº†ç¨³å®šè®­ç»ƒè¿‡ç¨‹å’ŒåŠ é€Ÿæ”¶æ•›çš„ä½œç”¨ã€‚ å®ƒé€šè¿‡è°ƒæ•´ç¥ç»ç½‘ç»œå±‚çš„è¾“å…¥åˆ†å¸ƒï¼Œå‡å°‘äº†å†…éƒ¨åå˜é‡åç§» (Internal Covariate Shift)ï¼Œä»è€Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´åŠ ç¨³å®šã€‚æ­¤å¤–ï¼ŒNormalization è¿˜å¯ä»¥å¸®åŠ©ç¼“è§£æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n\n2.1.1 Position of Normalization\n\n2.1.1.1 Post-Norm\nåœ¨Transformerä¸­ï¼ŒNormalizationæ”¾ç½®åœ¨Sublayerä¹‹åï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ Post-Norm ç»“æ„ã€‚ç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:\n\\[\n\\text{Post-Norm: } \\quad \\text{Norm}(x + \\text{Sublayer}(x))\n\\tag{1}\\]\nç„¶è€Œï¼Œ(Ba, Kiros, and Hinton 2016) æŒ‡å‡ºï¼ŒPost-Normå­˜åœ¨ä»¥ä¸‹çš„é—®é¢˜:\n\næ¢¯åº¦ä¸ç¨³å®šï¼Œç‰¹åˆ«æ˜¯åœ¨åˆå§‹åŒ–é˜¶æ®µï¼š è®ºæ–‡ä½¿ç”¨å¹³å‡åœºç†è®ºåˆ†ææŒ‡å‡ºï¼Œåœ¨ Post-Norm ç»“æ„ ä¸‹ï¼ˆå³ LayerNorm æ”¾åœ¨æ®‹å·®è¿æ¥ä¹‹åï¼‰ï¼Œé è¿‘è¾“å‡ºå±‚çš„å‚æ•°åœ¨åˆå§‹åŒ–æ—¶æ¢¯åº¦æœŸæœ›å€¼å¾ˆå¤§ã€‚ è¿™ä¼šå¯¼è‡´è®­ç»ƒåˆæœŸæ¢¯åº¦çˆ†ç‚¸ï¼Œä»è€Œå½±å“æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚\nä¾èµ–å¤æ‚çš„ warm-up è¶…å‚æ•°è°ƒä¼˜ï¼š ç”±äº Post-Norm ç»“æ„åœ¨è®­ç»ƒåˆæœŸå®¹æ˜“å‡ºç°æ¢¯åº¦ä¸ç¨³å®šçš„é—®é¢˜ï¼Œå› æ­¤éœ€è¦ä½¿ç”¨å¤æ‚çš„å­¦ä¹ ç‡ warm-up ç­–ç•¥æ¥ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚ è¿™å¢åŠ äº†æ¨¡å‹è®­ç»ƒçš„å¤æ‚æ€§å’Œè°ƒä¼˜éš¾åº¦ã€‚\n\n\nSpecifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem.  On Layer Normalization in the Transformer Architecture P.1 \n\n\n\n2.1.1.2 Pre-Norm\nä¸ºäº†ç¼“è§£ Post-Norm çš„é—®é¢˜ï¼Œ(Ba, Kiros, and Hinton 2016) æå‡ºäº† Pre-Norm ç»“æ„ï¼Œå³å°† Normalization æ”¾ç½®åœ¨ Sublayer ä¹‹å‰ã€‚ ç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:\n\\[\n\\text{Pre-Norm: } \\quad x + \\text{Sublayer}(\\text{Norm}(x))\n\\tag{2}\\]\nä¸‹å›¾å±•ç¤ºäº† Post-Norm ä¸ Pre-Norm ç»“æ„çš„å¯¹æ¯”:\n\n\n\n\n\n\nFigureÂ 2: Post Norm ä¸ Pre-Norm ç»“æ„å¯¹æ¯”ã€‚\n\n\n\nPre-Norm æœ‰ä»¥ä¸‹ä¼˜ç‚¹:\n\næé«˜è®­ç»ƒç¨³å®šæ€§ï¼š Pre-Norm ç»“æ„é€šè¿‡åœ¨æ¯ä¸ªå­å±‚ä¹‹å‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œå‡å°‘äº†æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±çš„é£é™©ï¼Œä»è€Œæé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚\nç®€åŒ–è¶…å‚æ•°è°ƒä¼˜ï¼š ç”±äº Pre-Norm ç»“æ„åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´åŠ ç¨³å®šï¼Œå› æ­¤ä¸å†éœ€è¦å¤æ‚çš„å­¦ä¹ ç‡ warm-up ç­–ç•¥ï¼Œç®€åŒ–äº†æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹å’Œè¶…å‚æ•°è°ƒä¼˜ã€‚\n\n\nWe show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.  On Layer Normalization in the Transformer Architecture P.1 \n\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä¸ºä»€ä¹ˆPre-Normèƒ½æœ‰è¿™ä¹ˆå¤šçš„å¥½å¤„ï¼š\n\nGradient Attenuation\n\n\n\n\n\n\n\nFigureÂ 3: ä¸Šå›¾å±•ç¤ºäº† Pre-Norm ä¸ Post-Norm Transformer åœ¨æ¢¯åº¦è¡Œä¸ºä¸Šçš„å·®å¼‚ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨åˆå§‹åŒ–é˜¶æ®µï¼ŒPost-Norm ä¼šå¯¼è‡´é è¿‘è¾“å‡ºå±‚çš„æ¢¯åº¦æœŸæœ›å€¼æ˜¾è‘—å¢å¤§ï¼Œè€Œåº•å±‚æ¢¯åº¦è¢«æ˜æ˜¾å‰Šå¼±ï¼Œå‘ˆç°å‡ºä¸¥é‡çš„æ¢¯åº¦å¤±è¡¡ï¼ˆgradient attenuation across layersï¼‰ï¼Œä»è€Œä½¿è®­ç»ƒè¿‡ç¨‹æä¸ç¨³å®šï¼Œå¿…é¡»ä¾èµ–å­¦ä¹ ç‡ warm-up è¿›è¡Œç¼“è§£ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒPre-Norm åœ¨åˆå§‹åŒ–æ—¶å„å±‚æ¢¯åº¦è§„æ¨¡ä¿æŒä¸€è‡´ä¸”ç¨³å®šï¼Œé¿å…äº†æ¢¯åº¦è¡°å‡ä¸çˆ†ç‚¸é—®é¢˜ã€‚\n\n\n\n\nGradient Spike / Noise\n\nå®éªŒè¡¨æ˜ (Nguyen and Salazar 2019)\n\n\n\n\n\n\nFigureÂ 4\n\n\n\n\nPost-norm produces noisy gradients with many sharp spikes, even towards the end of training. On the other hand, Pre-norm has fewer noisy gradients with smaller sizes, even without warmup.  Transformers without Tears: Improving the Normalization of Self-Attention P.6 \n\n\n\n2.1.1.3 Other Positions\né™¤äº† Pre-Norm å’Œ Post-Norm ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–çš„ Normalization ä½ç½®è®¾è®¡ï¼Œä¾‹å¦‚:\n\nSandwich Norm: å°† Normalization æ”¾ç½®åœ¨æ¯ä¸ªå­å±‚çš„è¾“å…¥å’Œè¾“å‡ºä¹‹é—´ã€‚\nDouble Norm: åœ¨æ¯ä¸ªå­å±‚çš„è¾“å…¥å’Œè¾“å‡ºéƒ½è¿›è¡Œå½’ä¸€åŒ–ã€‚\n\nä»è¿™äº›å®éªŒç»“æœæ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼š - å°½é‡ä¿æŒResidual Connectionä¸¤ç«¯çš„ä¿¡å·ç¨³å®šæ˜¯éå¸¸é‡è¦çš„, è¿™å¯ä»¥ä¿è¯æ¢¯åº¦åœ¨ç½‘ç»œä¸­é¡ºåˆ©ä¼ æ’­ã€‚\n\n\n\n2.1.2 Normalization Types\né™¤äº† Normalization çš„ä½ç½®è®¾è®¡ä¹‹å¤–ï¼ŒNormalization çš„å½¢å¼ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„è®¾è®¡é€‰æ‹©ã€‚ å¸¸è§çš„ Normalization å½¢å¼åŒ…æ‹¬:\n\nLayerNorm(Ba, Kiros, and Hinton 2016): å¯¹æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œé€‚ç”¨äºåºåˆ—æ•°æ®ã€‚\nRMSNorm(Zhang and Sennrich 2019): åªä½¿ç”¨å‡æ–¹æ ¹ï¼ˆRoot Mean Squareï¼‰æ¥è¿›è¡Œå½’ä¸€åŒ–ï¼Œçœç•¥äº†å‡å€¼çš„è®¡ç®—ï¼Œå‡å°‘äº†è®¡ç®—å¼€é”€ã€‚ RMSNorm åœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥æä¾›ä¸ LayerNorm ç›¸ä¼¼çš„æ€§èƒ½ï¼Œä½†è®¡ç®—æ›´é«˜æ•ˆã€‚\n\nåŸå§‹çš„Transformerä¸­ä½¿ç”¨çš„æ˜¯LayerNormï¼Œ ä½†æ˜¯ç°ä»£å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼ŒRMSNormè¢«å¹¿æ³›é‡‡ç”¨ï¼Œ ä¾‹å¦‚åœ¨ LLaMAã€GPT-4ã€PaLM ç­‰æ¨¡å‹ä¸­éƒ½ä½¿ç”¨äº† RMSNormã€‚\nRMSNormçš„å­˜åœ¨çš„ä¼˜åŠ¿æ˜¯ï¼Œ\n\nè®¡ç®—æ•ˆç‡æ›´é«˜ï¼š ç”±äº RMSNorm çœç•¥äº†å‡å€¼çš„è®¡ç®—ï¼Œå› æ­¤åœ¨è®¡ç®—ä¸Šæ›´åŠ é«˜æ•ˆï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­ï¼Œè¿™ç§æ•ˆç‡æå‡å°¤ä¸ºæ˜¾è‘—ã€‚\næ€§èƒ½ç›¸ä¼¼ï¼š å®éªŒè¡¨æ˜ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸­ï¼ŒRMSNorm å¯ä»¥æä¾›ä¸ LayerNorm ç›¸ä¼¼çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#activations",
    "href": "posts/CS336/Lecture03/lec03.html#activations",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "2.2 Activations",
    "text": "2.2 Activations\nActivation Functionsç»™æ¨¡å‹å¼•å…¥äº†éçº¿æ€§ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„å‡½æ•°æ˜ å°„å…³ç³»ã€‚ å¸¸è§çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ReLUã€Sigmoidã€Tanhç­‰ã€‚\n\nç°ä»£LLMä¸­ï¼Œæœ€å¸¸è§çš„æ¿€æ´»å‡½æ•°æ˜¯ Gated Activationså®¶æ—ï¼Œä¾‹å¦‚ SwiGLUï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹è¿™äº›æ¶æ„\n\n2.2.1 Gated Activations(*GLU)\nGated Activations é€šè¿‡å¼•å…¥é—¨æ§æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åœ¨å‰é¦ˆç¥ç»ç½‘ç»œä¸­åŠ¨æ€è°ƒæ•´ä¿¡æ¯æµï¼Œä»è€Œæé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ€§èƒ½ã€‚åœ¨ä¼ ç»Ÿçš„FFNä¸­ï¼Œè¾“å…¥é€šè¿‡ä¸¤ä¸ªçº¿æ€§å˜æ¢å’Œä¸€ä¸ªéçº¿æ€§æ¿€æ´»å‡½æ•°è¿›è¡Œå¤„ç†ã€‚è€Œåœ¨ Gated Activations ä¸­ï¼Œè¾“å…¥è¢«åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†é€šè¿‡æ¿€æ´»å‡½æ•°å¤„ç†ï¼Œå¦ä¸€éƒ¨åˆ†é€šè¿‡é—¨æ§æœºåˆ¶è¿›è¡Œè°ƒèŠ‚ï¼Œæœ€ç»ˆä¸¤éƒ¨åˆ†çš„è¾“å‡ºè¿›è¡Œå…ƒç´ çº§ä¹˜æ³•æ“ä½œã€‚ç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:\n\\[\n\\text{FF} = \\textcolor{red}{\\max (0, XW_1 )} \\ctimes (XW_2 )\n\\]\nGated Activations ä¸»è¦æ”¹å˜çš„å°±æ˜¯çº¢è‰²éƒ¨åˆ†ï¼Œç”¨æ•°å­¦è¡¨è¾¾å°±æ˜¯ï¼š \\[\n\\text{Gated FF} = \\textcolor{red}{(\\max (0, XW_1 ) \\odot XV )}W_2\n\\]\nå¸¸è§çš„ Gated Activations åŒ…æ‹¬:\n\nGeGLU:\n\n\\[\n\\text{GeGLU: } \\quad \\text{Gated FF} = (\\text{GELU}(XW_1 ) \\odot XV )W_2\n\\]\n\nSwiGLU: \\[\n\\text{SwiGLU: } \\quad \\text{Gated FF} = (\\text{SiLU}(XW_1 ) \\odot XV )W_2\n\\]\n\nå®éªŒè¡¨æ˜ï¼ŒGated Activations åœ¨è®¸å¤šä»»åŠ¡ä¸­éƒ½ä¼˜äºä¼ ç»Ÿçš„æ¿€æ´»å‡½æ•°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œä¾‹å¦‚ LLaMA å’Œ GPT-4 ç­‰æ¨¡å‹ä¸­éƒ½é‡‡ç”¨äº† SwiGLU ä½œä¸ºå‰é¦ˆç¥ç»ç½‘ç»œçš„æ¿€æ´»å‡½æ•°ã€‚\nä¸è¿‡éœ€è¦ä¸»è¦çš„ä¸€ç‚¹æ˜¯ï¼ŒGated Activationå¼•å…¥äº†ä¸€ä¸ªé¢å¤–çš„çº¿æ€§å˜æ¢çŸ©é˜µVï¼Œè¿™ä¼šå¢åŠ æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—å¼€é”€ã€‚ å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸ºäº†ä¿æŒæ¨¡å‹æ•°é‡çš„ä¸å˜ï¼Œé€šå¸¸æˆ‘ä»¬å°† \\(d_ff\\) è®¾å®šä¸º \\(\\frac{8}{3} d_{model}\\)ï¼Œ è¿™æ ·å°±å¯ä»¥åœ¨å¼•å…¥Gated Activationçš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹çš„å‚æ•°é‡ä¸å˜ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#serial-parallel-mlp",
    "href": "posts/CS336/Lecture03/lec03.html#serial-parallel-mlp",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "2.3 Serial & Parallel MLP",
    "text": "2.3 Serial & Parallel MLP\nä¼ ç»Ÿçš„Transformer Blockæ˜¯ä¸²è¡Œçš„ç»“æ„ FigureÂ 1ï¼Œ å³å…ˆç»è¿‡Attentionæ¨¡å—ï¼Œ ç„¶åå†ç»è¿‡MLPæ¨¡å—ã€‚ è¿™ç§è®¾è®¡è™½ç„¶ç®€å•ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½ä¼šé™åˆ¶æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚æœ‰ç ”ç©¶æå‡ºäº†å¹¶è¡Œçš„MLPè®¾è®¡ï¼Œå°†Attentionå’ŒMLPæ¨¡å—å¹¶è¡Œå¤„ç†ï¼Œç„¶åå°†å®ƒä»¬çš„è¾“å‡ºè¿›è¡Œèåˆã€‚è¿™ç§è®¾è®¡å¯ä»¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚ ç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:\n\\[\ny = x + \\text{MLP}(Norm(x)) + \\text{Attention}(Norm(x))\n\\]\né€šè¿‡å¹¶è¡Œè¿™ä¸¤å±‚ï¼Œå¯ä»¥è®©æ¨¡å‹è®­ç»ƒçš„æ›´å¿«é€Ÿï¼ŒåŒæ—¶å¯ä»¥å‡å°‘æ¨¡å‹çš„å‚æ•°ï¼Œæ¯”å¦‚Normå±‚åªéœ€è¦ä¸€å±‚ã€‚\nä¸è¿‡ï¼Œç›®å‰ä¸»æµçš„å¤§è¯­è¨€æ¨¡å‹ä»ç„¶é‡‡ç”¨ä¸²è¡Œçš„Transformer Blockè®¾è®¡ï¼Œä½†å¹¶è¡Œçš„MLPè®¾è®¡ä¸ºæœªæ¥çš„æ¨¡å‹æ¶æ„æä¾›äº†ä¸€ä¸ªæœ‰è¶£çš„æ–¹å‘ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#position-encoding",
    "href": "posts/CS336/Lecture03/lec03.html#position-encoding",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "2.4 Position Encoding",
    "text": "2.4 Position Encoding\nä½ç½®ç¼–ç  (Positional Encoding) ç”¨äºå¼•å…¥åºåˆ—ä¸­å•è¯çš„ä½ç½®ä¿¡æ¯ï¼Œå› ä¸ºè‡ªæ³¨æ„åŠ›æœºåˆ¶æœ¬èº«ä¸å…·å¤‡é¡ºåºä¿¡æ¯ã€‚ ä¼ ç»Ÿçš„Transformerä½¿ç”¨çš„æ˜¯ç»å¯¹ä½ç½®ç¼–ç ï¼Œä¾‹å¦‚æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ç¼–ç (Vaswani et al. 2023)ã€‚å¸¸è§çš„ä½ç½®ç¼–ç æ–¹æ³•åŒ…æ‹¬:\n\nAbsolute Position Encoding: ä½¿ç”¨å›ºå®šçš„ç¼–ç æ–¹å¼ä¸ºæ¯ä¸ªä½ç½®åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„å‘é‡è¡¨ç¤ºã€‚\nRelative Position Encoding: é€šè¿‡è®¡ç®—å•è¯ä¹‹é—´çš„ç›¸å¯¹ä½ç½®æ¥å¼•å…¥ä½ç½®ä¿¡æ¯ï¼Œå¢å¼ºæ¨¡å‹å¯¹åºåˆ—ä¸­å•è¯ç›¸å¯¹å…³ç³»çš„ç†è§£èƒ½åŠ›ã€‚\nRotary Position Embedding (RoPE)(Su et al. 2023): é€šè¿‡æ—‹è½¬ä½ç½®å‘é‡æ¥å¼•å…¥ä½ç½®ä¿¡æ¯ï¼Œå¢å¼ºæ¨¡å‹å¯¹é•¿è·ç¦»ä¾èµ–å…³ç³»çš„æ•æ‰èƒ½åŠ›ã€‚\n\næ¥ä¸‹æ¥æˆ‘ä»¬é‡ç‚¹ä»‹ç» RoPEã€‚\n\n2.4.1 Rotary Position Embedding (RoPE)\n\n\n\n\n\n\nFigureÂ 5\n\n\n\nRoPE é€šè¿‡å¯¹æŸ¥è¯¢å’Œé”®çš„å‘é‡è¿›è¡Œæ—‹è½¬æ¥å¼•å…¥ä½ç½®ä¿¡æ¯ã€‚ å…·ä½“æ¥è¯´ï¼ŒRoPE å°†ä½ç½®ç¼–ç è¡¨ç¤ºä¸ºä¸€ä¸ªæ—‹è½¬çŸ©é˜µï¼Œç„¶åå°†æŸ¥è¯¢å’Œé”®çš„å‘é‡ä¸è¯¥æ—‹è½¬çŸ©é˜µç›¸ä¹˜ï¼Œä»è€Œå¼•å…¥ä½ç½®ä¿¡æ¯ã€‚ ç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:\n\\[\n\\text{RoPE}(Q, K, P) = (Q R(P), K R(P))\n\\] å…¶ä¸­ï¼Œ\\(R(P)\\) æ˜¯ä½ç½®ç¼–ç å¯¹åº”çš„æ—‹è½¬çŸ©é˜µã€‚\nç”¨æ•°å­¦è¡¨ç¤ºå°±æ˜¯ï¼š \\[\nR_{\\Theta,m}^{d} \\mathbf{x}\n=\n\\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\\\\\nx_4\\\\\n\\vdots\\\\\nx_{d-1}\\\\\nx_d\n\\end{pmatrix}\n\\otimes\n\\begin{pmatrix}\n\\cos(m\\theta_{1})\\\\\n\\cos(m\\theta_{1})\\\\\n\\cos(m\\theta_{2})\\\\\n\\cos(m\\theta_{2})\\\\\n\\vdots\\\\\n\\cos\\!\\big(m\\theta_{d/2}\\big)\\\\\n\\cos\\!\\big(m\\theta_{d/2}\\big)\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n- x_2\\\\\nx_1\\\\\n- x_4\\\\\nx_3\\\\\n\\vdots\\\\\n- x_d\\\\\nx_{d-1}\n\\end{pmatrix}\n\\otimes\n\\begin{pmatrix}\n\\sin(m\\theta_{1})\\\\\n\\sin(m\\theta_{1})\\\\\n\\sin(m\\theta_{2})\\\\\n\\sin(m\\theta_{2})\\\\\n\\vdots\\\\\n\\sin\\!\\big(m\\theta_{d/2}\\big)\\\\\n\\sin\\!\\big(m\\theta_{d/2}\\big)\n\\end{pmatrix}\n\\]\næˆ‘éå¸¸æ¨èä»¥ä¸‹çš„è§†é¢‘ï¼Œå®ƒå¾ˆæ¸…æ¥šçš„ä»‹ç»äº†RoPEä»¥åŠå®ƒçš„æ‰©å±•ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å‰å»æŸ¥çœ‹ï¼š",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#mlp-width",
    "href": "posts/CS336/Lecture03/lec03.html#mlp-width",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "3.1 MLP Width",
    "text": "3.1 MLP Width\nMLPçš„å®½åº¦é€šå¸¸è®¾ç½®ä¸ºæ¨¡å‹ç»´åº¦çš„4å€ï¼Œä¾‹å¦‚å¯¹äºä¸€ä¸ª512ç»´çš„æ¨¡å‹ï¼ŒMLPçš„å®½åº¦é€šå¸¸è®¾ç½®ä¸º2048ã€‚ è¿™ç§è®¾è®¡å¯ä»¥æä¾›è¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›ï¼ŒåŒæ—¶ä¸ä¼šè¿‡åº¦å¢åŠ è®¡ç®—å¼€é”€ã€‚ å½“ç„¶ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰æåˆ°è¿‡ï¼Œ å¦‚æœä½¿ç”¨Gated Activation, é‚£ä¹ˆMLPçš„å®½åº¦é€šå¸¸è®¾ç½®ä¸º \\(\\frac{8}{3}\\) å€çš„æ¨¡å‹ç»´åº¦ã€‚åŸºæœ¬ä¸Šç›®å‰ä¸»æµçš„å¤§è¯­è¨€æ¨¡å‹éƒ½æ˜¯é‡‡ç”¨è¿™ä¸ªæ¯”ä¾‹ã€‚\né™¤äº†Gated Activationä¹‹å¤–ï¼Œ ä¹Ÿæœ‰ä¸€äº›æ¨¡å‹ä½¿ç”¨æ›´å®½çš„MLPï¼Œ ä¾‹å¦‚ T5 ä½¿ç”¨äº† 64 å€çš„MLPå®½åº¦ï¼Œ ä½†æ˜¯è¿™ç§è®¾è®¡ä¼šæ˜¾è‘—å¢åŠ è®¡ç®—å¼€é”€ï¼Œ å› æ­¤éœ€è¦æƒè¡¡æ¨¡å‹æ€§èƒ½ä¸è®¡ç®—èµ„æºã€‚\nè‡³äºä¸ºä»€ä¹ˆé€‰æ‹©4å€æˆ–è€… \\(\\frac{8}{3}\\) å€çš„MLPå®½åº¦ï¼Œ ä¸»è¦æ˜¯åŸºäºç»éªŒå’Œå®éªŒç»“æœã€‚ ç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æ¯”ä¾‹å¯ä»¥åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæä¾›è¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#attention-heads",
    "href": "posts/CS336/Lecture03/lec03.html#attention-heads",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "3.2 Attention Heads",
    "text": "3.2 Attention Heads\næ¨¡å‹çš„Head Dim é€šå¸¸è®¾ç½®ä¸º d_model / num_headsï¼Œ ä¹Ÿå°±æ˜¯è¯´ï¼ŒHead Dim ä¸æ¨¡å‹ç»´åº¦æˆåæ¯”ã€‚ å¸¸è§çš„Head Dimè®¾ç½®åŒ…æ‹¬64ã€128ç­‰ã€‚ä¸è¿‡ï¼ŒHead Dim ä¸ä¸€å®šå°±æ˜¯d_model / num_headsã€‚ ä¸è¿‡å¹¶æ²¡æœ‰å®éªŒè¡¨æ˜ï¼ŒHead Dim è¿‡å¤§æˆ–è€…è¿‡å°ä¼šæ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ã€‚ å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸æ ¹æ®è®¡ç®—èµ„æºå’Œæ¨¡å‹è§„æ¨¡æ¥é€‰æ‹©Head Dimã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#aspect-ratio",
    "href": "posts/CS336/Lecture03/lec03.html#aspect-ratio",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "3.3 Aspect Ratio",
    "text": "3.3 Aspect Ratio\nAspect Ratio æŒ‡çš„æ˜¯æ¨¡å‹çš„æ·±åº¦ï¼ˆn_layerï¼‰ä¸å®½åº¦ï¼ˆd_modelï¼‰ä¹‹æ¯”ã€‚ ç ”ç©¶è¡¨æ˜ï¼Œè¾ƒé«˜çš„Aspect Ratioï¼ˆå³æ›´æ·±çš„æ¨¡å‹ï¼‰é€šå¸¸å¯ä»¥æä¾›æ›´å¥½çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ã€‚ ç„¶è€Œï¼Œè¿‡æ·±çš„æ¨¡å‹ä¹Ÿå¯èƒ½å¯¼è‡´è®­ç»ƒå›°éš¾å’Œè¿‡æ‹Ÿåˆé—®é¢˜ã€‚\n\nä¸è¿‡è¿‡æ·±çš„æ¨¡å‹ä¹Ÿä¼šå¸¦æ¥ä¸€äº›æŒ‘æˆ˜ï¼Œä¾‹å¦‚Parallelismå’Œè®­ç»ƒç¨³å®šæ€§é—®é¢˜ã€‚ å› æ­¤ï¼Œåœ¨é€‰æ‹©Aspect Ratioæ—¶ï¼Œéœ€è¦æƒè¡¡æ¨¡å‹æ€§èƒ½ä¸è®­ç»ƒç¨³å®šæ€§ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#vocabulary-size",
    "href": "posts/CS336/Lecture03/lec03.html#vocabulary-size",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "3.4 Vocabulary Size",
    "text": "3.4 Vocabulary Size\nè¯è¡¨å¤§å°ï¼ˆVocabulary Sizeï¼‰æ˜¯æŒ‡æ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å”¯ä¸€å•è¯æˆ–å­è¯çš„æ•°é‡ã€‚ è¯è¡¨å¤§å°çš„é€‰æ‹©å¯¹äºæ¨¡å‹çš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡æœ‰ç€é‡è¦å½±å“ã€‚å¯¹äºå•ä¸€ä¸ªè¯­è¨€çš„æ¨¡å‹ï¼Œå¸¸è§çš„è¯è¡¨å¤§å°èŒƒå›´åœ¨30,000åˆ°100,000ä¹‹é—´ã€‚ å¯¹äºå¤šè¯­è¨€æ¨¡å‹ï¼Œè¯è¡¨å¤§å°é€šå¸¸æ›´å¤§ï¼Œä»¥è¦†ç›–æ›´å¤šçš„è¯­è¨€å’Œè¯æ±‡ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#regularization",
    "href": "posts/CS336/Lecture03/lec03.html#regularization",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "3.5 Regularization",
    "text": "3.5 Regularization\næ­£åˆ™åŒ–æŠ€æœ¯ç”¨äºé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä½†æ˜¯è®¸å¤šäººæå‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼Œ å¤§æ¨¡å‹æ˜¯å¦è¿˜éœ€è¦æ­£åˆ™åŒ–ï¼Ÿ å½“æ¨¡å‹è¶³å¤Ÿå¤§æ—¶ï¼Œ å®ƒä»¬ä¼¼ä¹å¹¶ä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œ å› æ­¤æ­£åˆ™åŒ–çš„å¿…è¦æ€§å—åˆ°è´¨ç–‘ã€‚",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#grouped-query-attention-gqa-multi-query-attention-mqa",
    "href": "posts/CS336/Lecture03/lec03.html#grouped-query-attention-gqa-multi-query-attention-mqa",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "5.1 Grouped Query Attention (GQA) / Multi-Query Attention (MQA)",
    "text": "5.1 Grouped Query Attention (GQA) / Multi-Query Attention (MQA)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#sparse-sliding-window-attention",
    "href": "posts/CS336/Lecture03/lec03.html#sparse-sliding-window-attention",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "5.2 Sparse / Sliding Window Attention",
    "text": "5.2 Sparse / Sliding Window Attention\n\nChild et al. (2019)",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#sliding-window-attention",
    "href": "posts/CS336/Lecture03/lec03.html#sliding-window-attention",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "5.3 Sliding Window Attention",
    "text": "5.3 Sliding Window Attention",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture03/lec03.html#interleaved-attention",
    "href": "posts/CS336/Lecture03/lec03.html#interleaved-attention",
    "title": "Lecture 03: LM Model Architecture & Hyperparameters",
    "section": "5.4 Interleaved Attention",
    "text": "5.4 Interleaved Attention",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 03: Transformer LM Architecture"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture10/lec10.html",
    "href": "posts/CS336/Lecture10/lec10.html",
    "title": "Lecture 10: Inference & Deployment",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 10: Inference & Deployment"
    ]
  },
  {
    "objectID": "posts/CS336/index.html",
    "href": "posts/CS336/index.html",
    "title": "CS336: LLM from Scratch Lecture Notes and Assignments",
    "section": "",
    "text": "Related Resources:\n\nLecture Website: CS336 LLM from Scratch\nLecture Recordings: YouTube Playlist\nMy Solution Repo: GitHub\n\n\n\nAbout this Course:\n\nThis course has 17 Lectures and 5 Assignments in total.\nIt might take around 200 hours to finish all the lectures and assignments.\n\n\n\n\nFor those who have limited time, I recommend focusing on the following key lectures and assignments:\n\nLECTURE 1, 2, 3, 4 & Assignment01: After completing these, you will have a solid understanding of the fundamentals of LLMs, such as the Transformer Language Model architecture, attention mechanism, Mixture of Experts, and the training process of LLMs using autoregressive language modeling.\nLECTURE 15, 16, 17 & Assignment05: These cover advanced topics such as LLM aligment algorithms, such as SFT, RLHF(PPO, DPO), and RLVR(GRPO, Dr.GRPO). After completing these, you will understand how to align LLMs with human preferences and train a reasoning LLM.\nLECTURE 5, 6, 7, 8 & Assignment02: These focus on the hardware and parallelism techniques for training large models. After completing these, you will understand how to efficiently train large LLMs using distributed systems, such as data parallelism, model parallelism, and pipeline parallelism, and speed up the training process by leveraging the power of GPU, and undertand FlashAttention and its implementation.\nThe remaining lectures and assignments are also important, but they can be studied at a later time based on your interests and needs. Those includes:\n\nLecture 9 & 11: Scaling Laws\nLecture 10: Inference Optimization\nLecture 12 & Assignment 03: Evaluation of LLMs\nLecture 13, 14 & Assignment 04: Data Collection and Processing\n\n\n\n\n\nLectures Notes\n\n\n\n\n\n\n\n\n\n\n\nLecture 01: Introduction & Tokenization\n\n\nLecture01ä»‹ç»äº†è¯¾ç¨‹çš„å¤§çº²ä»¥åŠLLMçš„ç°çŠ¶å’ŒåŸºæœ¬æ¦‚å¿µã€‚åœ¨è¯¾ç¨‹çš„ååŠæ®µä»‹ç»äº†Language Modelingçš„ç¬¬ä¸€æ­¥ï¼Œå³Tokenizationçš„åŸºæœ¬æ¦‚å¿µå’Œå¸¸ç”¨æ–¹æ³•ã€‚ç€é‡ä»‹ç»äº†Byte Pair Encoding (BPE)ç®—æ³•çš„åŸç†å’Œå®ç°ã€‚åœ¨å­¦ä¹ å®ŒLecture 01åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å°è¯•Assignment 01çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå³BPE-Tokenizationçš„å®ç°\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 02: PyTorch Basics & Resource Accounts\n\n\nLecture02 ä»‹ç»äº†PyTorchçš„åŸºæœ¬æ¦‚å¿µå’Œä½¿ç”¨æ–¹æ³•ã€‚å¯ä»¥å°†è¿™èŠ‚è¯¾å½“ä½œä¸€ä¸ªreviewï¼Œå¤ä¹ ä¸€ä¸‹ä¹‹å‰å­¦è¿‡çš„PyTorchçŸ¥è¯†ç‚¹ã€‚åŒæ—¶ï¼Œè¯¾ç¨‹ä¸­ä»‹ç»äº†ä¸€ä¸ª einops çš„åº“ï¼Œå¯ä»¥ç®€åŒ–å¼ é‡æ“ä½œçš„ä»£ç ç¼–å†™ã€‚è¿™èŠ‚è¯¾ä¹Ÿä»‹ç»äº†ä¸åŒæ•°æ®ç±»å‹ï¼ˆå¦‚FP32, FP16, BF16ç­‰ï¼‰åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨å’Œä¼˜ç¼ºç‚¹ã€‚å¹¶ä¸”é€šè¿‡è®¡ç®—è¿™äº›æ•°æ®ç±»å‹åœ¨å†…å­˜ä¸­çš„å ç”¨ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£ä¸ºä»€ä¹ˆæœ‰äº›æ•°æ®ç±»å‹æ›´é€‚åˆåœ¨æœ‰é™èµ„æºä¸‹è¿›è¡Œè®­ç»ƒ, å¹¶ä¸”åœ¨ä»€ä¹ˆæƒ…å†µä¸‹éœ€è¦åº”ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆMixed Precision Trainingï¼‰ï¼Œä»€ä¹ˆæƒ…å†µä¸‹éœ€è¦ç”¨é«˜ç²¾åº¦çš„æ•°æ®ç±»å‹ã€‚åœ¨è¯¾ç¨‹çš„æœ€åï¼Œè¿˜ä»‹ç»äº†ä¸åŒçš„Optimizerï¼ˆå¦‚SGD, Adamç­‰ï¼‰çš„åŸºæœ¬åŸç†å’Œä½¿ç”¨åœºæ™¯\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 03: LM Model Architecture & Hyperparameters\n\n\nLecture03 ä»‹ç»äº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒæ¶æ„ä¸è¶…å‚æ•°è®¾è®¡ã€‚è¯¾ç¨‹å¯¹æ¯”äº†åŸå§‹ Transformer ä¸ä¸»æµ LLaMA-like æ¶æ„ï¼Œæ€»ç»“äº† pre-normã€RMSNormã€SwiGLUã€RoPE ç­‰å…³é”®è®¾è®¡çš„ç»éªŒå…±è¯†ï¼Œå¹¶ç»“åˆå¤§é‡è¿‘æœŸæ¨¡å‹å®è·µï¼Œè®²è§£äº† MLP å®½åº¦æ¯”ä¾‹ã€æ³¨æ„åŠ›å¤´é…ç½®ã€æ¨¡å‹æ·±å®½æ¯”ä¸è¯è¡¨è§„æ¨¡ç­‰è¶…å‚æ•°é€‰æ‹©åŸåˆ™ã€‚åŒæ—¶è¿˜ä»‹ç»äº† z-lossã€QK-Normã€MQA/GQA ç­‰ç”¨äºæå‡è®­ç»ƒç¨³å®šæ€§å’Œæ¨ç†æ•ˆç‡çš„å…³é”®æŠ€å·§ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 04: Introduction to MoE\n\n\nLecture 04 ä»‹ç»äº† MoEï¼ˆMixture of Expertsï¼‰çš„åŸºæœ¬æ¦‚å¿µå’ŒåŸç†ã€‚ä»æ¨¡å‹æ¶æ„ã€è·¯ç”±æœºåˆ¶ã€è®­ç»ƒæ–¹æ³•ç­‰æ–¹é¢è¿›è¡Œäº†è¯¦ç»†è®²è§£ï¼Œå¹¶è®¨è®ºäº† MoE åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨å’Œä¼˜åŠ¿ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 05 & 06: GPUs, Kernels & Flash Attention\n\n\nLecture05ä»‹ç»äº†GPUçš„åŸºæœ¬æ¶æ„ä¸å·¥ä½œåŸç†ï¼Œå¹¶ä¸”ä»‹ç»äº†å‡ ç§æå‡è®¡ç®—æ•ˆç‡çš„æ–¹æ³•ï¼Œæ¯”å¦‚Kernel Fusion, Memory Coalescing Tiling ç­‰ï¼Œå¹¶ä¸”åœ¨è¯¾ç¨‹æœ€åä»‹ç»äº†Flash Attentionçš„åŸç†åŠå…¶å®ç°ç»†èŠ‚ã€‚åœ¨Lecture06ä¸­ï¼Œä¸»è¦ä»‹ç»äº†Tritonï¼Œä¸€ä¸ªç”¨äºç¼–å†™é«˜æ€§èƒ½GPUä»£ç çš„å¼€æºç¼–è¯‘å™¨ã€‚å†…å®¹æ¶µç›–äº†Tritonçš„åŸºæœ¬æ¦‚å¿µã€ç¼–ç¨‹æ¨¡å‹ä»¥åŠå¦‚ä½•ä½¿ç”¨Tritonç¼–å†™é«˜æ•ˆçš„GPUå†…æ ¸ã€‚é€šè¿‡å®é™…ç¤ºä¾‹ï¼Œå±•ç¤ºäº†Tritonåœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨å’Œä¼˜åŠ¿ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 07 & 08: Parallelism Training\n\n\nLecture 07ä¸08ä»‹ç»äº†æ·±åº¦å­¦ä¹ ä¸­çš„å¹¶è¡Œè®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬Data Parallelismï¼Œ Model Parallelismï¼ŒZeROï¼ŒPipleline Parallelismç­‰æŠ€æœ¯ã€‚é‡ç‚¹è®²è§£äº†å„ç±»å¹¶è¡Œæ–¹æ³•çš„åŸç†ã€å®ç°åŠå…¶åœ¨å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­çš„åº”ç”¨ã€‚ä¸ªäººè®¤ä¸ºè¿™ä¸¤èŠ‚å†…å®¹éå¸¸é‡è¦ï¼Œç†è§£è¿™äº›å¹¶è¡Œè®­ç»ƒæŠ€æœ¯å¯¹äºå¤„ç†å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ æ¨¡å‹è‡³å…³é‡è¦ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 09 & 11: Scaling Laws\n\n\nä¸ºä»€ä¹ˆLARGE language modelsåœ¨è§„æ¨¡ä¸Šè¡¨ç°æ›´å¥½ï¼ŸLecture 09å’Œ11ä»‹ç»äº†Scaling Lawsçš„åŸºæœ¬æ¦‚å¿µå’ŒåŸç†ï¼Œæ¢è®¨äº†æ¨¡å‹è§„æ¨¡ã€æ•°æ®è§„æ¨¡ä¸è®¡ç®—èµ„æºä¹‹é—´çš„å…³ç³»ã€‚å†…å®¹æ¶µç›–äº†ä¸åŒç±»å‹çš„Scaling Lawsï¼ˆå¦‚å‚æ•°è§„æ¨¡ã€æ•°æ®è§„æ¨¡å’Œè®¡ç®—è§„æ¨¡ï¼‰ä»¥åŠå®ƒä»¬å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡å®é™…æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†Scaling Lawsåœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨å’Œé‡è¦æ€§ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 10: Inference & Deployment\n\n\nè®­ç»ƒå®ŒLLMä¹‹åï¼Œå¦‚ä½•è¿›è¡Œé«˜æ•ˆçš„æ¨ç†å’Œéƒ¨ç½²æ˜¯éå¸¸é‡è¦çš„ã€‚Lecture 10ä»‹ç»äº†æ¨¡å‹å‹ç¼©ã€é‡åŒ–ã€è’¸é¦ç­‰æŠ€æœ¯ï¼Œä»¥æå‡æ¨ç†æ•ˆç‡å’Œé™ä½èµ„æºæ¶ˆè€—ã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†æ¨¡å‹éƒ¨ç½²çš„å¸¸è§æ–¹æ³•å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬äº‘ç«¯éƒ¨ç½²ã€æœ¬åœ°éƒ¨ç½²ä»¥åŠè¾¹ç¼˜è®¡ç®—ç­‰ã€‚é€šè¿‡è¿™äº›æŠ€æœ¯ï¼Œå¯ä»¥æ›´å¥½åœ°å°†è®­ç»ƒå¥½çš„æ¨¡å‹åº”ç”¨äºå®é™…åœºæ™¯ä¸­ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 12: Evaluation Metrics\n\n\nLecture 12ä»‹ç»äº†è¯„ä¼°è¯­è¨€æ¨¡å‹æ€§èƒ½çš„å„ç§æŒ‡æ ‡å’Œæ–¹æ³•ã€‚å†…å®¹æ¶µç›–äº†ä¼ ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ã€å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ç­‰ï¼Œä»¥åŠæ›´é€‚ç”¨äºç”Ÿæˆä»»åŠ¡çš„æŒ‡æ ‡ï¼Œå¦‚BLEUã€ROUGEå’ŒMETEORç­‰ã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†äººç±»è¯„ä¼°çš„é‡è¦æ€§åŠå…¶åœ¨æ¨¡å‹è¯„ä¼°ä¸­çš„ä½œç”¨ã€‚é€šè¿‡è¿™äº›è¯„ä¼°æ–¹æ³•ï¼Œå¯ä»¥æ›´å…¨é¢åœ°äº†è§£è¯­è¨€æ¨¡å‹çš„è¡¨ç°å’Œæ”¹è¿›æ–¹å‘ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 13 & 14: Data\n\n\nè¦æƒ³è®­ç»ƒå¥½ä¸€ä¸ªLLMï¼Œé™¤äº†æœ‰å¼ºå¤§çš„æ¨¡å‹æ¶æ„å’Œå……è¶³çš„è®¡ç®—èµ„æºï¼Œæ•°æ®åŒæ ·è‡³å…³é‡è¦ã€‚Lecture 13å’Œ14æ·±å…¥æ¢è®¨äº†ç”¨äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®æ”¶é›†ã€æ¸…æ´—å’Œå¤„ç†æ–¹æ³•ã€‚å†…å®¹æ¶µç›–äº†ä¸åŒç±»å‹çš„æ•°æ®æºï¼ˆå¦‚ç½‘ç»œæ–‡æœ¬ã€ä¹¦ç±ã€å¯¹è¯æ•°æ®ç­‰ï¼‰ï¼Œä»¥åŠå¦‚ä½•è¿›è¡Œæ•°æ®é¢„å¤„ç†ä»¥æå‡æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†æ•°æ®å¢å¼ºæŠ€æœ¯å’Œæ•°æ®è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œå¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£å¦‚ä½•åˆ©ç”¨é«˜è´¨é‡çš„æ•°æ®æ¥è®­ç»ƒå‡ºæ›´ä¼˜ç§€çš„è¯­è¨€æ¨¡å‹ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 15: LLM Alignment SFT & RLHF(PPO, DPO)\n\n\nLecture15ä¸»è¦æ¢³ç† LLM çš„åè®­ç»ƒï¼ˆPost-Trainingï¼‰ä¸»çº¿ï¼šä»ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„æ•°æ®ä¸ç›®æ ‡å‡½æ•°å‡ºå‘ï¼Œè§£é‡Šä¸ºä½•SFTå¯ä»¥è®©æ¨¡å‹è·å¾—ä¸€å®šçš„Instruct Followingçš„èƒ½åŠ›ï¼Œå¹¶ç³»ç»Ÿä»‹ç» RLHF çš„å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸ PPO æ›´æ–°æµç¨‹ï¼Œè¿›ä¸€æ­¥å¯¹æ¯” DPO/SimPO ç­‰å°† RL ç®€åŒ–ä¸ºç›‘ç£å­¦ä¹ çš„æ›¿ä»£æ–¹æ¡ˆã€‚æœ€åæ€»ç»“ RLHF çš„å…³é”®é£é™©ï¼ˆreward hackingã€model collapseï¼‰ï¼Œå¹¶è¯´æ˜ä¸ºä½•éœ€è¦èµ°å‘å¯éªŒè¯å¥–åŠ±çš„ RLVR æ¥æå‡æ¨ç†èƒ½åŠ›ä¸è®­ç»ƒç¨³å®šæ€§ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 16 & 17: LLM Alignment SFT & RLVRï¼ˆGRPOï¼‰\n\n\nè¿™èŠ‚ä»‹ç»äº†PPOï¼Œ ä»¥åŠDPOæ‰€å­˜åœ¨çš„é—®é¢˜ï¼Œå¹¶ä¸”å¼•å‡ºäº†Reinforcement Learning from Verified Rewards (RLVR)çš„æ–°æ–¹æ³•GRPOã€‚å†…å®¹åŒ…æ‹¬Advantage Functionã€Length Normalizationå…³é”®æŠ€æœ¯ç»†èŠ‚ï¼Œå¹¶é€šè¿‡DeepSeek-R1ã€Kimi 1.5å’ŒQwen3ç­‰æ¡ˆä¾‹å±•ç¤ºäº†GRPOåœ¨å®é™…ä¸­çš„åº”ç”¨ã€‚è€ŒLecture17åˆ™é€šè¿‡ä¸€ä¸ªæ’åºä»»åŠ¡çš„å…·ä½“ä¾‹å­ï¼Œè¯¦ç»†è®²è§£äº†GRPOç®—æ³•çš„å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬æ•°æ®ç”Ÿæˆã€å¥–åŠ±å‡½æ•°è®¾è®¡ã€æ¨¡å‹æ¶æ„ä»¥åŠè®­ç»ƒè¿‡ç¨‹ï¼Œåœ¨è¿™é‡Œå°±æŠŠä¸¤èŠ‚è¯¾åˆæˆä¸€èŠ‚è¯¾æ¥å†™ã€‚\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\nAssignments Solutions\n\n\n\n\n\n\n\n\n\n\n\nAssignment 01: Tokenization & Language Modeling\n\n\nAssignment 01 è¦æ±‚æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ¶µç›–æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å®šä¹‰ã€è®­ç»ƒå’Œè¯„ä¼°ç­‰æ­¥éª¤ã€‚é€šè¿‡è¿™ä¸ªä½œä¸šï¼Œæˆ‘ä»¬å°†å·©å›ºå¯¹è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€æ¦‚å¿µçš„ç†è§£ï¼Œå¹¶æŒæ¡ä½¿ç”¨PyTorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å‘çš„åŸºæœ¬æŠ€èƒ½\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 02: Flash Attention & Data Parallelism\n\n\nåœ¨Assignment 02ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°Flash Attentionå’ŒData Parallelismï¼Œæ·±å…¥ç†è§£å¦‚ä½•æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚é€šè¿‡è¿™äº›æŠ€æœ¯çš„åº”ç”¨ã€‚é¦–å…ˆæˆ‘ä»¬ä¼šç”¨Flash Attentionæ¥ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—æ•ˆç‡ï¼Œå‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—æ—¶é—´ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†å®ç°Data Parallelismï¼Œå°†æ¨¡å‹è®­ç»ƒä»»åŠ¡åˆ†å¸ƒåˆ°å¤šä¸ªGPUä¸Šï¼Œä»¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹å¹¶å¤„ç†æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚å®Œæˆè¿™ä¸¤ä¸ªéƒ¨åˆ†åï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿæ˜¾è‘—æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ï¼Œä¸ºåç»­çš„æ¨¡å‹å¼€å‘å’Œåº”ç”¨æ‰“ä¸‹åšå®åŸºç¡€ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 04: Data Collection & Processing\n\n\nåœ¨Assignment 04ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ç”¨äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®æ”¶é›†å’Œå¤„ç†æ–¹æ³•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä¼šæ¢ç´¢ä¸åŒç±»å‹çš„æ•°æ®æºï¼Œå¦‚ç½‘ç»œæ–‡æœ¬ã€ä¹¦ç±å’Œå¯¹è¯æ•°æ®ç­‰ï¼Œäº†è§£å®ƒä»¬çš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•è¿›è¡Œæ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†ï¼Œä»¥æå‡æ•°æ®è´¨é‡å’Œæ¨¡å‹æ€§èƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜å°†ä»‹ç»æ•°æ®å¢å¼ºæŠ€æœ¯å’Œæ•°æ®è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œå¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°åˆ©ç”¨é«˜è´¨é‡çš„æ•°æ®æ¥è®­ç»ƒå‡ºæ›´ä¼˜ç§€çš„è¯­è¨€æ¨¡å‹ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 05: LLM Alignment: SFT, Expert Iteration, GRPO & DPO\n\n\nåœ¨Assignment 05 æˆ‘ä»¬å°†ä¼šå®ç°SFTï¼Œ Expert Iterationä»¥åŠGRPOç®—æ³•ï¼Œå¯¹Qwen2.5-Math-1.5Bæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æå‡å…¶åœ¨MATHæ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡è¿™äº›ç®—æ³•çš„å®ç°ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç†è§£LLMçš„å¯¹é½æ–¹æ³•ï¼Œå¹¶æŒæ¡å¦‚ä½•åº”ç”¨è¿™äº›æŠ€æœ¯æ¥æ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "About this course"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture9&11/lec9.html",
    "href": "posts/CS336/Lecture9&11/lec9.html",
    "title": "Lecture 09 & 11: Scaling Laws",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 09&11: Scaling Laws"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture12/lec12.html",
    "href": "posts/CS336/Lecture12/lec12.html",
    "title": "Lecture 12: Evaluation Metrics",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 12: Evaluation"
    ]
  },
  {
    "objectID": "posts/CS336/Ass02/ass02.html",
    "href": "posts/CS336/Ass02/ass02.html",
    "title": "Assignment 02: Flash Attention & Data Parallelism",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Assignment 02: Flash Attention & Parallelism"
    ]
  },
  {
    "objectID": "posts/CS336/Lecture07&08/lec07.html",
    "href": "posts/CS336/Lecture07&08/lec07.html",
    "title": "Lecture 07 & 08: Parallelism Training",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "ğŸ“ Stanford CS336: LLM from Scratch",
      "Lecture 07&08: Parallelism"
    ]
  }
]